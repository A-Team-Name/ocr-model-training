{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from typing import Any\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import EpochLogs, grid_search, LogPoint\n",
    "from dataset.character_dataset import CharImageDataset\n",
    "from models.allcnn2d import AllCNN2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SPLIT: float = 0.8\n",
    "MODEL_NAME: str = \"z_BadapplePie\"\n",
    "LOAD_CHECKPOINT: str = r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\models\\allcnn\\z_ApplePie_epoch43_trainacc0.85371_valacc0.78599_Tloss0.027453_Vloss0.050662_lr0.0007224.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths\n",
    "Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir: str = os.path.abspath(\".\")\n",
    "root_dir: str = os.path.join(\n",
    "    notebook_dir,\n",
    "    os.pardir,\n",
    "    os.pardir\n",
    ")\n",
    "\n",
    "data_dir: str = r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\data\\alphanum\\val_p_train\\fix\"\n",
    "\n",
    "model_save_dirpath: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"models\",\n",
    "    \"allcnn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_path_glob: str = os.path.join(\n",
    "    data_dir,\n",
    "    \"u*.*\"\n",
    ")\n",
    "images_path_regex: str = r\"(u[0-9a-f]+)-([0-9a-zA-Z]+)\\.[(jpgpng)+]\"\n",
    "\n",
    "image_paths: list[str] = glob.glob(images_path_glob)\n",
    "random.shuffle(image_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging_path: str = f\"{MODEL_NAME}_log_{get_current_time()}.csv\"\n",
    "\n",
    "with open(logging_path, \"w\") as f:\n",
    "    f.write(\"TIME,EPOCH,TRAIN_ACC,VAL_ACC,TRAIN_LOSS,VAL_LOSS,LR\\n\")\n",
    "\n",
    "\n",
    "def log(\n",
    "    epoch: int,\n",
    "    train_acc: float,\n",
    "    train_loss: float,\n",
    "    val_acc: float,\n",
    "    val_loss,\n",
    "    lr: float\n",
    ") -> None:\n",
    "    with open(logging_path, \"a\") as f:\n",
    "        f.write(f\"{get_current_time()},{epoch},{train_acc},{val_acc},{train_loss},{val_loss},{lr}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Labels From File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61954, 61954)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "labeled_image_paths: list[tuple[str, str]] = []\n",
    "\n",
    "class_counts: dict[str, int] = defaultdict(lambda: 0)\n",
    "\n",
    "file_path: str\n",
    "for file_path in image_paths:\n",
    "    match = re.search(images_path_regex, file_path)\n",
    "\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    u_hexvalue: str = match.group(1)\n",
    "\n",
    "    class_counts[u_hexvalue] += 1\n",
    "\n",
    "    labeled_image_paths.append((u_hexvalue, file_path))\n",
    "\n",
    "labels: list[str]\n",
    "image_paths: list[str]\n",
    "labels, image_paths = list(zip(*labeled_image_paths))\n",
    "\n",
    "len(labels), len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'u31': 2194,\n",
       "         'u36': 1827,\n",
       "         'u30': 1734,\n",
       "         'u39': 1693,\n",
       "         'u34': 1639,\n",
       "         'u38': 1599,\n",
       "         'u69': 1597,\n",
       "         'u33': 1540,\n",
       "         'u37': 1491,\n",
       "         'u35': 1489,\n",
       "         'u32': 1450,\n",
       "         'u65': 1429,\n",
       "         'u41': 1409,\n",
       "         'u74': 1298,\n",
       "         'u4f': 1223,\n",
       "         'u45': 1179,\n",
       "         'u6c': 1117,\n",
       "         'u4e': 1092,\n",
       "         'u61': 1090,\n",
       "         'u53': 1062,\n",
       "         'u52': 1061,\n",
       "         'u4c': 1055,\n",
       "         'u49': 1052,\n",
       "         'u43': 1029,\n",
       "         'u6e': 992,\n",
       "         'u50': 988,\n",
       "         'u48': 951,\n",
       "         'u6f': 934,\n",
       "         'u4a': 906,\n",
       "         'u47': 889,\n",
       "         'u4d': 882,\n",
       "         'u72': 868,\n",
       "         'u64': 858,\n",
       "         'u51': 841,\n",
       "         'u73': 824,\n",
       "         'u42': 820,\n",
       "         'u44': 815,\n",
       "         'u59': 803,\n",
       "         'u4b': 799,\n",
       "         'u55': 791,\n",
       "         'u57': 751,\n",
       "         'u54': 714,\n",
       "         'u58': 694,\n",
       "         'u46': 639,\n",
       "         'u5a': 631,\n",
       "         'u75': 610,\n",
       "         'u68': 590,\n",
       "         'u56': 552,\n",
       "         'u70': 518,\n",
       "         'u66': 459,\n",
       "         'u67': 454,\n",
       "         'u63': 420,\n",
       "         'u6d': 418,\n",
       "         'u2e': 389,\n",
       "         'u62': 383,\n",
       "         'u79': 375,\n",
       "         'u77': 362,\n",
       "         'u2d': 360,\n",
       "         'u6a': 341,\n",
       "         'u6b': 324,\n",
       "         'u28': 274,\n",
       "         'u29': 273,\n",
       "         'u2c': 259,\n",
       "         'u76': 242,\n",
       "         'u3a': 235,\n",
       "         'u71': 224,\n",
       "         'u27': 224,\n",
       "         'u22': 224,\n",
       "         'u7a': 220,\n",
       "         'u2f': 211,\n",
       "         'u78': 205,\n",
       "         'u3b': 181,\n",
       "         'u21': 169,\n",
       "         'u24': 141,\n",
       "         'u3c': 129,\n",
       "         'u3d': 126,\n",
       "         'u3f': 121,\n",
       "         'u2b': 119,\n",
       "         'u23': 114,\n",
       "         'u5d': 83,\n",
       "         'u26': 81,\n",
       "         'u5e': 81,\n",
       "         'u25': 78,\n",
       "         'u7c': 76,\n",
       "         'u2a': 74,\n",
       "         'u5f': 67,\n",
       "         'u3e': 64,\n",
       "         'u7d': 61,\n",
       "         'u7b': 59,\n",
       "         'u5b': 58,\n",
       "         'u5c': 51,\n",
       "         'u40': 51,\n",
       "         'u60': 44,\n",
       "         'u7e': 41})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Classes Using Oversample/Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts: list[tuple[str, int]] = sorted(\n",
    "    class_counts.items(),\n",
    "    key=lambda x: x[0]\n",
    ")\n",
    "\n",
    "counts: list[int] = [pair[1] for pair in sorted_counts]\n",
    "\n",
    "max_count: int = max(counts)\n",
    "min_count: int = min(counts)\n",
    "\n",
    "to_add_counts: dict[str, int] = {\n",
    "    uid: max_count - count\n",
    "    for uid, count in\n",
    "    sorted_counts\n",
    "}\n",
    "\n",
    "to_undersample_counts: dict[str, int] = {\n",
    "    uid: min_count\n",
    "    for uid, count in\n",
    "    sorted_counts\n",
    "}\n",
    "\n",
    "total_items = sum(x[1] for x in sorted_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 2194, 61954)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count, max_count, total_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(*to_add_counts.items())\n",
    "# print(sorted([(chr(int(pair[0][1:], 16)), pair[1]) for pair in to_remove_counts.items()], key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_add_labels: list[str] = []\n",
    "# to_add_file_paths: list[str] = []\n",
    "#\n",
    "# while True in [to_add_count>0 for to_add_count in to_add_counts.values()]:\n",
    "#    for label, image_path in zip(labels, image_paths):\n",
    "#        remaining: int = to_add_counts[label]\n",
    "#\n",
    "#        if remaining > 0:\n",
    "#            to_add_labels.append(label)\n",
    "#            to_add_file_paths.append(image_path)\n",
    "#            to_add_counts[label] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep_labels: list[str] = []\n",
    "to_keep_file_paths: list[str] = []\n",
    "\n",
    "while True in [to_add_count > 0 for to_add_count in to_undersample_counts.values()]:\n",
    "    for label, image_path in zip(labels, image_paths):\n",
    "        remaining: int = to_undersample_counts[label]\n",
    "\n",
    "        if remaining > 0:\n",
    "            to_keep_labels.append(label)\n",
    "            to_keep_file_paths.append(image_path)\n",
    "            to_undersample_counts[label] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u4e',\n",
       " 'u61',\n",
       " 'u4f',\n",
       " 'u2a',\n",
       " 'u68',\n",
       " 'u2d',\n",
       " 'u48',\n",
       " 'u6f',\n",
       " 'u32',\n",
       " 'u4a',\n",
       " 'u35',\n",
       " 'u38',\n",
       " 'u72',\n",
       " 'u37',\n",
       " 'u70',\n",
       " 'u73',\n",
       " 'u73',\n",
       " 'u4c',\n",
       " 'u33',\n",
       " 'u61',\n",
       " 'u49',\n",
       " 'u59',\n",
       " 'u54',\n",
       " 'u48',\n",
       " 'u58',\n",
       " 'u44',\n",
       " 'u52',\n",
       " 'u6c',\n",
       " 'u37',\n",
       " 'u72',\n",
       " 'u5a',\n",
       " 'u61',\n",
       " 'u52',\n",
       " 'u65',\n",
       " 'u52',\n",
       " 'u4b',\n",
       " 'u52',\n",
       " 'u31',\n",
       " 'u3d',\n",
       " 'u62',\n",
       " 'u5a',\n",
       " 'u5d',\n",
       " 'u52',\n",
       " 'u33',\n",
       " 'u6c',\n",
       " 'u70',\n",
       " 'u4d',\n",
       " 'u64',\n",
       " 'u4a',\n",
       " 'u74',\n",
       " 'u37',\n",
       " 'u52',\n",
       " 'u30',\n",
       " 'u46',\n",
       " 'u6c',\n",
       " 'u6c',\n",
       " 'u42',\n",
       " 'u50',\n",
       " 'u4c',\n",
       " 'u65',\n",
       " 'u32',\n",
       " 'u58',\n",
       " 'u39',\n",
       " 'u46',\n",
       " 'u49',\n",
       " 'u49',\n",
       " 'u50',\n",
       " 'u44',\n",
       " 'u5c',\n",
       " 'u49',\n",
       " 'u36',\n",
       " 'u53',\n",
       " 'u35',\n",
       " 'u6e',\n",
       " 'u41',\n",
       " 'u33',\n",
       " 'u4e',\n",
       " 'u70',\n",
       " 'u43',\n",
       " 'u61',\n",
       " 'u49',\n",
       " 'u48',\n",
       " 'u24',\n",
       " 'u4f',\n",
       " 'u48',\n",
       " 'u35',\n",
       " 'u36',\n",
       " 'u77',\n",
       " 'u37',\n",
       " 'u79',\n",
       " 'u4b',\n",
       " 'u52',\n",
       " 'u79',\n",
       " 'u34',\n",
       " 'u6d',\n",
       " 'u6c',\n",
       " 'u52',\n",
       " 'u55',\n",
       " 'u4b',\n",
       " 'u50',\n",
       " 'u76',\n",
       " 'u4d',\n",
       " 'u36',\n",
       " 'u6b',\n",
       " 'u39',\n",
       " 'u31',\n",
       " 'u5a',\n",
       " 'u39',\n",
       " 'u29',\n",
       " 'u43',\n",
       " 'u62',\n",
       " 'u73',\n",
       " 'u51',\n",
       " 'u51',\n",
       " 'u5a',\n",
       " 'u50',\n",
       " 'u39',\n",
       " 'u4f',\n",
       " 'u51',\n",
       " 'u38',\n",
       " 'u4b',\n",
       " 'u53',\n",
       " 'u77',\n",
       " 'u64',\n",
       " 'u47',\n",
       " 'u31',\n",
       " 'u49',\n",
       " 'u57',\n",
       " 'u2e',\n",
       " 'u70',\n",
       " 'u4f',\n",
       " 'u6c',\n",
       " 'u3c',\n",
       " 'u52',\n",
       " 'u64',\n",
       " 'u53',\n",
       " 'u32',\n",
       " 'u73',\n",
       " 'u55',\n",
       " 'u33',\n",
       " 'u47',\n",
       " 'u4a',\n",
       " 'u6c',\n",
       " 'u34',\n",
       " 'u53',\n",
       " 'u4a',\n",
       " 'u34',\n",
       " 'u55',\n",
       " 'u55',\n",
       " 'u4f',\n",
       " 'u5c',\n",
       " 'u32',\n",
       " 'u23',\n",
       " 'u6e',\n",
       " 'u30',\n",
       " 'u43',\n",
       " 'u45',\n",
       " 'u49',\n",
       " 'u79',\n",
       " 'u4e',\n",
       " 'u72',\n",
       " 'u69',\n",
       " 'u43',\n",
       " 'u5a',\n",
       " 'u62',\n",
       " 'u4d',\n",
       " 'u42',\n",
       " 'u45',\n",
       " 'u35',\n",
       " 'u33',\n",
       " 'u61',\n",
       " 'u53',\n",
       " 'u41',\n",
       " 'u28',\n",
       " 'u52',\n",
       " 'u56',\n",
       " 'u6c',\n",
       " 'u38',\n",
       " 'u52',\n",
       " 'u28',\n",
       " 'u37',\n",
       " 'u71',\n",
       " 'u4f',\n",
       " 'u31',\n",
       " 'u75',\n",
       " 'u32',\n",
       " 'u66',\n",
       " 'u4e',\n",
       " 'u2d',\n",
       " 'u31',\n",
       " 'u69',\n",
       " 'u51',\n",
       " 'u42',\n",
       " 'u55',\n",
       " 'u72',\n",
       " 'u31',\n",
       " 'u61',\n",
       " 'u3a',\n",
       " 'u4e',\n",
       " 'u50',\n",
       " 'u6c',\n",
       " 'u39',\n",
       " 'u45',\n",
       " 'u34',\n",
       " 'u55',\n",
       " 'u30',\n",
       " 'u45',\n",
       " 'u6f',\n",
       " 'u74',\n",
       " 'u33',\n",
       " 'u43',\n",
       " 'u30',\n",
       " 'u76',\n",
       " 'u75',\n",
       " 'u6f',\n",
       " 'u47',\n",
       " 'u4c',\n",
       " 'u7a',\n",
       " 'u46',\n",
       " 'u61',\n",
       " 'u30',\n",
       " 'u30',\n",
       " 'u65',\n",
       " 'u77',\n",
       " 'u44',\n",
       " 'u7a',\n",
       " 'u6c',\n",
       " 'u59',\n",
       " 'u32',\n",
       " 'u46',\n",
       " 'u50',\n",
       " 'u6d',\n",
       " 'u35',\n",
       " 'u46',\n",
       " 'u27',\n",
       " 'u74',\n",
       " 'u5a',\n",
       " 'u36',\n",
       " 'u57',\n",
       " 'u41',\n",
       " 'u30',\n",
       " 'u79',\n",
       " 'u4c',\n",
       " 'u50',\n",
       " 'u46',\n",
       " 'u37',\n",
       " 'u46',\n",
       " 'u34',\n",
       " 'u75',\n",
       " 'u45',\n",
       " 'u75',\n",
       " 'u5a',\n",
       " 'u4f',\n",
       " 'u48',\n",
       " 'u72',\n",
       " 'u33',\n",
       " 'u56',\n",
       " 'u61',\n",
       " 'u32',\n",
       " 'u41',\n",
       " 'u34',\n",
       " 'u4e',\n",
       " 'u21',\n",
       " 'u57',\n",
       " 'u37',\n",
       " 'u6d',\n",
       " 'u41',\n",
       " 'u65',\n",
       " 'u4e',\n",
       " 'u57',\n",
       " 'u49',\n",
       " 'u31',\n",
       " 'u34',\n",
       " 'u38',\n",
       " 'u33',\n",
       " 'u65',\n",
       " 'u54',\n",
       " 'u2e',\n",
       " 'u31',\n",
       " 'u73',\n",
       " 'u31',\n",
       " 'u6f',\n",
       " 'u39',\n",
       " 'u72',\n",
       " 'u4f',\n",
       " 'u4f',\n",
       " 'u45',\n",
       " 'u42',\n",
       " 'u74',\n",
       " 'u50',\n",
       " 'u57',\n",
       " 'u36',\n",
       " 'u54',\n",
       " 'u38',\n",
       " 'u33',\n",
       " 'u64',\n",
       " 'u48',\n",
       " 'u4b',\n",
       " 'u49',\n",
       " 'u70',\n",
       " 'u6e',\n",
       " 'u6e',\n",
       " 'u4f',\n",
       " 'u39',\n",
       " 'u77',\n",
       " 'u58',\n",
       " 'u52',\n",
       " 'u43',\n",
       " 'u2d',\n",
       " 'u63',\n",
       " 'u56',\n",
       " 'u67',\n",
       " 'u65',\n",
       " 'u32',\n",
       " 'u4b',\n",
       " 'u37',\n",
       " 'u42',\n",
       " 'u72',\n",
       " 'u6d',\n",
       " 'u39',\n",
       " 'u38',\n",
       " 'u69',\n",
       " 'u75',\n",
       " 'u47',\n",
       " 'u65',\n",
       " 'u42',\n",
       " 'u36',\n",
       " 'u47',\n",
       " 'u65',\n",
       " 'u65',\n",
       " 'u45',\n",
       " 'u45',\n",
       " 'u55',\n",
       " 'u4f',\n",
       " 'u34',\n",
       " 'u35',\n",
       " 'u55',\n",
       " 'u42',\n",
       " 'u4e',\n",
       " 'u41',\n",
       " 'u51',\n",
       " 'u39',\n",
       " 'u31',\n",
       " 'u49',\n",
       " 'u4b',\n",
       " 'u31',\n",
       " 'u45',\n",
       " 'u5b',\n",
       " 'u6c',\n",
       " 'u6a',\n",
       " 'u56',\n",
       " 'u36',\n",
       " 'u42',\n",
       " 'u53',\n",
       " 'u4c',\n",
       " 'u25',\n",
       " 'u33',\n",
       " 'u29',\n",
       " 'u38',\n",
       " 'u37',\n",
       " 'u56',\n",
       " 'u34',\n",
       " 'u36',\n",
       " 'u4a',\n",
       " 'u51',\n",
       " 'u4a',\n",
       " 'u33',\n",
       " 'u34',\n",
       " 'u34',\n",
       " 'u69',\n",
       " 'u47',\n",
       " 'u39',\n",
       " 'u61',\n",
       " 'u43',\n",
       " 'u50',\n",
       " 'u38',\n",
       " 'u52',\n",
       " 'u64',\n",
       " 'u6a',\n",
       " 'u46',\n",
       " 'u3a',\n",
       " 'u52',\n",
       " 'u6c',\n",
       " 'u38',\n",
       " 'u79',\n",
       " 'u64',\n",
       " 'u65',\n",
       " 'u47',\n",
       " 'u64',\n",
       " 'u69',\n",
       " 'u69',\n",
       " 'u73',\n",
       " 'u4a',\n",
       " 'u30',\n",
       " 'u33',\n",
       " 'u73',\n",
       " 'u38',\n",
       " 'u6a',\n",
       " 'u6b',\n",
       " 'u4a',\n",
       " 'u32',\n",
       " 'u2d',\n",
       " 'u46',\n",
       " 'u51',\n",
       " 'u32',\n",
       " 'u23',\n",
       " 'u33',\n",
       " 'u4c',\n",
       " 'u72',\n",
       " 'u34',\n",
       " 'u47',\n",
       " 'u4c',\n",
       " 'u45',\n",
       " 'u7c',\n",
       " 'u61',\n",
       " 'u68',\n",
       " 'u57',\n",
       " 'u4b',\n",
       " 'u6c',\n",
       " 'u61',\n",
       " 'u33',\n",
       " 'u64',\n",
       " 'u69',\n",
       " 'u48',\n",
       " 'u50',\n",
       " 'u44',\n",
       " 'u6c',\n",
       " 'u35',\n",
       " 'u28',\n",
       " 'u37',\n",
       " 'u31',\n",
       " 'u7a',\n",
       " 'u36',\n",
       " 'u31',\n",
       " 'u33',\n",
       " 'u73',\n",
       " 'u6e',\n",
       " 'u6c',\n",
       " 'u4f',\n",
       " 'u65',\n",
       " 'u2c',\n",
       " 'u37',\n",
       " 'u4c',\n",
       " 'u34',\n",
       " 'u54',\n",
       " 'u39',\n",
       " 'u4c',\n",
       " 'u4a',\n",
       " 'u6a',\n",
       " 'u6e',\n",
       " 'u6c',\n",
       " 'u57',\n",
       " 'u37',\n",
       " 'u43',\n",
       " 'u33',\n",
       " 'u6f',\n",
       " 'u74',\n",
       " 'u42',\n",
       " 'u45',\n",
       " 'u62',\n",
       " 'u36',\n",
       " 'u72',\n",
       " 'u68',\n",
       " 'u79',\n",
       " 'u64',\n",
       " 'u6e',\n",
       " 'u61',\n",
       " 'u61',\n",
       " 'u34',\n",
       " 'u31',\n",
       " 'u49',\n",
       " 'u39',\n",
       " 'u4a',\n",
       " 'u45',\n",
       " 'u37',\n",
       " 'u6a',\n",
       " 'u36',\n",
       " 'u31',\n",
       " 'u71',\n",
       " 'u39',\n",
       " 'u37',\n",
       " 'u4f',\n",
       " 'u6d',\n",
       " 'u4d',\n",
       " 'u38',\n",
       " 'u52',\n",
       " 'u4c',\n",
       " 'u36',\n",
       " 'u45',\n",
       " 'u2d',\n",
       " 'u35',\n",
       " 'u48',\n",
       " 'u4f',\n",
       " 'u29',\n",
       " 'u30',\n",
       " 'u43',\n",
       " 'u4f',\n",
       " 'u53',\n",
       " 'u33',\n",
       " 'u6e',\n",
       " 'u45',\n",
       " 'u36',\n",
       " 'u39',\n",
       " 'u64',\n",
       " 'u69',\n",
       " 'u32',\n",
       " 'u61',\n",
       " 'u30',\n",
       " 'u32',\n",
       " 'u36',\n",
       " 'u4c',\n",
       " 'u6f',\n",
       " 'u31',\n",
       " 'u42',\n",
       " 'u59',\n",
       " 'u4d',\n",
       " 'u59',\n",
       " 'u51',\n",
       " 'u77',\n",
       " 'u32',\n",
       " 'u6c',\n",
       " 'u50',\n",
       " 'u44',\n",
       " 'u38',\n",
       " 'u6e',\n",
       " 'u72',\n",
       " 'u31',\n",
       " 'u6c',\n",
       " 'u6e',\n",
       " 'u45',\n",
       " 'u38',\n",
       " 'u74',\n",
       " 'u4a',\n",
       " 'u42',\n",
       " 'u30',\n",
       " 'u29',\n",
       " 'u36',\n",
       " 'u33',\n",
       " 'u38',\n",
       " 'u6c',\n",
       " 'u6d',\n",
       " 'u33',\n",
       " 'u64',\n",
       " 'u65',\n",
       " 'u6f',\n",
       " 'u72',\n",
       " 'u66',\n",
       " 'u73',\n",
       " 'u49',\n",
       " 'u39',\n",
       " 'u31',\n",
       " 'u4e',\n",
       " 'u6a',\n",
       " 'u31',\n",
       " 'u35',\n",
       " 'u50',\n",
       " 'u69',\n",
       " 'u48',\n",
       " 'u2a',\n",
       " 'u4a',\n",
       " 'u4f',\n",
       " 'u72',\n",
       " 'u33',\n",
       " 'u34',\n",
       " 'u49',\n",
       " 'u79',\n",
       " 'u65',\n",
       " 'u32',\n",
       " 'u70',\n",
       " 'u5d',\n",
       " 'u74',\n",
       " 'u75',\n",
       " 'u69',\n",
       " 'u22',\n",
       " 'u43',\n",
       " 'u41',\n",
       " 'u33',\n",
       " 'u34',\n",
       " 'u65',\n",
       " 'u36',\n",
       " 'u73',\n",
       " 'u74',\n",
       " 'u42',\n",
       " 'u78',\n",
       " 'u50',\n",
       " 'u48',\n",
       " 'u30',\n",
       " 'u61',\n",
       " 'u58',\n",
       " 'u31',\n",
       " 'u2e',\n",
       " 'u59',\n",
       " 'u59',\n",
       " 'u35',\n",
       " 'u71',\n",
       " 'u45',\n",
       " 'u3d',\n",
       " 'u45',\n",
       " 'u31',\n",
       " 'u6f',\n",
       " 'u43',\n",
       " 'u67',\n",
       " 'u6e',\n",
       " 'u4f',\n",
       " 'u41',\n",
       " 'u34',\n",
       " 'u74',\n",
       " 'u61',\n",
       " 'u32',\n",
       " 'u49',\n",
       " 'u43',\n",
       " 'u43',\n",
       " 'u32',\n",
       " 'u65',\n",
       " 'u30',\n",
       " 'u79',\n",
       " 'u6a',\n",
       " 'u56',\n",
       " 'u4c',\n",
       " 'u28',\n",
       " 'u75',\n",
       " 'u21',\n",
       " 'u43',\n",
       " 'u30',\n",
       " 'u75',\n",
       " 'u47',\n",
       " 'u32',\n",
       " 'u64',\n",
       " 'u3a',\n",
       " 'u69',\n",
       " 'u61',\n",
       " 'u4e',\n",
       " 'u2e',\n",
       " 'u3a',\n",
       " 'u65',\n",
       " 'u6c',\n",
       " 'u39',\n",
       " 'u61',\n",
       " 'u37',\n",
       " 'u4f',\n",
       " 'u4d',\n",
       " 'u4f',\n",
       " 'u51',\n",
       " 'u61',\n",
       " 'u4c',\n",
       " 'u4e',\n",
       " 'u66',\n",
       " 'u31',\n",
       " 'u54',\n",
       " 'u31',\n",
       " 'u69',\n",
       " 'u66',\n",
       " 'u53',\n",
       " 'u72',\n",
       " 'u22',\n",
       " 'u6e',\n",
       " 'u4f',\n",
       " 'u47',\n",
       " 'u39',\n",
       " 'u6e',\n",
       " 'u68',\n",
       " 'u28',\n",
       " 'u36',\n",
       " 'u4c',\n",
       " 'u30',\n",
       " 'u43',\n",
       " 'u36',\n",
       " 'u56',\n",
       " 'u34',\n",
       " 'u49',\n",
       " 'u53',\n",
       " 'u56',\n",
       " 'u47',\n",
       " 'u22',\n",
       " 'u34',\n",
       " 'u34',\n",
       " 'u30',\n",
       " 'u45',\n",
       " 'u27',\n",
       " 'u36',\n",
       " 'u55',\n",
       " 'u31',\n",
       " 'u32',\n",
       " 'u35',\n",
       " 'u6e',\n",
       " 'u4d',\n",
       " 'u38',\n",
       " 'u59',\n",
       " 'u79',\n",
       " 'u39',\n",
       " 'u69',\n",
       " 'u69',\n",
       " 'u6a',\n",
       " 'u54',\n",
       " 'u33',\n",
       " 'u77',\n",
       " 'u4c',\n",
       " 'u53',\n",
       " 'u64',\n",
       " 'u51',\n",
       " 'u69',\n",
       " 'u6c',\n",
       " 'u37',\n",
       " 'u4e',\n",
       " 'u37',\n",
       " 'u56',\n",
       " 'u53',\n",
       " 'u4e',\n",
       " 'u53',\n",
       " 'u57',\n",
       " 'u32',\n",
       " 'u64',\n",
       " 'u49',\n",
       " 'u46',\n",
       " 'u50',\n",
       " 'u56',\n",
       " 'u75',\n",
       " 'u69',\n",
       " 'u65',\n",
       " 'u33',\n",
       " 'u6e',\n",
       " 'u48',\n",
       " 'u45',\n",
       " 'u2d',\n",
       " 'u65',\n",
       " 'u29',\n",
       " 'u4a',\n",
       " 'u6c',\n",
       " 'u41',\n",
       " 'u43',\n",
       " 'u36',\n",
       " 'u4a',\n",
       " 'u3d',\n",
       " 'u72',\n",
       " 'u2e',\n",
       " 'u3b',\n",
       " 'u75',\n",
       " 'u31',\n",
       " 'u4a',\n",
       " 'u43',\n",
       " 'u4f',\n",
       " 'u57',\n",
       " 'u34',\n",
       " 'u44',\n",
       " 'u45',\n",
       " 'u51',\n",
       " 'u4c',\n",
       " 'u5c',\n",
       " 'u39',\n",
       " 'u49',\n",
       " 'u55',\n",
       " 'u30',\n",
       " 'u50',\n",
       " 'u6c',\n",
       " 'u36',\n",
       " 'u35',\n",
       " 'u57',\n",
       " 'u36',\n",
       " 'u58',\n",
       " 'u37',\n",
       " 'u6c',\n",
       " 'u37',\n",
       " 'u65',\n",
       " 'u53',\n",
       " 'u65',\n",
       " 'u36',\n",
       " 'u33',\n",
       " 'u75',\n",
       " 'u64',\n",
       " 'u31',\n",
       " 'u37',\n",
       " 'u30',\n",
       " 'u37',\n",
       " 'u6c',\n",
       " 'u28',\n",
       " 'u35',\n",
       " 'u31',\n",
       " 'u42',\n",
       " 'u46',\n",
       " 'u56',\n",
       " 'u31',\n",
       " 'u45',\n",
       " 'u48',\n",
       " 'u75',\n",
       " 'u54',\n",
       " 'u75',\n",
       " 'u70',\n",
       " 'u41',\n",
       " 'u34',\n",
       " 'u54',\n",
       " 'u55',\n",
       " 'u4e',\n",
       " 'u2c',\n",
       " 'u49',\n",
       " 'u31',\n",
       " 'u56',\n",
       " 'u61',\n",
       " 'u70',\n",
       " 'u36',\n",
       " 'u65',\n",
       " 'u64',\n",
       " 'u70',\n",
       " 'u34',\n",
       " 'u46',\n",
       " 'u31',\n",
       " 'u68',\n",
       " 'u32',\n",
       " 'u6c',\n",
       " 'u4a',\n",
       " 'u39',\n",
       " 'u4b',\n",
       " 'u64',\n",
       " 'u48',\n",
       " 'u66',\n",
       " 'u76',\n",
       " 'u4c',\n",
       " 'u50',\n",
       " 'u38',\n",
       " 'u6c',\n",
       " 'u4f',\n",
       " 'u74',\n",
       " 'u31',\n",
       " 'u33',\n",
       " 'u50',\n",
       " 'u54',\n",
       " 'u2d',\n",
       " 'u4c',\n",
       " 'u79',\n",
       " 'u37',\n",
       " 'u31',\n",
       " 'u66',\n",
       " 'u59',\n",
       " 'u52',\n",
       " 'u63',\n",
       " 'u67',\n",
       " 'u4a',\n",
       " 'u32',\n",
       " 'u50',\n",
       " 'u2e',\n",
       " 'u4f',\n",
       " 'u2e',\n",
       " 'u72',\n",
       " 'u30',\n",
       " 'u74',\n",
       " 'u36',\n",
       " 'u27',\n",
       " 'u41',\n",
       " 'u4e',\n",
       " 'u74',\n",
       " 'u28',\n",
       " 'u55',\n",
       " 'u67',\n",
       " 'u32',\n",
       " 'u31',\n",
       " 'u34',\n",
       " 'u2a',\n",
       " 'u73',\n",
       " 'u4d',\n",
       " 'u36',\n",
       " 'u35',\n",
       " 'u48',\n",
       " 'u70',\n",
       " 'u47',\n",
       " 'u56',\n",
       " 'u6a',\n",
       " 'u50',\n",
       " 'u61',\n",
       " 'u69',\n",
       " 'u57',\n",
       " 'u61',\n",
       " 'u47',\n",
       " 'u4d',\n",
       " 'u6b',\n",
       " 'u72',\n",
       " 'u44',\n",
       " 'u52',\n",
       " 'u47',\n",
       " 'u61',\n",
       " 'u2e',\n",
       " 'u48',\n",
       " 'u52',\n",
       " 'u47',\n",
       " 'u35',\n",
       " 'u46',\n",
       " 'u3e',\n",
       " 'u78',\n",
       " 'u54',\n",
       " 'u42',\n",
       " 'u34',\n",
       " 'u49',\n",
       " 'u31',\n",
       " 'u6c',\n",
       " 'u38',\n",
       " 'u51',\n",
       " 'u39',\n",
       " 'u37',\n",
       " 'u41',\n",
       " 'u4c',\n",
       " 'u32',\n",
       " 'u68',\n",
       " 'u6e',\n",
       " 'u38',\n",
       " 'u2e',\n",
       " 'u35',\n",
       " 'u4c',\n",
       " 'u32',\n",
       " 'u4c',\n",
       " 'u78',\n",
       " 'u6e',\n",
       " 'u61',\n",
       " 'u70',\n",
       " 'u35',\n",
       " 'u76',\n",
       " 'u57',\n",
       " 'u37',\n",
       " 'u38',\n",
       " 'u59',\n",
       " 'u4c',\n",
       " 'u6a',\n",
       " 'u65',\n",
       " 'u38',\n",
       " 'u33',\n",
       " 'u30',\n",
       " 'u28',\n",
       " 'u24',\n",
       " 'u53',\n",
       " 'u64',\n",
       " 'u27',\n",
       " 'u49',\n",
       " 'u39',\n",
       " 'u48',\n",
       " 'u37',\n",
       " 'u66',\n",
       " 'u46',\n",
       " 'u44',\n",
       " 'u26',\n",
       " 'u55',\n",
       " 'u4c',\n",
       " 'u31',\n",
       " 'u42',\n",
       " 'u31',\n",
       " 'u41',\n",
       " 'u35',\n",
       " 'u6c',\n",
       " 'u32',\n",
       " 'u33',\n",
       " 'u31',\n",
       " 'u33',\n",
       " 'u43',\n",
       " 'u4e',\n",
       " 'u73',\n",
       " 'u55',\n",
       " 'u4c',\n",
       " 'u7d',\n",
       " 'u69',\n",
       " 'u27',\n",
       " 'u67',\n",
       " 'u34',\n",
       " 'u43',\n",
       " 'u32',\n",
       " 'u6f',\n",
       " 'u68',\n",
       " 'u66',\n",
       " 'u57',\n",
       " 'u42',\n",
       " 'u33',\n",
       " 'u6c',\n",
       " 'u77',\n",
       " 'u3e',\n",
       " 'u69',\n",
       " 'u6e',\n",
       " 'u4e',\n",
       " 'u30',\n",
       " 'u37',\n",
       " 'u49',\n",
       " 'u32',\n",
       " 'u6e',\n",
       " 'u31',\n",
       " 'u38',\n",
       " 'u33',\n",
       " 'u36',\n",
       " 'u44',\n",
       " 'u44',\n",
       " 'u39',\n",
       " 'u57',\n",
       " 'u44',\n",
       " 'u69',\n",
       " 'u50',\n",
       " 'u56',\n",
       " 'u70',\n",
       " 'u6c',\n",
       " 'u32',\n",
       " 'u65',\n",
       " 'u74',\n",
       " 'u39',\n",
       " 'u43',\n",
       " 'u51',\n",
       " 'u39',\n",
       " 'u74',\n",
       " 'u4e',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_keep_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'u4e': 41,\n",
       "         'u61': 41,\n",
       "         'u4f': 41,\n",
       "         'u2a': 41,\n",
       "         'u68': 41,\n",
       "         'u2d': 41,\n",
       "         'u48': 41,\n",
       "         'u6f': 41,\n",
       "         'u32': 41,\n",
       "         'u4a': 41,\n",
       "         'u35': 41,\n",
       "         'u38': 41,\n",
       "         'u72': 41,\n",
       "         'u37': 41,\n",
       "         'u70': 41,\n",
       "         'u73': 41,\n",
       "         'u4c': 41,\n",
       "         'u33': 41,\n",
       "         'u49': 41,\n",
       "         'u59': 41,\n",
       "         'u54': 41,\n",
       "         'u58': 41,\n",
       "         'u44': 41,\n",
       "         'u52': 41,\n",
       "         'u6c': 41,\n",
       "         'u5a': 41,\n",
       "         'u65': 41,\n",
       "         'u4b': 41,\n",
       "         'u31': 41,\n",
       "         'u3d': 41,\n",
       "         'u62': 41,\n",
       "         'u5d': 41,\n",
       "         'u4d': 41,\n",
       "         'u64': 41,\n",
       "         'u74': 41,\n",
       "         'u30': 41,\n",
       "         'u46': 41,\n",
       "         'u42': 41,\n",
       "         'u50': 41,\n",
       "         'u39': 41,\n",
       "         'u5c': 41,\n",
       "         'u36': 41,\n",
       "         'u53': 41,\n",
       "         'u6e': 41,\n",
       "         'u41': 41,\n",
       "         'u43': 41,\n",
       "         'u24': 41,\n",
       "         'u77': 41,\n",
       "         'u79': 41,\n",
       "         'u34': 41,\n",
       "         'u6d': 41,\n",
       "         'u55': 41,\n",
       "         'u76': 41,\n",
       "         'u6b': 41,\n",
       "         'u29': 41,\n",
       "         'u51': 41,\n",
       "         'u47': 41,\n",
       "         'u57': 41,\n",
       "         'u2e': 41,\n",
       "         'u3c': 41,\n",
       "         'u23': 41,\n",
       "         'u45': 41,\n",
       "         'u69': 41,\n",
       "         'u28': 41,\n",
       "         'u56': 41,\n",
       "         'u71': 41,\n",
       "         'u75': 41,\n",
       "         'u66': 41,\n",
       "         'u3a': 41,\n",
       "         'u7a': 41,\n",
       "         'u27': 41,\n",
       "         'u21': 41,\n",
       "         'u63': 41,\n",
       "         'u67': 41,\n",
       "         'u5b': 41,\n",
       "         'u6a': 41,\n",
       "         'u25': 41,\n",
       "         'u7c': 41,\n",
       "         'u2c': 41,\n",
       "         'u22': 41,\n",
       "         'u78': 41,\n",
       "         'u3b': 41,\n",
       "         'u3e': 41,\n",
       "         'u26': 41,\n",
       "         'u7d': 41,\n",
       "         'u2f': 41,\n",
       "         'u60': 41,\n",
       "         'u5e': 41,\n",
       "         'u2b': 41,\n",
       "         'u3f': 41,\n",
       "         'u5f': 41,\n",
       "         'u7b': 41,\n",
       "         'u7e': 41,\n",
       "         'u40': 41})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Counter(to_keep_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3854, 3854)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = to_keep_file_paths\n",
    "labels = to_keep_labels\n",
    "len(image_paths), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# image_paths: list of file paths\n",
    "# labels: list of corresponding string labels\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths,\n",
    "    labels,\n",
    "    test_size=0.2,           # 20% for validation\n",
    "    stratify=labels,         # stratified by label\n",
    "    random_state=42          # for reproducibility\n",
    ")\n",
    "\n",
    "\n",
    "all_label_classes: list[str] = sorted(list(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(list(map(lambda x: chr(int(x[1:], 16)), all_label_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=train_paths,  # list(image_paths[:split_index]) + to_add_file_paths,\n",
    "    labels=train_labels,  # list(labels[:split_index]) + to_add_labels,\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.05,\n",
    "    translation_limit=0.2,\n",
    "    skew_limit=0.03,\n",
    "    zoom_change=1.2,\n",
    "    min_zoom=0.8,\n",
    "    thicken_sigma=-3.75,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "val_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=val_paths,\n",
    "    labels=val_labels,\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.0,\n",
    "    translation_limit=0.0,\n",
    "    skew_limit=0.00,\n",
    "    zoom_change=0.0,\n",
    "    min_zoom=1.0,\n",
    "    thicken_sigma=0.0,\n",
    "    image_dims=(64, 64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGfCAYAAAAZGgYhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAe+klEQVR4nO3df2yV5f3/8deptMdK6SmtcE47WlYjWhDLsEg5QbcEOhtjDI5qmMGMOaKRFRTQRPsH4JJpiUSdOH6oc2Ci2MkS1JogI1VL3EqFKhFl1qLN2lnOQRd7TunsadNe3z/8evY50AKnPe11zunzkVwJ3Nfdu9fVnnO/ep3zPvftMMYYAQAwxlJsDwAAMD4RQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKyaM1oG3bdumLVu2yOfzac6cOXr22Wc1f/78C37dwMCAOjo6NGnSJDkcjtEaHgBglBhj1NXVpby8PKWknGedY0ZBTU2NSUtLM3/+85/Np59+au655x6TlZVl/H7/Bb+2vb3dSKLRaDRagrf29vbznu9HJYDmz59vKisrw//v7+83eXl5prq6+oJf29nZaf2HRqPRaLSRt87OzvOe72P+HlBvb6+amppUVlYW3paSkqKysjI1NDScs38oFFIwGAy3rq6uWA8JAGDBhd5GiXkAffPNN+rv75fb7Y7Y7na75fP5ztm/urpaLpcr3PLz82M9JABAHLJeBVdVVaVAIBBu7e3ttocEABgDMa+Cu/zyy3XJJZfI7/dHbPf7/fJ4POfs73Q65XQ6Yz0MAEgoxsK9QW1XGsd8BZSWlqaSkhLV1dWFtw0MDKiurk5erzfW3w4AkKBG5XNA69ev14oVKzRv3jzNnz9ff/jDH9Td3a277757NL4dACABjUoALVu2TF9//bU2btwon8+nn/zkJ3r77bfPKUwAAIxfDmPjhcfzCAaDcrlctocBAGMqGd8DCgQCyszMHLLfehUcAGB8GrVrwQEAzhVnLzpZxQoIAGAFAQQAsIIAAgBYQQABAKygCAEARgHFBhfGCggAYAUBBACwggACAFhBAAEArCCAAABWUAUHACOUqBVvQ417rG5UxwoIAGAFAQQAsIIAAgBYQQABAKwggAAAVlAFBwAXKVGr3eIVKyAAgBUEEADACgIIAGAFAQQAsIIAAgBYQRUcAJyFarexwQoIAGAFAQQAsIIAAgBYQQABAKxI2iKERH4TcaxuBgUAgxns/Dka5yVWQAAAKwggAIAVBBAAwAoCCABgBQEEALAiKargErnibTBjVYECjHfJdu5INKyAAABWEEAAACsIIACAFQQQAMAKAggAYEVCVcGN54qVoeZOdRxwYeP53BHPWAEBAKwggAAAVhBAAAArCCAAgBUEEADAiqgD6NChQ7r11luVl5cnh8Oh119/PaLfGKONGzcqNzdX6enpKisrU0tLS6zGi7MYYwZtABDvog6g7u5uzZkzR9u2bRu0/4knntDWrVu1c+dONTY2auLEiSovL1dPT8+IBwsASB4OM4I/lx0Oh/bt26fbbrtN0vd/jefl5enBBx/UQw89JEkKBAJyu93avXu3fvnLX55zjFAopFAoFP5/MBhUfn7+oN+Pv+wvHp8PAv6Hc8fIDeecEggElJmZOWR/TN8Dam1tlc/nU1lZWXiby+VSaWmpGhoaBv2a6upquVyucBsqfAAAySWmAeTz+SRJbrc7Yrvb7Q73na2qqkqBQCDc2tvbYzkkAECcsn4pHqfTKafTaXsYAIAxFtMVkMfjkST5/f6I7X6/P9yHsUF1HIBYGo1zSkwDqLCwUB6PR3V1deFtwWBQjY2N8nq9sfxWAIAEF/VLcGfOnNHJkyfD/29tbdWxY8eUnZ2tgoICrV27Vr///e81Y8YMFRYWasOGDcrLywtXygEAIEkyUXr33XeNpHPaihUrjDHGDAwMmA0bNhi3222cTqdZvHixaW5uvujjBwKBQY8/jKFiEEP9bGm0ZG4YPef7uQcCgfN+7Yg+BzQagsGgXC7XoH1xNtSExOeDMB5x7hg95zunXOhzQNar4DC2BnsiEkoAbOBipAAAKwggAIAVBBAAwAoCCABgBQEEALAioarghqrWosRyZKL9+VE1ByAWWAEBAKwggAAAVhBAAAArCCAAgBUEEADAioSqgkN8GKpqjuo4xAOqYhMHKyAAgBUEEADACgIIAGAFAQQAsIIAAgBYQRUcYobqOADRYAUEALCCAAIAWEEAAQCsIIAAAFYkRRHCYG9yczmO+DHY74LCBACsgAAAVhBAAAArCCAAgBUEEADACgIIAGBFUlTBIfFw2R4ArIAAAFYQQAAAKwggAIAVBBAAwAoCCABgRdJWwQ1VTcU14gAgPrACAgBYQQABAKwggAAAVhBAAAArCCAAgBVJWwU3FKrj4hvXiAPi02g8B1kBAQCsIIAAAFYQQAAAKwggAIAVUQVQdXW1rr/+ek2aNElTp07Vbbfdpubm5oh9enp6VFlZqZycHGVkZKiiokJ+vz+mgwYAJL6oAqi+vl6VlZU6fPiwDh48qL6+Pt10003q7u4O77Nu3TrV1tZq7969qq+vV0dHh5YuXRrzgceaw+EYtCE+GGMGbRi/eEwkPocZwW/s66+/1tSpU1VfX6+f/vSnCgQCmjJlivbs2aPbb79dkvTZZ59p5syZamho0IIFCy54zGAwKJfLNdwhxRwP6PjGHwnjF8/NsTWc51ogEFBmZuaQ/SN6DygQCEiSsrOzJUlNTU3q6+tTWVlZeJ+ioiIVFBSooaFh0GOEQiEFg8GIBgBIfsMOoIGBAa1du1YLFy7U7NmzJUk+n09paWnKysqK2Nftdsvn8w16nOrqarlcrnDLz88f7pAAAAlk2AFUWVmpTz75RDU1NSMaQFVVlQKBQLi1t7eP6HgAgMQwrEvxrF69Wm+99ZYOHTqkadOmhbd7PB719vaqs7MzYhXk9/vl8XgGPZbT6ZTT6RzOMMbEYK978tozMHZ4viWvqFZAxhitXr1a+/bt0zvvvKPCwsKI/pKSEqWmpqquri68rbm5WW1tbfJ6vbEZMQAgKUS1AqqsrNSePXv0xhtvaNKkSeH3dVwul9LT0+VyubRy5UqtX79e2dnZyszM1Jo1a+T1ei+qAg4AMH5EVYY9VBnerl279Otf/1rS9x9EffDBB/Xqq68qFAqpvLxc27dvH/IluLPFWxn2YHhJIH5Qhp38eL7Fh9Eowx7R54BGAwGEaBBAyY/nW3yIu88BAQAwXOPuhnSxwE3t4gc3sAMSFysgAIAVBBAAwAoCCABgBQEEALCCAAIAWEEVXAxRHQcMH8+T+DFWVaSsgAAAVhBAAAArCCAAgBUEEADACgIIAGAFVXBjgOq4sTfYz5brwwHxhRUQAMAKAggAYAUBBACwggACAFhBAAEArKAKDuMGd08F4gsrIACAFQQQAMAKAggAYAUBBACwgiIEi7hED8YrHuOQWAEBACwhgAAAVhBAAAArCCAAgBUEEADACqrg4tBg1XFUDY0eLtGD8cr2Y5wVEADACgIIAGAFAQQAsIIAAgBYQQABAKygCg4YAtVxSBbx+phlBQQAsIIAAgBYQQABAKwggAAAVhBAAAArqIJLENw9FUCyYQUEALCCAAIAWEEAAQCsIIAAAFZEFUA7duxQcXGxMjMzlZmZKa/Xq/3794f7e3p6VFlZqZycHGVkZKiiokJ+vz/mg8b/OByOQRtGjzHmnIbBDfaz4uc1ehLtfBBVAE2bNk2bN29WU1OTjh49qkWLFmnJkiX69NNPJUnr1q1TbW2t9u7dq/r6enV0dGjp0qWjMnAAQGJzmBH+OZKdna0tW7bo9ttv15QpU7Rnzx7dfvvtkqTPPvtMM2fOVENDgxYsWHBRxwsGg3K5XCMZEkR59liL578ybeJxOLbi7XEYCASUmZk5ZP+w3wPq7+9XTU2Nuru75fV61dTUpL6+PpWVlYX3KSoqUkFBgRoaGoY8TigUUjAYjGgAgOQXdQAdP35cGRkZcjqduu+++7Rv3z7NmjVLPp9PaWlpysrKitjf7XbL5/MNebzq6mq5XK5wy8/Pj3oSAIDEE3UAXX311Tp27JgaGxu1atUqrVixQidOnBj2AKqqqhQIBMKtvb192McCACSOqC/Fk5aWpiuvvFKSVFJSoiNHjuiZZ57RsmXL1Nvbq87OzohVkN/vl8fjGfJ4TqdTTqcz+pEDwDgWb+/3DMeIPwc0MDCgUCikkpISpaamqq6uLtzX3NystrY2eb3ekX4bAECSiWoFVFVVpZtvvlkFBQXq6urSnj179N577+nAgQNyuVxauXKl1q9fr+zsbGVmZmrNmjXyer0XXQEHABg/ogqg06dP61e/+pVOnToll8ul4uJiHThwQD//+c8lSU8//bRSUlJUUVGhUCik8vJybd++fVQGDgBIbCP+HFCs8Tmg2IizX2vSS4bX40cDj8PRkwiPuVH7HBAAACPBDemSFDeww1jicYXhYAUEALCCAAIAWEEAAQCsIIAAAFYQQAAAK6iCA2JgqCqwRPisBmALKyAAgBUEEADACgIIAGAFAQQAsIIAAgBYQRUcgIvGNd8QS6yAAABWEEAAACsIIACAFQQQAMAKihDGmcEuDcMby0D8SubLObECAgBYQQABAKwggAAAVhBAAAArCCAAgBVUwQGjKFFvVEdlJMYCKyAAgBUEEADACgIIAGAFAQQAsIIAAgBYQRUchqzIohIKwGhiBQQAsIIAAgBYQQABAKwggAAAVhBAAAArqIIDLIina8RR7Rgf4v36gKOBFRAAwAoCCABgBQEEALCCAAIAWEERAobEJXrG3mgWJ/B7Q7xhBQQAsIIAAgBYQQABAKwggAAAVhBAAAArRhRAmzdvlsPh0Nq1a8Pbenp6VFlZqZycHGVkZKiiokJ+v3+k4wTGNWPMiBsQb4YdQEeOHNFzzz2n4uLiiO3r1q1TbW2t9u7dq/r6enV0dGjp0qUjHigAILkMK4DOnDmj5cuX64UXXtDkyZPD2wOBgF588UU99dRTWrRokUpKSrRr1y794x//0OHDh2M2aABA4htWAFVWVuqWW25RWVlZxPampib19fVFbC8qKlJBQYEaGhoGPVYoFFIwGIxoAIDkF/WVEGpqavThhx/qyJEj5/T5fD6lpaUpKysrYrvb7ZbP5xv0eNXV1frd734X7TAAAAkuqhVQe3u7HnjgAb3yyiu69NJLYzKAqqoqBQKBcGtvb4/JcQEA8S2qFVBTU5NOnz6t6667Lrytv79fhw4d0h//+EcdOHBAvb296uzsjFgF+f1+eTyeQY/pdDrldDqHN3pYwTXigOEbjzeeG0pUAbR48WIdP348Ytvdd9+toqIiPfzww8rPz1dqaqrq6upUUVEhSWpublZbW5u8Xm/sRg0ASHhRBdCkSZM0e/bsiG0TJ05UTk5OePvKlSu1fv16ZWdnKzMzU2vWrJHX69WCBQtiN2oAQMKL+e0Ynn76aaWkpKiiokKhUEjl5eXavn17rL8NACDBOUycvXAfDAblcrlsDwPDEGcPJSAujaf3gAKBgDIzM4fs51pwAAAruCMqAIyC8bTSGS5WQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFZwQzoAGCFuPjc8rIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBVVwiJmhKoGMMWM8EgCJgBUQAMAKAggAYAUBBACwggACAFhBAAEArKAKDgAuEtd8iy1WQAAAKwggAIAVBBAAwAoCCABgBUUIGHWDvXHL5XkQzyg2GBusgAAAVhBAAAArCCAAgBUEEADACgIIAGAFVXCwgpvXAWAFBACwggACAFhBAAEArCCAAABWEEAAACuiCqBHH31UDocjohUVFYX7e3p6VFlZqZycHGVkZKiiokJ+vz/mgwaAWDj7fPZDw9iIegV0zTXX6NSpU+H2/vvvh/vWrVun2tpa7d27V/X19ero6NDSpUtjOmAAQHKI+nNAEyZMkMfjOWd7IBDQiy++qD179mjRokWSpF27dmnmzJk6fPiwFixYMOjxQqGQQqFQ+P/BYDDaIQEAElDUK6CWlhbl5eXpiiuu0PLly9XW1iZJampqUl9fn8rKysL7FhUVqaCgQA0NDUMer7q6Wi6XK9zy8/OHMQ0AQKKJKoBKS0u1e/duvf3229qxY4daW1t14403qqurSz6fT2lpacrKyor4GrfbLZ/PN+Qxq6qqFAgEwq29vX1YEwEAJJaoXoK7+eabw/8uLi5WaWmppk+frtdee03p6enDGoDT6ZTT6RzW1wIAEteIyrCzsrJ01VVX6eTJk/J4POrt7VVnZ2fEPn6/f9D3jIDBUJWE0cDjKj6NKIDOnDmjL774Qrm5uSopKVFqaqrq6urC/c3NzWpra5PX6x3xQAEAySWql+Aeeugh3XrrrZo+fbo6Ojq0adMmXXLJJbrzzjvlcrm0cuVKrV+/XtnZ2crMzNSaNWvk9XqHrIADAIxfUQXQv//9b9155536z3/+oylTpuiGG27Q4cOHNWXKFEnS008/rZSUFFVUVCgUCqm8vFzbt28flYEDABKbw8TZDViCwaBcLpftYSDOxNnDFAmG93vsCAQCyszMHLKfa8EBAKzgjqhICNxBFReL1U7iYAUEALCCAAIAWEEAAQCsIIAAAFZQhICERnECkLhYAQEArCCAAABWEEAAACsIIACAFQQQAMAKquCQlAarjqMyDogvrIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBVVwGDe4blxy4cZziY8VEADACgIIAGAFAQQAsIIAAgBYQQABAKygCg5AXKPaLXmxAgIAWEEAAQCsIIAAAFYQQAAAKwggAIAVVMFh3OMacfGBarfxhxUQAMAKAggAYAUBBACwggACAFhBEQKAMUfBASRWQAAASwggAIAVBBAAwAoCCABgBQEEALCCKjhgCFyiZ+SodsP5sAICAFhBAAEArCCAAABWEEAAACuiDqCvvvpKd911l3JycpSenq5rr71WR48eDfcbY7Rx40bl5uYqPT1dZWVlamlpiemgAQCJL6oA+vbbb7Vw4UKlpqZq//79OnHihJ588klNnjw5vM8TTzyhrVu3aufOnWpsbNTEiRNVXl6unp6emA8eQHxwOByDNuC8TBQefvhhc8MNNwzZPzAwYDwej9myZUt4W2dnp3E6nebVV1+9qO8RCASMJBotbhvOZft3QovPFggEzvu4iWoF9Oabb2revHm64447NHXqVM2dO1cvvPBCuL+1tVU+n09lZWXhbS6XS6WlpWpoaBj0mKFQSMFgMKIBAJJfVAH05ZdfaseOHZoxY4YOHDigVatW6f7779dLL70kSfL5fJIkt9sd8XVutzvcd7bq6mq5XK5wy8/PH848AAAJJqoAGhgY0HXXXafHH39cc+fO1b333qt77rlHO3fuHPYAqqqqFAgEwq29vX3YxwIAJI6oAig3N1ezZs2K2DZz5ky1tbVJkjwejyTJ7/dH7OP3+8N9Z3M6ncrMzIxoAIDkF1UALVy4UM3NzRHbPv/8c02fPl2SVFhYKI/Ho7q6unB/MBhUY2OjvF5vDIYL2Deeq72odkNMRVPp8sEHH5gJEyaYxx57zLS0tJhXXnnFXHbZZebll18O77N582aTlZVl3njjDfPxxx+bJUuWmMLCQvPdd99d1PegCo6WiG28sP1zpiVWu1AVXNTPnNraWjN79mzjdDpNUVGRef755yP6BwYGzIYNG4zb7TZOp9MsXrzYNDc3X/TxCSBaIrbxwvbPmZZY7UIB5Pj/D6q4EQwG5XK5bA8DiEqcPY1GDS+3IRqBQOC87+tzLTgAgBXckA6IgWhXBvG+YmKlg7HACggAYAUBBACwggACAFhBAAEArCCAAABWUAUHWECVGcAKCABgCQEEALCCAAIAWEEAAQCsiLsAivdLlAAALs6FzudxF0BdXV22hwAAiIELnc/j7nYMAwMD6ujo0KRJk9TV1aX8/Hy1t7cn9a26g8Eg80wS42GOEvNMNrGepzFGXV1dysvLU0rK0OucuPscUEpKiqZNmybpf5+VyMzMTOpf/g+YZ/IYD3OUmGeyieU8L+a+bnH3EhwAYHwggAAAVsR1ADmdTm3atElOp9P2UEYV80we42GOEvNMNrbmGXdFCACA8SGuV0AAgORFAAEArCCAAABWEEAAACsIIACAFXEdQNu2bdOPf/xjXXrppSotLdUHH3xge0gjcujQId16663Ky8uTw+HQ66+/HtFvjNHGjRuVm5ur9PR0lZWVqaWlxc5gh6m6ulrXX3+9Jk2apKlTp+q2225Tc3NzxD49PT2qrKxUTk6OMjIyVFFRIb/fb2nEw7Njxw4VFxeHPznu9Xq1f//+cH8yzPFsmzdvlsPh0Nq1a8PbkmGejz76qBwOR0QrKioK9yfDHH/w1Vdf6a677lJOTo7S09N17bXX6ujRo+H+sT4HxW0A/eUvf9H69eu1adMmffjhh5ozZ47Ky8t1+vRp20Mbtu7ubs2ZM0fbtm0btP+JJ57Q1q1btXPnTjU2NmrixIkqLy9XT0/PGI90+Orr61VZWanDhw/r4MGD6uvr00033aTu7u7wPuvWrVNtba327t2r+vp6dXR0aOnSpRZHHb1p06Zp8+bNampq0tGjR7Vo0SItWbJEn376qaTkmOP/deTIET333HMqLi6O2J4s87zmmmt06tSpcHv//ffDfckyx2+//VYLFy5Uamqq9u/frxMnTujJJ5/U5MmTw/uM+TnIxKn58+ebysrK8P/7+/tNXl6eqa6utjiq2JFk9u3bF/7/wMCA8Xg8ZsuWLeFtnZ2dxul0mldffdXCCGPj9OnTRpKpr683xnw/p9TUVLN3797wPv/85z+NJNPQ0GBrmDExefJk86c//Snp5tjV1WVmzJhhDh48aH72s5+ZBx54wBiTPL/LTZs2mTlz5gzalyxzNMaYhx9+2Nxwww1D9ts4B8XlCqi3t1dNTU0qKysLb0tJSVFZWZkaGhosjmz0tLa2yufzRczZ5XKptLQ0oeccCAQkSdnZ2ZKkpqYm9fX1RcyzqKhIBQUFCTvP/v5+1dTUqLu7W16vN+nmWFlZqVtuuSViPlJy/S5bWlqUl5enK664QsuXL1dbW5uk5Jrjm2++qXnz5umOO+7Q1KlTNXfuXL3wwgvhfhvnoLgMoG+++Ub9/f1yu90R291ut3w+n6VRja4f5pVMcx4YGNDatWu1cOFCzZ49W9L380xLS1NWVlbEvok4z+PHjysjI0NOp1P33Xef9u3bp1mzZiXVHGtqavThhx+qurr6nL5kmWdpaal2796tt99+Wzt27FBra6tuvPFGdXV1Jc0cJenLL7/Ujh07NGPGDB04cECrVq3S/fffr5deekmSnXNQ3N2OAcmjsrJSn3zyScTr6cnk6quv1rFjxxQIBPTXv/5VK1asUH19ve1hxUx7e7seeOABHTx4UJdeeqnt4Yyam2++Ofzv4uJilZaWavr06XrttdeUnp5ucWSxNTAwoHnz5unxxx+XJM2dO1effPKJdu7cqRUrVlgZU1yugC6//HJdcskl51Sa+P1+eTweS6MaXT/MK1nmvHr1ar311lt69913w/d3kr6fZ29vrzo7OyP2T8R5pqWl6corr1RJSYmqq6s1Z84cPfPMM0kzx6amJp0+fVrXXXedJkyYoAkTJqi+vl5bt27VhAkT5Ha7k2KeZ8vKytJVV12lkydPJs3vUpJyc3M1a9asiG0zZ84Mv9xo4xwUlwGUlpamkpIS1dXVhbcNDAyorq5OXq/X4shGT2FhoTweT8Scg8GgGhsbE2rOxhitXr1a+/bt0zvvvKPCwsKI/pKSEqWmpkbMs7m5WW1tbQk1z8EMDAwoFAolzRwXL16s48eP69ixY+E2b948LV++PPzvZJjn2c6cOaMvvvhCubm5SfO7lKSFCxee85GIzz//XNOnT5dk6Rw0KqUNMVBTU2OcTqfZvXu3OXHihLn33ntNVlaW8fl8toc2bF1dXeajjz4yH330kZFknnrqKfPRRx+Zf/3rX8YYYzZv3myysrLMG2+8YT7++GOzZMkSU1hYaL777jvLI794q1atMi6Xy7z33nvm1KlT4fbf//43vM99991nCgoKzDvvvGOOHj1qvF6v8Xq9FkcdvUceecTU19eb1tZW8/HHH5tHHnnEOBwO87e//c0YkxxzHMz/rYIzJjnm+eCDD5r33nvPtLa2mr///e+mrKzMXH755eb06dPGmOSYozHGfPDBB2bChAnmscceMy0tLeaVV14xl112mXn55ZfD+4z1OShuA8gYY5599llTUFBg0tLSzPz5883hw4dtD2lE3n33XSPpnLZixQpjzPdlkBs2bDBut9s4nU6zePFi09zcbHfQURpsfpLMrl27wvt899135re//a2ZPHmyueyyy8wvfvELc+rUKXuDHobf/OY3Zvr06SYtLc1MmTLFLF68OBw+xiTHHAdzdgAlwzyXLVtmcnNzTVpamvnRj35kli1bZk6ePBnuT4Y5/qC2ttbMnj3bOJ1OU1RUZJ5//vmI/rE+B3E/IACAFXH5HhAAIPkRQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAV/w9Di6o1s/T9cgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in train_char_dataset:\n",
    "    plt.imshow(\n",
    "        rearrange(im, \"1 h w -> h w\")*255,\n",
    "        cmap=\"gray\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in val_char_dataset:\n",
    "    print(im.shape)\n",
    "    plt.imshow(rearrange(im, \"1 h w -> h w\")*255, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader: DataLoader = DataLoader(\n",
    "    train_char_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "val_dataloader: DataLoader = DataLoader(\n",
    "    val_char_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.0.weight\n",
      "Loaded: encoder_conv_blocks.1.0.bias\n",
      "Loaded: encoder_conv_blocks.1.2.weight\n",
      "Loaded: encoder_conv_blocks.1.2.bias\n",
      "Loaded: encoder_conv_blocks.1.2.running_mean\n",
      "Loaded: encoder_conv_blocks.1.2.running_var\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.4.weight\n",
      "Loaded: encoder_conv_blocks.1.4.bias\n",
      "Loaded: encoder_conv_blocks.1.6.weight\n",
      "Loaded: encoder_conv_blocks.1.6.bias\n",
      "Loaded: encoder_conv_blocks.1.6.running_mean\n",
      "Loaded: encoder_conv_blocks.1.6.running_var\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.0.weight\n",
      "Loaded: encoder_conv_blocks.2.0.bias\n",
      "Loaded: encoder_conv_blocks.2.2.weight\n",
      "Loaded: encoder_conv_blocks.2.2.bias\n",
      "Loaded: encoder_conv_blocks.2.2.running_mean\n",
      "Loaded: encoder_conv_blocks.2.2.running_var\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.4.weight\n",
      "Loaded: encoder_conv_blocks.2.4.bias\n",
      "Loaded: encoder_conv_blocks.2.6.weight\n",
      "Loaded: encoder_conv_blocks.2.6.bias\n",
      "Loaded: encoder_conv_blocks.2.6.running_mean\n",
      "Loaded: encoder_conv_blocks.2.6.running_var\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.3.0.weight:  loaded size:torch.Size([32, 32, 3, 3]) != model size:  torch.Size([64, 32, 3, 3])\n",
      "Skipping encoder_conv_blocks.3.0.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Skipping encoder_conv_blocks.3.2.weight:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Skipping encoder_conv_blocks.3.2.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Skipping encoder_conv_blocks.3.2.running_mean:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Skipping encoder_conv_blocks.3.2.running_var:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.3.4.weight:  loaded size:torch.Size([32, 32, 3, 3]) != model size:  torch.Size([64, 64, 3, 3])\n",
      "Skipping encoder_conv_blocks.3.4.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Skipping encoder_conv_blocks.3.6.weight:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Skipping encoder_conv_blocks.3.6.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Skipping encoder_conv_blocks.3.6.running_mean:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Skipping encoder_conv_blocks.3.6.running_var:  loaded size:torch.Size([32]) != model size:  torch.Size([64])\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Skipping fully_connected_blocks.0.0.weight:  loaded size:torch.Size([128, 512]) != model size:  torch.Size([256, 1024])\n",
      "Skipping fully_connected_blocks.0.0.bias:  loaded size:torch.Size([128]) != model size:  torch.Size([256])\n",
      "Skipping fully_connected_blocks.1.0.weight:  loaded size:torch.Size([94, 128]) != model size:  torch.Size([94, 256])\n",
      "Loaded: fully_connected_blocks.1.0.bias\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 94]                   --\n",
      "ModuleList: 1-1                        --                        --\n",
      "    Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "        Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "        Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "        BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "        LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "        Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "        Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "        BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "        LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "    Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "        Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "        Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "        BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "        LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "        Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "        Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "        BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "        LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "    Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "        Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "        Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "        BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "        LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "        Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "        Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "        BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "        LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "    Sequential: 2-4                   [1, 64, 4, 4]             --\n",
      "        Conv2d: 3-25                 [1, 64, 8, 8]             18,496\n",
      "        Dropout2d: 3-26              [1, 64, 8, 8]             --\n",
      "        BatchNorm2d: 3-27            [1, 64, 8, 8]             128\n",
      "        LeakyReLU: 3-28              [1, 64, 8, 8]             --\n",
      "        Conv2d: 3-29                 [1, 64, 4, 4]             36,928\n",
      "        Dropout2d: 3-30              [1, 64, 4, 4]             --\n",
      "        BatchNorm2d: 3-31            [1, 64, 4, 4]             128\n",
      "        LeakyReLU: 3-32              [1, 64, 4, 4]             --\n",
      "Sequential: 1-2                        [1, 1024]                 --\n",
      "    Flatten: 2-5                      [1, 1024]                 --\n",
      "ModuleList: 1-3                        --                        --\n",
      "    Sequential: 2-6                   [1, 256]                  --\n",
      "        Linear: 3-33                 [1, 256]                  262,400\n",
      "        Dropout: 3-34                [1, 256]                  --\n",
      "        LeakyReLU: 3-35              [1, 256]                  --\n",
      "    Sequential: 2-7                   [1, 94]                   --\n",
      "        Linear: 3-36                 [1, 94]                   24,158\n",
      "==========================================================================================\n",
      "Total params: 377,422\n",
      "Trainable params: 377,422\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 15.17\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.21\n",
      "Params size (MB): 1.51\n",
      "Estimated Total Size (MB): 3.74\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_model_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"conv_features\": (1, 16, 32, 32, 64),\n",
    "        \"fully_connected_features\": (256, len(all_label_classes)),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.15,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": LOAD_CHECKPOINT\n",
    "    }\n",
    "]\n",
    "\n",
    "all_optim_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"lr\": 0.0007224,\n",
    "        \"weight_decay\": 1\n",
    "    }\n",
    "]\n",
    "\n",
    "AllCNN2D(**all_model_parameters[0])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.6535841822624207\n",
      "Val Accuracy        : 0.686121940612793\n",
      "Loss                : 0.0751764178276062\n",
      "Val Loss            : 0.06670589745044708\n",
      "Learning Rate       : 0.0006140399999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...:  63%|   | 122/193 [00:22<00:12,  5.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_output\n\u001b[0;32m      3\u001b[0m epoch_log: EpochLogs\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_log \u001b[38;5;129;01min\u001b[39;00m grid_search(\n\u001b[0;32m      5\u001b[0m     model_factory\u001b[38;5;241m=\u001b[39mAllCNN2D,\n\u001b[0;32m      6\u001b[0m     all_model_parameters\u001b[38;5;241m=\u001b[39mall_model_parameters,\n\u001b[0;32m      7\u001b[0m     optim_factory\u001b[38;5;241m=\u001b[39mAdamW,\n\u001b[0;32m      8\u001b[0m     all_optim_params\u001b[38;5;241m=\u001b[39mall_optim_parameters,\n\u001b[0;32m      9\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[0;32m     10\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),\n\u001b[0;32m     11\u001b[0m     train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m     12\u001b[0m     val_dataloader\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[0;32m     13\u001b[0m     lr_decay_window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     14\u001b[0m     lr_decay_minimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m     15\u001b[0m     scheduler_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m,\n\u001b[0;32m     16\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m ):\n\u001b[0;32m     20\u001b[0m     clear_output()\n\u001b[0;32m     21\u001b[0m     train_logpoints: \u001b[38;5;28mlist\u001b[39m[LogPoint] \u001b[38;5;241m=\u001b[39m epoch_log\u001b[38;5;241m.\u001b[39mtrain_logs\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\training\\train.py:334\u001b[0m, in \u001b[0;36mgrid_search\u001b[1;34m(model_factory, all_model_parameters, optim_factory, all_optim_params, epochs, criterion, train_dataloader, val_dataloader, lr_decay_window_size, lr_decay_minimum, scheduler_scale, device, compile_model)\u001b[0m\n\u001b[0;32m    331\u001b[0m optimiser_loss: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m model_optimiser\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    333\u001b[0m train_log: LogPoint\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_log \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m    335\u001b[0m     train(\n\u001b[0;32m    336\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    337\u001b[0m         optimiser\u001b[38;5;241m=\u001b[39mmodel_optimiser,\n\u001b[0;32m    338\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[0;32m    339\u001b[0m         train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m    340\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m    341\u001b[0m     ),\n\u001b[0;32m    342\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    343\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[0;32m    344\u001b[0m ):\n\u001b[0;32m    345\u001b[0m     epoch_train_logs\u001b[38;5;241m.\u001b[39mappend(train_log)\n\u001b[0;32m    346\u001b[0m     epoch_cur_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m    347\u001b[0m         train_log\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach(\n\u001b[0;32m    348\u001b[0m         )\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    349\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\training\\train.py:258\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimiser, criterion, train_dataloader, device)\u001b[0m\n\u001b[0;32m    256\u001b[0m X: Tensor\n\u001b[0;32m    257\u001b[0m y: Tensor\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m    260\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m    262\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:102\u001b[0m, in \u001b[0;36mCharImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     99\u001b[0m image \u001b[38;5;241m=\u001b[39m reduce(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc h w -> 1 h w\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Apply random transformations\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_random_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# One-hot encode the label\u001b[39;00m\n\u001b[0;32m    107\u001b[0m one_hot_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_set),\n\u001b[0;32m    109\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m    110\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:201\u001b[0m, in \u001b[0;36mCharImageDataset._apply_random_transformations\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Apply GaussianBlur\u001b[39;00m\n\u001b[0;32m    194\u001b[0m gaussian_blur \u001b[38;5;241m=\u001b[39m GaussianBlur(\n\u001b[0;32m    195\u001b[0m     kernel_size\u001b[38;5;241m=\u001b[39mkernel_size,\n\u001b[0;32m    196\u001b[0m     sigma\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[0;32m    200\u001b[0m )\n\u001b[1;32m--> 201\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Adjust for thickening or thinning\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m thicken_thinning_sigma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;66;03m# Thickening: Increase the character's size by lowering the threshold\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:1812\u001b[0m, in \u001b[0;36mGaussianBlur.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;124;03m    img (PIL Image or Tensor): image to be blurred.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1809\u001b[0m \u001b[38;5;124;03m    PIL Image or Tensor: Gaussian blurred image\u001b[39;00m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1811\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m-> 1812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:1380\u001b[0m, in \u001b[0;36mgaussian_blur\u001b[1;34m(img, kernel_size, sigma)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be PIL Image or Tensor. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1378\u001b[0m     t_img \u001b[38;5;241m=\u001b[39m pil_to_tensor(img)\n\u001b[1;32m-> 1380\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1383\u001b[0m     output \u001b[38;5;241m=\u001b[39m to_pil_image(output, mode\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mmode)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:761\u001b[0m, in \u001b[0;36mgaussian_blur\u001b[1;34m(img, kernel_size, sigma)\u001b[0m\n\u001b[0;32m    759\u001b[0m padding \u001b[38;5;241m=\u001b[39m [kernel_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    760\u001b[0m img \u001b[38;5;241m=\u001b[39m torch_pad(img, padding, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 761\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    763\u001b[0m img \u001b[38;5;241m=\u001b[39m _cast_squeeze_out(img, need_cast, need_squeeze, out_dtype)\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "epoch_log: EpochLogs\n",
    "for epoch_log in grid_search(\n",
    "    model_factory=AllCNN2D,\n",
    "    all_model_parameters=all_model_parameters,\n",
    "    optim_factory=AdamW,\n",
    "    all_optim_params=all_optim_parameters,\n",
    "    epochs=10000,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    lr_decay_window_size=10,\n",
    "    lr_decay_minimum=0.0,\n",
    "    scheduler_scale=0.85,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \n",
    "    \n",
    "    clear_output()\n",
    "    train_logpoints: list[LogPoint] = epoch_log.train_logs\n",
    "    val_logpoints: list[LogPoint] = epoch_log.val_logs\n",
    "\n",
    "    train_count: int = 0\n",
    "    val_count: int = 0\n",
    "\n",
    "    train_losses_tally: float = 0.0\n",
    "    val_losses_tally: float = 0.0\n",
    "\n",
    "    train_correct_tally: int = 0\n",
    "    val_correct_tally: int = 0\n",
    "\n",
    "    for log_point in train_logpoints:\n",
    "\n",
    "        y_hat_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y_hat,\n",
    "            axis=-1\n",
    "        ).detach().cpu()\n",
    "\n",
    "        y_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y, axis=-1\n",
    "        ).detach().cpu()\n",
    "\n",
    "        train_is_correct = y_hat_pred == y_pred\n",
    "        train_correct_tally += torch.sum(train_is_correct)\n",
    "\n",
    "        train_losses_tally += torch.sum(log_point.loss)\n",
    "\n",
    "        train_count += len(y_hat_pred)\n",
    "\n",
    "    for log_point in val_logpoints:\n",
    "\n",
    "        y_hat_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y_hat,\n",
    "            axis=-1\n",
    "        ).detach().cpu()\n",
    "\n",
    "        y_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y, axis=-1\n",
    "        ).detach().cpu()\n",
    "        #print(y_hat_pred, y_pred)\n",
    "        val_correct_tally += torch.sum(y_hat_pred == y_pred)\n",
    "\n",
    "        val_losses_tally += torch.sum(log_point.loss)\n",
    "\n",
    "        val_count += len(y_hat_pred)\n",
    "\n",
    "    train_accuracy: float = train_correct_tally/train_count\n",
    "    val_accuracy: float = val_correct_tally/val_count if val_count > 0 else 0.0\n",
    "\n",
    "    train_loss: float = train_losses_tally/train_count\n",
    "    val_loss: float = val_losses_tally/val_count if val_count > 0 else 0.0\n",
    "\n",
    "    cur_learning_rate: float = epoch_log.optimiser.param_groups[0][\"lr\"]\n",
    "\n",
    "    model_checkpoint_path: str = os.path.join(\n",
    "        model_save_dirpath,\n",
    "        f\"{MODEL_NAME}_epoch{epoch_log.epoch}_trainacc{train_accuracy:.5}_valacc{val_accuracy:.5}_Tloss{train_loss:.5}_Vloss{val_loss:.5}_lr{cur_learning_rate}.pkl\"\n",
    "    )\n",
    "\n",
    "    with open(model_checkpoint_path, \"wb\") as f:\n",
    "        torch.save(epoch_log.model.state_dict(), f)\n",
    "\n",
    "    print(f\"Train Accuracy      : {train_accuracy}\")\n",
    "    print(f\"Val Accuracy        : {val_accuracy}\")\n",
    "    print(f\"Loss                : {train_loss}\")\n",
    "    print(f\"Val Loss            : {val_loss}\")\n",
    "    print(f\"Learning Rate       : {cur_learning_rate}\")\n",
    "\n",
    "    log(\n",
    "        epoch_log.epoch,\n",
    "        train_accuracy,\n",
    "        train_loss,\n",
    "        val_accuracy,\n",
    "        val_loss,\n",
    "        cur_learning_rate\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.0.weight\n",
      "Loaded: encoder_conv_blocks.1.0.bias\n",
      "Loaded: encoder_conv_blocks.1.2.weight\n",
      "Loaded: encoder_conv_blocks.1.2.bias\n",
      "Loaded: encoder_conv_blocks.1.2.running_mean\n",
      "Loaded: encoder_conv_blocks.1.2.running_var\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.4.weight\n",
      "Loaded: encoder_conv_blocks.1.4.bias\n",
      "Loaded: encoder_conv_blocks.1.6.weight\n",
      "Loaded: encoder_conv_blocks.1.6.bias\n",
      "Loaded: encoder_conv_blocks.1.6.running_mean\n",
      "Loaded: encoder_conv_blocks.1.6.running_var\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.0.weight\n",
      "Loaded: encoder_conv_blocks.2.0.bias\n",
      "Loaded: encoder_conv_blocks.2.2.weight\n",
      "Loaded: encoder_conv_blocks.2.2.bias\n",
      "Loaded: encoder_conv_blocks.2.2.running_mean\n",
      "Loaded: encoder_conv_blocks.2.2.running_var\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.4.weight\n",
      "Loaded: encoder_conv_blocks.2.4.bias\n",
      "Loaded: encoder_conv_blocks.2.6.weight\n",
      "Loaded: encoder_conv_blocks.2.6.bias\n",
      "Loaded: encoder_conv_blocks.2.6.running_mean\n",
      "Loaded: encoder_conv_blocks.2.6.running_var\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.0.weight\n",
      "Loaded: encoder_conv_blocks.3.0.bias\n",
      "Loaded: encoder_conv_blocks.3.2.weight\n",
      "Loaded: encoder_conv_blocks.3.2.bias\n",
      "Loaded: encoder_conv_blocks.3.2.running_mean\n",
      "Loaded: encoder_conv_blocks.3.2.running_var\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.4.weight\n",
      "Loaded: encoder_conv_blocks.3.4.bias\n",
      "Loaded: encoder_conv_blocks.3.6.weight\n",
      "Loaded: encoder_conv_blocks.3.6.bias\n",
      "Loaded: encoder_conv_blocks.3.6.running_mean\n",
      "Loaded: encoder_conv_blocks.3.6.running_var\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.0.weight\n",
      "Loaded: encoder_conv_blocks.4.0.bias\n",
      "Loaded: encoder_conv_blocks.4.2.weight\n",
      "Loaded: encoder_conv_blocks.4.2.bias\n",
      "Loaded: encoder_conv_blocks.4.2.running_mean\n",
      "Loaded: encoder_conv_blocks.4.2.running_var\n",
      "Loaded: encoder_conv_blocks.4.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.4.weight\n",
      "Loaded: encoder_conv_blocks.4.4.bias\n",
      "Loaded: encoder_conv_blocks.4.6.weight\n",
      "Loaded: encoder_conv_blocks.4.6.bias\n",
      "Loaded: encoder_conv_blocks.4.6.running_mean\n",
      "Loaded: encoder_conv_blocks.4.6.running_var\n",
      "Loaded: encoder_conv_blocks.4.6.num_batches_tracked\n",
      "Loaded: fully_connected_blocks.0.0.weight\n",
      "Loaded: fully_connected_blocks.0.0.bias\n",
      "Loaded: fully_connected_blocks.1.0.weight\n",
      "Loaded: fully_connected_blocks.1.0.bias\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 44]                   --\n",
      "ModuleList: 1-1                        --                        --\n",
      "    Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "        Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "        Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "        BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "        LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "        Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "        Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "        BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "        LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "    Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "        Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "        Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "        BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "        LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "        Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "        Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "        BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "        LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "    Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "        Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "        Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "        BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "        LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "        Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "        Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "        BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "        LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "    Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "        Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
      "        Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "        BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
      "        LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "        Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
      "        Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "        BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
      "        LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "    Sequential: 2-5                   [1, 32, 2, 2]             --\n",
      "        Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
      "        Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
      "        BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
      "        LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
      "        Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
      "        Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
      "        BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
      "        LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
      "Sequential: 1-2                        [1, 128]                  --\n",
      "    Flatten: 2-6                      [1, 128]                  --\n",
      "ModuleList: 1-3                        --                        --\n",
      "    Sequential: 2-7                   [1, 64]                   --\n",
      "        Linear: 3-41                 [1, 64]                   8,256\n",
      "        Dropout: 3-42                [1, 64]                   --\n",
      "        LeakyReLU: 3-43              [1, 64]                   --\n",
      "    Sequential: 2-8                   [1, 44]                   --\n",
      "        Linear: 3-44                 [1, 44]                   2,860\n",
      "==========================================================================================\n",
      "Total params: 83,548\n",
      "Trainable params: 83,548\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 14.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.18\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 2.53\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model: AllCNN2D = AllCNN2D(\n",
    "    **{\n",
    "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
    "        \"fully_connected_features\": (64, 44),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.0,  # 0.075,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\models\\allcnn\\Indigo_epoch26_trainacc0.71327_valacc0.99057_Tloss0.072851_Vloss0.0056362_lr0.0007224999999999999.pkl\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m char, label \u001b[38;5;129;01min\u001b[39;00m val_char_dataset:\n\u001b[0;32m      2\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(char[\u001b[38;5;241m0\u001b[39m, :, :])\n\u001b[0;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:100\u001b[0m, in \u001b[0;36mCharImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     97\u001b[0m image \u001b[38;5;241m=\u001b[39m reduce(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc h w -> 1 h w\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Apply random transformations\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_random_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# One-hot encode the label\u001b[39;00m\n\u001b[0;32m    105\u001b[0m one_hot_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_set),\n\u001b[0;32m    107\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m    108\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:128\u001b[0m, in \u001b[0;36mCharImageDataset._apply_random_transformations\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Pad the image to prevent cropping during transformations\u001b[39;00m\n\u001b[0;32m    127\u001b[0m pad_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Adjust padding size as needed\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Random rotation\u001b[39;00m\n\u001b[0;32m    131\u001b[0m rotation_angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m365\u001b[39m,\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m365\u001b[39m\n\u001b[0;32m    134\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: pad() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "for char, label in val_char_dataset:\n",
    "    plt.imshow(char[0, :, :])\n",
    "    plt.show()\n",
    "    pred: torch.Tensor = model.forward(char.unsqueeze(0)).squeeze()\n",
    "    pred_index: int = torch.argmax(pred).item()\n",
    "    print(chr(int(all_label_classes[pred_index][1:], base=16)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
