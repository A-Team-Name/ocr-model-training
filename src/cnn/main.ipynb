{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from typing import Any\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import EpochLogs, grid_search, LogPoint\n",
    "from dataset.character_dataset import CharImageDataset\n",
    "from models.allcnn2d import AllCNN2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SPLIT: float = 0.8\n",
    "MODEL_NAME: str = \"GeckoFull\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths\n",
    "Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir: str = os.path.abspath(\".\")\n",
    "root_dir: str = os.path.join(\n",
    "    notebook_dir,\n",
    "    os.pardir,\n",
    "    os.pardir\n",
    ")\n",
    "\n",
    "data_dir: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"data\",\n",
    "    \"lambda\"\n",
    ")\n",
    "\n",
    "model_save_dirpath: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"models\",\n",
    "    \"allcnn\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_path_glob: str = os.path.join(\n",
    "    data_dir,\n",
    "    \"u*.png\"\n",
    ")\n",
    "images_path_regex: str = r\"(u[0-9a-fA-F]+)-([0-9]+)\\.png\"\n",
    "\n",
    "image_paths: list[str] = glob.glob(images_path_glob)\n",
    "random.shuffle(image_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging_path: str = f\"{MODEL_NAME}_log_{get_current_time()}.csv\"\n",
    "\n",
    "with open(logging_path, \"w\") as f:\n",
    "    f.write(\"TIME,EPOCH,TRAIN_ACC,VAL_ACC,TRAIN_LOSS,VAL_LOSS,LR\\n\")\n",
    "\n",
    "def log(\n",
    "    epoch: int,\n",
    "    train_acc: float, \n",
    "    train_loss: float, \n",
    "    val_acc: float, \n",
    "    val_loss, \n",
    "    lr: float\n",
    ")-> None:\n",
    "    with open(logging_path, \"a\") as f:\n",
    "        f.write(f\"{get_current_time()},{epoch},{train_acc},{val_acc},{train_loss},{val_loss},{lr}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labeled_image_paths: list[tuple[str, str]] = []\n",
    "\n",
    "class_counts: dict[str, int] = defaultdict(lambda: 0)\n",
    "\n",
    "file_path: str\n",
    "for file_path in image_paths:\n",
    "    match = re.search(images_path_regex, file_path)\n",
    "    \n",
    "    if not match:\n",
    "        continue\n",
    "    \n",
    "    u_hexvalue: str = match.group(1)\n",
    "    \n",
    "    class_counts[u_hexvalue] += 1\n",
    "    \n",
    "    \n",
    "    labeled_image_paths.append((u_hexvalue, file_path))\n",
    "\n",
    "labels: list[str]\n",
    "image_paths: list[str]\n",
    "labels, image_paths =  list(zip(*labeled_image_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts: list[tuple[str, int]] = sorted(\n",
    "    class_counts.items(), \n",
    "    key=lambda x: x[0]\n",
    ")\n",
    "\n",
    "total_items = sum(x[1] for x in sorted_counts)\n",
    "\n",
    "class_proportions: list[tuple[str, int]] = [\n",
    "    (pair[0], pair[1]/total_items) \n",
    "    for pair in sorted_counts\n",
    "]\n",
    "\n",
    "class_weights: list[float] = [1.0 / p[1] for p in class_proportions]\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "weights_tensor: torch.Tensor = torch.tensor(class_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16.3542, 16.3542, 16.0204, 65.4167, 16.0204, 65.4167, 16.0204, 65.4167,\n",
       "        65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 16.0204,\n",
       "        16.0204, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167,\n",
       "        65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167,\n",
       "        65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167, 65.4167,\n",
       "        65.4167, 65.4167, 65.4167, 65.4167])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_index: int = int(len(image_paths)*DATASET_SPLIT)\n",
    "all_label_classes: list[str] = list(set(labels))\n",
    "\n",
    "train_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=image_paths[:split_index],\n",
    "    labels=labels[:split_index],\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.02,\n",
    "    translation_limit=0.2,\n",
    "    skew_limit=0.06,\n",
    "    zoom_change=0.35,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "val_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=image_paths[split_index:],\n",
    "    labels=labels[split_index:],\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.0,\n",
    "    translation_limit=0.0,\n",
    "    skew_limit=0.00,\n",
    "    zoom_change=0.0,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in train_char_dataset:\n",
    "    plt.imshow(\n",
    "        rearrange(im, \"1 h w -> h w\")*255, \n",
    "        cmap=\"gray\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGfCAYAAAAZGgYhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcb0lEQVR4nO3dbWxUZf7/8U9r27FQOoUiM+3SsjWiFREWi5QJGhOZtTHGoDSGbDRLXKMBi3LjA+0D0E1WSySuPzEI3uyqiTdduwkqJsiSIjWaglAlopAK2my7wkzXjT1Tu/QmzPV/sP+d7Ch30xa/neH9Sr6JPefM9LokmXemPW2znHNOAAD8zLKtFwAAuDARIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImc8/XEmzZt0oYNGxSJRDR79mw9++yzmjdv3lkfF4/HdezYMU2YMEFZWVnna3kAgPPEOafe3l6VlpYqO/sM73PcedDY2Ojy8vLcn//8Z/fll1+6e++91xUVFbloNHrWx3Z1dTlJDMMwTJpPV1fXGV/vz0uA5s2b5+rq6hIfnzx50pWWlrqGhoazPranp8f8fxrDMAwz8unp6Tnj6/2ofw9ocHBQbW1tCofDiWPZ2dkKh8NqbW39yfUDAwOKxWKJ6e3tHe0lAQAMnO3bKKMeoO+++04nT55UIBBIOh4IBBSJRH5yfUNDg/x+f2LKyspGe0kAgDHI/C64+vp6eZ6XmK6uLuslAQB+BqN+F9zkyZN10UUXKRqNJh2PRqMKBoM/ud7n88nn8432MgAAY9yovwPKy8tTVVWVmpubE8fi8biam5sVCoVG+9MBANLUefk5oDVr1mjp0qWaO3eu5s2bp//7v/9TX1+f7r777vPx6QAAaei8BGjJkiX65z//qXXr1ikSiehXv/qV3n///Z/cmAAAuHBlOeec9SL+VywWk9/vt14GAGCEPM9TYWHhac+b3wUHALgwESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATKQfoww8/1K233qrS0lJlZWXp7bffTjrvnNO6detUUlKi/Px8hcNhHTlyZLTWCwDIECkHqK+vT7Nnz9amTZtOef7JJ5/Uxo0btWXLFu3du1fjx49XTU2N+vv7R7xYAEAGcSMgyW3dujXxcTwed8Fg0G3YsCFxrKenx/l8Pvfmm2+e8jn6+/ud53mJ6erqcpIYhmGYNB/P887YkFH9HlBHR4cikYjC4XDimN/vV3V1tVpbW0/5mIaGBvn9/sSUlZWN5pIAAGPUqAYoEolIkgKBQNLxQCCQOPdj9fX18jwvMV1dXaO5JADAGJVjvQCfzyefz2e9DADAz2xU3wEFg0FJUjQaTToejUYT5wAAkEY5QBUVFQoGg2pubk4ci8Vi2rt3r0Kh0Gh+KgBAmkv5S3A//PCDjh49mvi4o6NDBw4c0KRJk1ReXq5Vq1bpD3/4g6ZPn66KigqtXbtWpaWluu2220Zz3QCAdJfqrdcffPDBKW+3W7p0aeJW7LVr17pAIOB8Pp9buHCha29vP+fn9zzP/NZBhmEYZuRzttuws5xzTmNILBaT3++3XgYAYIQ8z1NhYeFpz/O74AAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEykFKCGhgZde+21mjBhgqZMmaLbbrtN7e3tSdf09/errq5OxcXFKigoUG1traLR6KguGgCQ/lIKUEtLi+rq6rRnzx7t3LlTQ0NDuummm9TX15e4ZvXq1dq2bZuamprU0tKiY8eOafHixaO+cABAmnMj0N3d7SS5lpYW55xzPT09Ljc31zU1NSWuOXz4sJPkWltbz+k5Pc9zkhiGYZg0H8/zzvh6P6LvAXmeJ0maNGmSJKmtrU1DQ0MKh8OJayorK1VeXq7W1tZTPsfAwIBisVjSAAAy37ADFI/HtWrVKi1YsEAzZ86UJEUiEeXl5amoqCjp2kAgoEgkcsrnaWhokN/vT0xZWdlwlwQASCPDDlBdXZ2++OILNTY2jmgB9fX18jwvMV1dXSN6PgBAesgZzoNWrFih9957Tx9++KGmTp2aOB4MBjU4OKienp6kd0HRaFTBYPCUz+Xz+eTz+YazDABAGkvpHZBzTitWrNDWrVu1a9cuVVRUJJ2vqqpSbm6umpubE8fa29vV2dmpUCg0OisGAGSElN4B1dXV6Y033tA777yjCRMmJL6v4/f7lZ+fL7/fr3vuuUdr1qzRpEmTVFhYqAceeEChUEjz588/LxsAAKSpVG671mlutXv55ZcT15w4ccLdf//9buLEiW7cuHHu9ttvd8ePHz/nz8Ft2AzDMJkxZ7sNO+v/h2XMiMVi8vv91ssAAIyQ53kqLCw87Xl+FxwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMJFSgDZv3qxZs2apsLBQhYWFCoVC2r59e+J8f3+/6urqVFxcrIKCAtXW1ioajY76ogEA6S+lAE2dOlXr169XW1ub9u/frxtvvFGLFi3Sl19+KUlavXq1tm3bpqamJrW0tOjYsWNavHjxeVk4ACDNuRGaOHGie+mll1xPT4/Lzc11TU1NiXOHDx92klxra+s5P5/neU4SwzAMk+bjed4ZX++H/T2gkydPqrGxUX19fQqFQmpra9PQ0JDC4XDimsrKSpWXl6u1tfW0zzMwMKBYLJY0AIDMl3KADh48qIKCAvl8Pi1btkxbt27VjBkzFIlElJeXp6KioqTrA4GAIpHIaZ+voaFBfr8/MWVlZSlvAgCQflIO0BVXXKEDBw5o7969Wr58uZYuXapDhw4NewH19fXyPC8xXV1dw34uAED6yEn1AXl5ebrsssskSVVVVdq3b5+eeeYZLVmyRIODg+rp6Ul6FxSNRhUMBk/7fD6fTz6fL/WVA2fgnDvna7Oyss7jSgCczoh/Digej2tgYEBVVVXKzc1Vc3Nz4lx7e7s6OzsVCoVG+mkAABkmpXdA9fX1uvnmm1VeXq7e3l698cYb2r17t3bs2CG/36977rlHa9as0aRJk1RYWKgHHnhAoVBI8+fPP1/rBwCkqZQC1N3drd/+9rc6fvy4/H6/Zs2apR07dujXv/61JOnpp59Wdna2amtrNTAwoJqaGj333HPnZeEAgPSW5VL5YvnPIBaLye/3Wy8DaY7vAQH2PM9TYWHhac/zu+AAACZSvgsOGEvG2Bt4ACngHRAAwAQBAgCYIEAAABMECABgggABAExwFxzS2ul+hudUd8fx8z7A2MI7IACACQIEADBBgAAAJggQAMAEAQIAmOAuOGQk7ngDxj7eAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEyMKEDr169XVlaWVq1alTjW39+vuro6FRcXq6CgQLW1tYpGoyNdJwAgwww7QPv27dPzzz+vWbNmJR1fvXq1tm3bpqamJrW0tOjYsWNavHjxiBcKAMgwbhh6e3vd9OnT3c6dO90NN9zgVq5c6Zxzrqenx+Xm5rqmpqbEtYcPH3aSXGtr6zk9t+d5ThLDMAyT5uN53hlf74f1Dqiurk633HKLwuFw0vG2tjYNDQ0lHa+srFR5eblaW1tP+VwDAwOKxWJJAwDIfDmpPqCxsVGffvqp9u3b95NzkUhEeXl5KioqSjoeCAQUiURO+XwNDQ36/e9/n+oyAABpLqV3QF1dXVq5cqVef/11XXzxxaOygPr6enmel5iurq5ReV4AwNiWUoDa2trU3d2ta665Rjk5OcrJyVFLS4s2btyonJwcBQIBDQ4OqqenJ+lx0WhUwWDwlM/p8/lUWFiYNACAzJfSl+AWLlyogwcPJh27++67VVlZqYcfflhlZWXKzc1Vc3OzamtrJUnt7e3q7OxUKBQavVUDANJeSgGaMGGCZs6cmXRs/PjxKi4uThy/5557tGbNGk2aNEmFhYV64IEHFAqFNH/+/NFbNQAg7aV8E8LZPP3008rOzlZtba0GBgZUU1Oj5557brQ/DQAgzWU555z1Iv5XLBaT3++3XgYAYIQ8zzvj9/X5XXAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwERKAXrssceUlZWVNJWVlYnz/f39qqurU3FxsQoKClRbW6toNDrqiwYApL+U3wFdddVVOn78eGI++uijxLnVq1dr27ZtampqUktLi44dO6bFixeP6oIBAJkhJ+UH5OQoGAz+5LjnefrTn/6kN954QzfeeKMk6eWXX9aVV16pPXv2aP78+ad8voGBAQ0MDCQ+jsViqS4JAJCGUn4HdOTIEZWWlurSSy/VnXfeqc7OTklSW1ubhoaGFA6HE9dWVlaqvLxcra2tp32+hoYG+f3+xJSVlQ1jGwCAdJNSgKqrq/XKK6/o/fff1+bNm9XR0aHrr79evb29ikQiysvLU1FRUdJjAoGAIpHIaZ+zvr5enuclpqura1gbAQCkl5S+BHfzzTcn/nvWrFmqrq7WtGnT9NZbbyk/P39YC/D5fPL5fMN6LAAgfY3oNuyioiJdfvnlOnr0qILBoAYHB9XT05N0TTQaPeX3jAAAF7YRBeiHH37Q119/rZKSElVVVSk3N1fNzc2J8+3t7ers7FQoFBrxQgEAGcal4KGHHnK7d+92HR0d7uOPP3bhcNhNnjzZdXd3O+ecW7ZsmSsvL3e7du1y+/fvd6FQyIVCoVQ+hfM8z0liGIZh0nw8zzvj631K3wP6xz/+od/85jf617/+pUsuuUTXXXed9uzZo0suuUSS9PTTTys7O1u1tbUaGBhQTU2NnnvuuVQ+BQDgApHlnHPWi/hfsVhMfr/fehkAgBHyPE+FhYWnPc/vggMAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADCRcoC+/fZb3XXXXSouLlZ+fr6uvvpq7d+/P3HeOad169appKRE+fn5CofDOnLkyKguGgCQ/lIK0Pfff68FCxYoNzdX27dv16FDh/TUU09p4sSJiWuefPJJbdy4UVu2bNHevXs1fvx41dTUqL+/f9QXDwBIYy4FDz/8sLvuuutOez4ej7tgMOg2bNiQONbT0+N8Pp978803z+lzeJ7nJDEMwzBpPp7nnfH1PqV3QO+++67mzp2rO+64Q1OmTNGcOXP04osvJs53dHQoEokoHA4njvn9flVXV6u1tfWUzzkwMKBYLJY0AIDMl1KAvvnmG23evFnTp0/Xjh07tHz5cj344IN69dVXJUmRSESSFAgEkh4XCAQS536soaFBfr8/MWVlZcPZBwAgzaQUoHg8rmuuuUZPPPGE5syZo/vuu0/33nuvtmzZMuwF1NfXy/O8xHR1dQ37uQAA6SOlAJWUlGjGjBlJx6688kp1dnZKkoLBoCQpGo0mXRONRhPnfszn86mwsDBpAACZL6UALViwQO3t7UnHvvrqK02bNk2SVFFRoWAwqObm5sT5WCymvXv3KhQKjcJyAQAZ49zuf/uPTz75xOXk5LjHH3/cHTlyxL3++utu3Lhx7rXXXktcs379eldUVOTeeecd9/nnn7tFixa5iooKd+LECe6CYxiGuYDmbHfBpRQg55zbtm2bmzlzpvP5fK6ystK98MILSefj8bhbu3atCwQCzufzuYULF7r29vZzfn4CxDAMkxlztgBlOeecxpBYLCa/32+9DADACHmed8bv6/O74AAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE2MuQGPsd6MCAIbpbK/nYy5Avb291ksAAIyCs72ej7k/xxCPx3Xs2DFNmDBBvb29KisrU1dXV0b/qe5YLMY+M8SFsEeJfWaa0d6nc069vb0qLS1Vdvbp3+fkjPgzjbLs7GxNnTpVkpSVlSVJKiwszOh//P9in5njQtijxD4zzWju81z+rtuY+xIcAODCQIAAACbGdIB8Pp8effRR+Xw+66WcV+wzc1wIe5TYZ6ax2ueYuwkBAHBhGNPvgAAAmYsAAQBMECAAgAkCBAAwQYAAACbGdIA2bdqkX/7yl7r44otVXV2tTz75xHpJI/Lhhx/q1ltvVWlpqbKysvT2228nnXfOad26dSopKVF+fr7C4bCOHDlis9hhamho0LXXXqsJEyZoypQpuu2229Te3p50TX9/v+rq6lRcXKyCggLV1tYqGo0arXh4Nm/erFmzZiV+cjwUCmn79u2J85mwxx9bv369srKytGrVqsSxTNjnY489pqysrKSprKxMnM+EPf7Xt99+q7vuukvFxcXKz8/X1Vdfrf379yfO/9yvQWM2QH/5y1+0Zs0aPfroo/r00081e/Zs1dTUqLu723ppw9bX16fZs2dr06ZNpzz/5JNPauPGjdqyZYv27t2r8ePHq6amRv39/T/zSoevpaVFdXV12rNnj3bu3KmhoSHddNNN6uvrS1yzevVqbdu2TU1NTWppadGxY8e0ePFiw1WnburUqVq/fr3a2tq0f/9+3XjjjVq0aJG+/PJLSZmxx/+1b98+Pf/885o1a1bS8UzZ51VXXaXjx48n5qOPPkqcy5Q9fv/991qwYIFyc3O1fft2HTp0SE899ZQmTpyYuOZnfw1yY9S8efNcXV1d4uOTJ0+60tJS19DQYLiq0SPJbd26NfFxPB53wWDQbdiwIXGsp6fH+Xw+9+abbxqscHR0d3c7Sa6lpcU595895ebmuqampsQ1hw8fdpJca2ur1TJHxcSJE91LL72UcXvs7e1106dPdzt37nQ33HCDW7lypXMuc/4tH330UTd79uxTnsuUPTrn3MMPP+yuu+660563eA0ak++ABgcH1dbWpnA4nDiWnZ2tcDis1tZWw5WdPx0dHYpEIkl79vv9qq6uTus9e54nSZo0aZIkqa2tTUNDQ0n7rKysVHl5edru8+TJk2psbFRfX59CoVDG7bGurk633HJL0n6kzPq3PHLkiEpLS3XppZfqzjvvVGdnp6TM2uO7776ruXPn6o477tCUKVM0Z84cvfjii4nzFq9BYzJA3333nU6ePKlAIJB0PBAIKBKJGK3q/PrvvjJpz/F4XKtWrdKCBQs0c+ZMSf/ZZ15enoqKipKuTcd9Hjx4UAUFBfL5fFq2bJm2bt2qGTNmZNQeGxsb9emnn6qhoeEn5zJln9XV1XrllVf0/vvva/Pmzero6ND111+v3t7ejNmjJH3zzTfavHmzpk+frh07dmj58uV68MEH9eqrr0qyeQ0ac3+OAZmjrq5OX3zxRdLX0zPJFVdcoQMHDsjzPP31r3/V0qVL1dLSYr2sUdPV1aWVK1dq586duvjii62Xc97cfPPNif+eNWuWqqurNW3aNL311lvKz883XNnoisfjmjt3rp544glJ0pw5c/TFF19oy5YtWrp0qcmaxuQ7oMmTJ+uiiy76yZ0m0WhUwWDQaFXn13/3lSl7XrFihd577z198MEHib/vJP1nn4ODg+rp6Um6Ph33mZeXp8suu0xVVVVqaGjQ7Nmz9cwzz2TMHtva2tTd3a1rrrlGOTk5ysnJUUtLizZu3KicnBwFAoGM2OePFRUV6fLLL9fRo0cz5t9SkkpKSjRjxoykY1deeWXiy40Wr0FjMkB5eXmqqqpSc3Nz4lg8Hldzc7NCoZDhys6fiooKBYPBpD3HYjHt3bs3rfbsnNOKFSu0detW7dq1SxUVFUnnq6qqlJubm7TP9vZ2dXZ2ptU+TyUej2tgYCBj9rhw4UIdPHhQBw4cSMzcuXN15513Jv47E/b5Yz/88IO+/vprlZSUZMy/pSQtWLDgJz8S8dVXX2natGmSjF6DzsutDaOgsbHR+Xw+98orr7hDhw65++67zxUVFblIJGK9tGHr7e11n332mfvss8+cJPfHP/7RffbZZ+7vf/+7c8659evXu6KiIvfOO++4zz//3C1atMhVVFS4EydOGK/83C1fvtz5/X63e/dud/z48cT8+9//TlyzbNkyV15e7nbt2uX279/vQqGQC4VChqtO3SOPPOJaWlpcR0eH+/zzz90jjzzisrKy3N/+9jfnXGbs8VT+9y445zJjnw899JDbvXu36+jocB9//LELh8Nu8uTJrru72zmXGXt0zrlPPvnE5eTkuMcff9wdOXLEvf76627cuHHutddeS1zzc78GjdkAOefcs88+68rLy11eXp6bN2+e27Nnj/WSRuSDDz5wkn4yS5cudc795zbItWvXukAg4Hw+n1u4cKFrb2+3XXSKTrU/Se7ll19OXHPixAl3//33u4kTJ7px48a522+/3R0/ftxu0cPwu9/9zk2bNs3l5eW5Sy65xC1cuDARH+cyY4+n8uMAZcI+lyxZ4kpKSlxeXp77xS9+4ZYsWeKOHj2aOJ8Je/yvbdu2uZkzZzqfz+cqKyvdCy+8kHT+534N4u8BAQBMjMnvAQEAMh8BAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT/w8BwNO9h4XiqgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in val_char_dataset:\n",
    "    plt.imshow(rearrange(im, \"1 h w -> h w\")*255, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader: DataLoader = DataLoader(\n",
    "    train_char_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "val_dataloader: DataLoader = DataLoader(\n",
    "    val_char_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_checkpoint_path: str = os.path.join(\n",
    "    model_save_dirpath,\n",
    "    \"Echo_epoch2056_trainacc0.97426_valacc1.0_Tloss0.0062137_Vloss0.00043838_lr2.026109453287853e-11.pkl\"\n",
    ")\n",
    "\n",
    "all_model_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
    "        \"fully_connected_features\": (64, 44),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.075,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": model_checkpoint_path\n",
    "    }\n",
    "]\n",
    "\n",
    "all_optim_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.0001\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.1.0.weight:  loaded size:torch.Size([16, 16, 3, 3]) != model size:  torch.Size([32, 16, 3, 3])\n",
      "Skipping encoder_conv_blocks.1.0.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.1.2.weight:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.1.2.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.1.2.running_mean:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.1.2.running_var:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.1.4.weight:  loaded size:torch.Size([16, 16, 3, 3]) != model size:  torch.Size([32, 32, 3, 3])\n",
      "Skipping encoder_conv_blocks.1.4.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.1.6.weight:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.1.6.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.1.6.running_mean:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.1.6.running_var:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.2.0.weight:  loaded size:torch.Size([16, 16, 3, 3]) != model size:  torch.Size([32, 32, 3, 3])\n",
      "Skipping encoder_conv_blocks.2.0.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.2.2.weight:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.2.2.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.2.2.running_mean:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.2.2.running_var:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.2.4.weight:  loaded size:torch.Size([16, 16, 3, 3]) != model size:  torch.Size([32, 32, 3, 3])\n",
      "Skipping encoder_conv_blocks.2.4.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.2.6.weight:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.2.6.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.2.6.running_mean:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.2.6.running_var:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.3.0.weight:  loaded size:torch.Size([16, 16, 3, 3]) != model size:  torch.Size([32, 32, 3, 3])\n",
      "Skipping encoder_conv_blocks.3.0.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.3.2.weight:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.3.2.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.3.2.running_mean:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.3.2.running_var:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.3.4.weight:  loaded size:torch.Size([16, 16, 3, 3]) != model size:  torch.Size([32, 32, 3, 3])\n",
      "Skipping encoder_conv_blocks.3.4.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.3.6.weight:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.3.6.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.3.6.running_mean:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.3.6.running_var:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.4.0.weight:  loaded size:torch.Size([16, 16, 3, 3]) != model size:  torch.Size([32, 32, 3, 3])\n",
      "Skipping encoder_conv_blocks.4.0.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.4.2.weight:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.4.2.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.4.2.running_mean:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.4.2.running_var:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Loaded: encoder_conv_blocks.4.2.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.4.4.weight:  loaded size:torch.Size([16, 16, 3, 3]) != model size:  torch.Size([32, 32, 3, 3])\n",
      "Skipping encoder_conv_blocks.4.4.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.4.6.weight:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.4.6.bias:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.4.6.running_mean:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Skipping encoder_conv_blocks.4.6.running_var:  loaded size:torch.Size([16]) != model size:  torch.Size([32])\n",
      "Loaded: encoder_conv_blocks.4.6.num_batches_tracked\n",
      "Skipping fully_connected_blocks.0.0.weight:  loaded size:torch.Size([7, 32]) != model size:  torch.Size([64, 128])\n",
      "Skipping fully_connected_blocks.0.0.bias:  loaded size:torch.Size([7]) != model size:  torch.Size([64])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 44]                   --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 32, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
      "│    │    └─Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
      "│    │    └─LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
      "├─Sequential: 1-2                        [1, 128]                  --\n",
      "│    └─Flatten: 2-6                      [1, 128]                  --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-7                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-41                 [1, 64]                   8,256\n",
      "│    │    └─Dropout: 3-42                [1, 64]                   --\n",
      "│    │    └─LeakyReLU: 3-43              [1, 64]                   --\n",
      "│    └─Sequential: 2-8                   [1, 44]                   --\n",
      "│    │    └─Linear: 3-44                 [1, 44]                   2,860\n",
      "==========================================================================================\n",
      "Total params: 83,548\n",
      "Trainable params: 83,548\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 14.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.18\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 2.53\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 40/40 [00:30<00:00,  1.31it/s]\n",
      "Validating Model...: 100%|██████████| 10/10 [00:07<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.0270700640976429\n",
      "Val Accuracy        : 0.05095541477203369\n",
      "Loss                : 10.51938247680664\n",
      "Val Loss            : 10.723649024963379\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 40/40 [00:30<00:00,  1.32it/s]\n",
      "Validating Model...: 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.08757961541414261\n",
      "Val Accuracy        : 0.06369426846504211\n",
      "Loss                : 10.358499526977539\n",
      "Val Loss            : 10.626496315002441\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 40/40 [00:30<00:00,  1.31it/s]\n",
      "Validating Model...: 100%|██████████| 10/10 [00:06<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.08757961541414261\n",
      "Val Accuracy        : 0.05095541477203369\n",
      "Loss                : 10.362889289855957\n",
      "Val Loss            : 10.265523910522461\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 40/40 [00:30<00:00,  1.31it/s]\n",
      "Validating Model...: 100%|██████████| 10/10 [00:06<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.0843949019908905\n",
      "Val Accuracy        : 0.10191082954406738\n",
      "Loss                : 10.178698539733887\n",
      "Val Loss            : 10.171270370483398\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...:  48%|████▊     | 19/40 [00:15<00:16,  1.25it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epoch_log: EpochLogs\n",
    "for epoch_log in grid_search(\n",
    "    model_factory=AllCNN2D,\n",
    "    all_model_parameters=all_model_parameters,\n",
    "    optim_factory=AdamW,\n",
    "    all_optim_params=all_optim_parameters,\n",
    "    epochs=10000,\n",
    "    criterion=nn.CrossEntropyLoss(weight=weights_tensor.to(device=\"cuda\")),\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    lr_decay_window_size=10,\n",
    "    lr_decay_minimum=0.0,\n",
    "    scheduler_scale=0.85,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    train_logpoints: list[LogPoint] = epoch_log.train_logs\n",
    "    val_logpoints: list[LogPoint] = epoch_log.val_logs\n",
    "    \n",
    "    \n",
    "    train_count: int = 0\n",
    "    val_count: int = 0\n",
    "    \n",
    "    train_losses_tally: float = 0.0\n",
    "    val_losses_tally: float = 0.0\n",
    "    \n",
    "    train_correct_tally: int = 0\n",
    "    val_correct_tally: int = 0\n",
    "    \n",
    "    for log_point in train_logpoints: \n",
    "        \n",
    "        y_hat_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y_hat, \n",
    "            axis=-1\n",
    "        ).detach().cpu()\n",
    "        \n",
    "        y_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y, axis=-1\n",
    "        ).detach().cpu()\n",
    "\n",
    "        train_correct_tally += torch.sum(y_hat_pred==y_pred)\n",
    "        \n",
    "        train_losses_tally += torch.sum(log_point.loss)\n",
    "        \n",
    "        train_count += len(y_hat_pred)\n",
    "        \n",
    "    for log_point in val_logpoints: \n",
    "        \n",
    "        y_hat_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y_hat, \n",
    "            axis=-1\n",
    "        ).detach().cpu()\n",
    "        \n",
    "        y_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y, axis=-1\n",
    "        ).detach().cpu()\n",
    "\n",
    "        val_correct_tally += torch.sum(y_hat_pred==y_pred)\n",
    "        \n",
    "        val_losses_tally += torch.sum(log_point.loss)\n",
    "        \n",
    "        val_count += len(y_hat_pred)\n",
    "        \n",
    "    train_accuracy: float = train_correct_tally/train_count\n",
    "    val_accuracy: float = val_correct_tally/val_count\n",
    "    \n",
    "    train_loss: float = train_losses_tally/train_count\n",
    "    val_loss: float = val_losses_tally/val_count\n",
    "    \n",
    "    cur_learning_rate: float = epoch_log.optimiser.param_groups[0][\"lr\"]\n",
    "    \n",
    "    model_checkpoint_path: str = os.path.join(\n",
    "        model_save_dirpath,\n",
    "        f\"{MODEL_NAME}_epoch{epoch_log.epoch}_trainacc{train_accuracy:.5}_valacc{val_accuracy:.5}_Tloss{train_loss:.5}_Vloss{val_loss:.5}_lr{cur_learning_rate}.pkl\"\n",
    "    )\n",
    "    \n",
    "    with open(model_checkpoint_path, \"wb\") as f:\n",
    "        torch.save(epoch_log.model.state_dict(), f)\n",
    "    \n",
    "    print(f\"Train Accuracy      : {train_accuracy}\")\n",
    "    print(f\"Val Accuracy        : {val_accuracy}\")\n",
    "    print(f\"Loss                : {train_loss}\")\n",
    "    print(f\"Val Loss            : {val_loss}\")\n",
    "    print(f\"Learning Rate       : {cur_learning_rate}\")\n",
    "    \n",
    "    log(\n",
    "        epoch_log.epoch,\n",
    "        train_accuracy,\n",
    "        train_loss,\n",
    "        val_accuracy,\n",
    "        val_loss,\n",
    "        cur_learning_rate\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
