{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from typing import Any\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import EpochLogs, grid_search, LogPoint\n",
    "from dataset.character_dataset import CharImageDataset\n",
    "from models.allcnn2d import AllCNN2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SPLIT: float = 0.8\n",
    "MODEL_NAME: str = \"FoxTrot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths\n",
    "Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir: str = os.path.abspath(\".\")\n",
    "root_dir: str = os.path.join(\n",
    "    notebook_dir,\n",
    "    os.pardir,\n",
    "    os.pardir\n",
    ")\n",
    "\n",
    "data_dir: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"data\",\n",
    "    \"lambda\"\n",
    ")\n",
    "\n",
    "model_save_dirpath: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"models\",\n",
    "    \"allcnn\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_path_glob: str = os.path.join(\n",
    "    data_dir,\n",
    "    \"u*.png\"\n",
    ")\n",
    "images_path_regex: str = r\"(u[0-9a-fA-F]+)-([0-9]+)\\.png\"\n",
    "\n",
    "image_paths: list[str] = glob.glob(images_path_glob)\n",
    "random.shuffle(image_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging_path: str = f\"{MODEL_NAME}_log_{get_current_time()}.csv\"\n",
    "\n",
    "with open(logging_path, \"w\") as f:\n",
    "    f.write(\"TIME,EPOCH,TRAIN_ACC,VAL_ACC,TRAIN_LOSS,VAL_LOSS,LR\\n\")\n",
    "\n",
    "def log(\n",
    "    epoch: int,\n",
    "    train_acc: float, \n",
    "    train_loss: float, \n",
    "    val_acc: float, \n",
    "    val_loss, \n",
    "    lr: float\n",
    ")-> None:\n",
    "    with open(logging_path, \"a\") as f:\n",
    "        f.write(f\"{get_current_time()},{epoch},{train_acc},{val_acc},{train_loss},{val_loss},{lr}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labeled_image_paths: list[tuple[str, str]] = []\n",
    "\n",
    "file_path: str\n",
    "for file_path in image_paths:\n",
    "    match = re.search(images_path_regex, file_path)\n",
    "    \n",
    "    if not match:\n",
    "        continue\n",
    "    \n",
    "    u_hexvalue: str = match.group(1)\n",
    "    labeled_image_paths.append((u_hexvalue, file_path))\n",
    "\n",
    "labels: list[str]\n",
    "image_paths: list[str]\n",
    "labels, image_paths =  list(zip(*labeled_image_paths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_index: int = int(len(image_paths)*DATASET_SPLIT)\n",
    "all_label_classes: list[str] = list(set(labels))\n",
    "\n",
    "train_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=image_paths[:split_index],\n",
    "    labels=labels[:split_index],\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.1,\n",
    "    translation_limit=0.2,\n",
    "    skew_limit=0.05,\n",
    "    zoom_change=0.35,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "val_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=image_paths[split_index:],\n",
    "    labels=labels[split_index:],\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.0,\n",
    "    translation_limit=0.0,\n",
    "    skew_limit=0.00,\n",
    "    zoom_change=0.0,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in train_char_dataset:\n",
    "    plt.imshow(rearrange(im, \"1 h w -> h w\")*255, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in val_char_dataset:\n",
    "    plt.imshow(rearrange(im, \"1 h w -> h w\")*255, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader: DataLoader = DataLoader(\n",
    "    train_char_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "val_dataloader: DataLoader = DataLoader(\n",
    "    val_char_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_checkpoint_path: str = os.path.join(\n",
    "    model_save_dirpath,\n",
    "    \"Echo_epoch10_trainacc0.61397_valacc0.84058.pkl\"\n",
    ")\n",
    "\n",
    "all_model_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"conv_features\": (1, 16, 16, 16, 16, 16, 16, 32),\n",
    "        \"fully_connected_features\": (7,),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.05,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": model_checkpoint_path\n",
    "    }\n",
    "]\n",
    "\n",
    "all_optim_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.0001\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.0.weight\n",
      "Loaded: encoder_conv_blocks.1.0.bias\n",
      "Loaded: encoder_conv_blocks.1.2.weight\n",
      "Loaded: encoder_conv_blocks.1.2.bias\n",
      "Loaded: encoder_conv_blocks.1.2.running_mean\n",
      "Loaded: encoder_conv_blocks.1.2.running_var\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.4.weight\n",
      "Loaded: encoder_conv_blocks.1.4.bias\n",
      "Loaded: encoder_conv_blocks.1.6.weight\n",
      "Loaded: encoder_conv_blocks.1.6.bias\n",
      "Loaded: encoder_conv_blocks.1.6.running_mean\n",
      "Loaded: encoder_conv_blocks.1.6.running_var\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.0.weight\n",
      "Loaded: encoder_conv_blocks.2.0.bias\n",
      "Loaded: encoder_conv_blocks.2.2.weight\n",
      "Loaded: encoder_conv_blocks.2.2.bias\n",
      "Loaded: encoder_conv_blocks.2.2.running_mean\n",
      "Loaded: encoder_conv_blocks.2.2.running_var\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.4.weight\n",
      "Loaded: encoder_conv_blocks.2.4.bias\n",
      "Loaded: encoder_conv_blocks.2.6.weight\n",
      "Loaded: encoder_conv_blocks.2.6.bias\n",
      "Loaded: encoder_conv_blocks.2.6.running_mean\n",
      "Loaded: encoder_conv_blocks.2.6.running_var\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.0.weight\n",
      "Loaded: encoder_conv_blocks.3.0.bias\n",
      "Loaded: encoder_conv_blocks.3.2.weight\n",
      "Loaded: encoder_conv_blocks.3.2.bias\n",
      "Loaded: encoder_conv_blocks.3.2.running_mean\n",
      "Loaded: encoder_conv_blocks.3.2.running_var\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.4.weight\n",
      "Loaded: encoder_conv_blocks.3.4.bias\n",
      "Loaded: encoder_conv_blocks.3.6.weight\n",
      "Loaded: encoder_conv_blocks.3.6.bias\n",
      "Loaded: encoder_conv_blocks.3.6.running_mean\n",
      "Loaded: encoder_conv_blocks.3.6.running_var\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.0.weight\n",
      "Loaded: encoder_conv_blocks.4.0.bias\n",
      "Loaded: encoder_conv_blocks.4.2.weight\n",
      "Loaded: encoder_conv_blocks.4.2.bias\n",
      "Loaded: encoder_conv_blocks.4.2.running_mean\n",
      "Loaded: encoder_conv_blocks.4.2.running_var\n",
      "Loaded: encoder_conv_blocks.4.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.4.weight\n",
      "Loaded: encoder_conv_blocks.4.4.bias\n",
      "Loaded: encoder_conv_blocks.4.6.weight\n",
      "Loaded: encoder_conv_blocks.4.6.bias\n",
      "Loaded: encoder_conv_blocks.4.6.running_mean\n",
      "Loaded: encoder_conv_blocks.4.6.running_var\n",
      "Loaded: encoder_conv_blocks.4.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.5.0.weight\n",
      "Loaded: encoder_conv_blocks.5.0.bias\n",
      "Loaded: encoder_conv_blocks.5.2.weight\n",
      "Loaded: encoder_conv_blocks.5.2.bias\n",
      "Loaded: encoder_conv_blocks.5.2.running_mean\n",
      "Loaded: encoder_conv_blocks.5.2.running_var\n",
      "Loaded: encoder_conv_blocks.5.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.5.4.weight\n",
      "Loaded: encoder_conv_blocks.5.4.bias\n",
      "Loaded: encoder_conv_blocks.5.6.weight\n",
      "Loaded: encoder_conv_blocks.5.6.bias\n",
      "Loaded: encoder_conv_blocks.5.6.running_mean\n",
      "Loaded: encoder_conv_blocks.5.6.running_var\n",
      "Loaded: encoder_conv_blocks.5.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.6.0.weight\n",
      "Loaded: encoder_conv_blocks.6.0.bias\n",
      "Loaded: encoder_conv_blocks.6.2.weight\n",
      "Loaded: encoder_conv_blocks.6.2.bias\n",
      "Loaded: encoder_conv_blocks.6.2.running_mean\n",
      "Loaded: encoder_conv_blocks.6.2.running_var\n",
      "Loaded: encoder_conv_blocks.6.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.6.4.weight\n",
      "Loaded: encoder_conv_blocks.6.4.bias\n",
      "Loaded: encoder_conv_blocks.6.6.weight\n",
      "Loaded: encoder_conv_blocks.6.6.bias\n",
      "Loaded: encoder_conv_blocks.6.6.running_mean\n",
      "Loaded: encoder_conv_blocks.6.6.running_var\n",
      "Loaded: encoder_conv_blocks.6.6.num_batches_tracked\n",
      "Loaded: fully_connected_blocks.0.0.weight\n",
      "Loaded: fully_connected_blocks.0.0.bias\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 7]                    --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 16, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-10              [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-12              [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 16, 16, 16]           2,320\n",
      "│    │    └─Dropout2d: 3-14              [1, 16, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 16, 16, 16]           32\n",
      "│    │    └─LeakyReLU: 3-16              [1, 16, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 16, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 16, 16, 16]           2,320\n",
      "│    │    └─Dropout2d: 3-18              [1, 16, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 16, 16, 16]           32\n",
      "│    │    └─LeakyReLU: 3-20              [1, 16, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 16, 8, 8]             2,320\n",
      "│    │    └─Dropout2d: 3-22              [1, 16, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 16, 8, 8]             32\n",
      "│    │    └─LeakyReLU: 3-24              [1, 16, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 16, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 16, 8, 8]             2,320\n",
      "│    │    └─Dropout2d: 3-26              [1, 16, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 16, 8, 8]             32\n",
      "│    │    └─LeakyReLU: 3-28              [1, 16, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 16, 4, 4]             2,320\n",
      "│    │    └─Dropout2d: 3-30              [1, 16, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 16, 4, 4]             32\n",
      "│    │    └─LeakyReLU: 3-32              [1, 16, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 16, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 16, 4, 4]             2,320\n",
      "│    │    └─Dropout2d: 3-34              [1, 16, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 16, 4, 4]             32\n",
      "│    │    └─LeakyReLU: 3-36              [1, 16, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 16, 2, 2]             2,320\n",
      "│    │    └─Dropout2d: 3-38              [1, 16, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 16, 2, 2]             32\n",
      "│    │    └─LeakyReLU: 3-40              [1, 16, 2, 2]             --\n",
      "│    └─Sequential: 2-6                   [1, 16, 1, 1]             --\n",
      "│    │    └─Conv2d: 3-41                 [1, 16, 2, 2]             2,320\n",
      "│    │    └─Dropout2d: 3-42              [1, 16, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-43            [1, 16, 2, 2]             32\n",
      "│    │    └─LeakyReLU: 3-44              [1, 16, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-45                 [1, 16, 1, 1]             2,320\n",
      "│    │    └─Dropout2d: 3-46              [1, 16, 1, 1]             --\n",
      "│    │    └─BatchNorm2d: 3-47            [1, 16, 1, 1]             32\n",
      "│    │    └─LeakyReLU: 3-48              [1, 16, 1, 1]             --\n",
      "│    └─Sequential: 2-7                   [1, 32, 1, 1]             --\n",
      "│    │    └─Conv2d: 3-49                 [1, 32, 1, 1]             4,640\n",
      "│    │    └─Dropout2d: 3-50              [1, 32, 1, 1]             --\n",
      "│    │    └─BatchNorm2d: 3-51            [1, 32, 1, 1]             64\n",
      "│    │    └─LeakyReLU: 3-52              [1, 32, 1, 1]             --\n",
      "│    │    └─Conv2d: 3-53                 [1, 32, 1, 1]             9,248\n",
      "│    │    └─Dropout2d: 3-54              [1, 32, 1, 1]             --\n",
      "│    │    └─BatchNorm2d: 3-55            [1, 32, 1, 1]             64\n",
      "│    │    └─LeakyReLU: 3-56              [1, 32, 1, 1]             --\n",
      "├─Sequential: 1-2                        [1, 32]                   --\n",
      "│    └─Flatten: 2-8                      [1, 32]                   --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-9                   [1, 7]                    --\n",
      "│    │    └─Linear: 3-57                 [1, 7]                    231\n",
      "==========================================================================================\n",
      "Total params: 40,311\n",
      "Trainable params: 40,311\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 7.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1.75\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 1.93\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...:  41%|████      | 7/17 [00:05<00:08,  1.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epoch_log: EpochLogs\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_log \u001b[38;5;129;01min\u001b[39;00m grid_search(\n\u001b[0;32m      3\u001b[0m     model_factory\u001b[38;5;241m=\u001b[39mAllCNN2D,\n\u001b[0;32m      4\u001b[0m     all_model_parameters\u001b[38;5;241m=\u001b[39mall_model_parameters,\n\u001b[0;32m      5\u001b[0m     optim_factory\u001b[38;5;241m=\u001b[39mAdamW,\n\u001b[0;32m      6\u001b[0m     all_optim_params\u001b[38;5;241m=\u001b[39mall_optim_parameters,\n\u001b[0;32m      7\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[0;32m      8\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),\n\u001b[0;32m      9\u001b[0m     train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m     10\u001b[0m     val_dataloader\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[0;32m     11\u001b[0m     lr_decay_window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     lr_decay_minimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m     13\u001b[0m     scheduler_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m,\n\u001b[0;32m     14\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m ):\n\u001b[0;32m     16\u001b[0m     train_logpoints: \u001b[38;5;28mlist\u001b[39m[LogPoint] \u001b[38;5;241m=\u001b[39m epoch_log\u001b[38;5;241m.\u001b[39mtrain_logs\n\u001b[0;32m     17\u001b[0m     val_logpoints: \u001b[38;5;28mlist\u001b[39m[LogPoint] \u001b[38;5;241m=\u001b[39m epoch_log\u001b[38;5;241m.\u001b[39mval_logs\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\training\\train.py:334\u001b[0m, in \u001b[0;36mgrid_search\u001b[1;34m(model_factory, all_model_parameters, optim_factory, all_optim_params, epochs, criterion, train_dataloader, val_dataloader, lr_decay_window_size, lr_decay_minimum, scheduler_scale, device, compile_model)\u001b[0m\n\u001b[0;32m    331\u001b[0m optimiser_loss: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m model_optimiser\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    333\u001b[0m train_log: LogPoint\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_log \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m    335\u001b[0m     train(\n\u001b[0;32m    336\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    337\u001b[0m         optimiser\u001b[38;5;241m=\u001b[39mmodel_optimiser,\n\u001b[0;32m    338\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[0;32m    339\u001b[0m         train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m    340\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m    341\u001b[0m     ),\n\u001b[0;32m    342\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    343\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[0;32m    344\u001b[0m ):\n\u001b[0;32m    345\u001b[0m     epoch_train_logs\u001b[38;5;241m.\u001b[39mappend(train_log)\n\u001b[0;32m    346\u001b[0m     epoch_cur_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m    347\u001b[0m         train_log\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach(\n\u001b[0;32m    348\u001b[0m         )\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    349\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\training\\train.py:258\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimiser, criterion, train_dataloader, device)\u001b[0m\n\u001b[0;32m    256\u001b[0m X: Tensor\n\u001b[0;32m    257\u001b[0m y: Tensor\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m    260\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m    262\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:91\u001b[0m, in \u001b[0;36mCharImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     88\u001b[0m image \u001b[38;5;241m=\u001b[39m reduce(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc h w -> 1 h w\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Apply random transformations\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_random_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# One-hot encode the label\u001b[39;00m\n\u001b[0;32m     96\u001b[0m one_hot_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_set),\n\u001b[0;32m     98\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m     99\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:149\u001b[0m, in \u001b[0;36mCharImageDataset._apply_random_transformations\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    141\u001b[0m shear_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskew_limit\u001b[38;5;241m*\u001b[39mimage\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskew_limit\u001b[38;5;241m*\u001b[39mimage\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    144\u001b[0m )\n\u001b[0;32m    145\u001b[0m shear_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskew_limit\u001b[38;5;241m*\u001b[39mimage\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskew_limit\u001b[38;5;241m*\u001b[39mimage\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    148\u001b[0m )\n\u001b[1;32m--> 149\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtranslate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshear_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshear_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m image_shape: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    158\u001b[0m zoom_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzoom_change,\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzoom_change\n\u001b[0;32m    161\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:1246\u001b[0m, in \u001b[0;36maffine\u001b[1;34m(img, angle, translate, scale, shear, interpolation, fill, center)\u001b[0m\n\u001b[0;32m   1244\u001b[0m translate_f \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m translate]\n\u001b[0;32m   1245\u001b[0m matrix \u001b[38;5;241m=\u001b[39m _get_inverse_affine_matrix(center_f, angle, translate_f, scale, shear)\n\u001b[1;32m-> 1246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:617\u001b[0m, in \u001b[0;36maffine\u001b[1;34m(img, matrix, interpolation, fill)\u001b[0m\n\u001b[0;32m    615\u001b[0m shape \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    616\u001b[0m \u001b[38;5;66;03m# grid will be generated on the same device as theta and img\u001b[39;00m\n\u001b[1;32m--> 617\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[43m_gen_affine_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _apply_grid_transform(img, grid, interpolation, fill\u001b[38;5;241m=\u001b[39mfill)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:601\u001b[0m, in \u001b[0;36m_gen_affine_grid\u001b[1;34m(theta, w, h, ow, oh)\u001b[0m\n\u001b[0;32m    598\u001b[0m base_grid[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    600\u001b[0m rescaled_theta \u001b[38;5;241m=\u001b[39m theta\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m w, \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m h], dtype\u001b[38;5;241m=\u001b[39mtheta\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtheta\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 601\u001b[0m output_grid \u001b[38;5;241m=\u001b[39m \u001b[43mbase_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrescaled_theta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_grid\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, oh, ow, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epoch_log: EpochLogs\n",
    "for epoch_log in grid_search(\n",
    "    model_factory=AllCNN2D,\n",
    "    all_model_parameters=all_model_parameters,\n",
    "    optim_factory=AdamW,\n",
    "    all_optim_params=all_optim_parameters,\n",
    "    epochs=10000,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    lr_decay_window_size=20,\n",
    "    lr_decay_minimum=0.0,\n",
    "    scheduler_scale=0.85,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    train_logpoints: list[LogPoint] = epoch_log.train_logs\n",
    "    val_logpoints: list[LogPoint] = epoch_log.val_logs\n",
    "    \n",
    "    \n",
    "    train_count: int = 0\n",
    "    val_count: int = 0\n",
    "    \n",
    "    train_losses_tally: float = 0.0\n",
    "    val_losses_tally: float = 0.0\n",
    "    \n",
    "    train_correct_tally: int = 0\n",
    "    val_correct_tally: int = 0\n",
    "    \n",
    "    for log_point in train_logpoints: \n",
    "        \n",
    "        y_hat_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y_hat, \n",
    "            axis=-1\n",
    "        ).detach().cpu()\n",
    "        \n",
    "        y_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y, axis=-1\n",
    "        ).detach().cpu()\n",
    "\n",
    "        train_correct_tally += torch.sum(y_hat_pred==y_pred)\n",
    "        \n",
    "        train_losses_tally += torch.sum(log_point.loss)\n",
    "        \n",
    "        train_count += len(y_hat_pred)\n",
    "        \n",
    "    for log_point in val_logpoints: \n",
    "        \n",
    "        y_hat_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y_hat, \n",
    "            axis=-1\n",
    "        ).detach().cpu()\n",
    "        \n",
    "        y_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y, axis=-1\n",
    "        ).detach().cpu()\n",
    "\n",
    "        val_correct_tally += torch.sum(y_hat_pred==y_pred)\n",
    "        \n",
    "        val_losses_tally += torch.sum(log_point.loss)\n",
    "        \n",
    "        val_count += len(y_hat_pred)\n",
    "        \n",
    "    train_accuracy: float = train_correct_tally/train_count\n",
    "    val_accuracy: float = val_correct_tally/val_count\n",
    "    \n",
    "    train_loss: float = train_losses_tally/train_count\n",
    "    val_loss: float = val_losses_tally/val_count\n",
    "    \n",
    "    cur_learning_rate: float = epoch_log.optimiser.param_groups[0][\"lr\"]\n",
    "    \n",
    "    model_checkpoint_path: str = os.path.join(\n",
    "        model_save_dirpath,\n",
    "        f\"{MODEL_NAME}_epoch{epoch_log.epoch}_trainacc{train_accuracy:.5}_valacc{val_accuracy:.5}_Tloss{train_loss:.5}_Vloss{val_loss:.5}_lr{cur_learning_rate}.pkl\"\n",
    "    )\n",
    "    \n",
    "    with open(model_checkpoint_path, \"wb\") as f:\n",
    "        torch.save(epoch_log.model.state_dict(), f)\n",
    "    \n",
    "    print(f\"Train Accuracy      : {train_accuracy}\")\n",
    "    print(f\"Val Accuracy        : {val_accuracy}\")\n",
    "    print(f\"Loss                : {train_loss}\")\n",
    "    print(f\"Val Loss            : {val_loss}\")\n",
    "    print(f\"Learning Rate       : {cur_learning_rate}\")\n",
    "    \n",
    "    log(\n",
    "        epoch_log.epoch,\n",
    "        train_accuracy,\n",
    "        train_loss,\n",
    "        val_accuracy,\n",
    "        val_loss,\n",
    "        cur_learning_rate\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
