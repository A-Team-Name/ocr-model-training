{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from typing import Any\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import EpochLogs, grid_search, LogPoint\n",
    "from dataset.character_dataset import CharImageDataset\n",
    "from models.allcnn2d import AllCNN2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SPLIT: float = 0.8\n",
    "MODEL_NAME: str = \"Beta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths\n",
    "Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir: str = os.path.abspath(\".\")\n",
    "root_dir: str = os.path.join(\n",
    "    notebook_dir,\n",
    "    os.pardir,\n",
    "    os.pardir\n",
    ")\n",
    "\n",
    "data_dir: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"data\",\n",
    "    \"lambda\"\n",
    ")\n",
    "\n",
    "model_save_dirpath: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"models\",\n",
    "    \"allcnn\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_path_glob: str = os.path.join(\n",
    "    data_dir,\n",
    "    \"u*.png\"\n",
    ")\n",
    "images_path_regex: str = r\"(u[0-9a-fA-F]+)-([0-9]+)\\.png\"\n",
    "\n",
    "image_paths: list[str] = glob.glob(images_path_glob)\n",
    "random.shuffle(image_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging_path: str = f\"{MODEL_NAME}_log_{get_current_time()}.csv\"\n",
    "\n",
    "with open(logging_path, \"w\") as f:\n",
    "    f.write(\"TIME,EPOCH,TRAIN_ACC,VAL_ACC,TRAIN_LOSS,VAL_LOSS,LR\\n\")\n",
    "\n",
    "def log(\n",
    "    epoch: int,\n",
    "    train_acc: float, \n",
    "    train_loss: float, \n",
    "    val_acc: float, \n",
    "    val_loss, \n",
    "    lr: float\n",
    ")-> None:\n",
    "    with open(logging_path, \"a\") as f:\n",
    "        f.write(f\"{get_current_time()},{epoch},{train_acc},{val_acc},{train_loss},{val_loss},{lr}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labeled_image_paths: list[tuple[str, str]] = []\n",
    "\n",
    "file_path: str\n",
    "for file_path in image_paths:\n",
    "    match = re.search(images_path_regex, file_path)\n",
    "    \n",
    "    if not match:\n",
    "        continue\n",
    "    \n",
    "    u_hexvalue: str = match.group(1)\n",
    "    labeled_image_paths.append((u_hexvalue, file_path))\n",
    "\n",
    "labels: list[str]\n",
    "image_paths: list[str]\n",
    "labels, image_paths =  list(zip(*labeled_image_paths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_index: int = int(len(image_paths)*DATASET_SPLIT)\n",
    "all_label_classes: list[str] = list(set(labels))\n",
    "\n",
    "train_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=image_paths[:split_index],\n",
    "    labels=labels[:split_index],\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.1,\n",
    "    translation_limit=0.2,\n",
    "    skew_limit=0.05,\n",
    "    zoom_change=0.3,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "val_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=image_paths[split_index:],\n",
    "    labels=labels[split_index:],\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.0,\n",
    "    translation_limit=0.0,\n",
    "    skew_limit=0.00,\n",
    "    zoom_change=0.0,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in train_char_dataset:\n",
    "    plt.imshow(rearrange(im, \"1 h w -> h w\")*255, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in val_char_dataset:\n",
    "    plt.imshow(rearrange(im, \"1 h w -> h w\")*255, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader: DataLoader = DataLoader(\n",
    "    train_char_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "val_dataloader: DataLoader = DataLoader(\n",
    "    val_char_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_checkpoint_path: str = os.path.join(\n",
    "    model_save_dirpath,\n",
    "    \"AlphaAllCNN_epoch8_trainacc0.30147_valacc0.014493.pkl\"\n",
    ")\n",
    "\n",
    "all_model_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"conv_features\": (1, 16, 16, 16, 16, 16, 16, 32),\n",
    "        \"fully_connected_features\": (32,7),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.1,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": model_checkpoint_path\n",
    "    }\n",
    "]\n",
    "\n",
    "all_optim_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.0001\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.1.0.weight:  loaded size:torch.Size([32, 16, 3, 3]) != model size:  torch.Size([16, 16, 3, 3])\n",
      "Skipping encoder_conv_blocks.1.0.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.1.2.weight:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.1.2.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.1.2.running_mean:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.1.2.running_var:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.1.4.weight:  loaded size:torch.Size([32, 32, 3, 3]) != model size:  torch.Size([16, 16, 3, 3])\n",
      "Skipping encoder_conv_blocks.1.4.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.1.6.weight:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.1.6.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.1.6.running_mean:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.1.6.running_var:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.2.0.weight:  loaded size:torch.Size([32, 32, 3, 3]) != model size:  torch.Size([16, 16, 3, 3])\n",
      "Skipping encoder_conv_blocks.2.0.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.2.2.weight:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.2.2.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.2.2.running_mean:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.2.2.running_var:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.2.4.weight:  loaded size:torch.Size([32, 32, 3, 3]) != model size:  torch.Size([16, 16, 3, 3])\n",
      "Skipping encoder_conv_blocks.2.4.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.2.6.weight:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.2.6.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.2.6.running_mean:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.2.6.running_var:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.3.0.weight:  loaded size:torch.Size([32, 32, 3, 3]) != model size:  torch.Size([16, 16, 3, 3])\n",
      "Skipping encoder_conv_blocks.3.0.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.3.2.weight:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.3.2.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.3.2.running_mean:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.3.2.running_var:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Skipping encoder_conv_blocks.3.4.weight:  loaded size:torch.Size([32, 32, 3, 3]) != model size:  torch.Size([16, 16, 3, 3])\n",
      "Skipping encoder_conv_blocks.3.4.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.3.6.weight:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.3.6.bias:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.3.6.running_mean:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Skipping encoder_conv_blocks.3.6.running_var:  loaded size:torch.Size([32]) != model size:  torch.Size([16])\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Skipping fully_connected_blocks.0.0.weight:  loaded size:torch.Size([32, 512]) != model size:  torch.Size([32, 32])\n",
      "Loaded: fully_connected_blocks.0.0.bias\n",
      "Loaded: fully_connected_blocks.1.0.weight\n",
      "Loaded: fully_connected_blocks.1.0.bias\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 7]                    --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 16, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-10              [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-12              [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 16, 16, 16]           2,320\n",
      "│    │    └─Dropout2d: 3-14              [1, 16, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 16, 16, 16]           32\n",
      "│    │    └─LeakyReLU: 3-16              [1, 16, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 16, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 16, 16, 16]           2,320\n",
      "│    │    └─Dropout2d: 3-18              [1, 16, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 16, 16, 16]           32\n",
      "│    │    └─LeakyReLU: 3-20              [1, 16, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 16, 8, 8]             2,320\n",
      "│    │    └─Dropout2d: 3-22              [1, 16, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 16, 8, 8]             32\n",
      "│    │    └─LeakyReLU: 3-24              [1, 16, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 16, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 16, 8, 8]             2,320\n",
      "│    │    └─Dropout2d: 3-26              [1, 16, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 16, 8, 8]             32\n",
      "│    │    └─LeakyReLU: 3-28              [1, 16, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 16, 4, 4]             2,320\n",
      "│    │    └─Dropout2d: 3-30              [1, 16, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 16, 4, 4]             32\n",
      "│    │    └─LeakyReLU: 3-32              [1, 16, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 16, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 16, 4, 4]             2,320\n",
      "│    │    └─Dropout2d: 3-34              [1, 16, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 16, 4, 4]             32\n",
      "│    │    └─LeakyReLU: 3-36              [1, 16, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 16, 2, 2]             2,320\n",
      "│    │    └─Dropout2d: 3-38              [1, 16, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 16, 2, 2]             32\n",
      "│    │    └─LeakyReLU: 3-40              [1, 16, 2, 2]             --\n",
      "│    └─Sequential: 2-6                   [1, 16, 1, 1]             --\n",
      "│    │    └─Conv2d: 3-41                 [1, 16, 2, 2]             2,320\n",
      "│    │    └─Dropout2d: 3-42              [1, 16, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-43            [1, 16, 2, 2]             32\n",
      "│    │    └─LeakyReLU: 3-44              [1, 16, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-45                 [1, 16, 1, 1]             2,320\n",
      "│    │    └─Dropout2d: 3-46              [1, 16, 1, 1]             --\n",
      "│    │    └─BatchNorm2d: 3-47            [1, 16, 1, 1]             32\n",
      "│    │    └─LeakyReLU: 3-48              [1, 16, 1, 1]             --\n",
      "│    └─Sequential: 2-7                   [1, 32, 1, 1]             --\n",
      "│    │    └─Conv2d: 3-49                 [1, 32, 1, 1]             4,640\n",
      "│    │    └─Dropout2d: 3-50              [1, 32, 1, 1]             --\n",
      "│    │    └─BatchNorm2d: 3-51            [1, 32, 1, 1]             64\n",
      "│    │    └─LeakyReLU: 3-52              [1, 32, 1, 1]             --\n",
      "│    │    └─Conv2d: 3-53                 [1, 32, 1, 1]             9,248\n",
      "│    │    └─Dropout2d: 3-54              [1, 32, 1, 1]             --\n",
      "│    │    └─BatchNorm2d: 3-55            [1, 32, 1, 1]             64\n",
      "│    │    └─LeakyReLU: 3-56              [1, 32, 1, 1]             --\n",
      "├─Sequential: 1-2                        [1, 32]                   --\n",
      "│    └─Flatten: 2-8                      [1, 32]                   --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-9                   [1, 32]                   --\n",
      "│    │    └─Linear: 3-57                 [1, 32]                   1,056\n",
      "│    │    └─Dropout: 3-58                [1, 32]                   --\n",
      "│    │    └─LeakyReLU: 3-59              [1, 32]                   --\n",
      "│    └─Sequential: 2-10                  [1, 7]                    --\n",
      "│    │    └─Linear: 3-60                 [1, 7]                    231\n",
      "==========================================================================================\n",
      "Total params: 41,367\n",
      "Trainable params: 41,367\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 7.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1.75\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 1.93\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 17/17 [00:13<00:00,  1.25it/s]\n",
      "Validating Model...: 100%|██████████| 5/5 [00:03<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.13970588147640228\n",
      "Val Accuracy        : 0.15942029654979706\n",
      "Loss                : 0.12204380333423615\n",
      "Val Loss            : 0.14026100933551788\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 17/17 [00:13<00:00,  1.30it/s]\n",
      "Validating Model...: 100%|██████████| 5/5 [00:03<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.1875\n",
      "Val Accuracy        : 0.15942029654979706\n",
      "Loss                : 0.12122810631990433\n",
      "Val Loss            : 0.14200758934020996\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 17/17 [00:13<00:00,  1.27it/s]\n",
      "Validating Model...: 100%|██████████| 5/5 [00:03<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.20955882966518402\n",
      "Val Accuracy        : 0.18840579688549042\n",
      "Loss                : 0.11911924928426743\n",
      "Val Loss            : 0.14152903854846954\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 17/17 [00:13<00:00,  1.26it/s]\n",
      "Validating Model...: 100%|██████████| 5/5 [00:03<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.24632352590560913\n",
      "Val Accuracy        : 0.21739129722118378\n",
      "Loss                : 0.11732690036296844\n",
      "Val Loss            : 0.1349598467350006\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 17/17 [00:13<00:00,  1.26it/s]\n",
      "Validating Model...: 100%|██████████| 5/5 [00:03<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.24632352590560913\n",
      "Val Accuracy        : 0.3333333432674408\n",
      "Loss                : 0.11412256211042404\n",
      "Val Loss            : 0.12754669785499573\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 17/17 [00:13<00:00,  1.26it/s]\n",
      "Validating Model...: 100%|██████████| 5/5 [00:03<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.25735294818878174\n",
      "Val Accuracy        : 0.21739129722118378\n",
      "Loss                : 0.11113856732845306\n",
      "Val Loss            : 0.12262692302465439\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 17/17 [00:13<00:00,  1.29it/s]\n",
      "Validating Model...: 100%|██████████| 5/5 [00:03<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      : 0.24632352590560913\n",
      "Val Accuracy        : 0.23188406229019165\n",
      "Loss                : 0.11075931787490845\n",
      "Val Loss            : 0.11928322166204453\n",
      "Learning Rate       : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...:  65%|██████▍   | 11/17 [00:08<00:04,  1.23it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(10000):\n",
    "\n",
    "    epoch_log: EpochLogs\n",
    "    for epoch_log in grid_search(\n",
    "        model_factory=AllCNN2D,\n",
    "        all_model_parameters=all_model_parameters,\n",
    "        optim_factory=AdamW,\n",
    "        all_optim_params=all_optim_parameters,\n",
    "        epochs=100,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        lr_decay_window_size=10,\n",
    "        lr_decay_minimum=0.0,\n",
    "        scheduler_scale=0.5,\n",
    "        device=\"cuda\"\n",
    "    ):\n",
    "        train_logpoints: list[LogPoint] = epoch_log.train_logs\n",
    "        val_logpoints: list[LogPoint] = epoch_log.val_logs\n",
    "        \n",
    "        \n",
    "        train_count: int = 0\n",
    "        val_count: int = 0\n",
    "        \n",
    "        train_losses_tally: float = 0.0\n",
    "        val_losses_tally: float = 0.0\n",
    "        \n",
    "        train_correct_tally: int = 0\n",
    "        val_correct_tally: int = 0\n",
    "        \n",
    "        for log_point in train_logpoints: \n",
    "            \n",
    "            y_hat_pred: torch.Tensor = torch.argmax(\n",
    "                log_point.y_hat, \n",
    "                axis=-1\n",
    "            ).detach().cpu()\n",
    "            \n",
    "            y_pred: torch.Tensor = torch.argmax(\n",
    "                log_point.y, axis=-1\n",
    "            ).detach().cpu()\n",
    "\n",
    "            train_correct_tally += torch.sum(y_hat_pred==y_pred)\n",
    "            \n",
    "            train_losses_tally += torch.sum(log_point.loss)\n",
    "            \n",
    "            train_count += len(y_hat_pred)\n",
    "            \n",
    "        for log_point in val_logpoints: \n",
    "            \n",
    "            y_hat_pred: torch.Tensor = torch.argmax(\n",
    "                log_point.y_hat, \n",
    "                axis=-1\n",
    "            ).detach().cpu()\n",
    "            \n",
    "            y_pred: torch.Tensor = torch.argmax(\n",
    "                log_point.y, axis=-1\n",
    "            ).detach().cpu()\n",
    "\n",
    "            val_correct_tally += torch.sum(y_hat_pred==y_pred)\n",
    "            \n",
    "            val_losses_tally += torch.sum(log_point.loss)\n",
    "            \n",
    "            val_count += len(y_hat_pred)\n",
    "            \n",
    "        train_accuracy: float = train_correct_tally/train_count\n",
    "        val_accuracy: float = val_correct_tally/val_count\n",
    "        \n",
    "        train_loss: float = train_losses_tally/train_count\n",
    "        val_loss: float = val_losses_tally/val_count\n",
    "        \n",
    "        cur_learning_rate: float = epoch_log.optimiser.param_groups[0][\"lr\"]\n",
    "        \n",
    "        model_checkpoint_path: str = os.path.join(\n",
    "            model_save_dirpath,\n",
    "            f\"{MODEL_NAME}_epoch{epoch_log.epoch}_trainacc{train_accuracy:.5}_valacc{val_accuracy:.5}.pkl\"\n",
    "        )\n",
    "        \n",
    "        with open(model_checkpoint_path, \"wb\") as f:\n",
    "            torch.save(epoch_log.model.state_dict(), f)\n",
    "        \n",
    "        print(f\"Train Accuracy      : {train_accuracy}\")\n",
    "        print(f\"Val Accuracy        : {val_accuracy}\")\n",
    "        print(f\"Loss                : {train_loss}\")\n",
    "        print(f\"Val Loss            : {val_loss}\")\n",
    "        print(f\"Learning Rate       : {cur_learning_rate}\")\n",
    "        \n",
    "        log(\n",
    "            epoch_log.epoch,\n",
    "            train_accuracy,\n",
    "            train_loss,\n",
    "            val_accuracy,\n",
    "            val_loss,\n",
    "            cur_learning_rate\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
