{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from typing import Any\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import EpochLogs, grid_search, LogPoint\n",
    "from dataset.character_dataset import CharImageDataset\n",
    "from models.allcnn2d import AllCNN2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SPLIT: float = 0.8\n",
    "MODEL_NAME: str = \"Mongo\"\n",
    "LOAD_CHECKPOINT: str = r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\checkpoints\\Lake_epoch82_trainacc0.9782_valacc0.99419_Tloss0.0052215_Vloss0.0015499_lr0.0005219339999999999.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths\n",
    "Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir: str = os.path.abspath(\".\")\n",
    "root_dir: str = os.path.join(\n",
    "    notebook_dir,\n",
    "    os.pardir,\n",
    "    os.pardir\n",
    ")\n",
    "\n",
    "data_dir: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"data\",\n",
    "    \"lambda\"\n",
    ")\n",
    "\n",
    "model_save_dirpath: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"models\",\n",
    "    \"allcnn\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1149"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "images_path_glob: str = os.path.join(\n",
    "    data_dir,\n",
    "    \"u*.png\"\n",
    ")\n",
    "images_path_regex: str = r\"(u[0-9a-f]+)-([0-9]+)\\.png\"\n",
    "\n",
    "image_paths: list[str] = glob.glob(images_path_glob)\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging_path: str = f\"{MODEL_NAME}_log_{get_current_time()}.csv\"\n",
    "\n",
    "with open(logging_path, \"w\") as f:\n",
    "    f.write(\"TIME,EPOCH,TRAIN_ACC,VAL_ACC,TRAIN_LOSS,VAL_LOSS,LR\\n\")\n",
    "\n",
    "def log(\n",
    "    epoch: int,\n",
    "    train_acc: float, \n",
    "    train_loss: float, \n",
    "    val_acc: float, \n",
    "    val_loss, \n",
    "    lr: float\n",
    ")-> None:\n",
    "    with open(logging_path, \"a\") as f:\n",
    "        f.write(f\"{get_current_time()},{epoch},{train_acc},{val_acc},{train_loss},{val_loss},{lr}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Labels From File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139, 1139)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "labeled_image_paths: list[tuple[str, str]] = []\n",
    "\n",
    "class_counts: dict[str, int] = defaultdict(lambda: 0)\n",
    "\n",
    "file_path: str\n",
    "for file_path in image_paths:\n",
    "    match = re.search(images_path_regex, file_path)\n",
    "    \n",
    "    if not match:\n",
    "        continue\n",
    "    \n",
    "    u_hexvalue: str = match.group(1)\n",
    "    \n",
    "    class_counts[u_hexvalue] += 1\n",
    "    \n",
    "    \n",
    "    labeled_image_paths.append((u_hexvalue, file_path))\n",
    "\n",
    "labels: list[str]\n",
    "image_paths: list[str]\n",
    "labels, image_paths =  list(zip(*labeled_image_paths))\n",
    "\n",
    "len(labels), len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'u3a': 56,\n",
       "         'u61': 54,\n",
       "         'u31': 54,\n",
       "         'u3bb': 49,\n",
       "         'u2e': 49,\n",
       "         'u28': 48,\n",
       "         'u29': 48,\n",
       "         'u2203': 38,\n",
       "         'u3bc': 37,\n",
       "         'u2200': 26,\n",
       "         'u68': 20,\n",
       "         'u34': 20,\n",
       "         'u6f': 20,\n",
       "         'u38': 20,\n",
       "         'u62': 20,\n",
       "         'u77': 20,\n",
       "         'u71': 20,\n",
       "         'u7a': 20,\n",
       "         'u39': 20,\n",
       "         'u72': 20,\n",
       "         'u76': 20,\n",
       "         'u73': 20,\n",
       "         'u30': 20,\n",
       "         'u69': 20,\n",
       "         'u6c': 20,\n",
       "         'u6d': 20,\n",
       "         'u74': 20,\n",
       "         'u6e': 20,\n",
       "         'u35': 20,\n",
       "         'u36': 20,\n",
       "         'u6b': 20,\n",
       "         'u6a': 20,\n",
       "         'u37': 20,\n",
       "         'u63': 20,\n",
       "         'u64': 20,\n",
       "         'u75': 20,\n",
       "         'u66': 20,\n",
       "         'u33': 20,\n",
       "         'u67': 20,\n",
       "         'u70': 20,\n",
       "         'u79': 20,\n",
       "         'u32': 20,\n",
       "         'u78': 20,\n",
       "         'u65': 20})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Classes Using Oversample/Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts: list[tuple[str, int]] = sorted(\n",
    "    class_counts.items(), \n",
    "    key=lambda x: x[0]\n",
    ")\n",
    "\n",
    "counts: list[int] = [pair[1] for pair in sorted_counts]\n",
    "\n",
    "max_count: int = max(counts)\n",
    "min_count: int = min(counts)\n",
    "\n",
    "to_add_counts: dict[str, int] = {\n",
    "    uid: max_count - count \n",
    "    for uid, count in \n",
    "    sorted_counts\n",
    "}\n",
    "\n",
    "to_undersample_counts: dict[str, int] = {\n",
    "    uid: min_count\n",
    "    for uid, count in \n",
    "    sorted_counts\n",
    "}\n",
    "\n",
    "total_items = sum(x[1] for x in sorted_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 56, 1139)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count, max_count, total_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(*to_add_counts.items())\n",
    "#print(sorted([(chr(int(pair[0][1:], 16)), pair[1]) for pair in to_remove_counts.items()], key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_add_labels: list[str] = []\n",
    "#to_add_file_paths: list[str] = []\n",
    "#\n",
    "#while True in [to_add_count>0 for to_add_count in to_add_counts.values()]:  \n",
    "#    for label, image_path in zip(labels, image_paths):\n",
    "#        remaining: int = to_add_counts[label]\n",
    "#        \n",
    "#        if remaining > 0:\n",
    "#            to_add_labels.append(label)\n",
    "#            to_add_file_paths.append(image_path)\n",
    "#            to_add_counts[label] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep_labels: list[str] = []\n",
    "to_keep_file_paths: list[str] = []\n",
    "\n",
    "while True in [to_add_count>0 for to_add_count in to_undersample_counts.values()]:  \n",
    "    for label, image_path in zip(labels, image_paths):\n",
    "        remaining: int = to_undersample_counts[label]\n",
    "        \n",
    "        if remaining > 0:\n",
    "            to_keep_labels.append(label)\n",
    "            to_keep_file_paths.append(image_path)\n",
    "            to_undersample_counts[label] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u2203',\n",
       " 'u68',\n",
       " 'u34',\n",
       " 'u6f',\n",
       " 'u38',\n",
       " 'u62',\n",
       " 'u38',\n",
       " 'u77',\n",
       " 'u71',\n",
       " 'u3bb',\n",
       " 'u61',\n",
       " 'u7a',\n",
       " 'u39',\n",
       " 'u72',\n",
       " 'u68',\n",
       " 'u3bc',\n",
       " 'u72',\n",
       " 'u76',\n",
       " 'u73',\n",
       " 'u30',\n",
       " 'u3bb',\n",
       " 'u69',\n",
       " 'u30',\n",
       " 'u6c',\n",
       " 'u31',\n",
       " 'u31',\n",
       " 'u28',\n",
       " 'u6d',\n",
       " 'u3a',\n",
       " 'u2e',\n",
       " 'u74',\n",
       " 'u3bc',\n",
       " 'u61',\n",
       " 'u2200',\n",
       " 'u6c',\n",
       " 'u69',\n",
       " 'u7a',\n",
       " 'u62',\n",
       " 'u2e',\n",
       " 'u72',\n",
       " 'u6e',\n",
       " 'u71',\n",
       " 'u35',\n",
       " 'u35',\n",
       " 'u2203',\n",
       " 'u61',\n",
       " 'u31',\n",
       " 'u3a',\n",
       " 'u2200',\n",
       " 'u36',\n",
       " 'u3a',\n",
       " 'u3bc',\n",
       " 'u6b',\n",
       " 'u6d',\n",
       " 'u2200',\n",
       " 'u76',\n",
       " 'u76',\n",
       " 'u36',\n",
       " 'u6a',\n",
       " 'u31',\n",
       " 'u73',\n",
       " 'u61',\n",
       " 'u61',\n",
       " 'u30',\n",
       " 'u37',\n",
       " 'u28',\n",
       " 'u2203',\n",
       " 'u61',\n",
       " 'u63',\n",
       " 'u64',\n",
       " 'u6b',\n",
       " 'u6c',\n",
       " 'u62',\n",
       " 'u61',\n",
       " 'u37',\n",
       " 'u28',\n",
       " 'u64',\n",
       " 'u73',\n",
       " 'u62',\n",
       " 'u61',\n",
       " 'u62',\n",
       " 'u75',\n",
       " 'u31',\n",
       " 'u66',\n",
       " 'u2e',\n",
       " 'u6b',\n",
       " 'u63',\n",
       " 'u33',\n",
       " 'u2200',\n",
       " 'u29',\n",
       " 'u2203',\n",
       " 'u36',\n",
       " 'u6d',\n",
       " 'u2203',\n",
       " 'u73',\n",
       " 'u74',\n",
       " 'u67',\n",
       " 'u31',\n",
       " 'u28',\n",
       " 'u63',\n",
       " 'u37',\n",
       " 'u29',\n",
       " 'u76',\n",
       " 'u31',\n",
       " 'u6b',\n",
       " 'u70',\n",
       " 'u64',\n",
       " 'u3a',\n",
       " 'u29',\n",
       " 'u61',\n",
       " 'u3bb',\n",
       " 'u38',\n",
       " 'u76',\n",
       " 'u37',\n",
       " 'u2200',\n",
       " 'u6a',\n",
       " 'u2200',\n",
       " 'u68',\n",
       " 'u71',\n",
       " 'u6d',\n",
       " 'u69',\n",
       " 'u69',\n",
       " 'u73',\n",
       " 'u61',\n",
       " 'u31',\n",
       " 'u79',\n",
       " 'u32',\n",
       " 'u3a',\n",
       " 'u79',\n",
       " 'u61',\n",
       " 'u31',\n",
       " 'u61',\n",
       " 'u3a',\n",
       " 'u28',\n",
       " 'u3a',\n",
       " 'u29',\n",
       " 'u63',\n",
       " 'u6a',\n",
       " 'u2203',\n",
       " 'u61',\n",
       " 'u6b',\n",
       " 'u70',\n",
       " 'u67',\n",
       " 'u78',\n",
       " 'u76',\n",
       " 'u31',\n",
       " 'u34',\n",
       " 'u66',\n",
       " 'u7a',\n",
       " 'u74',\n",
       " 'u76',\n",
       " 'u69',\n",
       " 'u61',\n",
       " 'u6e',\n",
       " 'u29',\n",
       " 'u69',\n",
       " 'u73',\n",
       " 'u3bb',\n",
       " 'u32',\n",
       " 'u32',\n",
       " 'u3a',\n",
       " 'u28',\n",
       " 'u37',\n",
       " 'u29',\n",
       " 'u2203',\n",
       " 'u77',\n",
       " 'u2e',\n",
       " 'u64',\n",
       " 'u31',\n",
       " 'u38',\n",
       " 'u3bc',\n",
       " 'u37',\n",
       " 'u64',\n",
       " 'u65',\n",
       " 'u28',\n",
       " 'u3a',\n",
       " 'u35',\n",
       " 'u32',\n",
       " 'u66',\n",
       " 'u2203',\n",
       " 'u75',\n",
       " 'u2203',\n",
       " 'u30',\n",
       " 'u3bc',\n",
       " 'u30',\n",
       " 'u6f',\n",
       " 'u35',\n",
       " 'u3bb',\n",
       " 'u38',\n",
       " 'u33',\n",
       " 'u70',\n",
       " 'u6c',\n",
       " 'u28',\n",
       " 'u6b',\n",
       " 'u6d',\n",
       " 'u73',\n",
       " 'u29',\n",
       " 'u3a',\n",
       " 'u67',\n",
       " 'u63',\n",
       " 'u28',\n",
       " 'u6a',\n",
       " 'u73',\n",
       " 'u76',\n",
       " 'u32',\n",
       " 'u37',\n",
       " 'u61',\n",
       " 'u79',\n",
       " 'u39',\n",
       " 'u78',\n",
       " 'u28',\n",
       " 'u36',\n",
       " 'u2e',\n",
       " 'u2203',\n",
       " 'u62',\n",
       " 'u69',\n",
       " 'u6b',\n",
       " 'u32',\n",
       " 'u65',\n",
       " 'u63',\n",
       " 'u31',\n",
       " 'u36',\n",
       " 'u3bc',\n",
       " 'u61',\n",
       " 'u30',\n",
       " 'u28',\n",
       " 'u36',\n",
       " 'u29',\n",
       " 'u34',\n",
       " 'u77',\n",
       " 'u79',\n",
       " 'u2203',\n",
       " 'u64',\n",
       " 'u2e',\n",
       " 'u65',\n",
       " 'u29',\n",
       " 'u67',\n",
       " 'u2e',\n",
       " 'u35',\n",
       " 'u2203',\n",
       " 'u3bb',\n",
       " 'u37',\n",
       " 'u65',\n",
       " 'u67',\n",
       " 'u77',\n",
       " 'u73',\n",
       " 'u6b',\n",
       " 'u61',\n",
       " 'u75',\n",
       " 'u2e',\n",
       " 'u69',\n",
       " 'u29',\n",
       " 'u2200',\n",
       " 'u35',\n",
       " 'u72',\n",
       " 'u2203',\n",
       " 'u76',\n",
       " 'u3bb',\n",
       " 'u67',\n",
       " 'u72',\n",
       " 'u35',\n",
       " 'u34',\n",
       " 'u70',\n",
       " 'u73',\n",
       " 'u3a',\n",
       " 'u29',\n",
       " 'u36',\n",
       " 'u61',\n",
       " 'u33',\n",
       " 'u35',\n",
       " 'u29',\n",
       " 'u2203',\n",
       " 'u75',\n",
       " 'u29',\n",
       " 'u39',\n",
       " 'u3a',\n",
       " 'u70',\n",
       " 'u6f',\n",
       " 'u28',\n",
       " 'u2e',\n",
       " 'u29',\n",
       " 'u3bc',\n",
       " 'u6f',\n",
       " 'u70',\n",
       " 'u29',\n",
       " 'u77',\n",
       " 'u72',\n",
       " 'u6b',\n",
       " 'u63',\n",
       " 'u32',\n",
       " 'u66',\n",
       " 'u31',\n",
       " 'u79',\n",
       " 'u68',\n",
       " 'u28',\n",
       " 'u76',\n",
       " 'u61',\n",
       " 'u72',\n",
       " 'u3a',\n",
       " 'u36',\n",
       " 'u3a',\n",
       " 'u61',\n",
       " 'u72',\n",
       " 'u65',\n",
       " 'u74',\n",
       " 'u2e',\n",
       " 'u65',\n",
       " 'u3bb',\n",
       " 'u39',\n",
       " 'u38',\n",
       " 'u32',\n",
       " 'u67',\n",
       " 'u63',\n",
       " 'u3a',\n",
       " 'u29',\n",
       " 'u3bc',\n",
       " 'u6a',\n",
       " 'u67',\n",
       " 'u31',\n",
       " 'u31',\n",
       " 'u70',\n",
       " 'u79',\n",
       " 'u36',\n",
       " 'u36',\n",
       " 'u66',\n",
       " 'u75',\n",
       " 'u2203',\n",
       " 'u28',\n",
       " 'u31',\n",
       " 'u3bc',\n",
       " 'u32',\n",
       " 'u3bb',\n",
       " 'u3bb',\n",
       " 'u6e',\n",
       " 'u73',\n",
       " 'u29',\n",
       " 'u64',\n",
       " 'u63',\n",
       " 'u3a',\n",
       " 'u68',\n",
       " 'u6e',\n",
       " 'u77',\n",
       " 'u6c',\n",
       " 'u3a',\n",
       " 'u3a',\n",
       " 'u69',\n",
       " 'u6d',\n",
       " 'u31',\n",
       " 'u37',\n",
       " 'u3bc',\n",
       " 'u7a',\n",
       " 'u2203',\n",
       " 'u29',\n",
       " 'u65',\n",
       " 'u67',\n",
       " 'u76',\n",
       " 'u3a',\n",
       " 'u39',\n",
       " 'u31',\n",
       " 'u3bb',\n",
       " 'u72',\n",
       " 'u29',\n",
       " 'u62',\n",
       " 'u28',\n",
       " 'u6b',\n",
       " 'u39',\n",
       " 'u64',\n",
       " 'u71',\n",
       " 'u34',\n",
       " 'u2e',\n",
       " 'u30',\n",
       " 'u7a',\n",
       " 'u3a',\n",
       " 'u3bb',\n",
       " 'u2e',\n",
       " 'u74',\n",
       " 'u31',\n",
       " 'u39',\n",
       " 'u7a',\n",
       " 'u3bb',\n",
       " 'u6d',\n",
       " 'u31',\n",
       " 'u2e',\n",
       " 'u71',\n",
       " 'u32',\n",
       " 'u7a',\n",
       " 'u77',\n",
       " 'u75',\n",
       " 'u35',\n",
       " 'u66',\n",
       " 'u72',\n",
       " 'u2203',\n",
       " 'u28',\n",
       " 'u66',\n",
       " 'u3bc',\n",
       " 'u2e',\n",
       " 'u71',\n",
       " 'u32',\n",
       " 'u6c',\n",
       " 'u75',\n",
       " 'u32',\n",
       " 'u6e',\n",
       " 'u67',\n",
       " 'u6a',\n",
       " 'u39',\n",
       " 'u36',\n",
       " 'u3bb',\n",
       " 'u70',\n",
       " 'u33',\n",
       " 'u28',\n",
       " 'u2e',\n",
       " 'u3bb',\n",
       " 'u72',\n",
       " 'u6f',\n",
       " 'u62',\n",
       " 'u6f',\n",
       " 'u79',\n",
       " 'u64',\n",
       " 'u28',\n",
       " 'u6a',\n",
       " 'u28',\n",
       " 'u65',\n",
       " 'u2200',\n",
       " 'u3bb',\n",
       " 'u68',\n",
       " 'u29',\n",
       " 'u6d',\n",
       " 'u37',\n",
       " 'u73',\n",
       " 'u78',\n",
       " 'u3bb',\n",
       " 'u2203',\n",
       " 'u34',\n",
       " 'u65',\n",
       " 'u2e',\n",
       " 'u2203',\n",
       " 'u37',\n",
       " 'u67',\n",
       " 'u75',\n",
       " 'u2203',\n",
       " 'u39',\n",
       " 'u69',\n",
       " 'u37',\n",
       " 'u78',\n",
       " 'u3bc',\n",
       " 'u76',\n",
       " 'u74',\n",
       " 'u6c',\n",
       " 'u28',\n",
       " 'u2e',\n",
       " 'u66',\n",
       " 'u6f',\n",
       " 'u78',\n",
       " 'u76',\n",
       " 'u6a',\n",
       " 'u71',\n",
       " 'u71',\n",
       " 'u65',\n",
       " 'u62',\n",
       " 'u73',\n",
       " 'u6b',\n",
       " 'u79',\n",
       " 'u67',\n",
       " 'u79',\n",
       " 'u3bb',\n",
       " 'u6a',\n",
       " 'u36',\n",
       " 'u2e',\n",
       " 'u62',\n",
       " 'u6e',\n",
       " 'u34',\n",
       " 'u2e',\n",
       " 'u3bc',\n",
       " 'u2200',\n",
       " 'u6f',\n",
       " 'u30',\n",
       " 'u75',\n",
       " 'u7a',\n",
       " 'u74',\n",
       " 'u65',\n",
       " 'u36',\n",
       " 'u71',\n",
       " 'u69',\n",
       " 'u6c',\n",
       " 'u33',\n",
       " 'u35',\n",
       " 'u75',\n",
       " 'u6b',\n",
       " 'u37',\n",
       " 'u2200',\n",
       " 'u37',\n",
       " 'u30',\n",
       " 'u39',\n",
       " 'u38',\n",
       " 'u69',\n",
       " 'u71',\n",
       " 'u70',\n",
       " 'u37',\n",
       " 'u6a',\n",
       " 'u75',\n",
       " 'u3bc',\n",
       " 'u67',\n",
       " 'u3bc',\n",
       " 'u6c',\n",
       " 'u74',\n",
       " 'u3bb',\n",
       " 'u69',\n",
       " 'u71',\n",
       " 'u3bc',\n",
       " 'u2e',\n",
       " 'u39',\n",
       " 'u3bb',\n",
       " 'u6e',\n",
       " 'u34',\n",
       " 'u6a',\n",
       " 'u65',\n",
       " 'u64',\n",
       " 'u6b',\n",
       " 'u76',\n",
       " 'u76',\n",
       " 'u6b',\n",
       " 'u2200',\n",
       " 'u65',\n",
       " 'u69',\n",
       " 'u78',\n",
       " 'u39',\n",
       " 'u78',\n",
       " 'u68',\n",
       " 'u72',\n",
       " 'u72',\n",
       " 'u63',\n",
       " 'u71',\n",
       " 'u33',\n",
       " 'u6a',\n",
       " 'u6d',\n",
       " 'u35',\n",
       " 'u32',\n",
       " 'u6f',\n",
       " 'u68',\n",
       " 'u78',\n",
       " 'u65',\n",
       " 'u78',\n",
       " 'u34',\n",
       " 'u6b',\n",
       " 'u65',\n",
       " 'u64',\n",
       " 'u32',\n",
       " 'u33',\n",
       " 'u74',\n",
       " 'u3bc',\n",
       " 'u38',\n",
       " 'u33',\n",
       " 'u3bc',\n",
       " 'u7a',\n",
       " 'u6c',\n",
       " 'u39',\n",
       " 'u72',\n",
       " 'u64',\n",
       " 'u67',\n",
       " 'u32',\n",
       " 'u6e',\n",
       " 'u77',\n",
       " 'u38',\n",
       " 'u33',\n",
       " 'u69',\n",
       " 'u74',\n",
       " 'u70',\n",
       " 'u71',\n",
       " 'u6f',\n",
       " 'u36',\n",
       " 'u2200',\n",
       " 'u66',\n",
       " 'u6b',\n",
       " 'u6f',\n",
       " 'u37',\n",
       " 'u62',\n",
       " 'u69',\n",
       " 'u35',\n",
       " 'u6e',\n",
       " 'u78',\n",
       " 'u77',\n",
       " 'u3bc',\n",
       " 'u6c',\n",
       " 'u67',\n",
       " 'u34',\n",
       " 'u6e',\n",
       " 'u38',\n",
       " 'u62',\n",
       " 'u35',\n",
       " 'u62',\n",
       " 'u6d',\n",
       " 'u34',\n",
       " 'u71',\n",
       " 'u2200',\n",
       " 'u75',\n",
       " 'u33',\n",
       " 'u35',\n",
       " 'u30',\n",
       " 'u37',\n",
       " 'u78',\n",
       " 'u6e',\n",
       " 'u38',\n",
       " 'u34',\n",
       " 'u2200',\n",
       " 'u38',\n",
       " 'u6d',\n",
       " 'u6b',\n",
       " 'u6c',\n",
       " 'u3bc',\n",
       " 'u6f',\n",
       " 'u63',\n",
       " 'u6e',\n",
       " 'u64',\n",
       " 'u72',\n",
       " 'u36',\n",
       " 'u6a',\n",
       " 'u36',\n",
       " 'u33',\n",
       " 'u75',\n",
       " 'u79',\n",
       " 'u68',\n",
       " 'u64',\n",
       " 'u6d',\n",
       " 'u74',\n",
       " 'u68',\n",
       " 'u39',\n",
       " 'u65',\n",
       " 'u74',\n",
       " 'u62',\n",
       " 'u34',\n",
       " 'u2200',\n",
       " 'u76',\n",
       " 'u6c',\n",
       " 'u66',\n",
       " 'u74',\n",
       " 'u67',\n",
       " 'u62',\n",
       " 'u64',\n",
       " 'u35',\n",
       " 'u66',\n",
       " 'u30',\n",
       " 'u32',\n",
       " 'u63',\n",
       " 'u33',\n",
       " 'u72',\n",
       " 'u63',\n",
       " 'u2200',\n",
       " 'u79',\n",
       " 'u6e',\n",
       " 'u33',\n",
       " 'u65',\n",
       " 'u71',\n",
       " 'u6d',\n",
       " 'u32',\n",
       " 'u36',\n",
       " 'u6a',\n",
       " 'u35',\n",
       " 'u78',\n",
       " 'u69',\n",
       " 'u75',\n",
       " 'u77',\n",
       " 'u2200',\n",
       " 'u68',\n",
       " 'u6c',\n",
       " 'u33',\n",
       " 'u62',\n",
       " 'u71',\n",
       " 'u38',\n",
       " 'u6c',\n",
       " 'u6b',\n",
       " 'u66',\n",
       " 'u70',\n",
       " 'u79',\n",
       " 'u75',\n",
       " 'u63',\n",
       " 'u77',\n",
       " 'u78',\n",
       " 'u38',\n",
       " 'u64',\n",
       " 'u70',\n",
       " 'u73',\n",
       " 'u6b',\n",
       " 'u78',\n",
       " 'u74',\n",
       " 'u75',\n",
       " 'u76',\n",
       " 'u33',\n",
       " 'u74',\n",
       " 'u6e',\n",
       " 'u67',\n",
       " 'u73',\n",
       " 'u30',\n",
       " 'u33',\n",
       " 'u6e',\n",
       " 'u79',\n",
       " 'u63',\n",
       " 'u78',\n",
       " 'u6d',\n",
       " 'u66',\n",
       " 'u65',\n",
       " 'u6f',\n",
       " 'u76',\n",
       " 'u71',\n",
       " 'u69',\n",
       " 'u72',\n",
       " 'u37',\n",
       " 'u2200',\n",
       " 'u37',\n",
       " 'u70',\n",
       " 'u38',\n",
       " 'u30',\n",
       " 'u70',\n",
       " 'u6f',\n",
       " 'u6d',\n",
       " 'u68',\n",
       " 'u2200',\n",
       " 'u6c',\n",
       " 'u62',\n",
       " 'u7a',\n",
       " 'u6e',\n",
       " 'u7a',\n",
       " 'u6d',\n",
       " 'u6a',\n",
       " 'u78',\n",
       " 'u70',\n",
       " 'u77',\n",
       " 'u6f',\n",
       " 'u6d',\n",
       " 'u6a',\n",
       " 'u35',\n",
       " 'u66',\n",
       " 'u38',\n",
       " 'u62',\n",
       " 'u63',\n",
       " 'u79',\n",
       " 'u66',\n",
       " 'u6d',\n",
       " 'u38',\n",
       " 'u74',\n",
       " 'u35',\n",
       " 'u39',\n",
       " 'u63',\n",
       " 'u76',\n",
       " 'u38',\n",
       " 'u73',\n",
       " 'u6f',\n",
       " 'u69',\n",
       " 'u6e',\n",
       " 'u78',\n",
       " 'u77',\n",
       " 'u72',\n",
       " 'u30',\n",
       " 'u73',\n",
       " 'u63',\n",
       " 'u76',\n",
       " 'u77',\n",
       " 'u34',\n",
       " 'u6d',\n",
       " 'u6f',\n",
       " 'u75',\n",
       " 'u77',\n",
       " 'u65',\n",
       " 'u2200',\n",
       " 'u30',\n",
       " 'u71',\n",
       " 'u35',\n",
       " 'u77',\n",
       " 'u6f',\n",
       " 'u36',\n",
       " 'u62',\n",
       " 'u63',\n",
       " 'u38',\n",
       " 'u33',\n",
       " 'u66',\n",
       " 'u64',\n",
       " 'u78',\n",
       " 'u68',\n",
       " 'u74',\n",
       " 'u73',\n",
       " 'u30',\n",
       " 'u39',\n",
       " 'u6e',\n",
       " 'u73',\n",
       " 'u63',\n",
       " 'u68',\n",
       " 'u78',\n",
       " 'u6b',\n",
       " 'u67',\n",
       " 'u72',\n",
       " 'u73',\n",
       " 'u33',\n",
       " 'u6a',\n",
       " 'u6c',\n",
       " 'u6e',\n",
       " 'u36',\n",
       " 'u71',\n",
       " 'u77',\n",
       " 'u34',\n",
       " 'u79',\n",
       " 'u70',\n",
       " 'u69',\n",
       " 'u72',\n",
       " 'u77',\n",
       " 'u68',\n",
       " 'u67',\n",
       " 'u75',\n",
       " 'u7a',\n",
       " 'u30',\n",
       " 'u36',\n",
       " 'u74',\n",
       " 'u70',\n",
       " 'u34',\n",
       " 'u6e',\n",
       " 'u7a',\n",
       " 'u79',\n",
       " 'u77',\n",
       " 'u71',\n",
       " 'u68',\n",
       " 'u68',\n",
       " 'u7a',\n",
       " 'u34',\n",
       " 'u33',\n",
       " 'u30',\n",
       " 'u74',\n",
       " 'u75',\n",
       " 'u32',\n",
       " 'u77',\n",
       " 'u66',\n",
       " 'u6a',\n",
       " 'u6d',\n",
       " 'u7a',\n",
       " 'u32',\n",
       " 'u70',\n",
       " 'u6a',\n",
       " 'u74',\n",
       " 'u39',\n",
       " 'u39',\n",
       " 'u6a',\n",
       " 'u7a',\n",
       " 'u62',\n",
       " 'u68',\n",
       " 'u70',\n",
       " 'u34',\n",
       " 'u7a',\n",
       " 'u35',\n",
       " 'u39',\n",
       " 'u65',\n",
       " 'u67',\n",
       " 'u34',\n",
       " 'u66',\n",
       " 'u6f',\n",
       " 'u79',\n",
       " 'u79',\n",
       " 'u7a',\n",
       " 'u37',\n",
       " 'u66',\n",
       " 'u68',\n",
       " 'u78',\n",
       " 'u70',\n",
       " 'u64',\n",
       " 'u66',\n",
       " 'u68',\n",
       " 'u7a',\n",
       " 'u64',\n",
       " 'u39',\n",
       " 'u33',\n",
       " 'u79',\n",
       " 'u64',\n",
       " 'u6c',\n",
       " 'u34',\n",
       " 'u6f',\n",
       " 'u6c',\n",
       " 'u7a',\n",
       " 'u38',\n",
       " 'u75',\n",
       " 'u6c',\n",
       " 'u79',\n",
       " 'u30',\n",
       " 'u32',\n",
       " 'u30']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_keep_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'u2203': 20,\n",
       "         'u68': 20,\n",
       "         'u34': 20,\n",
       "         'u6f': 20,\n",
       "         'u38': 20,\n",
       "         'u62': 20,\n",
       "         'u77': 20,\n",
       "         'u71': 20,\n",
       "         'u3bb': 20,\n",
       "         'u61': 20,\n",
       "         'u7a': 20,\n",
       "         'u39': 20,\n",
       "         'u72': 20,\n",
       "         'u3bc': 20,\n",
       "         'u76': 20,\n",
       "         'u73': 20,\n",
       "         'u30': 20,\n",
       "         'u69': 20,\n",
       "         'u6c': 20,\n",
       "         'u31': 20,\n",
       "         'u28': 20,\n",
       "         'u6d': 20,\n",
       "         'u3a': 20,\n",
       "         'u2e': 20,\n",
       "         'u74': 20,\n",
       "         'u2200': 20,\n",
       "         'u6e': 20,\n",
       "         'u35': 20,\n",
       "         'u36': 20,\n",
       "         'u6b': 20,\n",
       "         'u6a': 20,\n",
       "         'u37': 20,\n",
       "         'u63': 20,\n",
       "         'u64': 20,\n",
       "         'u75': 20,\n",
       "         'u66': 20,\n",
       "         'u33': 20,\n",
       "         'u29': 20,\n",
       "         'u67': 20,\n",
       "         'u70': 20,\n",
       "         'u79': 20,\n",
       "         'u32': 20,\n",
       "         'u78': 20,\n",
       "         'u65': 20})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Counter(to_keep_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 880)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = to_keep_file_paths\n",
    "labels = to_keep_labels\n",
    "len(image_paths), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_index: int = int(len(image_paths)*DATASET_SPLIT)\n",
    "all_label_classes: list[str] = sorted(list(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'∀∃().0123456789:λμabcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(list(map(lambda x: chr(int(x[1:], 16)), all_label_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=image_paths[:split_index], #list(image_paths[:split_index]) + to_add_file_paths,\n",
    "    labels=labels[:split_index], #list(labels[:split_index]) + to_add_labels,\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.05,\n",
    "    translation_limit=0.2,\n",
    "    skew_limit=0.02,\n",
    "    zoom_change=1.2,\n",
    "    min_zoom=0.8,\n",
    "    thicken_sigma=-4.9,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "val_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=image_paths[split_index:],\n",
    "    labels=labels[split_index:],\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.0,\n",
    "    translation_limit=0.0,\n",
    "    skew_limit=0.00,\n",
    "    zoom_change=0.0,\n",
    "    min_zoom=1.0,\n",
    "    thicken_sigma=0.0,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in train_char_dataset:\n",
    "    plt.imshow(\n",
    "        rearrange(im, \"1 h w -> h w\")*255, \n",
    "        cmap=\"gray\"\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for im, lab in val_char_dataset:\n",
    "    print(im.shape)\n",
    "    plt.imshow(rearrange(im, \"1 h w -> h w\")*255, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader: DataLoader = DataLoader(\n",
    "    train_char_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "val_dataloader: DataLoader = DataLoader(\n",
    "    val_char_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_model_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
    "        \"fully_connected_features\": (64, len(all_label_classes)),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.075,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": LOAD_CHECKPOINT\n",
    "    }\n",
    "]\n",
    "\n",
    "all_optim_parameters: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"lr\": 0.0007224,\n",
    "        \"weight_decay\": 0.000001\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.0.weight\n",
      "Loaded: encoder_conv_blocks.1.0.bias\n",
      "Loaded: encoder_conv_blocks.1.2.weight\n",
      "Loaded: encoder_conv_blocks.1.2.bias\n",
      "Loaded: encoder_conv_blocks.1.2.running_mean\n",
      "Loaded: encoder_conv_blocks.1.2.running_var\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.4.weight\n",
      "Loaded: encoder_conv_blocks.1.4.bias\n",
      "Loaded: encoder_conv_blocks.1.6.weight\n",
      "Loaded: encoder_conv_blocks.1.6.bias\n",
      "Loaded: encoder_conv_blocks.1.6.running_mean\n",
      "Loaded: encoder_conv_blocks.1.6.running_var\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.0.weight\n",
      "Loaded: encoder_conv_blocks.2.0.bias\n",
      "Loaded: encoder_conv_blocks.2.2.weight\n",
      "Loaded: encoder_conv_blocks.2.2.bias\n",
      "Loaded: encoder_conv_blocks.2.2.running_mean\n",
      "Loaded: encoder_conv_blocks.2.2.running_var\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.4.weight\n",
      "Loaded: encoder_conv_blocks.2.4.bias\n",
      "Loaded: encoder_conv_blocks.2.6.weight\n",
      "Loaded: encoder_conv_blocks.2.6.bias\n",
      "Loaded: encoder_conv_blocks.2.6.running_mean\n",
      "Loaded: encoder_conv_blocks.2.6.running_var\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.0.weight\n",
      "Loaded: encoder_conv_blocks.3.0.bias\n",
      "Loaded: encoder_conv_blocks.3.2.weight\n",
      "Loaded: encoder_conv_blocks.3.2.bias\n",
      "Loaded: encoder_conv_blocks.3.2.running_mean\n",
      "Loaded: encoder_conv_blocks.3.2.running_var\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.4.weight\n",
      "Loaded: encoder_conv_blocks.3.4.bias\n",
      "Loaded: encoder_conv_blocks.3.6.weight\n",
      "Loaded: encoder_conv_blocks.3.6.bias\n",
      "Loaded: encoder_conv_blocks.3.6.running_mean\n",
      "Loaded: encoder_conv_blocks.3.6.running_var\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.0.weight\n",
      "Loaded: encoder_conv_blocks.4.0.bias\n",
      "Loaded: encoder_conv_blocks.4.2.weight\n",
      "Loaded: encoder_conv_blocks.4.2.bias\n",
      "Loaded: encoder_conv_blocks.4.2.running_mean\n",
      "Loaded: encoder_conv_blocks.4.2.running_var\n",
      "Loaded: encoder_conv_blocks.4.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.4.weight\n",
      "Loaded: encoder_conv_blocks.4.4.bias\n",
      "Loaded: encoder_conv_blocks.4.6.weight\n",
      "Loaded: encoder_conv_blocks.4.6.bias\n",
      "Loaded: encoder_conv_blocks.4.6.running_mean\n",
      "Loaded: encoder_conv_blocks.4.6.running_var\n",
      "Loaded: encoder_conv_blocks.4.6.num_batches_tracked\n",
      "Loaded: fully_connected_blocks.0.0.weight\n",
      "Loaded: fully_connected_blocks.0.0.bias\n",
      "Skipping fully_connected_blocks.1.0.weight:  loaded size:torch.Size([43, 64]) != model size:  torch.Size([44, 64])\n",
      "Skipping fully_connected_blocks.1.0.bias:  loaded size:torch.Size([43]) != model size:  torch.Size([44])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 44]                   --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 32, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
      "│    │    └─Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
      "│    │    └─LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
      "├─Sequential: 1-2                        [1, 128]                  --\n",
      "│    └─Flatten: 2-6                      [1, 128]                  --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-7                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-41                 [1, 64]                   8,256\n",
      "│    │    └─Dropout: 3-42                [1, 64]                   --\n",
      "│    │    └─LeakyReLU: 3-43              [1, 64]                   --\n",
      "│    └─Sequential: 2-8                   [1, 44]                   --\n",
      "│    │    └─Linear: 3-44                 [1, 44]                   2,860\n",
      "==========================================================================================\n",
      "Total params: 83,548\n",
      "Trainable params: 83,548\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 14.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.18\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 2.53\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:20<00:00,  1.84s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:07<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12, 14, 19,  4, 16, 22, 14, 31,  5, 16, 42,  3, 26, 19,  4,  5]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([ 4, 16, 35, 23, 16, 25, 14, 16, 35, 24, 24,  8, 19, 20, 39, 24]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([22, 22, 33, 24, 31, 20, 39, 21, 36, 14, 26,  5, 22,  0, 27, 14]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 25, 28, 22,  5, 28,  0, 22,  3, 14, 18, 36, 25, 14]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([19, 19, 20, 24,  8, 24, 21, 23, 19, 22, 36,  0, 31,  5, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([42, 41,  2, 24, 27, 36,  8,  1,  2,  5, 19, 18,  0, 28, 10, 16]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 12, 25, 42, 31,  0,  4, 14, 25, 10, 16, 28,  5,  4,  3,  0]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([31, 42, 42,  4, 28,  1, 14,  8, 41,  6,  0, 24, 35, 16,  4,  6]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([16, 36, 22, 31, 31, 35,  4, 19, 42, 16, 28,  4, 24, 16, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([28, 24,  5,  3, 21,  8, 14, 31, 39, 23,  8, 21, 24, 42,  4, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([31, 24, 21, 33, 33, 28, 14,  2,  4,  8, 41,  2,  9, 14, 14, 31]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.08664772659540176\n",
      "Val Accuracy        : 0.15909090638160706\n",
      "Loss                : 0.3183075189590454\n",
      "Val Loss            : 0.212050661444664\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:18<00:00,  1.79s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0,  4, 33, 11,  5, 31,  5, 30, 19, 30,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 17,  0, 32, 30, 27, 10, 14,  8, 19, 20, 41, 24]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 22, 37, 10, 14, 20, 39, 22, 36,  3, 26, 31, 41,  0, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39,  0, 28, 30, 32, 38,  0, 22,  0,  5, 34, 10, 38, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 11,  8, 35, 21, 41,  0, 22, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([ 0, 41, 28, 24, 35, 36,  8, 27,  2, 31, 19, 34,  0, 28, 10, 17]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 20,  0,  0, 24, 38, 26,  5, 19, 37, 33, 28, 31, 43,  3,  0]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34,  0, 19, 26, 28,  1,  5, 22, 38,  6,  0, 31, 27, 30, 26,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([17, 11, 33, 14, 14, 27, 26, 19, 40, 17, 38, 12, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([28, 10, 32, 41, 21, 43, 12, 31, 39,  7, 17, 21, 23, 40, 26, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8,  3, 21,  2, 28, 32,  2, 26,  8, 38,  2, 39,  5,  7, 13]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.3764204680919647\n",
      "Val Accuracy        : 0.5625\n",
      "Loss                : 0.14730754494667053\n",
      "Val Loss            : 0.10107637196779251\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:20<00:00,  1.83s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13, 32, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 24]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 22, 36, 32, 26, 31, 41, 40, 35, 32]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40, 28, 30, 32, 38, 38, 22,  0, 32, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36, 32, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27,  2, 31, 11, 34,  0, 28, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33, 28, 31, 43,  3, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43, 28,  8,  5, 37, 38,  7, 40, 23, 27, 30, 26,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 40, 33, 28, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([28, 24, 32, 39, 21, 43, 12, 31, 25, 41, 33, 21, 23, 25, 26, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8,  3, 21,  2, 28, 32,  2, 43, 13, 38,  2, 39, 32,  7, 32]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.6761363744735718\n",
      "Val Accuracy        : 0.8181818127632141\n",
      "Loss                : 0.08317940682172775\n",
      "Val Loss            : 0.04685560241341591\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:23<00:00,  1.90s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 38, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 11,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27,  2, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43,  3, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 20,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 40, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 19, 43, 12, 23, 25, 41, 33, 21, 23, 25, 26, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7, 13]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.8309659361839294\n",
      "Val Accuracy        : 0.9431818127632141\n",
      "Loss                : 0.05291016399860382\n",
      "Val Loss            : 0.02421625703573227\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:23<00:00,  1.89s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 38, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 40, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 21, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42, 32,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.8821022510528564\n",
      "Val Accuracy        : 0.9715909361839294\n",
      "Loss                : 0.0367712527513504\n",
      "Val Loss            : 0.014492644928395748\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:21<00:00,  1.85s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 38, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  1, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 19, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.8977272510528564\n",
      "Val Accuracy        : 0.9772727489471436\n",
      "Loss                : 0.029160786420106888\n",
      "Val Loss            : 0.010843638330698013\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:21<00:00,  1.85s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 38, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 40, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 21, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9119318127632141\n",
      "Val Accuracy        : 0.9772727489471436\n",
      "Loss                : 0.024810083210468292\n",
      "Val Loss            : 0.007852905429899693\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:19<00:00,  1.81s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12, 40, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  1, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9204545617103577\n",
      "Val Accuracy        : 0.9829545617103577\n",
      "Loss                : 0.020162826403975487\n",
      "Val Loss            : 0.006628526374697685\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:16<00:00,  1.74s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 29, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9,  5, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9176136255264282\n",
      "Val Accuracy        : 0.9829545617103577\n",
      "Loss                : 0.020817385986447334\n",
      "Val Loss            : 0.00595353078097105\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:20<00:00,  1.83s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35, 32]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0, 32, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36, 32, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43, 32, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8, 32, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42, 32,  7, 32]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9332386255264282\n",
      "Val Accuracy        : 0.9545454382896423\n",
      "Loss                : 0.01823740452528\n",
      "Val Loss            : 0.008752704598009586\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:17<00:00,  1.75s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27,  2, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 40, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 19, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9417613744735718\n",
      "Val Accuracy        : 0.9772727489471436\n",
      "Loss                : 0.017736855894327164\n",
      "Val Loss            : 0.006780210416764021\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:21<00:00,  1.84s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40,  5, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30,  5, 38, 40, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9,  5, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9417613744735718\n",
      "Val Accuracy        : 0.9772727489471436\n",
      "Loss                : 0.014097794890403748\n",
      "Val Loss            : 0.005654993932694197\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:18<00:00,  1.78s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12, 19, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 38, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9,  5, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9332386255264282\n",
      "Val Accuracy        : 0.9772727489471436\n",
      "Loss                : 0.017445413395762444\n",
      "Val Loss            : 0.005336768925189972\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:18<00:00,  1.79s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9375\n",
      "Val Accuracy        : 0.9943181872367859\n",
      "Loss                : 0.016258127987384796\n",
      "Val Loss            : 0.004200214520096779\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:21<00:00,  1.84s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42,  0, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9375\n",
      "Val Accuracy        : 0.9886363744735718\n",
      "Loss                : 0.01525322999805212\n",
      "Val Loss            : 0.0053617642261087894\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:18<00:00,  1.79s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 38, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9460227489471436\n",
      "Val Accuracy        : 0.9886363744735718\n",
      "Loss                : 0.012031173333525658\n",
      "Val Loss            : 0.003405382391065359\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:18<00:00,  1.79s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:06<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9346590638160706\n",
      "Val Accuracy        : 0.9943181872367859\n",
      "Loss                : 0.016104958951473236\n",
      "Val Loss            : 0.003849905217066407\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:17<00:00,  1.77s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9517045617103577\n",
      "Val Accuracy        : 0.9943181872367859\n",
      "Loss                : 0.01020336989313364\n",
      "Val Loss            : 0.0024750379379838705\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...: 100%|██████████| 44/44 [01:19<00:00,  1.81s/it]\n",
      "Validating Model...: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0,  2, 19, 43, 31]) tensor([35, 12,  0, 12, 33, 13,  5, 33, 32, 30, 25,  0, 29, 19, 43, 31])\n",
      "tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23]) tensor([43, 30, 27, 41, 33, 40, 32, 30, 27, 10, 23, 13, 19, 20, 42, 23])\n",
      "tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5]) tensor([30, 13, 37, 10, 14, 20, 39, 13, 36, 32, 26, 31, 41, 40, 35,  5])\n",
      "tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32]) tensor([36, 20, 39, 40,  9, 30, 32, 38, 40, 22,  0,  5, 34, 10, 40, 32])\n",
      "tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20]) tensor([11, 19, 20, 13,  8, 23, 21, 41, 25, 37, 36,  5, 14, 31, 36, 20])\n",
      "tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33]) tensor([25, 41, 28, 24, 35, 36,  8, 27, 29, 31, 11, 34, 40,  9, 42, 33])\n",
      "tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40]) tensor([26, 35, 40, 25, 24, 38, 43,  5, 11, 37, 33,  9, 31, 43, 42, 40])\n",
      "tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7]) tensor([34, 25, 25, 43,  9,  8,  5, 37, 38,  7, 40, 23, 27, 30, 43,  7])\n",
      "tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24]) tensor([33, 27, 37, 14, 14, 27, 43, 19, 25, 33,  9, 43, 10, 14, 22, 24])\n",
      "tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21]) tensor([ 9, 23, 32, 42, 42, 43, 12, 23, 25, 41, 33, 21, 23, 25, 43, 21])\n",
      "tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5]) tensor([14,  8, 42, 21, 29,  9, 32, 29, 43, 13, 38, 29, 42,  5,  7,  5])\n",
      "Train Accuracy      : 0.9360795617103577\n",
      "Val Accuracy        : 0.9943181872367859\n",
      "Loss                : 0.014423190616071224\n",
      "Val Loss            : 0.0024913884699344635\n",
      "Learning Rate       : 0.0007224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model...:   2%|▏         | 1/44 [00:03<02:11,  3.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epoch_log: EpochLogs\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_log \u001b[38;5;129;01min\u001b[39;00m grid_search(\n\u001b[0;32m      3\u001b[0m     model_factory\u001b[38;5;241m=\u001b[39mAllCNN2D,\n\u001b[0;32m      4\u001b[0m     all_model_parameters\u001b[38;5;241m=\u001b[39mall_model_parameters,\n\u001b[0;32m      5\u001b[0m     optim_factory\u001b[38;5;241m=\u001b[39mAdamW,\n\u001b[0;32m      6\u001b[0m     all_optim_params\u001b[38;5;241m=\u001b[39mall_optim_parameters,\n\u001b[0;32m      7\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[0;32m      8\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),\n\u001b[0;32m      9\u001b[0m     train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m     10\u001b[0m     val_dataloader\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[0;32m     11\u001b[0m     lr_decay_window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     12\u001b[0m     lr_decay_minimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m     13\u001b[0m     scheduler_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m,\n\u001b[0;32m     14\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m ):\n\u001b[0;32m     16\u001b[0m     train_logpoints: \u001b[38;5;28mlist\u001b[39m[LogPoint] \u001b[38;5;241m=\u001b[39m epoch_log\u001b[38;5;241m.\u001b[39mtrain_logs\n\u001b[0;32m     17\u001b[0m     val_logpoints: \u001b[38;5;28mlist\u001b[39m[LogPoint] \u001b[38;5;241m=\u001b[39m epoch_log\u001b[38;5;241m.\u001b[39mval_logs\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\training\\train.py:334\u001b[0m, in \u001b[0;36mgrid_search\u001b[1;34m(model_factory, all_model_parameters, optim_factory, all_optim_params, epochs, criterion, train_dataloader, val_dataloader, lr_decay_window_size, lr_decay_minimum, scheduler_scale, device, compile_model)\u001b[0m\n\u001b[0;32m    331\u001b[0m optimiser_loss: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m model_optimiser\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    333\u001b[0m train_log: LogPoint\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_log \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m    335\u001b[0m     train(\n\u001b[0;32m    336\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    337\u001b[0m         optimiser\u001b[38;5;241m=\u001b[39mmodel_optimiser,\n\u001b[0;32m    338\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[0;32m    339\u001b[0m         train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m    340\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m    341\u001b[0m     ),\n\u001b[0;32m    342\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    343\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[0;32m    344\u001b[0m ):\n\u001b[0;32m    345\u001b[0m     epoch_train_logs\u001b[38;5;241m.\u001b[39mappend(train_log)\n\u001b[0;32m    346\u001b[0m     epoch_cur_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m    347\u001b[0m         train_log\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach(\n\u001b[0;32m    348\u001b[0m         )\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    349\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\training\\train.py:258\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimiser, criterion, train_dataloader, device)\u001b[0m\n\u001b[0;32m    256\u001b[0m X: Tensor\n\u001b[0;32m    257\u001b[0m y: Tensor\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m    260\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m    262\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:102\u001b[0m, in \u001b[0;36mCharImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     99\u001b[0m image \u001b[38;5;241m=\u001b[39m reduce(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc h w -> 1 h w\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Apply random transformations\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_random_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# One-hot encode the label\u001b[39;00m\n\u001b[0;32m    107\u001b[0m one_hot_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_set),\n\u001b[0;32m    109\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m    110\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:201\u001b[0m, in \u001b[0;36mCharImageDataset._apply_random_transformations\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Apply GaussianBlur\u001b[39;00m\n\u001b[0;32m    194\u001b[0m gaussian_blur \u001b[38;5;241m=\u001b[39m GaussianBlur(\n\u001b[0;32m    195\u001b[0m     kernel_size\u001b[38;5;241m=\u001b[39mkernel_size,\n\u001b[0;32m    196\u001b[0m     sigma\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[0;32m    200\u001b[0m )\n\u001b[1;32m--> 201\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Adjust for thickening or thinning\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m thicken_thinning_sigma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;66;03m# Thickening: Increase the character's size by lowering the threshold\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:1812\u001b[0m, in \u001b[0;36mGaussianBlur.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;124;03m    img (PIL Image or Tensor): image to be blurred.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1809\u001b[0m \u001b[38;5;124;03m    PIL Image or Tensor: Gaussian blurred image\u001b[39;00m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1811\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m-> 1812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:1380\u001b[0m, in \u001b[0;36mgaussian_blur\u001b[1;34m(img, kernel_size, sigma)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be PIL Image or Tensor. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1378\u001b[0m     t_img \u001b[38;5;241m=\u001b[39m pil_to_tensor(img)\n\u001b[1;32m-> 1380\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1383\u001b[0m     output \u001b[38;5;241m=\u001b[39m to_pil_image(output, mode\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mmode)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:761\u001b[0m, in \u001b[0;36mgaussian_blur\u001b[1;34m(img, kernel_size, sigma)\u001b[0m\n\u001b[0;32m    759\u001b[0m padding \u001b[38;5;241m=\u001b[39m [kernel_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    760\u001b[0m img \u001b[38;5;241m=\u001b[39m torch_pad(img, padding, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 761\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    763\u001b[0m img \u001b[38;5;241m=\u001b[39m _cast_squeeze_out(img, need_cast, need_squeeze, out_dtype)\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epoch_log: EpochLogs\n",
    "for epoch_log in grid_search(\n",
    "    model_factory=AllCNN2D,\n",
    "    all_model_parameters=all_model_parameters,\n",
    "    optim_factory=AdamW,\n",
    "    all_optim_params=all_optim_parameters,\n",
    "    epochs=10000,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    lr_decay_window_size=10,\n",
    "    lr_decay_minimum=0.0,\n",
    "    scheduler_scale=0.85,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    train_logpoints: list[LogPoint] = epoch_log.train_logs\n",
    "    val_logpoints: list[LogPoint] = epoch_log.val_logs\n",
    "    \n",
    "    \n",
    "    train_count: int = 0\n",
    "    val_count: int = 0\n",
    "    \n",
    "    train_losses_tally: float = 0.0\n",
    "    val_losses_tally: float = 0.0\n",
    "    \n",
    "    train_correct_tally: int = 0\n",
    "    val_correct_tally: int = 0\n",
    "    \n",
    "    for log_point in train_logpoints: \n",
    "        \n",
    "        y_hat_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y_hat, \n",
    "            axis=-1\n",
    "        ).detach().cpu()\n",
    "        \n",
    "        y_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y, axis=-1\n",
    "        ).detach().cpu()\n",
    "\n",
    "        \n",
    "        train_is_correct = y_hat_pred==y_pred\n",
    "        train_correct_tally += torch.sum(train_is_correct)\n",
    "        \n",
    "        train_losses_tally += torch.sum(log_point.loss)\n",
    "        \n",
    "        train_count += len(y_hat_pred)\n",
    "        \n",
    "    for log_point in val_logpoints: \n",
    "        \n",
    "        y_hat_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y_hat, \n",
    "            axis=-1\n",
    "        ).detach().cpu()\n",
    "        \n",
    "        y_pred: torch.Tensor = torch.argmax(\n",
    "            log_point.y, axis=-1\n",
    "        ).detach().cpu()\n",
    "        print(y_hat_pred, y_pred)\n",
    "        val_correct_tally += torch.sum(y_hat_pred==y_pred)\n",
    "        \n",
    "        val_losses_tally += torch.sum(log_point.loss)\n",
    "        \n",
    "        val_count += len(y_hat_pred)\n",
    "        \n",
    "    train_accuracy: float = train_correct_tally/train_count\n",
    "    val_accuracy: float = val_correct_tally/val_count\n",
    "    \n",
    "    train_loss: float = train_losses_tally/train_count\n",
    "    val_loss: float = val_losses_tally/val_count\n",
    "    \n",
    "    cur_learning_rate: float = epoch_log.optimiser.param_groups[0][\"lr\"]\n",
    "    \n",
    "    model_checkpoint_path: str = os.path.join(\n",
    "        model_save_dirpath,\n",
    "        f\"{MODEL_NAME}_epoch{epoch_log.epoch}_trainacc{train_accuracy:.5}_valacc{val_accuracy:.5}_Tloss{train_loss:.5}_Vloss{val_loss:.5}_lr{cur_learning_rate}.pkl\"\n",
    "    )\n",
    "    \n",
    "    with open(model_checkpoint_path, \"wb\") as f:\n",
    "        torch.save(epoch_log.model.state_dict(), f)\n",
    "    \n",
    "    print(f\"Train Accuracy      : {train_accuracy}\")\n",
    "    print(f\"Val Accuracy        : {val_accuracy}\")\n",
    "    print(f\"Loss                : {train_loss}\")\n",
    "    print(f\"Val Loss            : {val_loss}\")\n",
    "    print(f\"Learning Rate       : {cur_learning_rate}\")\n",
    "    \n",
    "    log(\n",
    "        epoch_log.epoch,\n",
    "        train_accuracy,\n",
    "        train_loss,\n",
    "        val_accuracy,\n",
    "        val_loss,\n",
    "        cur_learning_rate\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.0.weight\n",
      "Loaded: encoder_conv_blocks.1.0.bias\n",
      "Loaded: encoder_conv_blocks.1.2.weight\n",
      "Loaded: encoder_conv_blocks.1.2.bias\n",
      "Loaded: encoder_conv_blocks.1.2.running_mean\n",
      "Loaded: encoder_conv_blocks.1.2.running_var\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.4.weight\n",
      "Loaded: encoder_conv_blocks.1.4.bias\n",
      "Loaded: encoder_conv_blocks.1.6.weight\n",
      "Loaded: encoder_conv_blocks.1.6.bias\n",
      "Loaded: encoder_conv_blocks.1.6.running_mean\n",
      "Loaded: encoder_conv_blocks.1.6.running_var\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.0.weight\n",
      "Loaded: encoder_conv_blocks.2.0.bias\n",
      "Loaded: encoder_conv_blocks.2.2.weight\n",
      "Loaded: encoder_conv_blocks.2.2.bias\n",
      "Loaded: encoder_conv_blocks.2.2.running_mean\n",
      "Loaded: encoder_conv_blocks.2.2.running_var\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.4.weight\n",
      "Loaded: encoder_conv_blocks.2.4.bias\n",
      "Loaded: encoder_conv_blocks.2.6.weight\n",
      "Loaded: encoder_conv_blocks.2.6.bias\n",
      "Loaded: encoder_conv_blocks.2.6.running_mean\n",
      "Loaded: encoder_conv_blocks.2.6.running_var\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.0.weight\n",
      "Loaded: encoder_conv_blocks.3.0.bias\n",
      "Loaded: encoder_conv_blocks.3.2.weight\n",
      "Loaded: encoder_conv_blocks.3.2.bias\n",
      "Loaded: encoder_conv_blocks.3.2.running_mean\n",
      "Loaded: encoder_conv_blocks.3.2.running_var\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.4.weight\n",
      "Loaded: encoder_conv_blocks.3.4.bias\n",
      "Loaded: encoder_conv_blocks.3.6.weight\n",
      "Loaded: encoder_conv_blocks.3.6.bias\n",
      "Loaded: encoder_conv_blocks.3.6.running_mean\n",
      "Loaded: encoder_conv_blocks.3.6.running_var\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.0.weight\n",
      "Loaded: encoder_conv_blocks.4.0.bias\n",
      "Loaded: encoder_conv_blocks.4.2.weight\n",
      "Loaded: encoder_conv_blocks.4.2.bias\n",
      "Loaded: encoder_conv_blocks.4.2.running_mean\n",
      "Loaded: encoder_conv_blocks.4.2.running_var\n",
      "Loaded: encoder_conv_blocks.4.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.4.weight\n",
      "Loaded: encoder_conv_blocks.4.4.bias\n",
      "Loaded: encoder_conv_blocks.4.6.weight\n",
      "Loaded: encoder_conv_blocks.4.6.bias\n",
      "Loaded: encoder_conv_blocks.4.6.running_mean\n",
      "Loaded: encoder_conv_blocks.4.6.running_var\n",
      "Loaded: encoder_conv_blocks.4.6.num_batches_tracked\n",
      "Loaded: fully_connected_blocks.0.0.weight\n",
      "Loaded: fully_connected_blocks.0.0.bias\n",
      "Loaded: fully_connected_blocks.1.0.weight\n",
      "Loaded: fully_connected_blocks.1.0.bias\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 44]                   --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 32, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
      "│    │    └─Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
      "│    │    └─LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
      "├─Sequential: 1-2                        [1, 128]                  --\n",
      "│    └─Flatten: 2-6                      [1, 128]                  --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-7                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-41                 [1, 64]                   8,256\n",
      "│    │    └─Dropout: 3-42                [1, 64]                   --\n",
      "│    │    └─LeakyReLU: 3-43              [1, 64]                   --\n",
      "│    └─Sequential: 2-8                   [1, 44]                   --\n",
      "│    │    └─Linear: 3-44                 [1, 44]                   2,860\n",
      "==========================================================================================\n",
      "Total params: 83,548\n",
      "Trainable params: 83,548\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 14.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.18\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 2.53\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model: AllCNN2D = AllCNN2D(\n",
    "    **{\n",
    "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
    "        \"fully_connected_features\": (64, 44),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.0,#0.075,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\models\\allcnn\\Indigo_epoch26_trainacc0.71327_valacc0.99057_Tloss0.072851_Vloss0.0056362_lr0.0007224999999999999.pkl\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m char, label \u001b[38;5;129;01min\u001b[39;00m val_char_dataset:\n\u001b[0;32m      2\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(char[\u001b[38;5;241m0\u001b[39m, :, :])\n\u001b[0;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:100\u001b[0m, in \u001b[0;36mCharImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     97\u001b[0m image \u001b[38;5;241m=\u001b[39m reduce(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc h w -> 1 h w\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Apply random transformations\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_random_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# One-hot encode the label\u001b[39;00m\n\u001b[0;32m    105\u001b[0m one_hot_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_set),\n\u001b[0;32m    107\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m    108\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:128\u001b[0m, in \u001b[0;36mCharImageDataset._apply_random_transformations\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Pad the image to prevent cropping during transformations\u001b[39;00m\n\u001b[0;32m    127\u001b[0m pad_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Adjust padding size as needed\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Random rotation\u001b[39;00m\n\u001b[0;32m    131\u001b[0m rotation_angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m365\u001b[39m,\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m365\u001b[39m\n\u001b[0;32m    134\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: pad() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "for char, label in val_char_dataset:\n",
    "    plt.imshow(char[0, :, :])\n",
    "    plt.show()\n",
    "    pred: torch.Tensor = model.forward(char.unsqueeze(0)).squeeze()\n",
    "    pred_index: int = torch.argmax(pred).item()\n",
    "    print(chr(int(all_label_classes[pred_index][1:], base=16)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
