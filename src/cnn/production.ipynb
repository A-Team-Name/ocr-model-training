{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from typing import Any\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import torch.nn.functional as torch_func\n",
    "from torchvision.transforms.functional import rotate, affine, resize, center_crop\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.allcnn2d import AllCNN2D, AllCNN2D_Prod\n",
    "from drawing.interactive import draw_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path: str = os.path.abspath(\".\")\n",
    "root_path: str = os.path.join(file_path, os.pardir, os.pardir)\n",
    "checkpoint_path: str = os.path.join(\n",
    "    root_path, \n",
    "    \"checkpoints\", \n",
    "    \"GeckoFull_epoch1980_trainacc0.90605_valacc0.98089_Tloss0.78068_Vloss0.20101_lr6.320194197753456e-11.pkl\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D_Prod                            [1, 44]                   --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 32, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
      "│    │    └─Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
      "│    │    └─LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
      "├─Sequential: 1-2                        [1, 128]                  --\n",
      "│    └─Flatten: 2-6                      [1, 128]                  --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-7                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-41                 [1, 64]                   8,256\n",
      "│    │    └─Dropout: 3-42                [1, 64]                   --\n",
      "│    │    └─LeakyReLU: 3-43              [1, 64]                   --\n",
      "│    └─Sequential: 2-8                   [1, 44]                   --\n",
      "│    │    └─Linear: 3-44                 [1, 44]                   2,860\n",
      "==========================================================================================\n",
      "Total params: 83,548\n",
      "Trainable params: 83,548\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 14.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.18\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 2.53\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "alphabet: list[str] = ['(', ')', '+', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'λ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '×', '÷']\n",
    "\n",
    "model: AllCNN2D_Prod = AllCNN2D_Prod(\n",
    "    labels_map=alphabet,\n",
    "    **{\n",
    "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
    "        \"fully_connected_features\": (64, 44),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cpu\",\n",
    "        \"conv_dropout\": 0.0,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": \"GeckoFinal\",\n",
    "        #\"checkpoint_path\": checkpoint_path\n",
    "    }\n",
    "\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '(', 40),\n",
       " (1, ')', 41),\n",
       " (2, '+', 43),\n",
       " (3, '-', 45),\n",
       " (4, '.', 46),\n",
       " (5, '0', 48),\n",
       " (6, '1', 49),\n",
       " (7, '2', 50),\n",
       " (8, '3', 51),\n",
       " (9, '4', 52),\n",
       " (10, '5', 53),\n",
       " (11, '6', 54),\n",
       " (12, '7', 55),\n",
       " (13, '8', 56),\n",
       " (14, '9', 57),\n",
       " (15, 'λ', 955),\n",
       " (16, 'a', 97),\n",
       " (17, 'b', 98),\n",
       " (18, 'c', 99),\n",
       " (19, 'd', 100),\n",
       " (20, 'e', 101),\n",
       " (21, 'f', 102),\n",
       " (22, 'g', 103),\n",
       " (23, 'h', 104),\n",
       " (24, 'i', 105),\n",
       " (25, 'j', 106),\n",
       " (26, 'k', 107),\n",
       " (27, 'l', 108),\n",
       " (28, 'm', 109),\n",
       " (29, 'n', 110),\n",
       " (30, 'o', 111),\n",
       " (31, 'p', 112),\n",
       " (32, 'q', 113),\n",
       " (33, 'r', 114),\n",
       " (34, 's', 115),\n",
       " (35, 't', 116),\n",
       " (36, 'u', 117),\n",
       " (37, 'v', 118),\n",
       " (38, 'w', 119),\n",
       " (39, 'x', 120),\n",
       " (40, 'y', 121),\n",
       " (41, 'z', 122),\n",
       " (42, '×', 215),\n",
       " (43, '÷', 247)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, char, ord(char)) for i, char in enumerate(alphabet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\models\\allcnn2d.py:573: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  softmaxed_char.tolist(),\n",
      "c:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\models\\allcnn2d.py:585: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  softmax_ordered: Tensor = tensor(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dummy input tensor\n",
    "dummy_input = torch.randn(1, 1, 64, 64)  # Example input\n",
    "\n",
    "# Define the ONNX file path\n",
    "onnx_file_path = \"model.onnx\"\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_file_path,\n",
    "    input_names=[\"input\"],  # Name of the input layer\n",
    "    output_names=[\"logits\", \"softmax\", \"softmax_ordered\"],  # Names of the output layers\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"},  # Variable batch size\n",
    "                  \"logits\": {0: \"batch_size\"},\n",
    "                  \"softmax\": {0: \"batch_size\"},\n",
    "                  \"softmax_ordered\": {0: \"batch_size\"}},\n",
    "    opset_version=11  # Specify the ONNX opset version\n",
    ")\n",
    "\n",
    "print(f\"Model saved to {onnx_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the ONNX model\n",
    "model_path = \"model.onnx\"\n",
    "session = onnxruntime.InferenceSession(model_path)\n",
    "\n",
    "input_image = np.random.random(\n",
    "    (\n",
    "        1,  # batch: stack as many images as you like here\n",
    "        1,  # channels: needs to be 1 (grayscale), pixels are 1.0 or 0.0\n",
    "        64, # height: fixed to 64 pixels for now\n",
    "        64  # width: fixed to 64 pixels for now\n",
    "    )\n",
    ").astype(np.float32)\n",
    "\n",
    "# Run inference\n",
    "inputs: list[onnxruntime.NodeArg] = session.get_inputs()\n",
    "outputs: list[onnxruntime.NodeArg] = session.get_outputs()\n",
    "\n",
    "input_name: list[str] = inputs[0].name\n",
    "output_names: list[str] = [out.name for out in outputs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "softmax: np.ndarray\n",
    "softmax_ordered: np.ndarray\n",
    "logits: np.ndarray\n",
    "\n",
    "logits, softmax, softmax_ordered = session.run(\n",
    "    output_names, \n",
    "    {input_name: input_image}\n",
    ")\n",
    "\n",
    "# logits.shape is shape (batch, character) for all character labels\n",
    "# softmax.shape is shape (batch, character) for all character labels\n",
    "# softmax_ordered is shape (batch, character, [label index, label prob, unicode character value])\n",
    "\n",
    "# character dim is 44 (there are 44 character labels)\n",
    "# label index is from 0 to 44 (corresponding to each ordered label index)\n",
    "# label prob is a softmaxed probability for this label prediction\n",
    "# unicode character value is the unicode character for this prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 44), (1, 44), (1, 44, 3))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, softmax.shape, softmax_ordered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "top_character_probs: list[list[float]] = softmax_ordered[:, :, 1].tolist()\n",
    "\n",
    "top_characters: list[list[str]] = [\n",
    "    [\n",
    "        chr(int(softmax_ordered[batch_i, i, 2])) \n",
    "        for i in range(softmax_ordered.shape[1])\n",
    "    ] for batch_i in \n",
    "    range(softmax_ordered.shape[0])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextReShitter(nn.Module):\n",
    "    \n",
    "    def __init__(self, alphabet: list[str], text: str):\n",
    "        \n",
    "        super(TextReShitter, self).__init__()\n",
    "        \n",
    "        self.alphabet: list[str] = alphabet\n",
    "        self.text: str = text\n",
    "        \n",
    "        self.logits: list[torch.Tensor] = []\n",
    "        \n",
    "        for c in self.text:\n",
    "            c_index: int = self.alphabet.index(c)\n",
    "            \n",
    "            char_logits: torch.Tensor = torch.rand((len(alphabet),))\n",
    "            char_logits[c_index] += 2\n",
    "            char_logits *= (torch.rand(1)+0.1)\n",
    "\n",
    "            self.logits.append(char_logits)\n",
    "\n",
    "        self.logits_tensor: torch.Tensor = torch.stack(self.logits, dim=0)\n",
    "        \n",
    "        self.logits_tensor = self.logits_tensor.unsqueeze(0) # batch, chars, logit\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        self.logits_tensor = self.logits_tensor + x.sum() * 0.0  \n",
    "\n",
    "        softmax = torch.softmax(self.logits_tensor, dim=-1)\n",
    "        \n",
    "        # Create indices for the first dimension (char_prob_i)\n",
    "        char_prob_indices = torch.arange(softmax.size(-1), device=softmax.device).reshape(1, 1, -1, 1)\n",
    "        \n",
    "        # Create indices for the third dimension (ord(self.alphabet[char_prob_i]))\n",
    "        alphabet_indices = torch.tensor([ord(c) for c in self.alphabet], device=softmax.device).reshape(1, 1, -1, 1)\n",
    "        \n",
    "        # Expand dimensions to match softmax shape\n",
    "        char_prob_indices = char_prob_indices.expand(*softmax.shape, 1)\n",
    "        alphabet_indices = alphabet_indices.expand(*softmax.shape, 1)\n",
    "        \n",
    "        # Concatenate along the last dimension\n",
    "        softmax_ordered = torch.cat([char_prob_indices, softmax.unsqueeze(-1), alphabet_indices], dim=-1)\n",
    "        \n",
    "        # Sort along the probability dimension (dim=-2)\n",
    "        sorting_indices = softmax_ordered[..., 1].argsort(dim=-1, descending=True)\n",
    "        sorted_tensor = torch.gather(softmax_ordered, -2, sorting_indices.unsqueeze(-1).expand(-1, -1, -1, 3))\n",
    "        \n",
    "        x = x * 0.5\n",
    "        \n",
    "        unicodes: torch.Tensor = sorted_tensor[0, :, :, 2]\n",
    "        probs: torch.Tensor = sorted_tensor[0, :, :, 1]\n",
    "        \n",
    "        unicodes = unicodes.to(dtype=torch.int)\n",
    "        \n",
    "        return unicodes, probs \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[104,  54,  57,  98, 121, 113, 111, 105,  50, 118,  55, 119,  51,  43,\n",
       "          116,  40, 108, 117, 247,  97, 215, 115, 122,  99,  52,  45, 110,  53,\n",
       "           41, 112,  48,  46, 103, 100,  49, 109,  56, 120, 955, 106, 114, 107,\n",
       "          101, 102],\n",
       "         [101, 103,  57, 955,  53,  97, 100, 215,  51, 114, 119,  40, 109,  48,\n",
       "          108,  54,  46,  50, 102, 121, 247, 120, 116, 115, 122,  99,  55, 104,\n",
       "           98,  41, 107, 110, 106, 113, 118, 105,  43, 117,  45, 111,  52, 112,\n",
       "           56,  49],\n",
       "         [108,  51,  50, 103, 105, 100, 113, 116, 247, 109, 119,  99,  45, 104,\n",
       "          121, 118,  46,  43,  98,  55, 120,  52, 955,  54,  41,  49,  57, 115,\n",
       "          102,  48,  53, 112, 101,  40, 114, 111, 215, 122,  56, 106,  97, 117,\n",
       "          107, 110],\n",
       "         [108,  45, 116,  99,  54,  48, 102, 121, 106,  51,  98,  56,  46, 215,\n",
       "          115, 247, 101,  40,  52,  49,  57, 104, 111, 120, 955,  55, 110, 122,\n",
       "          119, 113, 100,  41, 109,  50,  97, 117,  43, 118, 103, 114, 107, 105,\n",
       "           53, 112],\n",
       "         [111, 101,  57,  48,  99, 118, 112, 215,  49, 104, 114, 122, 105,  98,\n",
       "           46, 103, 110, 120, 115,  97,  54,  45,  53,  51, 116,  40,  50, 108,\n",
       "           56, 117, 113, 109, 119,  43, 121, 107, 100,  41,  52,  55, 955, 102,\n",
       "          247, 106],\n",
       "         [ 46, 112, 117, 106, 111, 115, 247, 119,  54, 103, 109, 113, 107, 101,\n",
       "           97, 122, 110, 121, 114,  43,  40, 116, 118, 105,  49, 215, 100,  57,\n",
       "           48,  51,  52,  56,  55,  41, 104, 955,  53,  98, 108,  99,  45, 120,\n",
       "          102,  50],\n",
       "         [119, 112,  55,  45,  51, 111,  54,  98, 102,  52, 247,  57, 955,  40,\n",
       "          118, 115, 100,  97, 103, 101, 110, 107, 117, 106, 121, 109,  41,  53,\n",
       "          120, 105,  49,  46,  56, 114, 104,  48, 108,  43, 215, 122, 116,  99,\n",
       "          113,  50],\n",
       "         [111,  55, 107, 120, 100,  98,  57,  41, 113,  51,  99, 103,  50, 108,\n",
       "          105, 116,  48, 215, 112, 106,  43,  56, 122,  46,  52, 119,  40, 109,\n",
       "           45, 102,  97, 104, 101, 118,  49, 110, 114,  53, 247, 121,  54, 115,\n",
       "          955, 117],\n",
       "         [114,  56, 104,  97, 103,  55, 116,  41, 105, 215,  49,  48, 101, 118,\n",
       "           57, 107, 119, 109, 247, 955,  40, 111,  52,  98, 108,  51,  54, 120,\n",
       "          112, 115,  53,  45, 117, 121, 100,  46, 102,  99,  43,  50, 106, 110,\n",
       "          122, 113],\n",
       "         [108,  54,  43, 118, 115,  51, 102,  41,  55, 117,  98, 101, 122, 215,\n",
       "          119, 100,  56, 116, 107,  99,  48, 109,  49, 106,  45, 121,  46, 105,\n",
       "           53,  52,  97, 112, 955, 104, 113, 111, 114,  50, 247,  40, 103, 120,\n",
       "           57, 110],\n",
       "         [100,  46, 103, 105, 215, 117, 110, 104, 113, 119, 118, 247,  54,  48,\n",
       "          121, 112, 122, 114,  49, 106,  57,  56, 120,  98, 102, 955,  52, 101,\n",
       "          108, 107,  40, 115, 109,  43,  51,  99,  50, 111,  55,  97, 116,  45,\n",
       "           53,  41]], dtype=torch.int32),\n",
       " tensor([[0.1105, 0.0316, 0.0312, 0.0310, 0.0306, 0.0294, 0.0279, 0.0268, 0.0261,\n",
       "          0.0260, 0.0260, 0.0257, 0.0255, 0.0242, 0.0237, 0.0235, 0.0226, 0.0226,\n",
       "          0.0222, 0.0219, 0.0219, 0.0214, 0.0208, 0.0202, 0.0198, 0.0196, 0.0191,\n",
       "          0.0187, 0.0187, 0.0170, 0.0165, 0.0162, 0.0154, 0.0151, 0.0150, 0.0145,\n",
       "          0.0142, 0.0142, 0.0136, 0.0125, 0.0122, 0.0114, 0.0114, 0.0113],\n",
       "         [0.0369, 0.0249, 0.0248, 0.0248, 0.0248, 0.0248, 0.0246, 0.0245, 0.0243,\n",
       "          0.0243, 0.0241, 0.0240, 0.0239, 0.0239, 0.0238, 0.0238, 0.0236, 0.0233,\n",
       "          0.0231, 0.0231, 0.0229, 0.0229, 0.0227, 0.0226, 0.0224, 0.0224, 0.0223,\n",
       "          0.0219, 0.0219, 0.0217, 0.0216, 0.0212, 0.0212, 0.0210, 0.0208, 0.0201,\n",
       "          0.0201, 0.0199, 0.0196, 0.0193, 0.0193, 0.0192, 0.0190, 0.0190],\n",
       "         [0.0446, 0.0253, 0.0252, 0.0250, 0.0250, 0.0248, 0.0247, 0.0247, 0.0240,\n",
       "          0.0240, 0.0240, 0.0239, 0.0237, 0.0235, 0.0235, 0.0234, 0.0232, 0.0229,\n",
       "          0.0227, 0.0227, 0.0223, 0.0221, 0.0219, 0.0219, 0.0216, 0.0215, 0.0214,\n",
       "          0.0211, 0.0210, 0.0210, 0.0208, 0.0206, 0.0206, 0.0205, 0.0205, 0.0205,\n",
       "          0.0203, 0.0203, 0.0202, 0.0202, 0.0201, 0.0199, 0.0196, 0.0194],\n",
       "         [0.0365, 0.0246, 0.0246, 0.0244, 0.0243, 0.0242, 0.0241, 0.0241, 0.0240,\n",
       "          0.0239, 0.0239, 0.0237, 0.0237, 0.0234, 0.0234, 0.0234, 0.0230, 0.0228,\n",
       "          0.0227, 0.0226, 0.0225, 0.0225, 0.0225, 0.0222, 0.0221, 0.0220, 0.0220,\n",
       "          0.0220, 0.0219, 0.0218, 0.0217, 0.0215, 0.0213, 0.0212, 0.0210, 0.0208,\n",
       "          0.0208, 0.0208, 0.0206, 0.0205, 0.0204, 0.0203, 0.0203, 0.0202],\n",
       "         [0.1248, 0.0297, 0.0292, 0.0291, 0.0290, 0.0290, 0.0286, 0.0275, 0.0272,\n",
       "          0.0262, 0.0250, 0.0244, 0.0243, 0.0241, 0.0234, 0.0230, 0.0226, 0.0218,\n",
       "          0.0217, 0.0214, 0.0207, 0.0202, 0.0202, 0.0192, 0.0190, 0.0188, 0.0184,\n",
       "          0.0184, 0.0182, 0.0176, 0.0174, 0.0168, 0.0154, 0.0148, 0.0144, 0.0142,\n",
       "          0.0135, 0.0133, 0.0133, 0.0132, 0.0132, 0.0130, 0.0129, 0.0121],\n",
       "         [0.0831, 0.0307, 0.0302, 0.0302, 0.0297, 0.0293, 0.0292, 0.0292, 0.0285,\n",
       "          0.0281, 0.0271, 0.0266, 0.0250, 0.0245, 0.0234, 0.0233, 0.0230, 0.0228,\n",
       "          0.0226, 0.0214, 0.0211, 0.0208, 0.0207, 0.0204, 0.0200, 0.0194, 0.0189,\n",
       "          0.0182, 0.0177, 0.0177, 0.0177, 0.0168, 0.0166, 0.0164, 0.0163, 0.0160,\n",
       "          0.0156, 0.0155, 0.0150, 0.0147, 0.0142, 0.0141, 0.0141, 0.0140],\n",
       "         [0.0618, 0.0272, 0.0269, 0.0265, 0.0264, 0.0263, 0.0259, 0.0255, 0.0254,\n",
       "          0.0251, 0.0251, 0.0249, 0.0246, 0.0242, 0.0237, 0.0234, 0.0233, 0.0232,\n",
       "          0.0227, 0.0227, 0.0224, 0.0223, 0.0221, 0.0203, 0.0202, 0.0200, 0.0199,\n",
       "          0.0199, 0.0199, 0.0196, 0.0194, 0.0193, 0.0193, 0.0191, 0.0190, 0.0189,\n",
       "          0.0183, 0.0181, 0.0181, 0.0180, 0.0178, 0.0178, 0.0178, 0.0178],\n",
       "         [0.0979, 0.0313, 0.0303, 0.0293, 0.0291, 0.0289, 0.0271, 0.0265, 0.0259,\n",
       "          0.0257, 0.0252, 0.0244, 0.0241, 0.0236, 0.0231, 0.0230, 0.0216, 0.0215,\n",
       "          0.0213, 0.0207, 0.0207, 0.0205, 0.0204, 0.0203, 0.0198, 0.0195, 0.0189,\n",
       "          0.0188, 0.0184, 0.0183, 0.0180, 0.0180, 0.0169, 0.0168, 0.0164, 0.0163,\n",
       "          0.0161, 0.0157, 0.0156, 0.0156, 0.0151, 0.0147, 0.0143, 0.0142],\n",
       "         [0.0317, 0.0248, 0.0247, 0.0247, 0.0246, 0.0245, 0.0241, 0.0241, 0.0239,\n",
       "          0.0238, 0.0236, 0.0236, 0.0233, 0.0233, 0.0233, 0.0232, 0.0232, 0.0228,\n",
       "          0.0227, 0.0226, 0.0225, 0.0225, 0.0224, 0.0224, 0.0224, 0.0220, 0.0219,\n",
       "          0.0219, 0.0218, 0.0218, 0.0218, 0.0216, 0.0215, 0.0214, 0.0212, 0.0212,\n",
       "          0.0212, 0.0212, 0.0211, 0.0210, 0.0209, 0.0207, 0.0206, 0.0205],\n",
       "         [0.0449, 0.0259, 0.0256, 0.0250, 0.0250, 0.0250, 0.0250, 0.0248, 0.0246,\n",
       "          0.0245, 0.0243, 0.0238, 0.0237, 0.0236, 0.0233, 0.0233, 0.0232, 0.0231,\n",
       "          0.0230, 0.0230, 0.0230, 0.0226, 0.0220, 0.0220, 0.0218, 0.0218, 0.0217,\n",
       "          0.0213, 0.0212, 0.0209, 0.0207, 0.0207, 0.0203, 0.0202, 0.0201, 0.0200,\n",
       "          0.0200, 0.0197, 0.0195, 0.0193, 0.0193, 0.0192, 0.0191, 0.0190],\n",
       "         [0.0325, 0.0244, 0.0240, 0.0239, 0.0239, 0.0237, 0.0236, 0.0236, 0.0236,\n",
       "          0.0236, 0.0233, 0.0233, 0.0230, 0.0229, 0.0229, 0.0228, 0.0228, 0.0228,\n",
       "          0.0228, 0.0228, 0.0228, 0.0227, 0.0227, 0.0227, 0.0226, 0.0226, 0.0226,\n",
       "          0.0225, 0.0223, 0.0223, 0.0223, 0.0222, 0.0221, 0.0215, 0.0214, 0.0214,\n",
       "          0.0212, 0.0211, 0.0211, 0.0209, 0.0208, 0.0207, 0.0206, 0.0204]]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello_world_model = TextReShitter(alphabet, \"hello.world\")\n",
    "\n",
    "hello_world_model.forward(torch.zeros(1, 1, 1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX: Save Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to hello_world.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leon\\AppData\\Local\\Temp\\ipykernel_1824\\427549207.py:35: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  alphabet_indices = torch.tensor([ord(c) for c in self.alphabet], device=softmax.device).reshape(1, 1, -1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy input tensor\n",
    "dummy_input = torch.randn(1, 1, 100, 100)  # Example input\n",
    "\n",
    "# Define the ONNX file path\n",
    "onnx_file_path = \"hello_world.onnx\"\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    hello_world_model,\n",
    "    dummy_input,\n",
    "    onnx_file_path,\n",
    "    input_names=[\"input\"],  # Name of the input layer\n",
    "    output_names=[\"unicode\", \"probability\"],  # Names of the output layers\n",
    "    dynamic_axes={\"input\": {2: \"height\", 3: \"width\"}},\n",
    "    opset_version=11  # Specify the ONNX opset version\n",
    ")\n",
    "\n",
    "print(f\"Model saved to {onnx_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Hello World Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'e', 'l', 'l', 'o', '.', 'w', 'o', 'r', 'l', 'd']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the ONNX model\n",
    "model_path = \"hello_world.onnx\"\n",
    "session = onnxruntime.InferenceSession(model_path)\n",
    "\n",
    "input_image = np.random.random(\n",
    "    (\n",
    "        1,  # batch: stack as many images as you like here\n",
    "        1,  # channels: needs to be 1 (grayscale), pixels are 1.0 or 0.0\n",
    "        2,  # height: fixed to 1 for now\n",
    "        1   # width: fixed to 1 for now\n",
    "    )\n",
    ").astype(np.float32)\n",
    "\n",
    "# Run inference\n",
    "inputs: list[onnxruntime.NodeArg] = session.get_inputs()\n",
    "outputs: list[onnxruntime.NodeArg] = session.get_outputs()\n",
    "\n",
    "input_name: str = inputs[0].name\n",
    "output_names: list[str] = [out.name for out in outputs]\n",
    "softmax: np.ndarray\n",
    "softmax_ordered: np.ndarray\n",
    "logits: np.ndarray\n",
    "\n",
    "unicodes, probs = session.run(\n",
    "    output_names, \n",
    "    {input_name: input_image}\n",
    ")\n",
    "\n",
    "list(map(chr, unicodes[:, 0].tolist()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CNN Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.0.weight\n",
      "Loaded: encoder_conv_blocks.1.0.bias\n",
      "Loaded: encoder_conv_blocks.1.2.weight\n",
      "Loaded: encoder_conv_blocks.1.2.bias\n",
      "Loaded: encoder_conv_blocks.1.2.running_mean\n",
      "Loaded: encoder_conv_blocks.1.2.running_var\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.4.weight\n",
      "Loaded: encoder_conv_blocks.1.4.bias\n",
      "Loaded: encoder_conv_blocks.1.6.weight\n",
      "Loaded: encoder_conv_blocks.1.6.bias\n",
      "Loaded: encoder_conv_blocks.1.6.running_mean\n",
      "Loaded: encoder_conv_blocks.1.6.running_var\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.0.weight\n",
      "Loaded: encoder_conv_blocks.2.0.bias\n",
      "Loaded: encoder_conv_blocks.2.2.weight\n",
      "Loaded: encoder_conv_blocks.2.2.bias\n",
      "Loaded: encoder_conv_blocks.2.2.running_mean\n",
      "Loaded: encoder_conv_blocks.2.2.running_var\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.4.weight\n",
      "Loaded: encoder_conv_blocks.2.4.bias\n",
      "Loaded: encoder_conv_blocks.2.6.weight\n",
      "Loaded: encoder_conv_blocks.2.6.bias\n",
      "Loaded: encoder_conv_blocks.2.6.running_mean\n",
      "Loaded: encoder_conv_blocks.2.6.running_var\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.0.weight\n",
      "Loaded: encoder_conv_blocks.3.0.bias\n",
      "Loaded: encoder_conv_blocks.3.2.weight\n",
      "Loaded: encoder_conv_blocks.3.2.bias\n",
      "Loaded: encoder_conv_blocks.3.2.running_mean\n",
      "Loaded: encoder_conv_blocks.3.2.running_var\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.4.weight\n",
      "Loaded: encoder_conv_blocks.3.4.bias\n",
      "Loaded: encoder_conv_blocks.3.6.weight\n",
      "Loaded: encoder_conv_blocks.3.6.bias\n",
      "Loaded: encoder_conv_blocks.3.6.running_mean\n",
      "Loaded: encoder_conv_blocks.3.6.running_var\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.0.weight\n",
      "Loaded: encoder_conv_blocks.4.0.bias\n",
      "Loaded: encoder_conv_blocks.4.2.weight\n",
      "Loaded: encoder_conv_blocks.4.2.bias\n",
      "Loaded: encoder_conv_blocks.4.2.running_mean\n",
      "Loaded: encoder_conv_blocks.4.2.running_var\n",
      "Loaded: encoder_conv_blocks.4.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.4.weight\n",
      "Loaded: encoder_conv_blocks.4.4.bias\n",
      "Loaded: encoder_conv_blocks.4.6.weight\n",
      "Loaded: encoder_conv_blocks.4.6.bias\n",
      "Loaded: encoder_conv_blocks.4.6.running_mean\n",
      "Loaded: encoder_conv_blocks.4.6.running_var\n",
      "Loaded: encoder_conv_blocks.4.6.num_batches_tracked\n",
      "Loaded: fully_connected_blocks.0.0.weight\n",
      "Loaded: fully_connected_blocks.0.0.bias\n",
      "Loaded: fully_connected_blocks.1.0.weight\n",
      "Loaded: fully_connected_blocks.1.0.bias\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 44]                   --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 32, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
      "│    │    └─Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
      "│    │    └─LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
      "├─Sequential: 1-2                        [1, 128]                  --\n",
      "│    └─Flatten: 2-6                      [1, 128]                  --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-7                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-41                 [1, 64]                   8,256\n",
      "│    │    └─Dropout: 3-42                [1, 64]                   --\n",
      "│    │    └─LeakyReLU: 3-43              [1, 64]                   --\n",
      "│    └─Sequential: 2-8                   [1, 44]                   --\n",
      "│    │    └─Linear: 3-44                 [1, 44]                   2,860\n",
      "==========================================================================================\n",
      "Total params: 83,548\n",
      "Trainable params: 83,548\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 14.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.18\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 2.53\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leon\\AppData\\Local\\Temp\\ipykernel_1824\\2691209791.py:52: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor([0, 0, 0, 0], device=im.device)  # Default value if no foreground\n",
      "C:\\Users\\Leon\\AppData\\Local\\Temp\\ipykernel_1824\\2691209791.py:57: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor([0, 0, im.size(2) - 1, im.size(3) - 1], device=im.device)  # Default value if no foreground\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to char_model_lamda_calculus.onnx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class KrudModel(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        alphabet: list[str], \n",
    "        target_width: int = 64, \n",
    "        target_height: int = 64, \n",
    "        padding: int = 1,\n",
    "        model: torch.nn.Module = None\n",
    "    ):\n",
    "        \n",
    "        super(KrudModel, self).__init__()\n",
    "        \n",
    "        self.alphabet: list[str] = alphabet\n",
    "        self.alphabet_float: torch.Tensor = torch.tensor([ord(a) for a in self.alphabet], dtype=torch.float32) \n",
    "        self.target_width: int = target_width\n",
    "        self.target_height: int = target_height\n",
    "        self.padding: int = padding\n",
    "        self._unpadded_dims: tuple[int] = (\n",
    "            self.target_height-self.padding*2,\n",
    "            self.target_width-self.padding*2\n",
    "        )\n",
    "        self.model: torch.nn.Module = model.eval()\n",
    "    \n",
    "        \n",
    "    def preprocess_image(\n",
    "        self, \n",
    "        im: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Preprocesses the input image by cropping, resizing, binarizing, and padding it.\n",
    "\n",
    "        Args:\n",
    "            im (torch.Tensor): Input image tensor of shape (C, H, W) or (B, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Preprocessed image tensor.\n",
    "        \"\"\"\n",
    "        # Step 1: Binarize the image (foreground = 0, background = 1)\n",
    "        mask = im > 0.5\n",
    "\n",
    "        # Step 2: Find bounding box coordinates of the foreground\n",
    "        coords = torch.nonzero(mask)  # Get coordinates of non-zero (foreground) pixels\n",
    "\n",
    "        # Step 3: Check if there are any foreground pixels (traceable)\n",
    "        has_foreground = torch.any(mask)\n",
    "\n",
    "        # Step 4: Compute min and max coordinates for cropping (if foreground exists)\n",
    "        min_coords = torch.where(\n",
    "            has_foreground,\n",
    "            coords.min(dim=0)[0],\n",
    "            torch.tensor([0, 0, 0, 0], device=im.device)  # Default value if no foreground\n",
    "        )\n",
    "        max_coords = torch.where(\n",
    "            has_foreground,\n",
    "            coords.max(dim=0)[0],\n",
    "            torch.tensor([0, 0, im.size(2) - 1, im.size(3) - 1], device=im.device)  # Default value if no foreground\n",
    "        )\n",
    "\n",
    "        # Step 5: Extract min and max coordinates for height and width (assuming input is 4D: B, C, H, W)\n",
    "        min_x, min_y = min_coords[2], min_coords[3]\n",
    "        max_x, max_y = max_coords[2], max_coords[3]\n",
    "\n",
    "        # Step 6: Crop the image (use slicing, which is traceable)\n",
    "        im = im[:, :, min_x:max_x + 1, min_y:max_y + 1]\n",
    "\n",
    "        # Step 7: Resize the image to the desired dimensions\n",
    "        im = torch_func.interpolate(\n",
    "            im, \n",
    "            size=self._unpadded_dims, \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        # Step 8: Binarize the image again (optional, depending on your use case)\n",
    "        im = (im > 0.5).type(torch.uint8).type(torch.float32)\n",
    "\n",
    "        # Step 9: Pad the image\n",
    "        im = torch_func.pad(\n",
    "            im,\n",
    "            (self.padding, self.padding, self.padding, self.padding),\n",
    "            mode='constant',\n",
    "            value=0.0\n",
    "        )\n",
    "\n",
    "        return im\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.preprocess_image(x)\n",
    "        \n",
    "        #plt.imshow(x.squeeze(), cmap=\"gray\")\n",
    "        #plt.show()\n",
    "        \n",
    "        y_hat: torch.Tensor = self.model(x)\n",
    "        y_hat = y_hat.squeeze().squeeze()\n",
    "        \n",
    "        softmax = torch.softmax(y_hat, dim=-1)\n",
    "        \n",
    "        stacked = torch.stack([self.alphabet_float, softmax], dim=1)\n",
    "        sorted_indices = torch.argsort(stacked[:, 1], descending=True)\n",
    "        sorted_tensor = stacked[sorted_indices]\n",
    "\n",
    "        unicodes: torch.Tensor = sorted_tensor[:, 0]\n",
    "        probabilities: torch.Tensor = sorted_tensor[:, 1]\n",
    "\n",
    "        unicodes = unicodes.to(dtype=torch.int)\n",
    "        probabilities = probabilities.detach()\n",
    "\n",
    "        return unicodes.unsqueeze(0), probabilities.unsqueeze(0)\n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "label_map: list[str] = ['(', ')', '+', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'λ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '×', '÷']\n",
    "\n",
    "checkpoint_path: str = os.path.join(\n",
    "    root_path, \n",
    "    \"checkpoints\", \n",
    "    \"Krud_epoch29_trainacc0.93466_valacc0.97159_Tloss0.013132_Vloss0.0056677_lr0.0007224.pkl\"\n",
    ")\n",
    "\n",
    "model: AllCNN2D = AllCNN2D(\n",
    "    **{\n",
    "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
    "        \"fully_connected_features\": (64, 44),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cpu\",\n",
    "        \"conv_dropout\": 0.0,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": \"KrudEval\",\n",
    "        \"checkpoint_path\": checkpoint_path\n",
    "    }\n",
    "\n",
    ").eval()\n",
    "krud_model: KrudModel = KrudModel(\n",
    "    label_map,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "dummy_input = torch.randn(1, 1, 100, 100)  # Example input\n",
    "\n",
    "# Define the ONNX file path\n",
    "onnx_file_path = \"char_model_lamda_calculus.onnx\"\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    krud_model,\n",
    "    dummy_input,\n",
    "    onnx_file_path,\n",
    "    input_names=[\"input\"],  # Name of the input layer\n",
    "    output_names=[\"unicode\", \"probability\"],  # Names of the output layers\n",
    "    dynamic_axes={\"input\": {2: \"height\", 3: \"width\"}},\n",
    "    opset_version=11  # Specify the ONNX opset version\n",
    ")\n",
    "\n",
    "print(f\"Model saved to {onnx_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 43, 215, 247,  55, 120, 955, 102, 121, 104, 107,  52, 116, 100,  49,\n",
       "          122, 109, 113,  57, 114, 118,  53,  56,  97, 119,  45, 110,  51, 112,\n",
       "          105, 103,  50,  98, 117, 115,  54,  41, 101, 108,  40, 106,  99,  48,\n",
       "          111,  46]], dtype=torch.int32),\n",
       " tensor([[9.3858e-01, 5.7565e-02, 1.5453e-03, 1.4862e-03, 5.4839e-04, 1.8937e-04,\n",
       "          4.8974e-05, 2.8834e-05, 1.5799e-06, 8.6764e-07, 6.3947e-07, 1.6689e-07,\n",
       "          1.0515e-07, 9.0722e-08, 6.1379e-08, 4.4690e-08, 3.3480e-08, 1.2193e-08,\n",
       "          3.4486e-09, 9.5328e-10, 3.0586e-10, 1.8158e-10, 1.6832e-10, 7.8394e-11,\n",
       "          4.7620e-11, 3.2993e-11, 1.9548e-11, 5.6589e-12, 2.6825e-12, 2.6386e-12,\n",
       "          5.4703e-13, 4.1399e-13, 3.9216e-13, 1.3443e-13, 1.4182e-14, 8.0470e-15,\n",
       "          4.4367e-15, 6.8224e-16, 3.5865e-16, 1.7180e-17, 1.5004e-17, 1.1964e-17,\n",
       "          6.5156e-19, 2.4627e-22]]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plus_im: np.ndarray = np.asarray(Image.open(r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\data\\lambda\\u2b-1736974496947.png\"))\n",
    "\n",
    "plus_im = plus_im[:, :, 3]\n",
    "\n",
    "\n",
    "plus_im = plus_im.astype(np.float32)/255\n",
    "\n",
    "plus_im_ten = torch.tensor(plus_im, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "krud_model.forward(plus_im_ten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Krud ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_image = Image.open(\"test_im.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = np.asarray(input_image)\n",
    "test_image = ((1.0-test_image[:, :, 0]/255) > 0.5).astype(np.uint8)*1.0\n",
    "\n",
    "plt.imshow(test_image, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "test_image = np.expand_dims(np.expand_dims(test_image, 0), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 143, 154)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.68143886\n",
      "o 0.31727558\n",
      "c 0.0009891384\n",
      "6 0.0001600089\n",
      "s 5.1013758e-05\n",
      "8 2.8218346e-05\n",
      "5 2.4816827e-05\n",
      "n 8.780571e-06\n",
      "p 5.5376886e-06\n",
      "e 3.6561419e-06\n",
      "a 3.0133053e-06\n",
      "( 2.676651e-06\n",
      "v 2.4739402e-06\n",
      "l 1.5798223e-06\n",
      "j 1.5708143e-06\n",
      "i 8.663088e-07\n",
      "g 6.861411e-07\n",
      "m 5.575756e-07\n",
      "2 4.7443012e-07\n",
      "b 3.30369e-07\n",
      "w 6.3471326e-08\n",
      "q 2.9459986e-08\n",
      "z 2.2759442e-08\n",
      "3 1.8600712e-08\n",
      "- 1.800039e-08\n",
      "1 1.2019766e-08\n",
      "u 3.3489278e-09\n",
      "9 3.006773e-09\n",
      "f 2.6663645e-09\n",
      "y 2.0556845e-09\n",
      "h 1.1345208e-09\n",
      "d 3.8724163e-10\n",
      ") 2.8197075e-10\n",
      "r 1.6642417e-10\n",
      "t 3.9026893e-11\n",
      "x 1.4455865e-11\n",
      "7 1.027535e-11\n",
      "λ 8.538898e-12\n",
      ". 2.8815811e-13\n",
      "4 2.1714051e-13\n",
      "k 4.009424e-14\n",
      "× 2.7764098e-14\n",
      "÷ 2.0496294e-15\n",
      "+ 9.230513e-16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the ONNX model\n",
    "model_path = \"char_model_lamda_calculus.onnx\"\n",
    "session = onnxruntime.InferenceSession(model_path)\n",
    "\n",
    "# Run inference\n",
    "inputs: list[onnxruntime.NodeArg] = session.get_inputs()\n",
    "outputs: list[onnxruntime.NodeArg] = session.get_outputs()\n",
    "\n",
    "input_name: str = inputs[0].name            # Only one input \n",
    "output_names: list[str] = [output.name for output in outputs]    # Only one output [unicode, prob] pairs for a single character\n",
    "\n",
    "unicodes: torch.Tensor\n",
    "probabilities: torch.Tensor\n",
    "unicodes, probabilities = session.run(\n",
    "    output_names, \n",
    "    {input_name: test_image.astype(np.float32)} # Must be float32 image of shape (batch, channels, height, width) -> (1, 1, Any, Any)\n",
    ")\n",
    "\n",
    "\n",
    "for char, prob in zip(unicodes[0], probabilities[0]):\n",
    "    print(chr(int(char)), prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 48, 112, 100,  54, 116,  56,  53, 111, 113, 102,  98,  40, 119,\n",
       "        109, 107, 106, 104, 110,  50,  99, 120, 114, 215,  51,  45,  49,\n",
       "        118,  57, 103, 122, 105, 101,  41, 115, 117, 121,  55,  97,  46,\n",
       "         52, 108, 247, 955,  43], dtype=int32),\n",
       " array([6.8143886e-01, 3.1727558e-01, 9.8913838e-04, 1.6000890e-04,\n",
       "        5.1013758e-05, 2.8218346e-05, 2.4816827e-05, 8.7805711e-06,\n",
       "        5.5376886e-06, 3.6561419e-06, 3.0133053e-06, 2.6766511e-06,\n",
       "        2.4739402e-06, 1.5798223e-06, 1.5708143e-06, 8.6630882e-07,\n",
       "        6.8614111e-07, 5.5757562e-07, 4.7443012e-07, 3.3036901e-07,\n",
       "        6.3471326e-08, 2.9459986e-08, 2.2759442e-08, 1.8600712e-08,\n",
       "        1.8000391e-08, 1.2019766e-08, 3.3489278e-09, 3.0067731e-09,\n",
       "        2.6663645e-09, 2.0556845e-09, 1.1345208e-09, 3.8724163e-10,\n",
       "        2.8197075e-10, 1.6642417e-10, 3.9026893e-11, 1.4455865e-11,\n",
       "        1.0275350e-11, 8.5388979e-12, 2.8815811e-13, 2.1714051e-13,\n",
       "        4.0094240e-14, 2.7764098e-14, 2.0496294e-15, 9.2305130e-16],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mkrud_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      3\u001b[0m [\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;28mint\u001b[39m(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m preds]\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "preds = krud_model.eval().forward(torch.tensor(test_image.astype(np.float32)))[:, 0].tolist()\n",
    "\n",
    "[chr(int(x)) for x in preds]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
