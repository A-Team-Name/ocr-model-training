{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leonbass\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.8/10.0 MB 14.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.0 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 12.3 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, pyyaml, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.2 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "#%pip install torch\n",
    "#%pip install torchinfo\n",
    "#%pip install matplotlib\n",
    "#%pip install numpy\n",
    "#%pip install tqdm\n",
    "#%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import save\n",
    "import datetime\n",
    "from torch import nn, Tensor, tensor\n",
    "from torchinfo import summary\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.trocr_apl import TrocrApl\n",
    "from training.train import EpochLogs, LogPoint, train, grid_search\n",
    "from dataset.dataset import HandwrittenLineOfCodeDataset\n",
    "from training.train import ThresholdData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "__filedir__: str = os.path.abspath(\".\")\n",
    "\n",
    "DEVICE: str = \"cuda\"\n",
    "EPOCHS: int = 100000\n",
    "BATCH_SIZE: int = 50\n",
    "IMAGE_CHANNELS: int = 1\n",
    "IMAGE_WIDTH: int = 64\n",
    "IMAGE_HEIGHT: int = 64\n",
    "ROTATE_RANGE: tuple[int, int] = (-90, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dirpath: str = os.path.join(\n",
    "    __filedir__,\n",
    "    os.pardir,\n",
    ")\n",
    "\n",
    "\n",
    "data_root_dirpath: str = os.path.join(\n",
    "    root_dirpath,\n",
    "    \"dataset\",    \n",
    ")\n",
    "\n",
    "flattened_dataset_dirpath: str = os.path.join(\n",
    "    data_root_dirpath,\n",
    "    \"flattened_dataset\"\n",
    ")\n",
    "\n",
    "dataset_info_csv_path: str = os.path.join(\n",
    "    flattened_dataset_dirpath,\n",
    "    \"dataset_info.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_dirpath: str = os.path.join(\n",
    "    root_dirpath,\n",
    "    \"logs\"\n",
    ")\n",
    "os.makedirs(log_dirpath, exist_ok=True)\n",
    "\n",
    "checkpoint_dirpath: str = os.path.join(\n",
    "    root_dirpath,\n",
    "    \"checkpoints\"\n",
    ")\n",
    "os.makedirs(checkpoint_dirpath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import VisionEncoderDecoderModel, TrOCRProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the model and processor\n",
    "model_name = \"microsoft/trocr-base-handwritten\"\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Create your dataset instance\n",
    "dataset = HandwrittenLineOfCodeDataset(\n",
    "    dataset_line_text=[\"print('Hello, World!')\", \"x = y + 2\"],  # Replace with your lines\n",
    "    unicode_character_filepath_map={\n",
    "        # Example: Map of unicode characters to image paths\n",
    "        \"p\": [\"path_to_image_p.png\"], \"r\": [\"path_to_image_r.png\"],  # Fill this out properly\n",
    "        # Add mappings for all characters...\n",
    "    },\n",
    "    eol_char=\"<EOL>\"\n",
    ")\n",
    "\n",
    "# Wrap dataset in a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "        # Extract batch data\n",
    "        text_image_tensors, text_label_tensors = batch\n",
    "        text_image_tensors = text_image_tensors.to(device)\n",
    "        text_label_tensors = text_label_tensors.to(device)\n",
    "        \n",
    "        # Generate pixel_values compatible with the model\n",
    "        pixel_values = text_image_tensors  # Ensure this matches model input expectations\n",
    "        labels = text_label_tensors.argmax(dim=-1)  # Convert one-hot to token indices\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Track loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed. Loss: {epoch_loss / len(dataloader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
