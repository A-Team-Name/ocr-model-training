{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from typing import Any\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from torchinfo import summary\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "from torch import sigmoid\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import EpochLogs, grid_search, LogPoint\n",
    "from dataset.character_dataset import CharImageDataset\n",
    "from models.allcnn2d import AllCNN2D\n",
    "from models.allcnn2d_rnn import CNNRNNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE: int = 16\n",
    "MODEL_NAME: str = \"BEST_APL_MODEL_V5\"\n",
    "LOAD_CHECKPOINT: str = r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn_lora\\20250421_153213__BEST_APL_MODEL_V5__Epoch19_tLoss1.74373_tL152.87395_tMSE38.48472_tAcc0.57227_vLoss1.02986_vL153.56228_vMSE41.70430_vAcc0.70546.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths\n",
    "Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir: str = os.path.abspath(\".\")\n",
    "root_dir: str = os.path.join(\n",
    "    notebook_dir,\n",
    "    os.pardir,\n",
    "    os.pardir\n",
    ")\n",
    "\n",
    "data_dir: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"data\",\n",
    "    \"apl_dataset\"\n",
    ")\n",
    "\n",
    "model_save_dirpath: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"models\",\n",
    "    MODEL_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15298"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "images_path_glob: str = os.path.join(\n",
    "    data_dir,\n",
    "    \"u*.png\"\n",
    ")\n",
    "images_path_regex: str = r\"(u[0-9a-f]+)[-]+([0-9a-zA-Z]+)\\.png\"\n",
    "\n",
    "image_paths: list[str] = glob.glob(images_path_glob)\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Labels From File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15294, 15294)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "labeled_image_paths: list[tuple[str, str]] = []\n",
    "\n",
    "class_counts: dict[str, int] = defaultdict(lambda: 0)\n",
    "\n",
    "file_path: str\n",
    "for file_path in image_paths:\n",
    "    match = re.search(images_path_regex, file_path)\n",
    "    \n",
    "    if not match:\n",
    "        continue\n",
    "    \n",
    "    u_hexvalue: str = match.group(1)[1:]\n",
    "    \n",
    "    char: str = chr(int(u_hexvalue, base=16))\n",
    "    \n",
    "    \n",
    "    class_counts[char] += 1\n",
    "    \n",
    "    \n",
    "    labeled_image_paths.append((char, file_path))\n",
    "\n",
    "labels: list[str]\n",
    "image_paths: list[str]\n",
    "labels, image_paths =  list(zip(*labeled_image_paths))\n",
    "\n",
    "len(labels), len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'⍝': 333,\n",
       "         '⍬': 130,\n",
       "         '⋄': 122,\n",
       "         '6': 120,\n",
       "         '9': 120,\n",
       "         '7': 120,\n",
       "         '∇': 120,\n",
       "         '1': 120,\n",
       "         '8': 120,\n",
       "         '4': 120,\n",
       "         '2': 120,\n",
       "         '5': 120,\n",
       "         '3': 120,\n",
       "         '0': 119,\n",
       "         'S': 119,\n",
       "         '⍺': 119,\n",
       "         'Q': 119,\n",
       "         'R': 119,\n",
       "         'W': 119,\n",
       "         '⍵': 119,\n",
       "         'D': 118,\n",
       "         'a': 118,\n",
       "         'J': 118,\n",
       "         'Y': 118,\n",
       "         't': 118,\n",
       "         'L': 118,\n",
       "         'w': 118,\n",
       "         'x': 118,\n",
       "         'O': 118,\n",
       "         'B': 118,\n",
       "         'b': 118,\n",
       "         'v': 118,\n",
       "         'm': 118,\n",
       "         'k': 118,\n",
       "         'e': 118,\n",
       "         'Z': 118,\n",
       "         'P': 118,\n",
       "         'l': 118,\n",
       "         'c': 118,\n",
       "         'F': 118,\n",
       "         'h': 118,\n",
       "         'E': 118,\n",
       "         'K': 118,\n",
       "         'H': 118,\n",
       "         'C': 118,\n",
       "         'V': 118,\n",
       "         'n': 118,\n",
       "         'X': 118,\n",
       "         'z': 118,\n",
       "         'j': 118,\n",
       "         'q': 118,\n",
       "         'p': 118,\n",
       "         'u': 118,\n",
       "         'i': 118,\n",
       "         'I': 118,\n",
       "         'y': 118,\n",
       "         'd': 118,\n",
       "         'o': 118,\n",
       "         'f': 118,\n",
       "         'A': 118,\n",
       "         'G': 118,\n",
       "         'r': 118,\n",
       "         's': 118,\n",
       "         'M': 118,\n",
       "         'N': 118,\n",
       "         'U': 118,\n",
       "         'T': 118,\n",
       "         'g': 118,\n",
       "         '\\\\': 113,\n",
       "         '.': 91,\n",
       "         '@': 80,\n",
       "         '£': 77,\n",
       "         '%': 73,\n",
       "         '⌸': 73,\n",
       "         '←': 73,\n",
       "         '⌺': 73,\n",
       "         '⊆': 72,\n",
       "         '´': 72,\n",
       "         '¯': 72,\n",
       "         '∣': 72,\n",
       "         '⍞': 72,\n",
       "         '!': 72,\n",
       "         '⌿': 71,\n",
       "         '×': 71,\n",
       "         \"'\": 71,\n",
       "         '⊃': 71,\n",
       "         '→': 71,\n",
       "         '⍒': 71,\n",
       "         '⍣': 71,\n",
       "         '≥': 71,\n",
       "         ';': 70,\n",
       "         '<': 70,\n",
       "         '[': 70,\n",
       "         '/': 70,\n",
       "         '⍙': 70,\n",
       "         '÷': 70,\n",
       "         '⎕': 70,\n",
       "         '~': 70,\n",
       "         '¨': 70,\n",
       "         '⍟': 70,\n",
       "         '?': 69,\n",
       "         '⊂': 69,\n",
       "         '{': 69,\n",
       "         '⍕': 69,\n",
       "         '|': 69,\n",
       "         '⍉': 69,\n",
       "         '>': 69,\n",
       "         '}': 69,\n",
       "         '_': 69,\n",
       "         '↑': 69,\n",
       "         '⍷': 69,\n",
       "         '⍫': 69,\n",
       "         '=': 69,\n",
       "         '-': 69,\n",
       "         '·': 69,\n",
       "         '≠': 69,\n",
       "         '⍨': 68,\n",
       "         '○': 68,\n",
       "         '∧': 68,\n",
       "         '↓': 68,\n",
       "         ',': 68,\n",
       "         '*': 68,\n",
       "         ']': 68,\n",
       "         '∨': 68,\n",
       "         ')': 68,\n",
       "         '^': 68,\n",
       "         ':': 68,\n",
       "         '⍳': 68,\n",
       "         '⍋': 68,\n",
       "         '∪': 68,\n",
       "         '≡': 68,\n",
       "         '⌶': 68,\n",
       "         '∩': 68,\n",
       "         '∊': 68,\n",
       "         '∘': 68,\n",
       "         '⊣': 68,\n",
       "         '∆': 68,\n",
       "         '⍎': 68,\n",
       "         '⊤': 67,\n",
       "         '⌊': 67,\n",
       "         '⊖': 67,\n",
       "         '⍴': 67,\n",
       "         '⌽': 67,\n",
       "         '⍀': 67,\n",
       "         '≢': 67,\n",
       "         '`': 67,\n",
       "         '⊥': 67,\n",
       "         '√': 67,\n",
       "         '⍪': 67,\n",
       "         '⍲': 67,\n",
       "         '⊢': 67,\n",
       "         '⍱': 67,\n",
       "         '≤': 67,\n",
       "         '⌷': 67,\n",
       "         '⌈': 67,\n",
       "         '⌹': 67,\n",
       "         '⍢': 66,\n",
       "         '#': 66,\n",
       "         '⊇': 66,\n",
       "         '(': 66,\n",
       "         '\"': 66,\n",
       "         '⍛': 66,\n",
       "         '⍠': 66,\n",
       "         '+': 66,\n",
       "         '⍤': 65,\n",
       "         '⍸': 65,\n",
       "         '$': 65,\n",
       "         '&': 65,\n",
       "         '⍥': 65})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Classes Using Oversample/Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts: list[tuple[str, int]] = sorted(\n",
    "    class_counts.items(), \n",
    "    key=lambda x: x[0]\n",
    ")\n",
    "\n",
    "counts: list[int] = [pair[1] for pair in sorted_counts]\n",
    "\n",
    "max_count: int = max(counts)\n",
    "min_count: int = min(counts)\n",
    "\n",
    "to_add_counts: dict[str, int] = {\n",
    "    uid: max_count - count \n",
    "    for uid, count in \n",
    "    sorted_counts\n",
    "}\n",
    "\n",
    "to_undersample_counts: dict[str, int] = {\n",
    "    uid: min_count\n",
    "    for uid, count in \n",
    "    sorted_counts\n",
    "}\n",
    "\n",
    "total_items = sum(x[1] for x in sorted_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 333, 15294)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count, max_count, total_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(*to_add_counts.items())\n",
    "#print(sorted([(chr(int(pair[0][1:], 16)), pair[1]) for pair in to_remove_counts.items()], key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_add_labels: list[str] = []\n",
    "#to_add_file_paths: list[str] = []\n",
    "#\n",
    "#while True in [to_add_count>0 for to_add_count in to_add_counts.values()]:  \n",
    "#    for label, image_path in zip(labels, image_paths):\n",
    "#        remaining: int = to_add_counts[label]\n",
    "#        \n",
    "#        if remaining > 0:\n",
    "#            to_add_labels.append(label)\n",
    "#            to_add_file_paths.append(image_path)\n",
    "#            to_add_counts[label] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep_labels: list[str] = []\n",
    "to_keep_file_paths: list[str] = []\n",
    "\n",
    "while True in [to_add_count>0 for to_add_count in to_undersample_counts.values()]:  \n",
    "    for label, image_path in zip(labels, image_paths):\n",
    "        remaining: int = to_undersample_counts[label]\n",
    "        \n",
    "        if remaining > 0:\n",
    "            to_keep_labels.append(label)\n",
    "            to_keep_file_paths.append(image_path)\n",
    "            to_undersample_counts[label] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, ., ⍨, D, ○, ⌿, a, J, %, ?, S, Y, ∧, D, ⍢, ↓, ×, ⊤, t, ,, L, w, x, O, ⍺, Q, B, #, R, b, v, £, ⍤, ⊂, m, {, k, m, e, ⌊, Y, ⊖, *, 6, ;, ], ⍝, ⍸, ∨, ., Z, 9, w, Q, P, ⊆, ⊤, l, ⍤, ⌸, ⌿, c, F, ), ;, <, h, ⍝, 7, m, E, F, ', Q, h, ^, ∇, F, m, :, K, H, h, ⊇, J, <, C, ], ⍝, [, (, k, a, V, ´, ⊃, $, b, ⍕, ⍴, n, ⍳, /, ´, Q, 1, ⊂, R, ⊃, 6, X, ⊖, %, ;, Z, ∧, ⍙, (, ⊇, x, ⍕, S, w, x, ÷, ⋄, ⌽, ;, ⎕, z, 8, £, j, m, q, h, b, ⊇, ,, \\, 1, W, E, ⍝, v, p, P, ¯, /, |, @, 4, |, ⍀, ⍉, ;, u, P, 2, 2, i, ≢, \\, ⍳, *, ¯, Z, h, ⌽, 7, I, \", 6, ⎕, y, £, b, a, →, P, b, ⊤, ⍝, ⍝, K, n, P, ∇, d, o, f, ⊃, A, K, Y, H, d, B, 6, c, `, ], 5, Q, V, b, ∣, ~, 6, >, ⋄, ⍬, G, ∣, V, ⍒, x, r, i, s, ÷, s, *, 5, I, R, ⍉, o, (, I, ⍣, £, ⊇, q, \", w, l, D, ⍝, ○, ≥, I, M, K, 1, ∧, ~, f, ⍝, e, 7, I, I, ¨, Q, P, ⊥, &, G, ⊂, w, v, x, M, 8, d, ⍉, ⍋, X, ⍕, Q, K, q, }, ⍳, <, N, Q, r, _, k, ×, ., ⊃, ⍬, £, m, √, Y, 2, *, B, ≢, ⍸, K, l, [, \", b, #, ⌿, ⍬, ⊥, ´, ⍪, ⍉, ÷, H, Z, Y, k, ¯, X, F, ⊖, u, U, ∪, 5, i, T, ∇, 3, q, t, w, ⍞, ⍝, ○, ?, ⍲, 1, ↑, x, `, x, &, ⍝, ≡, c, ⌶, 2, L, :, A, I, I, ^, ⍒, {, 3, T, ⍪, ⍷, 9, ⍴, O, ⍙, ∇, o, m, s, ⍀, ⍞, o, @, O, 5, c, ⍣, Z, ↓, l, n, h, $, Y, ⍪, Z, i, [, U, H, ⍪, ⌸, X, _, g, ⍫, ;, ∪, @, ⍴, d, H, ∩, O, /, p, q, Q, 9, \\, G, =, ¯, \\, ⍟, ÷, ⊢, ⍞, ⍣, Q, ∩, u, g, \", g, ⌿, ´, 9, ∊, ¯, }, e, z, ∪, e, ∨, |, B, a, s, ⍷, q, D, l, (, ○, K, ⍤, $, ⊢, 9, Q, 3, S, R, c, 9, ⌽, ∇, e, z, \", ⍝, x, j, B, i, ¯, {, ⍱, ⍝, ∣, N, O, 0, ?, ,, T, ⌿, ⍛, ⍠, √, N, ⍀, 5, r, }, 3, ⊤, Q, O, s, ⊆, u, e, ⍛, h, x, ⍨, ≤, [, ∨, _, _, 7, ⍷, ¨, +, ⊆, ¯, v, e, U, ∪, ⍱, i, ∇, P, ⊤, ⍝, 8, ⍬, o, K, >, ¯, d, ⌊, ⍋, ⊂, 8, ∨, W, K, t, I, 1, ÷, r, ×, ⌸, l, \\, `, -, [, 8, ∪, ^, ⌷, h, q, k, 9, i, W, ⊖, ∇, ⍨, ·, ⍺, a, #, F, m, t, ↓, ⍝, P, Q, ⍺, }, ´, ., ⍴, f, X, r, {, ~, ⋄, j, f, y, V, ⍬, f, ≤, ⍠, <, A, ⍷, X, 3, ⍒, ⍬, $, G, 6, -, ÷, ⎕, g, ⋄, F, ´, ⍫, ⍢, ⍠, 3, ↓, ⍞, ⍙, u, |, L, ≡, ∇, @, ⍝, ⍬, A, C, 4, ≡, s, ⍵, ⊢, ⍳, _, ○, ⍙, I, m, e, g, [, ⌈, x, D, j, ≠, 7, ↓, 9, W, u, ∘, f, ~, ⍉, ⍛, ∊, %, c, ⊣, T, ⍤, a, F, 6, ≢, ⍟, 7, ⍞, ⍲, j, ⍝, R, ←, /, ⍵, p, ∩, ⍋, ⍉, ⌊, ⍟, 0, z, ⍙, %, g, U, T, (, ⍞, ⍠, o, g, n, ≡, ., 5, ⊥, b, m, ), l, ⍣, ←, B, ⍋, 0, 0, ⍀, G, ⊣, m, ○, ⍺, T, 6, ⍵, Y, ⌈, ≠, H, ⍣, 1, ~, ⍲, {, y, O, 3, N, P, ⋄, ⍋, 4, 0, ≤, ⍥, ⍵, ⌿, ∪, ⊖, p, D, y, r, e, Q, F, 3, p, R, ⊖, ⍥, ∆, ∇, ~, k, Q, t, 2, L, ⋄, ¨, ', R, ⍝, ¯, %, ⌈, Y, j, R, E, D, %, q, (, 1, ⍫, ⊇, i, ⊃, z, :, ~, r, N, \", d, i, ∧, ⊂, ⍎, 0, {, ¯, $, G, ⋄, *, N, ^, h, ⍲, u, h, f, U, ), p, z, y, O, T, ¯, +, ∣, ⊃, k, A, ⍒, ∨, Y, ≥, e, s, _, ⍥, N, {, f, K, W, |, ⍵, ∨, M, ≡, M, ⍪, ], ⍢, ⊤, ×, ⍝, O, k, 3, ', ·, ⍛, g, k, →, *, ^, ⍤, N, ⍞, ⊣, /, m, %, ;, ↓, ⌊, ≢, e, ⍲, ⍸, e, e, ⍝, r, K, ⍝, ⋄, 6, (, ⍤, 3, o, ⍝, t, ?, ⋄, r, m, 4, ≡, -, ⍒, V, X, ∊, t, ', T, ≡, ⍨, ≠, B, J, F, p, !, (, l, D, ⍛, ∇, ⍢, :, f, ⍒, 3, ⍤, ;, L, Y, g, ⍢, `, q, x, ⊇, ⊢, ;, n, |, M, ⊇, h, :, ⌸, R, ≡, 9, Z, w, 0, U, M, E, k, ⊖, m, ⊤, G, W, P, l, ⍋, k, |, √, 5, ⍷, ⍺, w, _, B, ], t, ¯, ∧, U, Q, @, n, ≤, (, K, Y, D, F, p, E, #, ×, ∪, N, \", ⌊, G, !, #, <, ⍲, ∪, ⍤, y, ⌺, ⌽, |, *, =, ⍋, ⊖, ⍢, ⍀, ~, >, y, O, 2, ∣, k, q, ⍙, X, }, Q, e, ⍙, 4, ⍝, -, ,, ;, D, ⊂, ⍸, r, p, J, i, √, a, ⌽, h, 9, Z, c, 8, ⌊, ⍱, 5, ⍳, ∘, b, ¯, k, ⍀, ⌸, ⍪, 4, ⍤, ⌈, x, q, /, 0, W, ⊣, ⍲, r, :, \\, ∣, G, ⍺, X, ⍒, ⍷, ., C, ≡, 6, →, ⍪, O, ⍠, m, ⍲, a, y, #, e, o, U, ⍟, 7, v, £, ⍫, b, A, |, t, O, ⍵, ⌸, ∣, c, ⍉, X, ⍙, ', _, C, ÷, c, {, p, ∆, p, ⊖, 3, l, I, \\, ⌺, e, I, m, C, e, ∨, 6, 7, ⍥, ⌊, ⍉, T, d, L, ←, u, ≢, +, ⍛, j, ¯, ⌈, ⊣, Q, ⌶, ?, ', x, ⍥, ⍪, B, W, ⍺, ⍟, ≤, ∇, ∪, *, ⍨, ⍨, N, ⊂, ⊢, E, k, i, r, 5, R, 1, /, ~, U, ×, ∊, M, Q, 2, ⍎, q, a, ⍵, ⍝, N, &, ', 8, 5, p, ., ⋄, n, 4, ⌽, S, ⊖, ), ⍝, ·, ⌽, ⍕, A, m, ÷, y, ≡, n, ¯, %, ∩, s, K, ⌹, r, ∇, ,, 1, K, {, 9, z, ⌹, h, N, ⍟, ⌈, ∊, ¯, u, 5, d, m, D, W, F, p, m, N, √, l, ,, i, 5, s, b, ⍷, →, 4, a, i, <, }, U, ⍺, r, F, ○, ≢, I, d, 3, a, £, ⍥, B, ≡, ∨, ·, ⍞, ⍝, ⍬, B, ⌺, A, w, Z, m, B, ⍥, H, K, W, ○, T, ⍛, m, ⍺, `, Z, l, v, ⊥, ∧, ⊥, ., ≥, ⍱, ,, z, ⊤, ⌶, k, |, 2, j, _, m, ⌹, n, v, ⍝, ?, a, G, V, ⋄, U, r, g, 5, 9, i, ⍬, 6, ⍨, S, ⍝, ⌸, J, P, £, Z, R, u, y, (, I, P, ∧, 9, ⍀, ⍸, a, ⊥, ⍺, ⊆, ∊, U, £, ⊂, /, e, !, a, ⍳, \", ⌿, ↑, ⍫, B, x, O, ⍛, R, ⍣, ⍟, ⍝, M, !, T, ≥, P, ⋄, v, =, ⌊, Y, y, }, l, ∆, G, W, m, ~, ←, P, ⋄, C, J, h, A, ⍒, ⍋, ⍥, ←, I, g, ⌸, ⌸, Q, ⍟, o, ∣, c, ⌷, ←, ⌹, ≠, 1, ≡, ⍝, o, ⌊, ⍤, p, ∊, X, ↓, ↑, ⍵, ⌽, I, Z, +, ⍫, ⍎, ⍀, -, ~, X, ), B, ∩, ⊇, ∧, ∩, a, ,, R, ⍕, ⍸, ⌊, ⊖, 0, ⊂, I, 5, ⊥, ⌺, z, 6, d, ⌿, ⍫, #, B, ,, ⍲, ., B, }, 2, e, H, :, ⍱, ⊇, ⍺, \\, 7, O, {, J, l, g, !, [, R, ↑, \\, 7, f, H, d, h, K, ⍙, P, Z, ⊇, ⍠, ○, H, \\, C, ·, ⍟, N, *, ⌺, ⋄, ⍱, ⊆, →, ≠, (, ⍝, ←, q, @, n, X, t, A, J, K, c, ⊖, ≡, ⍨, ⍱, f, a, =, x, ⍱, Z, %, |, l, d, t, J, ⎕, ¨, ., 1, ⍉, u, 7, d, ', i, ⍬, C, ≠, w, C, ∘, H, b, ⌺, E, |, ∪, c, x, u, =, 8, ⌽, o, ⌺, ·, P, ⊥, ⌈, #, C, ⍉, U, S, m, j, 3, h, r, E, ○, $, ⍵, ≥, }, $, ⊢, ×, ∨, X, ≤, t, ⍉, ≥, e, ⍝, i, ⍉, ⍺, 6, ⍞, ⍬, 0, 0, \\, +, m, C, E, ⊂, ⊢, =, ↑, 0, ↓, G, ⎕, g, z, ∆, p, 7, V, 5, n, ,, ,, ∇, ⍒, e, B, M, ⋄, i, x, ×, ), H, ⍱, M, \", ^, c, 5, j, n, ×, ↓, o, #, 9, ⊥, P, 2, S, ⊢, Q, ⌿, 0, J, 4, W, ⍬, ∩, i, K, y, 6, j, 5, ¨, ⍤, 7, ⍬, ⍟, ⍸, s, U, v, u, ≤, ⍙, h, W, H, ⍺, u, ⊤, ⍎, f, o, k, n, :, 9, 7, ∇, ;, ←, X, `, ⍺, →, `, _, ←, w, v, K, k, ⊢, 0, ⍝, ∇, ⌶, ?, *, [, 7, \", ∣, >, ÷, /, r, D, W, ), 5, 9, m, ·, ⍨, ', 5, S, ~, ⌶, ⍸, m, G, →, ,, 9, 8, ^, ≢, ¨, x, ;, M, H, 4, K, F, D, j, q, l, Y, i, £, ⍷, A, ), J, Y, ⍝, O, ´, ⊃, ⍷, ], ⍷, ⍒, £, ⌹, ⍳, ], %, -, N, Z, W, ∧, 5, ⌷, ÷, ⍨, ⊥, z, ⍝, \\, ≠, ., ⌷, ⍸, Y, :, T, v, U, ¨, ⍥, R, ⍢, D, I, ×, R, K, ⌽, 0, ○, i, 7, D, ⍷, ⊖, ○, 4, y, +, ^, N, ⌸, C, 7, y, M, ⌸, q, ⍵, :, M, _, ∨, ⍱, D, A, ∩, 3, G, 3, ≢, ;, ⍀, s, f, P, r, b, q, =, ×, ⍺, P, ⍣, +, ⌿, ∇, l, f, j, l, j, G, I, r, ∊, ⍥, ., ⍝, ⊃, ⍣, ⍱, o, p, J, !, ⍸, O, ⊆, F, :, w, ≥, ⍣, \\, ⍕, ⌹, D, p, ≤, ⍺, ⍝, ⍥, ⌺, ;, \\, k, -, 8, ⊥, >, ⊥, ⊇, →, ⍵, b, *, e, ., =, g, =, O, ≡, h, n, s, d, c, ×, 7, 2, ∊, 6, ⌸, ⍺, ∣, n, R, :, 8, 5, q, ], ⍒, e, ), ), }, ⊖, ←, R, ,, 2, D, f, ⍋, ⍥, d, m, ⍝, ≢, g, V, ⍒, p, }, √, ', x, 7, R, d, →, ., h, :, Q, 4, 6, V, f, \", y, H, 1, a, O, {, W, n, ^, ⊖, ⍫, L, ⌷, /, $, ⎕, ⍷, ≡, n, B, ⍞, ↑, i, ⍉, t, ., p, ⊥, ←, ∪, ∆, 7, X, =, ≠, }, ∆, c, 1, !, K, ⍝, S, b, 2, =, ↓, ⌽, t, l, ⍴, v, ⍞, a, &, 2, 1, s, 7, f, \\, 1, =, ⍥, ∪, ⍤, 6, r, g, ⊆, _, ¨, |, K, [, z, ?, O, 2, I, 4, ⌷, ·, ⍙, 4, M, ⍤, f, g, ⍵, C, q, e, ´, ⌽, s, e, B, ∘, m, B, K, `, ∣, 7, ⍎, S, <, ⍞, 7, ⊣, ≠, £, ', ∣, ⍝, \\, O, m, ?, ∧, G, 4, P, R, z, E, ·, u, ⋄, x, ], ∇, 7, ~, 3, ¯, B, ⍸, C, A, y, c, Y, ∘, e, a, m, ⍢, F, M, ⍝, m, *, ⊆, s, H, ⍬, ⍕, <, p, h, n, \", ', ∩, &, ⌶, ⍎, p, v, (, v, ⍢, t, v, g, $, X, {, ⍛, ], s, M, =, √, i, F, t, ←, ⊃, A, L, ⍪, ⍝, b, w, ⍵, 6, 9, z, F, ⍺, ○, ⍝, ⊥, X, Y, ∧, 3, ⌊, ⋄, ≢, ⊆, M, 4, ⍝, -, |, ⊃, W, ⎕, Q, S, I, >, ⍫, ¨, ⍎, S, V, !, ⋄, l, ⍺, ⍨, C, [, 7, 5, N, ^, S, ⍷, !, b, _, [, G, ⍺, X, u, ⌈, e, ⍟, ∧, H, @, -, ÷, _, ⌺, G, ⊤, P, ○, Z, Y, ⌹, \", }, ⍝, L, ;, i, 1, 3, j, 4, B, ⍎, P, ∘, j, 5, p, ., =, ⍛, F, 3, ⍬, K, ⌹, J, t, w, ', \\, +, j, #, ⍪, o, V, N, n, ⍺, ⍬, ⊇, h, 5, J, A, ⊖, U, ., !, a, ⌊, k, <, j, ⍱, q, ⊢, o, T, b, v, ⍷, ⌷, q, x, ⊃, ⍕, i, E, r, ⊣, K, j, ⌸, h, f, ≠, ≤, 3, C, ·, l, ⍢, c, t, ⍙, @, ≠, h, ⍠, 5, →, ⌺, 1, ⌽, h, 9, ,, ←, ×, Z, i, y, i, M, A, 7, M, ¨, A, s, ∇, 1, N, ⋄, o, ⊢, {, J, S, ), ⍳, ., ´, ⍝, ⎕, }, ⍲, N, w, ∆, p, ⍠, S, ⍥, $, b, q, ⎕, ⌿, ⊢, H, >, n, S, I, f, I, 5, J, ∊, ⍥, #, ., 3, ↑, q, G, J, £, ⍨, j, ⎕, ⍳, b, C, p, I, N, ⌷, ⍳, ⍤, ¨, w, ⍳, Y, ⊖, ⌽, ⍠, ⍛, o, q, q, ,, ⍒, ≥, n, ⍀, →, U, ., 0, j, r, b, ⊤, ⍷, #, y, 6, !, 8, v, |, ⍵, £, h, 3, a, -, ⍞, ⍟, N, _, l, ~, j, A, j, ⊥, S, ;, ⍢, [, $, :, 7, O, _, i, A, r, =, I, ⌊, \\, ⍨, ⊥, (, -, ⍉, ≢, 6, 1, *, v, W, √, M, F, ', ≥, ⍣, G, \", o, ⍕, o, D, ⌈, b, U, ], v, ○, F, o, e, z, ´, u, z, ⍒, P, F, 5, h, ⍱, B, ⍠, U, ⍤, ⍥, ≥, U, q, y, ∪, P, ⊇, ⊂, ?, G, ⊂, T, ≡, a, ⊣, ↓, J, Y, p, ⍝, ⍝, ⍺, ⍱, ?, D, v, 0, \", 1, M, X, ¨, ≡, F, 7, Y, ⍒, ⊢, ⍝, B, g, ⍋, H, r, B, h, U, a, ∆, B, 4, ⊖, J, ⍣, M, R, 6, o, u, √, V, ', f, !, ↓, *, w, T, ⍷, M, ←, d, ⌊, H, (, ⌿, 8, C, ⍝, ,, D, w, q, 1, ∇, m, ⍛, u, E, ⍋, _, ¯, z, G, ⍟, *, >, →, ⍝, ⌽, ⍬, ·, ≥, !, ~, 6, 1, ∨, ⍀, f, n, F, g, ⌊, I, [, L, E, j, ⍵, ., ⍷, n, T, ⍱, 2, r, ∇, 4, G, 4, o, ⊣, O, ⍱, ×, [, A, ⍉, ,, q, v, &, r, ⎕, ⌊, _, 7, 9, ⊖, T, l, ⍟, T, s, ⍵, ⍛, Y, ⍪, K, ⍟, ∆, ⍳, ≠, 1, z, ∊, K, c, 9, o, /, 1, O, i, R, ↑, D, E, ∆, v, ⍎, c, T, P, \", c, ;, Y, L, ∆, ⊃, i, ⍕, ⍱, b, ⍳, e, ⍉, ∧, ⍨, I, ⍵, ⍫, ⊆, e, y, ⍝, Y, W, 8, t, ⍴, k, +, a, ⋄, 6, ¨, ∊, ⊣, ≤, ⍬, ⍛, G, 3, C, X, 0, G, T, ~, ⌽, ⍕, ⌺, ., U, A, ∪, ⍵, ⍲, 9, ⍀, `, y, ^, *, K, o, C, 2, !, ∇, Y, k, r, i, ⊢, ∨, A, ↓, @, 5, &, ⍺, ⊃, |, ∊, Q, 0, ?, ⌹, ∘, l, O, √, k, ⍀, x, N, ⊤, ⍱, ⍉, ∊, V, ⍋, ´, D, I, y, ⌿, ○, ∣, Z, ≢, u, p, U, Q, ⍠, ⍵, ⌷, 4, =, :, ⍬, 3, E, [, ⎕, ∩, ∘, ∪, A, ⍝, 0, ⌷, t, 7, r, o, Q, z, ¨, P, ↓, u, 5, *, ], ≤, ¯, !, M, ?, ], ÷, ⌸, ⍉, ∪, ∇, }, <, E, ,, h, 3, ⍞, ⍺, A, J, ∇, ⍛, ⍬, ○, ⍞, x, ∩, ·, }, ⍬, ., x, ,, L, ∧, ○, q, !, /, ∣, @, ⍝, G, 4, f, e, l, 6, ∘, ⍒, M, ⍒, j, 0, r, √, A, C, C, W, ≠, E, ⌿, £, ], ∘, P, k, ⋄, ÷, ⍺, ·, r, ', L, ', _, +, e, ∩, U, >, ⍉, 0, =, ↑, :, l, G, e, ), h, b, j, b, o, ⊖, ⌿, M, T, K, ⌊, w, ⍸, Z, D, w, ), C, ⊃, $, g, h, 7, 0, @, V, 9, B, U, £, ⍋, K, 5, 9, L, s, £, ⍝, ⍢, 3, T, ⊤, l, ⍺, ⍎, ⍠, ⍺, ∪, N, 8, f, 5, E, ⍋, R, K, j, ⍥, ⎕, ⍵, a, ⌿, ⍴, ∪, P, 1, S, ≡, ↑, ⍝, V, ´, L, ), b, 9, ^, z, u, C, F, ⍵, U, y, k, ⍵, ∣, ⎕, `, y, *, q, ⍳, Z, 8, 4, ∇, ⍪, 1, 8, @, o, 5, R, ~, ⍕, ⍉, {, 7, ·, ⊣, O, ⊇, ⍤, `, ⍠, B, ∆, >, ⍺, √, A, ⍉, ∊, u, ÷, ⊇, ⍝, V, ⍕, L, R, ⍪, !, ⍪, a, j, Y, ], ↑, G, K, /, ;, ≤, <, 9, ⍳, y, 6, ⍳, ⍴, b, [, E, ', 2, ´, ⍝, `, ⍠, u, j, ⍝, E, s, j, 5, ⍪, Q, ⌺, Y, ←, ⍸, ⍉, ⊇, ⎕, W, ↑, ⍲, o, -, ∣, ⌿, ⍪, Z, b, (, 0, E, N, %, ⍳, w, P, y, ⍝, t, ⊇, &, |, 0, ×, 8, ∧, ○, Q, i, !, A, F, =, ·, ⍷, U, ↓, √, e, ⊇, C, !, ≥, \\, c, X, r, ⍝, ∆, ⍕, 8, ≢, ⍬, ⍣, !, 9, S, D, ⍥, ⊢, U, ⍝, L, ○, _, U, @, ⌸, ⍥, ´, n, C, ≠, Q, z, >, v, f, ⋄, ∩, 1, ≤, ∆, ., B, 1, U, 6, r, ≥, >, /, ⍤, p, ∘, ⍬, L, ⍎, O, Q, ⊖, A, k, -, 8, ⋄, ⌺, E, O, u, C, f, J, ⊇, |, *, ⍺, √, f, e, k, <, `, *, 7, q, ⍟, ⍱, 1, ⍪, ⍉, ´, G, ⊇, *, -, #, Y, ⍉, F, H, 3, ⍪, \", I, ⍉, ↓, ↓, ⍷, a, %, L, ⊆, ⍤, £, 4, ≡, j, A, :, ⍟, ⍬, 1, ⍸, v, :, ≥, A, S, ´, ⌿, v, B, l, f, p, T, q, 3, ⍵, →, %, -, 8, }, 5, ⍝, ⍫, 2, R, Q, ⌽, C, ×, ∇, ~, u, ×, n, ⍝, ⋄, 7, w, ⍉, ⍕, ≤, @, ⊃, %, Q, W, W, h, ⌶, W, #, ≠, ⌈, >, 8, M, Z, ⊤, ⍬, ⌊, a, ^, d, m, 0, P, >, ⍠, ¨, &, \", ], 6, K, }, P, n, ⍫, ≤, /, 1, ⌸, T, →, ⍵, \\, ⌽, 4, ⋄, ⍛, g, I, o, ., ÷, ⍨, ⍝, ⍒, e, /, x, ⍬, ⍺, ⌶, ⊥, ., j, ⍥, U, q, H, =, ⌹, x, >, O, w, 3, x, ⍥, ⋄, ⍬, ⌽, 6, @, u, o, R, V, ∊, 8, H, ∩, ⍵, *, ↓, H, ⌷, l, ∇, ∪, O, v, ⍺, #, 3, I, &, ⍛, ≡, 8, ⍵, ↑, H, ↑, ⍙, W, \", 9, ⍳, O, 6, ;, X, ⍣, ≡, ⍝, q, J, 8, ⍥, =, ⌹, A, 0, ⍺, 1, ≡, G, !, n, ⊇, @, ⋄, R, R, w, ⍠, ↓, c, P, o, t, 2, Y, /, z, ⌈, Z, ^, ⍟, ⍬, 9, ⊖, 8, !, A, b, \\, ∘, ⍳, P, ∣, X, U, y, B, ⍨, ○, y, H, N, ⍛, u, %, 3, 9, u, ○, ⋄, ⍣, #, z, ←, v, [, 9, 4, ], ⍀, →, ≢, +, P, \\, @, :, V, ⌸, y, £, A, V, ⍒, z, ⌽, 3, K, ⍢, %, D, ¨, &, b, H, ^, ∇, ↓, t, ;, n, ⊂, X, J, 1, 8, J, ⌹, E, F, {, i, ), 4, ⍵, A, ⍎, ⊂, x, M, 6, Z, ⌽, G, I, +, <, ∆, ←, ∨, ⍥, X, ⌸, ∊, j, }, h, q, ⋄, X, H, F, w, ≥, \", n, ), ,, ⍬, i, ?, v, C, B, ⌈, ⍵, l, B, ⌹, K, ·, d, ?, {, ∣, ∇, e, x, ⌿, ´, ⍫, w, g, 7, q, c, {, F, →, ⍕, ), J, v, e, T, ⍷, ', ⍴, N, m, L, r, e, ≠, l, B, \\, <, ⊃, 9, ⍋, 3, t, ⍟, A, S, ⍵, ⍴, ?, £, r, ⌹, g, u, ¨, $, D, 9, ∘, D, →, X, u, ), ⍕, ⍉, ⍫, ), l, ⍙, =, ≤, D, →, }, ⌿, {, ⊤, h, b, z, 8, ⌈, K, c, \\, _, A, ⊥, ≡, J, L, ←, c, [, k, |, 2, n, ⍳, h, n, ∇, ⊢, :, ⍴, v, ⍲, x, t, ∇, 8, n, p, -, 8, ⊃, ⍱, O, l, ,, v, ⋄, ^, ⍤, c, ⍢, ≥, g, ≢, y, h, O, √, M, ⌊, _, ≡, ·, ⍉, ⍥, q, n, P, 6, P, T, z, ⍉, √, ·, x, 8, ⍪, k, d, ≠, ?, ∩, i, 1, q, }, 6, ⍒, ⌸, l, H, 3, ,, ·, p, h, G, %, O, →, =, V, 4, b, ○, /, J, ^, F, v, ⊤, O, ⍺, ⋄, }, j, ¯, O, ⌺, T, 7, p, ∩, ⍤, ¨, T, >, X, g, 3, 4, ⍞, 4, V, ⍲, ⊖, E, ⍸, ⌿, ⌹, ⍋, U, ∣, q, w, =, ⌺, q, $, ?, ⍲, ⊣, h, ⍴, d, L, o, ⍴, W, &, K, 7, ⊥, N, n, d, ⌈, ;, G, ⍣, ∇, 3, S, ⌶, j, ⍤, ⍉, \", N, ⌿, ⍥, ⌹, B, 6, z, ⍞, ⍲, f, +, 9, ⍒, G, ´, £, g, x, V, 4, G, ≢, K, ⍕, G, @, X, v, !, ≢, ,, I, ⌸, 0, u, y, *, ⊥, i, G, B, ⌽, }, ⊢, ⍲, ∩, _, ⍋, ⌿, ⍟, x, Q, n, :, a, >, ;, O, ⍨, ⍬, L, ⊆, ⌿, b, a, !, s, ×, £, (, →, v, ⊂, x, ¨, (, B, q, :, ¯, v, V, ⌽, ⊂, m, g, ⌶, k, ⍋, f, ⊤, u, ⍥, ⍋, ⍟, ⋄, ⍳, ⍬, ○, Q, q, ∣, z, D, ·, t, ,, X, w, ⍸, ∪, →, m, \", L, ⍬, &, ⊣, T, ⌊, ←, ≤, >, 6, G, ), ↓, C, X, j, A, ', r, v, L, -, 4, ⍤, c, P, ∩, k, O, $, 4, ⍋, I, ⍪, ⎕, o, z, h, u, ∆, ⍟, N, d, ⊤, I, L, ⌿, m, ⊂, ~, $, *, :, l, ⌹, ⊆, u, ⊇, g, ⍎, ↓, G, A, ⍱, ⍙, h, ⍪, !, ⍣, ), ⍫, 5, M, £, K, E, [, v, R, =, ⍎, ⌈, ⌸, ⍸, \", =, ⍀, R, p, 5, ⍸, {, |, ⌊, ⊃, ⍬, ⋄, U, j, q, ⌽, ⍱, ⊇, ], ∘, -, 1, ∊, ÷, I, √, ∨, 7, ⍵, ⊤, f, ⍲, >, 4, w, O, ⍨, N, ⊤, ⊤, R, ⍎, k, 1, ⍫, B, k, c, j, h, ∩, ↓, ⍙, I, I, g, ⍎, j, c, @, 5, E, ⍱, ×, N, !, i, ≡, 4, P, ∪, ⌺, ∇, c, v, @, ⌷, `, O, ⊥, ≥, x, d, x, {, 6, f, c, ×, e, ⍛, 6, m, H, U, E, @, U, ⋄, 8, l, C, ⍵, l, ≥, ⊤, ⊃, 5, k, ), k, ⍬, V, ⊣, W, ⍨, S, $, N, 9, 2, ⍳, i, 4, Q, f, p, ⍵, A, ⊖, *, 8, ⍫, =, j, 4, y, G, @, ⍙, K, ⌸, #, q, ⍲, G, -, X, b, i, ≡, K, 6, ⍣, l, ∪, ., ∊, z, ¯, ,, y, Q, N, ⊢, ., %, r, p, q, S, `, J, ⍳, u, w, 5, ⌺, ∪, ;, ⌹, N, £, ⍫, ⍺, ¨, W, Y, 6, 6, -, `, 3, ∇, ⊖, o, ⍵, ⍎, ←, 4, ⍕, ←, C, <, ⍀, R, ⊇, I, 9, \\, ⍒, =, :, D, V, ∧, k, |, \", j, £, √, m, 9, }, ⌺, ←, y, r, ←, √, G, 6, ⍬, ÷, 4, &, ⍺, !, m, a, H, ⍒, q, ⍨, V, h, ´, x, ⊇, =, ⍀, t, n, ⍵, ←, G, ≤, Z, b, R, ⍵, y, ↑, E, ;, ·, a, ∪, x, ⊤, ∘, 2, f, [, ⍱, U, 7, G, ÷, ←, i, y, ⍲, X, o, Q, j, l, →, \", ⍣, l, ⊥, [, D, ⍙, 8, T, 1, &, w, ¯, ⍙, ⍢, ⊖, L, ⌊, #, V, 4, Y, o, s, _, q, 6, *, ⊤, 9, w, F, ,, %, ;, √, z, w, &, ', ⌹, +, ⊤, ⍕, ∇, N, J, @, K, #, M, ⍣, N, s, |, 5, N, J, ~, }, ⍎, ∇, ⍟, ⍛, ⍪, ¨, +, X, b, @, E, p, {, [, l, x, 1, ∇, [, m, Z, /, ⎕, H, ∇, z, ], G, £, 9, ≥, s, M, √, G, F, Y, P, ⍟, 6, ⍎, ⍪, 4, P, ⊆, ⍎, ⍒, ´, <, A, →, X, b, ⍲, ~, L, v, ⍛, ÷, ⍴, ⌿, J, O, ·, ∩, p, -, z, @, R, 8, ⍛, $, ⊂, l, ∘, F, ´, V, ⍷, m, ·, k, q, x, N, U, I, <, B, ;, ⌽, +, /, <, ], ⍫, Z, ⊂, F, ´, u, ¯, ⊃, b, J, ⍫, S, W, ∇, O, √, c, h, &, b, ⍤, @, ⌊, U, G, X, ⋄, ·, ÷, ≥, R, ⍎, o, ⌸, {, M, d, 8, s, F, ^, _, ⍤, X, S, `, 3, ⍱, 3, 7, ¨, F, ⎕, H, |, ⍋, ≡, J, x, a, ⍒, ⊣, ⊆, ⊖, R, ↓, ⍕, g, x, ', ⍠, ·, N, P, C, R, T, ⍣, u, ⍤, 6, x, J, D, S, o, s, ⍵, ⍤, s, #, h, f, _, \\, A, ×, ⊂, J, ⊤, U, _, ⍋, =, ⊃, ⊂, ∩, ≠, P, 9, ·, ⍨, ´, $, *, ⊣, 9, h, ⊇, ⌺, ·, A, q, ↑, U, *, F, ↑, ⊃, U, ⍵, D, ⌽, ≥, u, ⊖, n, C, ⊃, F, +, J, f, 4, 1, s, ∧, F, L, *, ∇, b, h, !, <, k, R, <, K, F, 7, R, ⍞, s, ·, ;, <, Z, f, ⍺, r, ≢, (, ⍛, ⌶, }, R, q, C, 1, C, ⌽, ∇, ⊆, V, q, %, |, \\, ;, ⍤, R, ∆, ≠, Y, A, ⍉, |, ⌽, ⌷, x, T, H, ⍫, p, E, P, W, ⌷, z, ∇, ), M, ⊤, j, G, ?, &, \\, D, ⎕, Q, J, 8, D, n, ∧, u, \\, 7, k, 5, ⌽, j, 0, r, n, o, <, ⊣, W, R, B, ·, Z, E, n, ∆, $, ∇, 7, o, L, L, o, A, w, ), |, \\, r, ∘, ⍵, g, X, W, h, W, ⍺, R, 7, £, ⊣, {, D, E, ⊥, 8, ↑, =, ⍟, v, √, ¯, Y, U, ≢, t, ⊥, s, ⍵, e, :, E, ∊, $, ⊃, m, S, 3, ⍪, 5, p, \", X, |, F, ⍀, \\, ⍞, ⍥, S, ,, ⍙, ´, C, w, ⍵, ⍬, w, 6, ↑, W, S, ', S, \\, 3, v, ∇, I, ⍺, B, Y, ⍱, ⍸, 3, >, ≤, ⍢, -, [, %, ¯, ⍒, ⊃, ~, a, j, N, F, S, ⍢, ⊣, 2, ⌶, ∘, ⊃, H, g, ↑, ⊖, L, T, ⊃, B, 7, ∩, <, ≥, ⍎, g, ⍋, ?, f, ¯, →, ○, V, U, X, ⍒, W, 4, C, P, ←, 2, ⍟, !, ∪, &, ⌹, b, ⊇, W, P, ⊤, 1, Y, C, ⍷, ⍸, >, r, j, t, ∪, c, ⍒, >, ⌶, ∇, P, v, ≢, g, ], ⍤, 7, ⊇, ·, |, ⊥, t, I, l, c, p, ≤, r, &, !, ↓, c, q, k, [, f, f, ⍫, ⍋, >, ⊆, ⍣, T, u, ⍙, V, 2, R, ⍬, S, m, ⍳, ⍬, D, [, =, 1, e, f, E, I, ⍬, ⍞, }, j, H, ∧, C, ⍣, e, q, ⊣, ⍳, ×, ⊣, r, k, Z, 7, p, m, ⍙, ≠, p, A, Z, p, 3, →, ≥, ⍸, ., F, ≤, q, k, s, L, s, v, R, ⌈, ≤, ⍸, [, k, T, ⊥, *, 7, ⍨, s, $, g, L, ⌽, R, 0, C, ⍴, Q, ⌸, ⍵, l, i, 4, G, $, n, d, h, @, ⍪, ∨, t, Q, \\, l, 7, 2, c, >, x, u, ⊃, c, i, ⍺, ⍬, ⌷, L, J, ≢, a, x, O, 9, ⍫, b, d, b, ⍎, ⍙, ⍸, A, e, 7, ¯, ´, d, R, ∪, u, a, -, \\, ⌺, \\, n, ⌷, x, 6, ⍛, \", ∇, ⌿, e, ∨, t, ⍠, b, Y, ⌈, ⌶, Y, ⍛, ⍴, ≠, ≠, →, Y, ⌊, M, ⍋, 0, _, ¯, ≡, ⍨, ↓, ⌊, ⍲, g, [, 5, ⍙, -, ^, ⍺, \\, |, ~, %, Q, $, w, ⍤, 3, ), ?, r, ⍣, ≠, /, I, P, K, ⍣, -, ), 1, ⍥, ⍬, ⍴, ⍕, ⍨, ⍉, ?, I, =, +, &, l, C, ∊, 8, 7, y, 7, J, E, H, m, +, ⌹, Z, 0, 1, ⍋, :, _, 0, V, e, ⊣, N, ⍪, b, 3, o, ., ], G, g, s, i, =, ∩, Z, 7, Q, £, J, ⋄, 3, ∇, ∧, a, ~, Q, ⊤, ⋄, w, ., s, ↑, f, _, B, ⍥, G, L, ⍤, N, ⊇, ⌈, s, ⍥, ∩, |, _, 8, 9, ∘, d, ⊃, 1, 7, ⍷, V, ⍫, A, Q, ⍕, ≠, }, ⍨, #, K, ⌽, ⌸, ⌶, ⍬, e, a, V, ⍥, ⍺, ∆, 5, ≡, t, ○, ⍒, 0, r, ≢, 4, h, ⌺, E, 1, ⍥, ←, c, N, r, W, ., ⍙, B, f, w, ⍛, J, ;, ⊤, j, T, ⍙, g, ⋄, ∘, 7, ⍣, z, 6, ⍟, k, ·, ○, e, ∨, e, J, 1, :, @, I, X, ⍣, ), I, ≡, n, A, ∨, ⍺, ≤, ∣, u, ↓, e, ∣, p, 8, k, @, K, C, I, w, g, x, ⋄, ¨, \", n, v, 3, c, ⊖, ⍬, -, |, ⍷, v, ÷, Y, _, →, (, ≥, ≢, L, G, w, ↑, \", ⍬, ¯, 0, ⌶, 1, ⍛, ∣, ⍢, ,, 1, ⊃, x, ∩, ⍠, N, ⌈, q, V, ≢, F, C, Y, ⍛, D, ⌊, ∩, ⍞, {, ,, ), ⍴, ⊖, ⍤, a, 5, i, ⊃, ⌈, ≢, ↑, B, I, ⍸, [, Q, ⍟, 3, ´, ., -, s, z, @, h, ↑, S, ∇, v, n, z, 0, &, 5, ⍕, c, ., ⌊, ⍬, ⍵, M, d, ⍛, [, ⍺, z, ,, d, s, `, Q, W, ⊆, ⊤, 3, ↑, m, b, 5, ≡, ≤, 2, ↑, ×, 4, k, ^, ⌶, 4, ○, ⍫, ⍸, F, C, $, =, ×, ¨, ⊇, i, A, 7, -, ⊂, ←, o, ∩, t, ⌶, r, ○, H, s, ⍷, 0, G, |, /, ⍕, _, g, 5, X, ¯, ⍒, 2, I, v, E, 9, ○, ⋄, ⍵, ?, @, x, ⊂, ⌽, a, a, q, 7, ¯, -, ⌶, f, ∘, `, X, L, ≥, d, x, 2, i, ⍣, ∊, ⍳, ⊥, e, <, ⍱, ., ⍞, v, ⍙, G, t, Z, `, 0, 0, 4, \", ⍱, y, Q, o, ⊤, ', Z, W, ⌶, H, ∊, ÷, ⍞, `, 8, m, *, ⍺, ⍨, 7, ≡, G, ⊖, 1, L, W, V, B, p, M, ⍷, F, ⍛, ,, n, ⍵, O, ⋄, Z, ⍎, C, ×, ⊆, \\, 1, √, %, ⍀, ¨, ⍵, £, ⌷, C, ⍢, ⌶, f, >, $, +, ⌈, D, b, 9, Z, ↑, 8, (, ⊣, 7, ⊥, T, √, ⍎, S, b, Z, ∆, ~, Q, Z, \", Y, ∩, g, c, n, ⍸, f, S, ⌹, !, %, N, ⋄, x, ?, 7, %, p, ∊, →, k, M, ∣, d, l, j, G, &, &, X, ´, `, √, &, 0, ⊤, H, ⍛, N, ⍱, ⍨, !, ⍳, j, D, Q, R, d, ⍤, ≤, m, ⌈, ⊆, √, h, 1, v, ∧, h, `, Z, ⍬, D, ·, 6, f, k, U, u, ≢, w, ⍞, T, ⊂, ⊢, ,, h, ⊂, V, ⍺, -, ÷, ≡, ⍢, £, k, w, ⍥, ⋄, 2, ⋄, n, n, O, f, ∩, \", ., 4, V, r, ., R, ⌸, ∘, 5, N, j, b, ⍣, a, ⋄, 3, ⍳, =, Y, j, ⍉, ○, ⍒, ⌶, G, ⍸, y, ⊥, w, F, A, B, d, o, ⍞, ^, ⌺, Y, ∆, ¯, √, u, ⊥, z, y, *, ⍎, ÷, d, f, (, ⌹, G, z, 2, ∘, 4, ', b, ^, j, j, n, T, +, ⌊, 2, {, £, E, 7, Y, &, ⌈, j, K, b, m, 2, v, +, ⌈, ⋄, R, ⊆, k, t, ∨, ⍢, ○, ⍨, ←, ∨, S, G, E, ∘, p, i, 1, ^, F, F, \", 1, ^, £, q, ´, ∘, ⊢, t, 8, X, 7, ·, ↑, C, x, ⍋, ⍒, ≥, ⍉, u, o, r, G, E, 9, ], l, M, ∪, m, f, E, Q, ⍴, C, ⎕, *, ⍥, ⊥, 9, j, 8, ⍲, ⌸, z, 1, s, ⍕, D, ∪, ⎕, ⍺, H, ⎕, G, ∆, u, (, B, K, =, ⍵, ⍛, ⌿, ∇, ⍤, ¨, (, ≢, z, R, T, ;, u, ⍞, V, t, #, →, d, B, I, s, z, ¨, ⊇, ⌶, S, 6, ⌶, n, ⍒, !, ⍎, v, u, p, V, 8, p, C, 3, ⌷, @, ⍬, Q, T, M, 6, ∆, D, ¯, ⍵, L, J, m, J, ~, Z, z, R, X, Q, D, A, F, g, y, ∧, B, ⍋, B, 4, ∆, ⍴, ⊥, ⍙, s, A, ≥, ∣, X, K, l, D, Q, w, j, ⌷, ∨, x, ⊣, W, Y, ⊥, <, i, %, ⍥, ∨, L, -, ⍲, s, ⊣, ∪, ,, ⍒, ∘, $, z, v, ⍙, ÷, v, ⍵, h, ∘, ∆, ↑, ⍠, N, _, ⎕, ≥, U, J, k, p, u, S, {, ≢, 0, 9, E, w, 3, ⍬, ⍠, 8, ⌷, ⊤, →, 8, W, 6, D, i, ¯, ⍵, o, O, \\, R, ⌈, ⋄, ⍙, ¨, ⍺, e, i, ⍙, j, E, T, ·, G, ⊣, t, J, ⍀, Y, U, ∇, 6, R, <, D, ⍷, B, a, _, ⍞, ., £, L, k, ⍲, ¨, ⍥, w, g, S, o, H, 4, s, M, C, ⊥, ´, c, X, =, S, g, o, ⍣, ⌶, $, ∊, Q, z, B, 7, p, ∇, @, ⌺, ⍴, √, b, +, <, ., ⍸, 7, 9, c, N, P, ⋄, ⌈, 2, ^, ∊, ⍺, ⍢, ⊆, y, ⍀, ⌶, ⍷, ≤, ⌽, ○, x, ⍢, a, ⊆, d, ?, ∣, t, <, ⍲, N, ⍒, W, t, ⌸, ÷, ⍴, K, (, ↑, z, \\, 6, w, £, %, P, 8, d, ↑, ≤, ⌺, ∧, 7, r, f, :, ⍴, ⌷, 6, d, ⊤, ⊤, S, s, D, ⍙, ×, n, 9, ⍋, J, _, →, R, V, ⌿, 6, ∩, \", <, T, c, 6, k, `, &, e, ⍋, <, ⍢, ⋄, ⍒, ∆, g, ≡, ^, r, {, V, ⍫, {, U, %, Q, H, p, ∧, 0, _, ], 2, g, k, Y, q, ), ⌶, @, t, ≥, m, ↓, :, d, d, ⌸, l, X, r, 0, P, p, M, [, ~, U, Z, I, %, ⌊, S, G, ⍢, 0, =, ., D, |, b, √, q, m, R, o, ⌹, &, S, ⍎, G, E, i, @, ∇, ?, Z, u, r, e, z, Q, ¯, ⍠, j, ∨, T, \\, W, #, ⍤, ⍠, ⍕, g, n, D, ⌿, ⍕, ⎕, 2, _, v, J, Z, *, 0, j, `, n, @, ⊢, 6, A, a, q, z, ⊃, a, W, ≤, >, ×, B, ?, B, O, ≠, ∨, ∘, R, %, W, X, ⍒, p, ○, ⍢, ○, Z, b, ⍉, &, ⍟, A, ⊂, h, ⌊, ⍙, W, _, 5, ', F, |, T, q, ⌈, 6, ∧, ⍢, ⌹, ∊, ↓, +, q, u, ), ⍀, ÷, i, p, ⍥, ∧, ⍞, ∨, ⌸, F, B, ⍙, p, ⍥, ⊇, £, r, D, >, T, n, ⊂, H, (, ⍉, 4, L, x, g, √, r, f, V, t, ≤, i, ⊃, *, ⊖, s, ←, ·, ´, ∣, ∇, u, w, ⊤, z, R, ¨, ⍣, t, X, a, d, #, v, d, b, →, <, m, <, A, ], w, ⍵, ∨, 1, S, /, g, <, o, ∇, 8, ⊥, ∨, O, k, ⍴, ⍤, ¯, 2, →, ∧, v, ↓, ^, Y, ⍠, 0, c, ∊, ∧, 1, 0, ', p, ∩, ⊇, ∩, `, N, ^, T, <, ∩, I, ^, Y, →, ⌶, *, ≤, ⌽, 0, b, ?, A, ⍀, t, ⌷, k, ⍟, ←, t, ∨, ∊, ⍛, ∧, 2, /, A, M, *, ⍪, k, l, ⍷, ⍬, 2, ⊂, ⊖, b, ≡, n, ∣, n, n, 8, >, 1, ⍋, ⌈, ⍥, 4, ←, R, g, ⍳, u, S, R, K, (, <, k, Z, 6, ', ⌸, ⌹, z, [, N, £, √, 3, r, 3, 0, ⊃, ⍤, S, W, ⍨, F, 4, \", P, ⍺, ⍛, ⍀, =, ∆, m, m, ∪, (, B, ⌸, ≠, ∆, S, ≢, H, ←, p, -, G, \\, Z, (, 8, ', ⍺, T, `, P, ⍟, Q, ⍀, ., t, s, ⍢, M, 0, v, →, ⊤, 8, O, ⍢, l, @, V, d, 9, r, f, ⍺, ⍺, Z, w, ≡, s, E, →, ⊖, N, -, K, ⍢, \\, ^, o, ↓, ⍢, p, ⌊, ⍎, L, ⊃, T, /, ⍱, B, ⍬, ≥, ⍙, #, ⍺, ⍙, !, R, ⍋, /, ⍴, B, i, ⍨, ⍟, ⌶, J, ≠, Y, ⍵, ⍳, O, ⍙, a, y, ], f, ⌈, P, 2, w, ., s, ⊇, L, z, 4, p, ⌽, ⌈, ←, g, ⍎, *, o, ⍒, ⍀, ○, I, S, £, r, ⌸, ⍢, s, ⍒, o, 6, ○, l, \\, X, ↑, ⊃, >, T, 1, ⊖, u, ⍳, ⊃, I, ⍵, ∆, K, {, ´, w, ⊖, ⍷, b, ↑, E, 5, ⍬, ], ∪, ´, f, U, ', C, s, n, ⍱, b, ○, t, L, ⌊, q, h, ), ^, £, ⍤, O, ~, R, ≡, `, ×, ≠, 0, |, U, ↑, ∨, T, }, ≢, ^, k, 6, a, ⌽, ⌸, %, →, a, ⍬, l, ⊂, D, ?, ÷, O, o, A, ↓, ∨, ⊣, c, {, ~, %, Z, U, >, W, ⌈, ¨, K, v, [, ≤, U, ^, ⌿, c, }, R, O, Z, ⍠, b, r, 1, a, ⌷, 1, ∩, f, ⌶, \\, R, ⍬, W, 8, (, %, ⍴, r, ⌹, m, ⎕, $, >, ^, L, ÷, a, Q, ⊢, 2, ↑, ∇, n, ⌊, \\, Q, 8, ¯, ⌽, ^, ∩, ⍫, y, U, ⌊, o, 6, ⍥, ⊆, ~, \\, ≠, (, ÷, #, P, ∧, E, c, ≥, ⍒, ∊, x, v, ⊂, ∇, Y, ○, 2, d, B, ⌊, ⍪, e, H, ⍪, *, ⍞, ∨, 4, H, l, ⍠, A, }, ´, ÷, ∆, N, ⍛, C, ⍣, ⋄, ⌿, ⌸, ⊢, 0, ., S, ), ⍳, /, f, e, I, T, ⍫, g, ⌺, a, T, \\, *, V, ∇, @, ⍬, f, W, ⍉, O, ↓, E, t, £, ⍎, ∧, {, j, ○, d, U, -, W, n, ∊, h, 1, v, 2, Q, ⍫, 9, Q, ⋄, e, D, |, i, j, ⍎, Z, ¨, q, J, b, b, c, |, ⍉, 2, ⊂, ⍕, ), ∪, P, F, ↑, o, m, ⍱, M, e, ¯, ≢, d, ○, ⍟, Z, √, ⎕, x, ⌊, ⍀, ∪, y, e, s, (, ←, /, ⍬, ∘, V, ⍢, ¨, v, 4, ´, U, ⍟, ⍒, h, W, →, ⍣, L, -, ⍞, U, P, d, !, ⍲, 9, >, m, x, ⌹, ⊤, ⊤, -, w, J, ÷, 5, k, n, q, 6, x, ⍥, P, ⍙, ∘, ⊢, 6, ⍬, h, a, n, ⍺, 2, u, K, w, r, s, ?, /, l, ⍛, X, 6, ∧, o, _, ÷, w, <, →, ∩, ⌺, ⊆, c, ⍺, ⊃, :, w, ⍋, ⍎, S, V, w, u, ≠, f, D, h, ⍳, g, a, ⊖, I, £, J, ⍙, y, ⊣, J, D, ⌹, D, O, ⊢, ⌹, I, X, ⊃, ×, ⌹, ⍳, z, C, A, ∇, v, ⍥, ⍠, →, ^, c, ≥, z, E, M, ∣, \", D, 3, y, V, ⊥, W, ⊇, ⌈, W, ⎕, ∆, \", @, ≢, L, H, t, ¨, ', ], c, ∧, i, ÷, ¨, ⊆, n, T, ¨, ⍞, ·, M, E, E, ⍀, m, l, =, d, P, M, ⍬, !, m, ⌿, ⌶, I, M, ⍺, C, ⍷, ⍣, ~, ≥, ⍵, ↓, c, =, ≥, ⊣, ⍙, 9, u, Z, ≠, ⊆, ∩, e, d, 0, 2, 3, h, ⍛, p, Y, ⍴, h, ), ∘, ≥, !, !, ∊, ⍠, o, £, j, `, ⍋, ⍷, }, 2, ∣, P, l, N, ⊤, ·, ≢, O, ⍉, (, Y, ⍙, /, ≠, #, u, h, ⌺, z, ⍴, \", 0, M, 2, z, v, ∪, z, ⍲, ', ∨, k, ⍕, &, -, 5, 3, ⌺, ⊆, [, :, ⊖, ⍷, 2, ⍴, t, ∧, ∣, B, 3, ∇, B, p, q, ⍷, b, H, 2, H, ⌷, ÷, O, ≤, M, T, p, ), k, \", ⍷, V, ↑, 9, [, ≠, Z, ↓, g, ⊢, ⍳, j, P, W, J, l, e, ○, $, 3, o, ∨, Y, ↓, +, o, ⌺, ∆, ⌺, ↓, I, {, 3, 5, Q, ⌷, ;, ;, 2, ∇, ⍎, ⍠, ⊣, ⍴, b, v, V, ↓, |, ⊂, -, O, ·, ∘, c, ⍀, e, ?, ∣, 9, j, ⌶, ⊂, Z, ⍎, ↓, r, ≥, ⊆, ⎕, ⌊, W, h, M, 5, i, T, t, m, ⍉, g, ⎕, o, |, L, z, p, ⌺, ⍀, ⍪, B, r, \\, 1, 3, ', ⍎, |, I, ⍫, ∇, 1, 3, l, N, 5, E, ⍟, ⍢, M, ), !, B, ⍒, 9, h, ), ≡, ⋄, ⍒, %, ↓, !, ⍺, $, ≠, ⍣, r, t, C, F, ⊥, ,, ⍲, ∇, ∇, ↓, ∣, ⋄, O, M, :, ∣, ⎕, ⍷, v, Q, 0, M, ≠, ⍢, ⎕, ≥, K, ⊆, ⍢, ×, ≥, ⋄, B, ⋄, ∇, M, O, A, O, H, #, u, 1, ≢, i, ⌹, 0, 0, D, E, (, Q, #, ], P, ⍺, `, I, n, V, ⊥, ⊂, (, Z, 9, ⊂, T, d, [, w, 0, $, E, ∩, C, ^, ∘, *, ∨, ⍺, ⍵, |, 5, 9, }, ⍴, ∆, ⍸, c, →, ⊃, r, X, ,, ⊖, T, ∣, ⍨, √, P, m, ∇, f, !, i, L, ⍬, ⌷, ≥, h, &, ⌺, ⍥, b, ⍴, ○, >, ⊤, ., U, x, ⍒, _, $, ´, √, Z, ⋄, ⌺, _, $, U, ⍷, x, ·, ⌿, F, t, L, e, ↓, ', ⍨, ⌸, &, ⍎, 2, E, e, ←, A, W, O, ⋄, ⍟, ⍒, l, F, T, t, z, ;, p, =, y, ⍟, y, ⍞, J, w, S, /, M, ∆, `, 5, -, _, ⊇, ≤, ⍺, ´, %, ⊣, x, 0, ⍙, /, ⍢, Z, =, ⍴, X, N, ⌽, M, ⍨, }, E, g, ), D, 3, V, T, w, ≡, -, t, :, ⍵, ∧, d, M, ⊥, y, J, ∩, ⊥, N, ∊, ⍣, ∩, ∘, a, ⌈, →, C, -, O, |, $, ⍲, ≤, ⍲, ⍟, ×, ⋄, ⍱, N, ,, ⌶, ., I, ¨, L, ↓, ≤, E, ⌊, 2, ⌿, ⍛, ⌺, -, ⍲, ⍞, 9, ⍤, ⍞, ←, o, ⌽, 9, ∆, ⍷, O, 2, ⍫, |, L, M, f, L, ⍺, ⍞, ⊤, e, ⍵, 8, ⍨, ∊, ⍥, ⍞, #, ., g, Y, V, f, \\, ∊, ', i, ⍳, Q, ⍉, ), ⍠, ⍱, y, c, ¨, ⍲, ⍫, <, ¯, ⍣, y, F, ,, ⍣, A, !, w, ⊢, ⍎, Z, ⍬, |, ≥, p, <, g, H, 9, F, ⍛, V, ⎕, L, y, ∪, %, ⍠, 8, ≠, £, ⎕, D, ←, a, ∩, g, |, i, N, ⍛, 5, ⍀, ×, 5, z, ⍬, ⊂, ×, ⍟, \\, c, ~, z, ⍕, ⍎, *, ⌸, ⍒, ⍴, Y, C, →, ⌈, ∧, ⍀, ⍬, X, {, ∆, A, i, ~, ⍉, N, ⌊, f, U, C, ⍤, ⍷, !, J, d, ⌽, E, +, s, T, ;, ⌶, &, J, 2, O, g, ⌸, H, X, o, ⊃, ⍲, D, ⍒, ⌊, ≠, ¯, ≠, {, i, 3, Y, f, ·, k, 8, ∪, }, ⊖, i, ∇, %, ⎕, I, ⌹, H, 4, 0, S, S, ∧, ⍵, k, ⍕, ?, ⌷, 4, √, ⍬, ⌹, Z, C, ⍴, ¨, 5, f, *, ÷, -, ∊, ○, T, O, d, (, ×, ], ¨, P, ⍴, (, ⌽, {, ], U, ⍸, ⊣, ⍙, t, ⍕, ⍪, 2, ⎕, ⍬, t, ∣, K, g, ∣, t, ∩, ⍲, ~, ⌿, £, ⌈, ≤, 5, \\, s, _, →, u, ⌹, 8, Z, ⌹, i, D, ⍒, y, a, ⋄, d, 9, z, ≠, ⊖, i, S, ⍞, D, 0, J, T, ', ⌷, S, \\, (, ;, ×, x, ⍱, z, /, ;, N, E, ⍪, ○, /, *, ⌺, ⌷, ÷, ⍷, F, N, 5, ⍺, ⍴, P, H, I, ⍒, ∘, {, ⍎, ∣, \", ], E, ⍞, →, ∩, \", ⍫, ⌺, 9, x, ⌷, ⌽, {, M, ⌈, ⍫, ), ⍙, ´, →, ⊢, ⍬, X, C, ⍫, ⊣, 8, ⍬, P, ⍕, U, D, ⍸, \", ⊆, √, =, ≥, Z, T, S, ;, Z, \\, ×, y, ⍸, N, &, ¯, ⌷, C, @, 8, ⊂, ⍕, T, U, L, F, ⍵, Y, ., k, 4, ⍫, ⊣, ^, S, &, k, ⌶, ×, a, ⍛, H, ⍵, ∧, J, <, ○, [, @, ⋄, >, }, c, [, ∆, 2, ⎕, a, ⍷, F, ⍤, ⍱, ⍕, [, }, ○, M, ⊣, \", l, ⍎, ⍳, H, K, S, S, ⋄, ), K, \\, ⍲, A, L, ¯, ∨, ⍛, ^, %, ⊤, ⋄, ⍳, l, /, s, ×, c, W, M, ⍱, ⌹, ⍀, 5, ⊖, ≥, ´, L, £, ∧, ⌊, ⍉, √, Y, ≢, g, 4, ⍟, ←, C, t, ;, w, ⍤, !, E, l, ⊣, ⍀, ⍲, ⍸, ⍷, z, ∣, E, u, ⌹, ⌶, {, ⌽, Z, 0, W, ⌸, S, 0, ≤, ,, H, ⊢, Y, S, ⌹, `, W, V, ⍀, \", 9, a, ⋄, ⍀, H, <, F, ⍴, 5, ⌺, ;, ⍵, 8, ⍳, H, ∊, X, ⍢, ∘, :, `, ∊, d, w, ~, W, ⍢, U, $, £, 8, ⌿, ¯, ⍙, ⍕, Z, ⍫, →, L, ⍎, y, >, H, U, =, C, ¯, ?, ≢, d, \\, E, g, ⍪, ∆, ⍉, ⋄, ⊇, ⌶, H, ⍵, 4, £, s, Y, ⌊, ⍺, ⍉, ⊣, ∪, ⍺, ⌊, ´, ⋄, M, ], #, K, M, %, ⍸, ⌷, ⍟, F, 0, Y, ', ¨, ∆, ⍥, ∨, ⍞, ⍵, *, ), (, F, ⌸, ○, ⍵, £, ↓, ;, ´, ⍉, ×, ], S, ⍳, ↓, ⊇, S, ⍫, d, ∪, J, <, l, {, ∨, ⌽, ⍤, ∘, /, ↓, ⌈, @, c, ⍙, V, ⍛, z, >, ⍷, ⊖, ', [, ⍲, W, ⊖, ≤, X, ., w, ⍞, ∘, (, d, ⍵, \", ÷, H, d, y, ,, 4, V, ⎕, ⍪, ≠, ⍠, ⍢, ÷, 2, c, ⍒, @, [, 2, ≤, ⍨, 2, }, ≢, £, ~, ⌊, ⍳, K, S, ∣, X, $, K, ·, y, c, ⍵, ∧, X, ⊣, `, ○, K, c, ÷, u, 2, ⊂, y, Y, s, W, ⌷, *, ;, ⊂, ⌷, \", ⍺, `, |, ←, ], J, E, →, ⍱, !, a, +, ⍤, ., ⎕, ., ⎕, 8, ·, y, 2, _, W, ;, ⊇, 4, ⍀, g, ⍋, s, E, ∪, ∊, ⍪, ∨, ], ·, +, ∨, ≢, ⍛, →, ≠, -, √, }, ⊃, ¯, c, ⍀, ∪, |, ⎕, ·, ⍱, ⎕, u, ,, ↓, ⍉, /, y, X, :, -, |, ∪, =, ⎕, (, ⍋, ⍴, ], +, /, ⍎, (, ⍞, ⊥, ⊇, H, ⌷, *, ∨, K, L, ⊂, ⌸, ⍣, ≥, ⌷, ?, ∘, ↑, ⍠, V, ⊣, →, ⎕, ], y, ], ⍒, \\, @, ∘, ⌸, ⎕, £, >, ⍛, ⊂, d, t, ⍢, 8, ·, ⍣, ⊤, ↑, ⍎, ⍀, ¨, ∧, ⌊, ~, <, ., ⍸, ', ¨, ⌶, ←, a, V, ⍪, ⍱, ⊆, ⍉, \", H, y, ¯, ⍋, ⊖, ⍳, #, ⍉, ´, ⍋, ⍪, ⍱, ⍫, ⍟, ≢, c, ⌹, ⍣, \\, ⍋, ←, ⍳, ×, d, ?, ←, s, =, ⍲, ', #, !, a, ⌷, ´, ⍷, ≥, ¯, y, ⍸, :, }, ⍫, =, a, $, ∆, ⌽, ⊥, ¨, ⍢, ⍸, ⌷, ⍨, ≤, d, ∆, {, ⊆, ¨, L, ⍣, ⍞, ⊥, \", ⌺, ,, 2, \\, ⌹, ≢, ≠, ○, ⌺, ⌊, ⍲, $, t, ⍱, ⌿, |, ⍒, t, ⊤, ↓, ', _, +, +, ⍥, ○, _, L, ∨, ⌹, ⊃, 2, √, ⍣, £, V, y, ⌿, ⌊, ⍒, J, ⍞, ×, ⊆, ,, ., ⍛, ⍉, ', >, ⍫, ⍟, ⍨, J, Y, ⍥, +, $, ⊆, ×, ↑, ←, ;, ⊣, :, ⌿, (, ?, ×, ⊥, ·, ∘, V, ¨, s, ≡, t, ⌷, *, ⍣, ⍕, ⍪, ⍞, s, ⍉, ^, ), ?, ', ⊂, }, ↑, \\, ⍥, @, ∆, ;, ·, &, ⍠, @, L, /, ⍣, ¯, ⍥, ⊣, &, ⍴, ≠, ⌿, ⍨, (, (, ⍱, J, ≥, d, \\, ), ≤, !, +, ~, ⌺, ⍎, ⍲, ↑, {, ⌿, ∧, ´, ., ´, ⍨, ¯, ≥, >, ≥, ⌸, ∣, &, ⊆, ⌹, ⊣, £, ⍷, ⍤, _, ×, ⍀, @, ⍙, ´, L, [, ⍨, {, ,, {, ., ¯, |, ⊣, ←, ←, ⍋, ⍥, ⍱, ≤, ⍞, ?, ⍤, @, ÷, -, !, @, ⊣, s, ∊, ?, ⊃, ⌶, ⍕, →, ⊖, /, £, ⌺, ⌈, ⌽, @, >, ÷, V, ⍱, ¯, ⍀, ⍥, ⌊, ∊, ⌸, ⊥, ∘, ⍠, \", ⌹, ⍛, @, @, ⊢, %, ⍋, ⌶, ⍛, ≡, ⌺, #, @, ', /, ⍣, ,, ÷, ⍨, ⊆, ⎕, √, :, =, V, +, ∘, ⍞, V, |, ∊, ⌊, ⍀, }, ⌈, ¯, ⌺, ⍟, ↑, ,, ≥, ⍳, {, \\, ↓, ¨, ≡, ⍨, £, ⌿, ⊖, +, <, @, ¯, £, +, ~, £, _, ←, ,, ¨, ⍷, $, ⍱, ⊆, ⊥, *, %, |, ⍒, ⊃, ⍣, ∪, ⍳, ≠, ;, ∧, ⍀, ⊢, ⍎, ⍉, ⌸, ⌈, V, ~, ≤, ←, ∘, ⊤, _, ↑, ., ⌈, ⍴, #, ⌷, >, ≤, ⍳, ⊇, *, ≠, ⊣, →, ≠, ⍣, ⌿, £, ≥, ∊, %, ;, \", ⌷, ≠, ⍙, ⊆, £, ∩, ⌺, ⊃, ≢, ⍎, ⍴, ∘, ., \", ⍱, ⍤, \\, ⊢, t, ⎕, ⍠, ], (, ⊢, ←, \\, ⍳, %, ∪, ×, ≠, +, ∣, ⌷, ∊, ¨, =, %, ←, ⍤, ⍨, ∊, ⊣, `, ≠, ⌿, ⍎, ⍒, -, ⍕, ⍣, ↑, ∣, ⍸, √, ÷, ÷, ∨, ×, ⍲, ⍕, ∧, ∣, ⌊, \", ⊇, ↑, ⍲, @, ), ⊢, ⎕, ⌿, ', ×, ⍕, |, #, ⍴, ~, ⎕, ⊆, ´, ⌽, ⌿, √, ´, !, :, ⊤, √, ⊇, :, ⍋, ⍒, ⍤, ⌈, ⌹, ×, ., ⍳, *, &, ¨, ⊃, ×, >, :, }, ∧, ,, &, :, !, }, ⊆, ↓, ⊣, ;, ÷, ⍞, /, ∣, ´, ⌺, =, ⌸, ↑, \\, (, @, ⍢, ^, &, ⍨, ], ⊢, @, s, +, /, `, ⍀, @, ⊆, ⌸, ¨, ⊢, ⌺, ?, ⍫, ], £, ⍉, ⊂, ⍪, *, $, ~, √, ⊂, ⊢, +, ⍳, ∊, ⌿, ⊃, ∣, s, ⍴, ⍤, ⌶, ⊖, ≥, ↑, !, ⍞, %, @, ⍛, ⌸, *, ⍕, ⍕, ⍒, ⊇, `, ⊣, ⊇, #, ⍫, \\, ⌷, >, ⍣, ⊢, √, ↓, [, √, √, ⍤, ., ∊, -, ⌺, ↓, ⌹, ⍋, +, ', :, ⍳, ∩, ⌺, ⍷, ⊆, ⍸, ', ⍣, !, ↓, ÷, {, ←, ?, `, ⌸, ⍛, ←, ∨, `, ⌿, %, ≢, ⍀, £, ⌈, ', ⍕, #, ⌶, ∧, ⊣, ⍎, }, >, <, ⍴, ⍥, ., %, ⍷, ×, ○, _, ⊥, >, ⍀, ?, ', ¨, ⍥, \", ×, ∧, ⌶, ⍋, ∩, @, ⍱, ., ←, ⊆, =, (, /, ⍷, ¯, >, ↑, ⍪, ⍙, ⌹, ∆, ⍥, ⌹, ', ), ⌿, ⊤, <, {, +, ⍣, ⍕, ⍎, ⍸, ∩, ], ⍋, ≥, ⍫, ⎕, ⊃, ⍸, &, ↓, ?, √, ⍟, %, ∊, ⌈, ⌽, >, ⍨, ', ×, ⊇, |, ^, ⌊, ⌶, {, ⊢, ;, $, ÷, ∪, ⍥, ⌊, ⍕, ≡, {, ⍎, ⌺, ⌽, ⊣, ⌊, }, ?, ⍞, ^, ?, ⌶, ∨, ⍪, ·, ⍨, ∘, ⍋, -, ⍉, ≥, >, ⍷, ⊢, ≢, ⌽, ^, ∆, ⊃, @, ≥, !, +, ⌷, ∣, ⊃, ⍴, ⍱, ⍪, ⍋, ⍙, %, ⊆, ∣, ⌹, |, &, ], ⌸, ., ⌽, ', ⊇, ⍨, ×, ↓, ≠, ×, @, ⊆, ), /, √, !, ⊇, ⍤, ), ∪, ~, ⍛, £, ↑, ○, `, ≥, ⌺, (, ¯, ≡, }, ⌈, ⊆, ⍀, !, ⌿, ⍴, /, ⌿, ÷, *, ·, #, ⎕, ÷, ⊆, ., £, ,, ⊖, ⌈, ⌊, ∨, ⌿, ⍕, ], ?, ↓, ÷, ≥, ∊, ⌿, ⍷, ⌈, ∆, +, ⍟, ⌽, ×, ⍪, ⍠, ⍢, ⊆, ÷, ⍞, *, >, ∨, [, ∆, ⍀, ⍫, _, ', @, +, ´, {, [, ≥, ∨, `, ⌶, ⍋, *, ⌽, ∆, ⌺, ;, ∘, ⊂, ⊥, ⍒, ∩, \", ≡, ⍥, ≤, ., ⍒, ∨, ↑, {, ~, `, ⊂, ⍣, ⌿, √, *, $, ∊, ⌸, ≥, £, ⍨, <, ⍷, ⍛, +, ⊤, ⌹, ⊇, ~, ⊖, ⍕, ≡, ⍞, ⍫, $, ⍨, ⍳, ⍟, ≡, ~, ⊃, £, ., ∘, ⌈, |, ⍟, ⍙, ⊆, ´, /, `, !, _, (, \", ⌶, ⍢, ⍒, -, <, ⍳, ⍕, ←, ≤, ], ⍸, ⍱, <, ], ∣, ⍫, ⍀, ⌶, ,, >, ⍠, ↑, ∘, |, ⊆, ⍤, ⌸, -, ⌺, ∧, +, :, ≡, ⍨, ∩, ⍫, ○, ∆, ⊣, ⍪, ⊥, ], ⌺, ⍥, (, ⌹, ↑, ⊣, ∧, ×, ⊢, ⍠, ∧, ⍟, ⍸, ∩, ~, $, ⌷, ⍕, ¨, ⍸, ≤, ⌷, _, ], ~, ⍲, ∊, →, →, >, ⌽, ^, ,, ↑, ¯, ⍠, ⊢, ∧, ⍴, ·, ⍙, ∆, }, ≤, {, ⊤, ≤, }, ⌶, }, ⌹, ÷, ←, ∪, ·, `, #, ⊆, ⊆, ≥, ¯, ?, ⊣, ', £, ^, ≡, ?, !, ⊂, ⍷, ∣, ⌺, ., ≢, +, ⊂, ⌸, ⍕, !, :, ⊤, ⊃, √, √, ], ', &, ⍱, ⎕, ⍪, ∩, ;, ⊂, !, $, ⊂, ≡, ⍪, ⌈, `, ^, ⌊, ⍣, ⊥, ∨, ⊂, ⍪, ⍲, ⍳, ⎕, ⌺, ), ∨, ⍙, ⍙, #, ⌺, ), ⍛, ⍟, ≥, (, ⍨, ⍴, |, ⊆, ∘, -, ⍪, ⊢, _, :, ⌺, ⍲, £, ⍳, ⌺, ], ×, ⍒, ↑, +, ⍋, #, ⍲, ~, ⌺, ⌽, ¨, #, ·, ⌈, ⍉, ⊣, ⊣, ⍸, [, [, ⌽, ~, ⊢, {, ⍨, ⊢, :, |, $, ,, ⍋, ⊆, ×, ∩, ⍙, ←, ∆, ⍉, ⍉, ´, <, %, ⌸, ⍠, ⌹, \", ⊢, ∘, ∪, `, ⊃, ?, (, ⍙, ', ⍸, (, ⌈, ⊢, ≤, ⍴, ⊇, @, \", ', ⌶, ^, }, {, ⍥, ↑, ⊇, %, {, ∘, *, ⊖, ≤, _, @, ≠, /, ´, ⌷, ⍣, ⍠, #, [, ´, ⍳, ⍛, ;, ∆, ·, ⍀, ⍕, ⊢, ,, /, $, ⍠, `, ⍳, ⌿, ⍕, `, ○, %, ÷, %, ←, ⊇, ;, ⍒, ·, ⍣, +, ⌺, ∩, ⍪, #, ⌺, ], ⌺, ⍠, ≤, ↑, |, ⎕, *, ≥, ⊆, ×, ⍋, ≥, ÷, ⍫, +, ~, ←, ⊂, ⊇, +, /, ⍪, ≢, ⍢, ⍴, ≤, ×, ⍉, *, ⍫, ∆, $, &, ⍞, ⊃, ∣, (, ≡, ^, #, %, ¨, ⍟, ⌹, ≡, ⌈, }, ≠, √, ⍫, ?, _, ⍛, ∘, ≢, ⌽, ↑, ?, /, ´, ], |, ⍠, ;, ⍪, *, ⍎, ⌶, ⊃, ~, ⍀, [, `, →, ⍲, →, ↑, ←, →, ∨, :, ↑, ⌶, ←, √, ≠, ÷, ∨, ⍉, #, ⌺, ), ⌺, ;, ´, ⍥, &, ], ⍢, /, %, ⍒, ⌶, ⍴, →, ⌊, √, ⍸, ⍕, ⊃, <, +, +, =, ⍱, ⎕, ⍟, ⍙, `, ⍠, ⊣, ⍋, ´, %, ⍛, [, ⍋, ≠, ∊, [, /, ⍪, ∣, ⍋, ⊂, ≢, ⍙, ⍤, ∧, <, ⌈, ⍠, ⍉, /, `, [, ', √, ⌿, ¨, ⍟, ⎕, ⍞, ⍲, #, ∧, ⍞, ∘, ⍢, [, ⊆, ∪, ⍙, ⍠, →, ⊢, ⍋, ⌷, (, ;, ⍢, /, [, <, \", !, ⊥, ⍀, ⊣, (, ´, ], ≢, /, }, ⍀, >, ∪, ∨, ∩, ≠, !, ⍤, \", ⍷, [, <, ∧, :, ∧, ·, ⍙, ·, ⊢, ~, ⌶, ⍕, ´, ∨, ⊖, ≡, ⍢, >, ¨, ⌷, ?, -, ⊣, ⍸, ], ⍷, <, ⊣, ∨, _, +, ⍨, ↑, ~, ×, ⍞, ←, ⍢, ⎕, ⌈, ⍉, ⊂, ≤, ~, ⌿, }, ⍴, ○, →, ⍉, ⍥, ;, %, ⊢, ⍎, ⍫, ·, :, ⍱, ○, ⊇, ↑, ∊, ⍉, ⌿, ∊, ≥, ∨, ⍱, ⍲, ⍕, ?, ?, ⌸, ¨, ←, #, >, %, ⊆, ∣, ×, {, ∣, ⍠, ⊖, #, ⍫, `, ⍫, ⍕, ⍤, (, ≢, ∘, ⍳, /, ⍲, (, ^, ⍙, ⍲, ⍴, ⍢, ×, ⍨, _, ¯, ', ;, ⌽, /, ?, ~, ⍙, #, >, ⍙, ^, ⌶, |, ↓, ⍎, ⊖, ⍠, ⌊, ⌽, ·, }, ⍪, ?, ^, ⍷, ⊖, [, %, -, →, ?, }, $, |, ⌶, :, >, #, ∊, ⍒, ⌈, ,, &, ÷, ⊥, ⊣, ~, ,, ⍎, ∣, ∘, ,, ~, ⊇, ←, >, [, √, ), ⍠, ≥, \", ⍷, =, ⌸, ⍋, ⍸, $, ⌸, ⍢, ⍳, ∣, ⊃, ⌈, ¯, ⍪, ⊤, =, ⍠, ⊇, {, ', ¨, ⍸, ⌈, {, ·, ⍙, <, }, ⌸, ∨, ^, ≠, ⍴, |, ], ÷, ⍳, ~, ⍛, ⍨, ∆, ∊, &, ⌽, ⌷, ⌺, ·, {, }, ⊥, ⍒, ⍣, ≢, ⍱, (, ⎕, ⌹, ¨, ⌷, ⊤, ∧, ¨, ⍀, ⊥, ', <, ⊥, ≠, ?, |, ∩, ≤, ~, -, }, #, ⍕, +, ⌿, ⌸, ⍳, ∩, (, ≥, ⌽, ¯, ⊤, ⍕, ⍲, ⍥, ⍨, ⊣, ⍉, ∆, ⍣, -, #, ≡, ⌷, ,, -, ⍞, ∪, ⌈, ·, ,, [, ∧, ), ), ^, ⍷, ⍴, $, ≢, ⎕, ⍴, ⍀, ≢, ⍪, _, ⍋, &, -, ⊤, ⍫, %, √, *, ⍲, ⍎, ⍤, >, ⍸, ∘, ⍕, ∘, ⍕, ⍳, ;, ÷, ∩, ⍉, ?, `, ], ∘, %, ⊆, ⍠, ', ∪, *, →, ⍤, ∘, =, ∪, +, ⍋, ⍟, ), !, ⍳, ⌈, ⍠, →, ∩, :, ⍟, √, ⊤, ⍟, ⊖, ×, ⌶, ↓, ≢, ←, =, ÷, #, `, >, {, ∊, #, ⌊, ○, ⊃, ∆, ≢, ⍞, ´, ∣, ∆, (, ⊂, {, ⍫, ⌸, ≤, ⍱, ⊤, ∣, ⍣, ⍕, ⌹, ~, -, ⍎, =, ⍸, ⍟, ⍞, ⍱, ⍟, ,, _, ⍀, ⌹, ⌷, /, ○, ∊, ¨, ´, ⊆, ⍴, ≡, ⌷, #, ⍎, ', ⍀, ⍷, ,, ↓, ⊂, ], ¨, ⊥, $, /, ⍸, ≤, `, {, ⍸, ), ⌈, ≢, ○, ⌶, ⍣, ⍱, ⊂, %, ∩, ○, ∣, &, ,, ⌸, ×, ⍢, ∊, ⌽, ≤, ', ⊆, ∨, ¯, ?, ⎕, ⍋, ´, <, ≡, ⍲, -, ∧, ∊, ;, {, ≠, ), ∧, =, ∪, ⌶, ⎕, <, ⌿, ≡, }, ´, ⌽, ⍤, ⌊, }, ⍞, ⌊, ), (, ⍎, ⊢, ≡, %, &, ⍸, ≡, ⊇, ≥, +, ^, ;, ⌽, $, ↓, ⊢, ⍲, ⍸, ≡, ↓, ∘, ≠, *, /, ⌿, ·, ←, ⊣, $, ⍲, ⍤, #, ⍛, ⍙, ∧, √, ⍷, ⍱, ⊖, {, ', ⊢, ⍫, ⍫, ≢, [, ∣, ¨, ⌷, ∣, ≤, ⍸, -, ⌸, &, /, ⊂, ⌈, ∪, ⌈, ⍀, ), &, ⍷, ⍫, ⍀, ⍪, _, ´, ∆, [, }, ⊢, -, ), ⊇, ⌷, ), ⍸, ∣, ), ⊤, %, ∨, ⊃, ≤, ∪, >, ^, ⌶, ⍤, ⍸, ⊂, :, &, ~, ⊃, ·, ⍴, $, ⊥, ∩, ⌊, ⎕, ≢, ≠, ⊇, ], ∨, ;, ∘, ⊖, +, ?, ∩, ⊢, ⊥, ∣, ⍪, ⌿, →, ⎕, ⍟, +, →, ∆, ⊖, ⌿, ⌊, !, {, ⍞, ⊥, ⍠, ~, ¨, ↓, ⊂, :, ⊤, ⍋, ∨, +, -, ], ⊃, ,, ⍞, ^, ⊃, ⌷, `, :, ⊃, ⊢, ∊, ∘, #, ⊣, <, ∩, $, \", >, ⍞, [, ⊖, ·, ⍨, [, {, -, ⊤, ⍨, ,, [, ⌈, ≡, =, ⊢, &, ⍤, ⌹, ⍫, ,, ⍕, ⌿, $, ⍴, ⍷, ∊, ·, ⊃, #, ⍣, ⍋, ), ¯, ⍲, √, ], \", ⍴, ⍴, ÷, ⍟, ⊇, ⍕, :, ⍣, ^, ´, ≠, ⌸, ⍲, <, ↑, ⍤, ;, ⍤, ;, ⍞, ⌈, ⍠, ], }, ≢, ⌽, ⍀, ⍠, ⌊, +, ⍳, ∧, ⎕, √, ∆, _, ⊆, ¯, ¯, ⍲, ], ⍞, ∪, /, [, $, ≢, _, &, ´, =, ≡, ⌷, ⌈, :, ⊆, %, ⌶, ∘, ⍞, ⍟, `, ⍋, ⎕, :, /, ⌶, ⍱, !, }, ⍪, &, ∪, #, ⍋, ⌊, :, ⍠, >, ⍫, ⍳, ⌷, ⊣, ;, ⊢, ⊂, ⍸, ⌸, ⍟, ∆, ⊤, `, ⍲, ⍪, ~, ∣, +, ⍋, ∧, <, !, ⊢, ⎕, ⍣, :, ⍲, _, ⌸, ⊇, ○, (, =, ⍀, ÷, >, ⍫, [, ↓, ⊂, ∆, ⍣, ÷, ~, ≢, ⍫, ^, =, ⊤, ⍲, ⍷, ∨, ⍪, ⌶, ⊢, ⍨, ^, ≠, :, ⍱, ⍲, ⍳, =, ^, ⌷, ≡, ⍟, ≢, ⍨, ⍛, ⍛, ∨, ⍷, ⍴, ⊣, ⍢, ≤, ⌶, ⌶, ∣, ], ≠, ∩, ⊢, ?, ⍣, &, ?, =, ⍱, ↑, ⊆, `, ∧, √, ⊥, ⍀, +, ⍴, ⍎, ⊆, ⍱, ⍎, ^, ⍎, ⍣, ⍷, ⍫, :, ), >, -, ⍠, ⍴, ⊂, ?, ^, ⍟, }, ⍠, ≤, ⍎, ↑, &, ⍥, *, ⍀, $, ∆, ○, <, ⍠, ≤, ⍢, ⍪, <, ⍫, ⌷, ;, ,, ⊇, &, ∪, (, ∊, ⊤, `, ⍠, ≡, ⍸, ∆, ⍸, ⌹, ⍤, <, ⊢, >, ⊥, ⍟, ↓, ⍢, ∊, ∪, ), ↓, ≢, &, $, :, ⍛, $, ⍥, ⍀, ≤, ∆, ∆, ⊥, ⌹, ○, ?, `, ∩, <, ∩, ⌷, #, ≢, ○, ⍲, ≡, ⍢, ⍥, :, ⊤, `, ⊇, ^, ⌊, ⍠, `, ⍎, :, ≠, ⍢, √, \", ⍸, ⊂, ⍱, ≤, ⍛, /, ⍎, ⊥, `, $, ⍸, ∪, ,, ^, ∘, ⍤, ⍋, ⊢, ⊖, ∊, ⍪, ⍀, ⍨, ⊢, ÷, ∪, $, \", (, ⊇, ⍢, \", ⌹, ⌷, ⍛, ⊥, ⌹, ⍨, ÷, ⊂, ⍨, ⍛, ⍱, ⌷, ⊇, ⍠, ∪, ≠, ⍪, ⍥, ≢, ⍢, ∪, ∪, ≢, ∧, ∧, ∨, ∨, ⌷, ⍪, ⌹, #, ⍢, ⊖, &, ⍠, &, ⍢, ⍸, ⍨, ⌹, ⊥, ⊖, ⌹, ⍨, ⊖, &, ⍪, #, +, ⍢, #, ⍛, ⍢, +, &\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(to_keep_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10985, 10985)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = to_keep_file_paths\n",
    "labels = to_keep_labels\n",
    "len(image_paths), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stratified_split(file_paths, labels, test_size=0.15, val_size=0.15, min_val_samples=1, random_state=42):\n",
    "    \"\"\"\n",
    "    Stratified split with minimum samples per class in all splits\n",
    "    \n",
    "    Args:\n",
    "        file_paths: List of lists of paths - [[class1_paths], [class2_paths], ...]\n",
    "        labels: List of class labels corresponding to file_paths\n",
    "        test_size: Proportion for test split\n",
    "        val_size: Proportion for validation split (relative to remaining after test)\n",
    "        min_samples: Minimum samples per class in each split (default=1)\n",
    "    \"\"\"\n",
    "    # Flatten structure and create label array\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(file_paths)\n",
    "    y = np.array(labels)\n",
    "    unique_classes = np.unique(y)\n",
    "    \n",
    "    # First split: test with min samples per class\n",
    "    test_indices = []\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        n_test = int(test_size * len(cls_indices))\n",
    "        test_indices.extend(np.random.choice(cls_indices, n_test, replace=False))\n",
    "    \n",
    "    # Remaining indices for train/val\n",
    "    remaining_mask = ~np.isin(np.arange(len(X)), test_indices)\n",
    "    X_remaining, y_remaining = X[remaining_mask], y[remaining_mask]\n",
    "    \n",
    "    # Second split: validation from remaining\n",
    "    val_indices = []\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y_remaining == cls)[0]\n",
    "        n_val = max(min_val_samples, int(val_size * len(cls_indices)))\n",
    "        val_indices.extend(np.random.choice(cls_indices, n_val, replace=False))\n",
    "    \n",
    "    # Final indices\n",
    "    train_mask = ~np.isin(np.arange(len(X_remaining)), val_indices)\n",
    "    return (\n",
    "        X_remaining[train_mask].tolist(), y_remaining[train_mask].tolist(),  # Train\n",
    "        X_remaining[val_indices].tolist(), y_remaining[val_indices].tolist(),  # Val\n",
    "        X[test_indices].tolist(), y[test_indices].tolist()  # Test\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (9464)\n",
      "Val   (1521)\n",
      "Test  (0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_x, train_y, val_x, val_y, test_x, test_y = stratified_split(image_paths, labels, val_size=0.15, min_val_samples=1, test_size=0.00)\n",
    "\n",
    "print(f\"Train ({len(train_x)})\")\n",
    "print(f\"Val   ({len(val_x)})\")\n",
    "print(f\"Test  ({len(test_x)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = sorted(set(to_keep_labels))\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'!','\"','#','$','%','&',''','(',')','*','+',',','-','.','/','0','1','2','3','4','5','6','7','8','9',':',';','<','=','>','?','@','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','[','\\',']','^','_','`','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','{','|','}','~','£','¨','¯','´','·','×','÷','←','↑','→','↓','∆','∇','∊','∘','√','∣','∧','∨','∩','∪','≠','≡','≢','≤','≥','⊂','⊃','⊆','⊇','⊖','⊢','⊣','⊤','⊥','⋄','⌈','⌊','⌶','⌷','⌸','⌹','⌺','⌽','⌿','⍀','⍉','⍋','⍎','⍒','⍕','⍙','⍛','⍝','⍞','⍟','⍠','⍢','⍣','⍤','⍥','⍨','⍪','⍫','⍬','⍱','⍲','⍳','⍴','⍵','⍷','⍸','⍺','⎕','○'\n"
     ]
    }
   ],
   "source": [
    "print(','.join([\"\\'\" + str(x) + \"\\'\" for x in alphabet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\",\"\"\",\"#\",\"$\",\"%\",\"&\",\"\\'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\"`\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\",\"{\",\"|\",\"}\",\"~\",\"£\",\"¨\",\"¯\",\"´\",\"·\",\"×\",\"÷\",\"←\",\"↑\",\"→\",\"↓\",\"∆\",\"∇\",\"∊\",\"∘\",\"√\",\"∣\",\"∧\",\"∨\",\"∩\",\"∪\",\"≠\",\"≡\",\"≢\",\"≤\",\"≥\",\"⊂\",\"⊃\",\"⊆\",\"⊇\",\"⊖\",\"⊢\",\"⊣\",\"⊤\",\"⊥\",\"⋄\",\"⌈\",\"⌊\",\"⌶\",\"⌷\",\"⌸\",\"⌹\",\"⌺\",\"⌽\",\"⌿\",\"⍀\",\"⍉\",\"⍋\",\"⍎\",\"⍒\",\"⍕\",\"⍙\",\"⍛\",\"⍝\",\"⍞\",\"⍟\",\"⍠\",\"⍢\",\"⍣\",\"⍤\",\"⍥\",\"⍨\",\"⍪\",\"⍫\",\"⍬\",\"⍱\",\"⍲\",\"⍳\",\"⍴\",\"⍵\",\"⍷\",\"⍸\",\"⍺\",\"⎕\",\"○]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"[\" + \"\\\",\\\"\".join(alphabet) + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~£¨¯´·×÷←↑→↓∆∇∊∘√∣∧∨∩∪≠≡≢≤≥⊂⊃⊆⊇⊖⊢⊣⊤⊥⋄⌈⌊⌶⌷⌸⌹⌺⌽⌿⍀⍉⍋⍎⍒⍕⍙⍛⍝⍞⍟⍠⍢⍣⍤⍥⍨⍪⍫⍬⍱⍲⍳⍴⍵⍷⍸⍺⎕○'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\".join(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=train_x, #list(image_paths[:split_index]) + to_add_file_paths,\n",
    "    labels=train_y, #list(labels[:split_index]) + to_add_labels,\n",
    "    all_label_classes=alphabet,\n",
    "    rotation_limit=0.05,\n",
    "    translation_limit=0.2,\n",
    "    skew_limit=0.025,\n",
    "    zoom_change=1.2,\n",
    "    min_zoom=0.8,\n",
    "    thicken_sigma=-4,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "val_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=val_x,\n",
    "    labels=val_y,\n",
    "    all_label_classes=alphabet,\n",
    "    rotation_limit=0.0,\n",
    "    translation_limit=0.0,\n",
    "    skew_limit=0.00,\n",
    "    zoom_change=0.0,\n",
    "    min_zoom=1.0,\n",
    "    thicken_sigma=0.0,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for i, (im, lab) in enumerate(train_char_dataset):\n",
    "    \n",
    "    if i == 5:\n",
    "            \n",
    "        plt.imshow(\n",
    "            rearrange(im, \"1 h w -> h w\")*255, \n",
    "            cmap=\"gray\"\n",
    "        )\n",
    "        plt.show()\n",
    "        print(lab)\n",
    "        print(alphabet[np.argmax(lab)])\n",
    "    if i > 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function to pad sequences to the same length.\n",
    "    \"\"\"\n",
    "    # Separate images and labels\n",
    "    images, labels = zip(*batch)\n",
    "\n",
    "    # Pad image sequences\n",
    "    images_padded = pad_sequence(images, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    # Pad label sequences\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    return images_padded, labels_padded\n",
    "\n",
    "train_dataloader: DataLoader = DataLoader(\n",
    "    train_char_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_dataloader: DataLoader = DataLoader(\n",
    "    val_char_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Pretrained CNN Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.0.weight\n",
      "Loaded: encoder_conv_blocks.1.0.bias\n",
      "Loaded: encoder_conv_blocks.1.2.weight\n",
      "Loaded: encoder_conv_blocks.1.2.bias\n",
      "Loaded: encoder_conv_blocks.1.2.running_mean\n",
      "Loaded: encoder_conv_blocks.1.2.running_var\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.4.weight\n",
      "Loaded: encoder_conv_blocks.1.4.bias\n",
      "Loaded: encoder_conv_blocks.1.6.weight\n",
      "Loaded: encoder_conv_blocks.1.6.bias\n",
      "Loaded: encoder_conv_blocks.1.6.running_mean\n",
      "Loaded: encoder_conv_blocks.1.6.running_var\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.0.weight\n",
      "Loaded: encoder_conv_blocks.2.0.bias\n",
      "Loaded: encoder_conv_blocks.2.2.weight\n",
      "Loaded: encoder_conv_blocks.2.2.bias\n",
      "Loaded: encoder_conv_blocks.2.2.running_mean\n",
      "Loaded: encoder_conv_blocks.2.2.running_var\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.4.weight\n",
      "Loaded: encoder_conv_blocks.2.4.bias\n",
      "Loaded: encoder_conv_blocks.2.6.weight\n",
      "Loaded: encoder_conv_blocks.2.6.bias\n",
      "Loaded: encoder_conv_blocks.2.6.running_mean\n",
      "Loaded: encoder_conv_blocks.2.6.running_var\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.0.weight\n",
      "Loaded: encoder_conv_blocks.3.0.bias\n",
      "Loaded: encoder_conv_blocks.3.2.weight\n",
      "Loaded: encoder_conv_blocks.3.2.bias\n",
      "Loaded: encoder_conv_blocks.3.2.running_mean\n",
      "Loaded: encoder_conv_blocks.3.2.running_var\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.4.weight\n",
      "Loaded: encoder_conv_blocks.3.4.bias\n",
      "Loaded: encoder_conv_blocks.3.6.weight\n",
      "Loaded: encoder_conv_blocks.3.6.bias\n",
      "Loaded: encoder_conv_blocks.3.6.running_mean\n",
      "Loaded: encoder_conv_blocks.3.6.running_var\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Loaded: fully_connected_blocks.0.0.weight\n",
      "Loaded: fully_connected_blocks.0.0.bias\n",
      "Loaded: fully_connected_blocks.1.0.weight\n",
      "Loaded: fully_connected_blocks.1.0.bias\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 256]                  --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "├─Sequential: 1-2                        [1, 512]                  --\n",
      "│    └─Flatten: 2-5                      [1, 512]                  --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-6                   [1, 256]                  --\n",
      "│    │    └─Linear: 3-33                 [1, 256]                  131,328\n",
      "│    │    └─Dropout: 3-34                [1, 256]                  --\n",
      "│    │    └─LeakyReLU: 3-35              [1, 256]                  --\n",
      "│    └─Sequential: 2-7                   [1, 256]                  --\n",
      "│    │    └─Linear: 3-36                 [1, 256]                  65,792\n",
      "==========================================================================================\n",
      "Total params: 250,928\n",
      "Trainable params: 250,928\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 14.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.17\n",
      "Params size (MB): 1.00\n",
      "Estimated Total Size (MB): 3.20\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "cnn_model: nn.Module = AllCNN2D(\n",
    "    **{\n",
    "        \"conv_features\": (1, 16, 32, 32, 32),\n",
    "        \"fully_connected_features\": (256, 256),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": DEVICE,\n",
    "        \"conv_dropout\": 0.05,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": LOAD_CHECKPOINT,\n",
    "        \"use_lora\": False,\n",
    "        \"frozen_layer_prefixes\": [],\n",
    "        \"lora_configs\": [\n",
    "            {\n",
    "                \"name\": \"NA\",\n",
    "                \"rank\": 128,\n",
    "                \"alpha\": 128\n",
    "            }\n",
    "        ],\n",
    "        \"default_lora_name\": \"NA\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze Non-LoRA Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unfrozen] encoder_conv_blocks.0.0.weight\n",
      "[unfrozen] encoder_conv_blocks.0.0.bias\n",
      "[unfrozen] encoder_conv_blocks.0.2.weight\n",
      "[unfrozen] encoder_conv_blocks.0.2.bias\n",
      "[unfrozen] encoder_conv_blocks.0.4.weight\n",
      "[unfrozen] encoder_conv_blocks.0.4.bias\n",
      "[unfrozen] encoder_conv_blocks.0.6.weight\n",
      "[unfrozen] encoder_conv_blocks.0.6.bias\n",
      "[unfrozen] encoder_conv_blocks.1.0.weight\n",
      "[unfrozen] encoder_conv_blocks.1.0.bias\n",
      "[unfrozen] encoder_conv_blocks.1.2.weight\n",
      "[unfrozen] encoder_conv_blocks.1.2.bias\n",
      "[unfrozen] encoder_conv_blocks.1.4.weight\n",
      "[unfrozen] encoder_conv_blocks.1.4.bias\n",
      "[unfrozen] encoder_conv_blocks.1.6.weight\n",
      "[unfrozen] encoder_conv_blocks.1.6.bias\n",
      "[unfrozen] encoder_conv_blocks.2.0.weight\n",
      "[unfrozen] encoder_conv_blocks.2.0.bias\n",
      "[unfrozen] encoder_conv_blocks.2.2.weight\n",
      "[unfrozen] encoder_conv_blocks.2.2.bias\n",
      "[unfrozen] encoder_conv_blocks.2.4.weight\n",
      "[unfrozen] encoder_conv_blocks.2.4.bias\n",
      "[unfrozen] encoder_conv_blocks.2.6.weight\n",
      "[unfrozen] encoder_conv_blocks.2.6.bias\n",
      "[unfrozen] encoder_conv_blocks.3.0.weight\n",
      "[unfrozen] encoder_conv_blocks.3.0.bias\n",
      "[unfrozen] encoder_conv_blocks.3.2.weight\n",
      "[unfrozen] encoder_conv_blocks.3.2.bias\n",
      "[unfrozen] encoder_conv_blocks.3.4.weight\n",
      "[unfrozen] encoder_conv_blocks.3.4.bias\n",
      "[unfrozen] encoder_conv_blocks.3.6.weight\n",
      "[unfrozen] encoder_conv_blocks.3.6.bias\n",
      "[unfrozen] fully_connected_blocks.0.0.weight\n",
      "[unfrozen] fully_connected_blocks.0.0.bias\n",
      "[unfrozen] fully_connected_blocks.1.0.weight\n",
      "[unfrozen] fully_connected_blocks.1.0.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in cnn_model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        print(f\"[frozen]   {name}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"[unfrozen] {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(model):\n",
    "    l2_reg = 0.0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            l2_reg += torch.sum(param**2)\n",
    "    return l2_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "optim: AdamW = AdamW(\n",
    "    cnn_model.parameters(),\n",
    "    lr = 0.00001,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler: torch.optim.lr_scheduler.LRScheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optim,\n",
    "    T_0=20,\n",
    "    T_mult=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9528, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_regularization(cnn_model) * 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trainable] encoder_conv_blocks.0.0.weight\n",
      "[trainable] encoder_conv_blocks.0.0.bias\n",
      "[trainable] encoder_conv_blocks.0.2.weight\n",
      "[trainable] encoder_conv_blocks.0.2.bias\n",
      "[trainable] encoder_conv_blocks.0.4.weight\n",
      "[trainable] encoder_conv_blocks.0.4.bias\n",
      "[trainable] encoder_conv_blocks.0.6.weight\n",
      "[trainable] encoder_conv_blocks.0.6.bias\n",
      "[trainable] encoder_conv_blocks.1.0.weight\n",
      "[trainable] encoder_conv_blocks.1.0.bias\n",
      "[trainable] encoder_conv_blocks.1.2.weight\n",
      "[trainable] encoder_conv_blocks.1.2.bias\n",
      "[trainable] encoder_conv_blocks.1.4.weight\n",
      "[trainable] encoder_conv_blocks.1.4.bias\n",
      "[trainable] encoder_conv_blocks.1.6.weight\n",
      "[trainable] encoder_conv_blocks.1.6.bias\n",
      "[trainable] encoder_conv_blocks.2.0.weight\n",
      "[trainable] encoder_conv_blocks.2.0.bias\n",
      "[trainable] encoder_conv_blocks.2.2.weight\n",
      "[trainable] encoder_conv_blocks.2.2.bias\n",
      "[trainable] encoder_conv_blocks.2.4.weight\n",
      "[trainable] encoder_conv_blocks.2.4.bias\n",
      "[trainable] encoder_conv_blocks.2.6.weight\n",
      "[trainable] encoder_conv_blocks.2.6.bias\n",
      "[trainable] encoder_conv_blocks.3.0.weight\n",
      "[trainable] encoder_conv_blocks.3.0.bias\n",
      "[trainable] encoder_conv_blocks.3.2.weight\n",
      "[trainable] encoder_conv_blocks.3.2.bias\n",
      "[trainable] encoder_conv_blocks.3.4.weight\n",
      "[trainable] encoder_conv_blocks.3.4.bias\n",
      "[trainable] encoder_conv_blocks.3.6.weight\n",
      "[trainable] encoder_conv_blocks.3.6.bias\n",
      "[trainable] fully_connected_blocks.0.0.weight\n",
      "[trainable] fully_connected_blocks.0.0.bias\n",
      "[trainable] fully_connected_blocks.1.0.weight\n",
      "[trainable] fully_connected_blocks.1.0.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in cnn_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"[trainable] {name}\")\n",
    "        #print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.allcnn2d import LoRALinearWrapper, LoRAConv2DWrapper\n",
    "\n",
    "\n",
    "for name, module in cnn_model.named_modules():\n",
    "    if isinstance(module, LoRALinearWrapper) or isinstance(module, LoRAConv2DWrapper):\n",
    "        print(f\"{name}: adapters={list(module.lora_adapters.keys())}, scalings={module.active_scalings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m train_samples: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     27\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Training\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     29\u001b[0m     X: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     30\u001b[0m     y: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn_lora\\dataset\\character_dataset.py:136\u001b[0m, in \u001b[0;36mCharImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    133\u001b[0m image: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mfloat32] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_images[index]\n\u001b[0;32m    134\u001b[0m one_hot_label: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mfloat32] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_labels[index]\n\u001b[1;32m--> 136\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_random_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, one_hot_label\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn_lora\\dataset\\character_dataset.py:228\u001b[0m, in \u001b[0;36mCharImageDataset._apply_random_transformations\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# Apply GaussianBlur\u001b[39;00m\n\u001b[0;32m    221\u001b[0m gaussian_blur \u001b[38;5;241m=\u001b[39m GaussianBlur(\n\u001b[0;32m    222\u001b[0m     kernel_size\u001b[38;5;241m=\u001b[39mkernel_size,\n\u001b[0;32m    223\u001b[0m     sigma\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m     )\n\u001b[0;32m    227\u001b[0m )\n\u001b[1;32m--> 228\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Adjust for thickening or thinning\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m thicken_thinning_sigma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;66;03m# Thickening: Increase the character's size by lowering the threshold\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:1812\u001b[0m, in \u001b[0;36mGaussianBlur.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;124;03m    img (PIL Image or Tensor): image to be blurred.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1809\u001b[0m \u001b[38;5;124;03m    PIL Image or Tensor: Gaussian blurred image\u001b[39;00m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1811\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m-> 1812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:1380\u001b[0m, in \u001b[0;36mgaussian_blur\u001b[1;34m(img, kernel_size, sigma)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be PIL Image or Tensor. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1378\u001b[0m     t_img \u001b[38;5;241m=\u001b[39m pil_to_tensor(img)\n\u001b[1;32m-> 1380\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1383\u001b[0m     output \u001b[38;5;241m=\u001b[39m to_pil_image(output, mode\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mmode)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:761\u001b[0m, in \u001b[0;36mgaussian_blur\u001b[1;34m(img, kernel_size, sigma)\u001b[0m\n\u001b[0;32m    759\u001b[0m padding \u001b[38;5;241m=\u001b[39m [kernel_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    760\u001b[0m img \u001b[38;5;241m=\u001b[39m torch_pad(img, padding, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 761\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    763\u001b[0m img \u001b[38;5;241m=\u001b[39m _cast_squeeze_out(img, need_cast, need_squeeze, out_dtype)\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup\n",
    "\n",
    "\n",
    "SESSION_STARTTIME_STR = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "CSV_LOG_FILE = f\"{SESSION_STARTTIME_STR}__{MODEL_NAME}__training_metric.csv\"\n",
    "\n",
    "# Write CSV header if file doesn't exist\n",
    "if not os.path.isfile(CSV_LOG_FILE):\n",
    "    with open(CSV_LOG_FILE, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\n",
    "            \"epoch\",\n",
    "            \"train_loss\", \"train_l1\", \"train_mse\", \"train_acc\",\n",
    "            \"val_loss\", \"val_l1\", \"val_mse\", \"val_acc\"\n",
    "        ])\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    train_loss_total: float = 0\n",
    "    train_l1_total: float = 0\n",
    "    train_mse_total: float = 0\n",
    "    train_correct: int = 0\n",
    "    train_samples: int = 0\n",
    "\n",
    "    train_loader = tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch+1} - Training\", leave=False)\n",
    "    for X, y in train_loader:\n",
    "        X: torch.Tensor = X.to(DEVICE)\n",
    "        y: torch.Tensor = y.to(DEVICE)\n",
    "\n",
    "        y_pred: torch.Tensor = cnn_model(X)\n",
    "\n",
    "        y_padded: torch.Tensor = F.pad(y, (0, y_pred.shape[1] - y.shape[1]))\n",
    "\n",
    "        loss: torch.Tensor = F.cross_entropy(y_pred, y.argmax(dim=1), reduction='sum')\n",
    "        l1_loss: torch.Tensor = F.l1_loss(sigmoid(y_pred), y_padded, reduction='sum')\n",
    "        mse_loss: torch.Tensor = F.mse_loss(sigmoid(y_pred), y_padded, reduction='sum')\n",
    "\n",
    "        \n",
    "        reg = optim.param_groups[0][\"weight_decay\"] * l2_regularization(cnn_model) \n",
    "\n",
    "        \n",
    "        loss = loss / X.size(0) + reg\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        \n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "        train_loss_total += loss.item() * X.size(0)\n",
    "        train_l1_total += l1_loss.item()\n",
    "        train_mse_total += mse_loss.item()\n",
    "        \n",
    "        \n",
    "        preds = y_pred.argmax(dim=1)\n",
    "        targets = y.argmax(dim=1).long()\n",
    "        train_correct += (preds == targets).sum().item()\n",
    "        train_samples += X.size(0)\n",
    "\n",
    "        scheduler.step(epoch + train_samples / len(train_dataloader.dataset))\n",
    "\n",
    "        train_loader.set_postfix({\n",
    "            \"L2Reg\": f\"{reg:.4f}\",\n",
    "            \"Loss (Total)\": f\"{loss.item():.4f}\",\n",
    "            \"Loss (L1)\": f\"{l1_loss.item()/X.size(0):.4f}\",\n",
    "            \"Loss (MSE)\": f\"{mse_loss.item()/X.size(0):.4f}\"\n",
    "        })\n",
    "\n",
    "    # Validation\n",
    "    cnn_model.eval()\n",
    "    val_loss_total: float = 0\n",
    "    val_l1_total: float = 0\n",
    "    val_mse_total: float = 0\n",
    "    val_correct: int = 0\n",
    "    val_samples: int = 0\n",
    "\n",
    "    val_loader = tqdm.tqdm(val_dataloader, desc=f\"Epoch {epoch+1} - Validation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val: torch.Tensor = X_val.to(DEVICE)\n",
    "            y_val: torch.Tensor = y_val.to(DEVICE)\n",
    "\n",
    "            y_val_pred: torch.Tensor = cnn_model(X_val)\n",
    "            y_val_padded: torch.Tensor = F.pad(y_val, (0, y_val_pred.shape[1] - y_val.shape[1]))\n",
    "\n",
    "            val_loss: torch.Tensor = F.cross_entropy(y_val_pred, y_val.argmax(dim=1), reduction='sum')\n",
    "            val_l1: torch.Tensor = F.l1_loss(sigmoid(y_val_pred), y_val_padded, reduction='sum')\n",
    "            val_mse: torch.Tensor = F.mse_loss(sigmoid(y_val_pred), y_val_padded, reduction='sum')\n",
    "\n",
    "            val_loss_total += val_loss.item()\n",
    "            val_l1_total += val_l1.item()\n",
    "            val_mse_total += val_mse.item()\n",
    "\n",
    "            val_preds = y_val_pred.argmax(dim=1)\n",
    "            val_targets = y_val.argmax(dim=1).long()\n",
    "            val_correct += (val_preds == val_targets).sum().item()\n",
    "            val_samples += X_val.size(0)\n",
    "\n",
    "            val_loader.set_postfix({\n",
    "                \"Loss\": f\"{val_loss.item() / X_val.size(0):.4f}\",\n",
    "                \"L1\": f\"{val_l1.item() / X_val.size(0):.4f}\",\n",
    "                \"MSE\": f\"{val_mse.item() / X_val.size(0):.4f}\"\n",
    "            })\n",
    "    # Averages\n",
    "    train_loss_avg = train_loss_total / train_samples if train_samples > 0 else -1\n",
    "    train_l1_avg = train_l1_total / train_samples if train_samples > 0 else -1\n",
    "    train_mse_avg = train_mse_total / train_samples if train_samples > 0 else -1\n",
    "    train_acc = train_correct / train_samples if train_samples > 0 else -1\n",
    "\n",
    "    val_loss_avg = val_loss_total / val_samples if val_samples > 0 else -1\n",
    "    val_l1_avg = val_l1_total / val_samples if val_samples > 0 else -1\n",
    "    val_mse_avg = val_mse_total / val_samples if val_samples > 0 else -1\n",
    "    val_acc = val_correct / val_samples if val_samples > 0 else -1\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    with open(CSV_LOG_FILE, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\n",
    "            epoch + 1,\n",
    "            train_loss_avg, train_l1_avg, train_mse_avg, train_acc,\n",
    "            val_loss_avg, val_l1_avg, val_mse_avg, val_acc\n",
    "        ])\n",
    "\n",
    "    # Save model\n",
    "    model_filename = (\n",
    "        f\"{SESSION_STARTTIME_STR}__{MODEL_NAME}__\"\n",
    "        f\"Epoch{epoch+1}_\"\n",
    "        f\"tLoss{train_loss_avg:.5f}_tL1{train_l1_avg:.5f}_tMSE{train_mse_avg:.5f}_tAcc{train_acc:.5f}_\"\n",
    "        f\"vLoss{val_loss_avg:.5f}_vL1{val_l1_avg:.5f}_vMSE{val_mse_avg:.5f}_vAcc{val_acc:.5f}.pt\"\n",
    "    )\n",
    "    try:\n",
    "        print(\"Saving model\")\n",
    "        torch.save(cnn_model.state_dict(), model_filename)\n",
    "        print(model_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error skipping... {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder_conv_blocks.0.0.original.weight',\n",
       "              tensor([[[[ 0.2740,  0.2949,  0.1547],\n",
       "                        [-0.2473,  0.1952,  0.0204],\n",
       "                        [-0.2675,  0.1130,  0.1736]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2254, -0.3073,  0.2675],\n",
       "                        [-0.1299,  0.0767,  0.2313],\n",
       "                        [ 0.0535, -0.1954, -0.1494]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1853,  0.2320,  0.1130],\n",
       "                        [ 0.1332, -0.1923,  0.1763],\n",
       "                        [ 0.1956,  0.3145,  0.1967]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1237,  0.2570, -0.0376],\n",
       "                        [-0.1617,  0.1369,  0.1147],\n",
       "                        [ 0.1059, -0.1323,  0.2945]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0822, -0.3164,  0.1172],\n",
       "                        [-0.0444, -0.2802, -0.3248],\n",
       "                        [ 0.1585, -0.1598, -0.0478]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2215, -0.3077, -0.1132],\n",
       "                        [ 0.1584,  0.3051, -0.2879],\n",
       "                        [-0.0756, -0.2539,  0.2468]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0485,  0.2291,  0.0525],\n",
       "                        [ 0.1137,  0.2694, -0.2377],\n",
       "                        [ 0.2547,  0.1293,  0.3277]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2767,  0.2067, -0.2432],\n",
       "                        [-0.0620,  0.3267,  0.1080],\n",
       "                        [-0.1666,  0.2270, -0.0361]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3321,  0.0428, -0.0677],\n",
       "                        [-0.2624, -0.3182, -0.3021],\n",
       "                        [-0.1693, -0.1113, -0.2265]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3055,  0.0148,  0.1519],\n",
       "                        [-0.0391,  0.2853, -0.3239],\n",
       "                        [ 0.0462,  0.0657, -0.0307]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0198, -0.2685,  0.1583],\n",
       "                        [ 0.2726, -0.1221, -0.2841],\n",
       "                        [ 0.1155,  0.3312, -0.1069]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2196,  0.1378, -0.0630],\n",
       "                        [-0.1681, -0.2022,  0.2297],\n",
       "                        [ 0.3243,  0.2457,  0.1123]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2669,  0.1241,  0.0876],\n",
       "                        [ 0.3025,  0.1234,  0.0148],\n",
       "                        [-0.1498,  0.0813,  0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0579, -0.1749, -0.2864],\n",
       "                        [-0.0445, -0.2565, -0.0260],\n",
       "                        [ 0.0860,  0.2270, -0.2719]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0793,  0.2322,  0.0780],\n",
       "                        [-0.2256,  0.2590, -0.2806],\n",
       "                        [-0.2775,  0.0020,  0.0089]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1326,  0.1171, -0.2682],\n",
       "                        [-0.1023,  0.0957,  0.0722],\n",
       "                        [ 0.2547, -0.0195,  0.2282]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.0.original.bias',\n",
       "              tensor([ 0.1374,  0.2693,  0.1668,  0.2459,  0.2702, -0.2257, -0.0631, -0.1948,\n",
       "                       0.1776,  0.0589,  0.2904, -0.2657, -0.2081, -0.2792, -0.1413,  0.1979],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-1.2316e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5083e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8695e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9500e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1312e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0931e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7483e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.0659e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2492e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7330e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7963e-05]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.3223e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2045e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6161e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4063e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3837e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2828e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.4095e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5254e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9101e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0948e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5603e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0790e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2577e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6268e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1672e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.8136e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2740e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1664e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2024e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6474e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7134e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6136e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6311e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.8135e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7295e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4068e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9993e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.9236e-05]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7514e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8610e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.3322e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4840e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.3413e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7530e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3188e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.7264e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3191e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3945e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2658e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2647e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.1231e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.6776e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8827e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7003e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.4534e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3649e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2886e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2008e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1518e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2013e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5378e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5495e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1083e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2942e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4640e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4544e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4757e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6933e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.0819e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.3238e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0233e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0039e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0176e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4933e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1095e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3976e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5823e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3690e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9962e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1283e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.4834e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.4892e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3515e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0037e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5571e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1956e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.4704e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4661e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.3156e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5246e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6667e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6928e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.4180e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6915e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.5251e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5617e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3125e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8996e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9253e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2979e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0630e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4784e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.6671e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7187e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6956e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9372e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6639e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1159e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3212e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.9336e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.9629e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1302e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1630e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0817e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.0312e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1841e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7921e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6665e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1297e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6597e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.6103e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2481e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4852e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5659e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8376e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7148e-05]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8419e-03]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 6.4479e-03]],\n",
       "              \n",
       "                       [[-9.8954e-04]],\n",
       "              \n",
       "                       [[-2.2635e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5363e-02]],\n",
       "              \n",
       "                       [[-1.7757e-04]],\n",
       "              \n",
       "                       [[ 2.2564e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0576e-02]],\n",
       "              \n",
       "                       [[ 2.5806e-03]],\n",
       "              \n",
       "                       [[ 5.1797e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.4507e-02]],\n",
       "              \n",
       "                       [[ 6.8729e-05]],\n",
       "              \n",
       "                       [[-2.9701e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0922e-02]],\n",
       "              \n",
       "                       [[ 2.4098e-03]],\n",
       "              \n",
       "                       [[ 4.0756e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.0115e-02]],\n",
       "              \n",
       "                       [[ 6.7385e-04]],\n",
       "              \n",
       "                       [[-3.5443e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 6.9486e-03]],\n",
       "              \n",
       "                       [[ 1.7256e-03]],\n",
       "              \n",
       "                       [[-1.0919e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.3744e-03]],\n",
       "              \n",
       "                       [[ 5.8388e-05]],\n",
       "              \n",
       "                       [[-6.1531e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0429e-01]],\n",
       "              \n",
       "                       [[-2.5364e-03]],\n",
       "              \n",
       "                       [[ 5.9545e-05]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5045e-01]],\n",
       "              \n",
       "                       [[-5.4927e-04]],\n",
       "              \n",
       "                       [[ 1.7566e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7770e-02]],\n",
       "              \n",
       "                       [[-2.8487e-03]],\n",
       "              \n",
       "                       [[-6.1460e-06]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.0371e-02]],\n",
       "              \n",
       "                       [[-1.2995e-03]],\n",
       "              \n",
       "                       [[ 7.0958e-04]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.weight',\n",
       "              tensor([1.0185, 1.1374, 1.0385, 0.9431, 1.1595, 0.9680, 1.1423, 1.2673, 1.1990,\n",
       "                      1.0115, 1.0030, 1.0278, 0.9815, 1.1700, 0.9411, 1.1512],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.bias',\n",
       "              tensor([-0.1333, -0.1129,  0.0586,  0.0626, -0.0852, -0.2463, -0.1423, -0.3704,\n",
       "                      -0.0401,  0.0354,  0.3304, -0.0737,  0.0164, -0.2029,  0.2965,  0.0013],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.running_mean',\n",
       "              tensor([ 0.3011,  0.2721,  0.4038,  0.3415,  0.0807, -0.3448,  0.2059, -0.0414,\n",
       "                      -0.0703,  0.1771,  0.3030, -0.0894, -0.1068, -0.4313, -0.1983,  0.3269],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.running_var',\n",
       "              tensor([0.1034, 0.0173, 0.1572, 0.0368, 0.1230, 0.0619, 0.2211, 0.0812, 0.2103,\n",
       "                      0.0517, 0.0269, 0.0821, 0.0364, 0.0989, 0.0237, 0.0570],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.4.original.weight',\n",
       "              tensor([[[[ 0.0681,  0.0665, -0.0344],\n",
       "                        [ 0.0169, -0.0294,  0.0593],\n",
       "                        [ 0.0611,  0.0535, -0.0366]],\n",
       "              \n",
       "                       [[-0.0602,  0.0124,  0.0762],\n",
       "                        [-0.0644, -0.0262, -0.0219],\n",
       "                        [-0.0351, -0.0100, -0.0116]],\n",
       "              \n",
       "                       [[ 0.0406, -0.0204,  0.0716],\n",
       "                        [ 0.0767, -0.0057,  0.0756],\n",
       "                        [-0.0577,  0.0784,  0.0372]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0816,  0.0420, -0.0583],\n",
       "                        [-0.0830,  0.0452, -0.0438],\n",
       "                        [-0.0823, -0.0377,  0.0788]],\n",
       "              \n",
       "                       [[-0.0340,  0.0522, -0.0026],\n",
       "                        [ 0.0666, -0.0173, -0.0502],\n",
       "                        [-0.0052,  0.0810, -0.0686]],\n",
       "              \n",
       "                       [[-0.0324, -0.0186,  0.0107],\n",
       "                        [ 0.0186,  0.0330,  0.0778],\n",
       "                        [-0.0810,  0.0641,  0.0422]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0763, -0.0153, -0.0730],\n",
       "                        [ 0.0131, -0.0243,  0.0205],\n",
       "                        [ 0.0230, -0.0457, -0.0432]],\n",
       "              \n",
       "                       [[-0.0011, -0.0570,  0.0777],\n",
       "                        [ 0.0577,  0.0140, -0.0056],\n",
       "                        [ 0.0231, -0.0769, -0.0312]],\n",
       "              \n",
       "                       [[ 0.0603, -0.0591, -0.0214],\n",
       "                        [ 0.0306,  0.0473,  0.0428],\n",
       "                        [-0.0105,  0.0410, -0.0084]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0694,  0.0047,  0.0097],\n",
       "                        [-0.0794,  0.0799, -0.0721],\n",
       "                        [ 0.0426,  0.0117,  0.0565]],\n",
       "              \n",
       "                       [[ 0.0449, -0.0026,  0.0363],\n",
       "                        [ 0.0644,  0.0822,  0.0197],\n",
       "                        [ 0.0510,  0.0107,  0.0459]],\n",
       "              \n",
       "                       [[ 0.0760,  0.0829, -0.0693],\n",
       "                        [-0.0309, -0.0283, -0.0830],\n",
       "                        [ 0.0277, -0.0202,  0.0753]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0542,  0.0657,  0.0048],\n",
       "                        [ 0.0539, -0.0446,  0.0393],\n",
       "                        [ 0.0776,  0.0698,  0.0665]],\n",
       "              \n",
       "                       [[-0.0094,  0.0022,  0.0062],\n",
       "                        [ 0.0491,  0.0203,  0.0296],\n",
       "                        [-0.0410,  0.0425, -0.0271]],\n",
       "              \n",
       "                       [[-0.0312,  0.0753,  0.0456],\n",
       "                        [ 0.0408, -0.0507, -0.0246],\n",
       "                        [ 0.0123, -0.0425, -0.0212]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0490, -0.0073,  0.0527],\n",
       "                        [-0.0818, -0.0536,  0.0588],\n",
       "                        [-0.0605, -0.0205, -0.0415]],\n",
       "              \n",
       "                       [[ 0.0186, -0.0776,  0.0021],\n",
       "                        [ 0.0353,  0.0316,  0.0655],\n",
       "                        [-0.0048,  0.0454, -0.0059]],\n",
       "              \n",
       "                       [[ 0.0595,  0.0830, -0.0701],\n",
       "                        [ 0.0482,  0.0500, -0.0171],\n",
       "                        [ 0.0498, -0.0572,  0.0277]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0681, -0.0124,  0.0168],\n",
       "                        [ 0.0312,  0.0054, -0.0408],\n",
       "                        [ 0.0287,  0.0084,  0.0480]],\n",
       "              \n",
       "                       [[-0.0449, -0.0681, -0.0479],\n",
       "                        [ 0.0548,  0.0607, -0.0246],\n",
       "                        [-0.0716,  0.0722, -0.0255]],\n",
       "              \n",
       "                       [[ 0.0819, -0.0364,  0.0203],\n",
       "                        [-0.0098, -0.0211, -0.0414],\n",
       "                        [-0.0755, -0.0383,  0.0148]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0522, -0.0645,  0.0454],\n",
       "                        [-0.0095, -0.0205,  0.0683],\n",
       "                        [ 0.0533, -0.0246, -0.0470]],\n",
       "              \n",
       "                       [[-0.0431, -0.0582,  0.0599],\n",
       "                        [-0.0245, -0.0335, -0.0196],\n",
       "                        [-0.0171, -0.0616, -0.0168]],\n",
       "              \n",
       "                       [[ 0.0192,  0.0031,  0.0760],\n",
       "                        [ 0.0615,  0.0432,  0.0754],\n",
       "                        [-0.0384, -0.0646,  0.0590]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0410, -0.0330,  0.0314],\n",
       "                        [-0.0019, -0.0200,  0.0809],\n",
       "                        [ 0.0652,  0.0225,  0.0351]],\n",
       "              \n",
       "                       [[ 0.0226, -0.0705,  0.0402],\n",
       "                        [ 0.0038,  0.0302, -0.0614],\n",
       "                        [-0.0160,  0.0179, -0.0477]],\n",
       "              \n",
       "                       [[-0.0808, -0.0087,  0.0495],\n",
       "                        [ 0.0826,  0.0299, -0.0544],\n",
       "                        [ 0.0693, -0.0357, -0.0091]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0029,  0.0626, -0.0473],\n",
       "                        [-0.0500, -0.0291,  0.0546],\n",
       "                        [-0.0186,  0.0058,  0.0571]],\n",
       "              \n",
       "                       [[ 0.0289, -0.0085,  0.0407],\n",
       "                        [ 0.0174, -0.0045,  0.0320],\n",
       "                        [ 0.0240,  0.0809,  0.0720]],\n",
       "              \n",
       "                       [[-0.0556,  0.0508, -0.0820],\n",
       "                        [ 0.0241,  0.0759,  0.0718],\n",
       "                        [-0.0472,  0.0334, -0.0413]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0368, -0.0051, -0.0691],\n",
       "                        [ 0.0520,  0.0105,  0.0152],\n",
       "                        [-0.0595,  0.0412, -0.0117]],\n",
       "              \n",
       "                       [[-0.0571,  0.0287, -0.0205],\n",
       "                        [ 0.0805,  0.0243,  0.0637],\n",
       "                        [ 0.0246,  0.0530,  0.0047]],\n",
       "              \n",
       "                       [[ 0.0610, -0.0385, -0.0315],\n",
       "                        [-0.0796, -0.0592, -0.0720],\n",
       "                        [ 0.0148, -0.0338, -0.0038]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0304,  0.0291, -0.0145],\n",
       "                        [ 0.0315,  0.0808, -0.0244],\n",
       "                        [ 0.0058, -0.0672, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0363,  0.0811,  0.0755],\n",
       "                        [ 0.0810, -0.0222, -0.0492],\n",
       "                        [ 0.0832,  0.0815,  0.0821]],\n",
       "              \n",
       "                       [[-0.0601,  0.0512,  0.0497],\n",
       "                        [ 0.0354,  0.0565,  0.0831],\n",
       "                        [-0.0371, -0.0387,  0.0131]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.4.original.bias',\n",
       "              tensor([ 0.0097, -0.0131, -0.0170, -0.0476, -0.0690, -0.0073,  0.0174, -0.0034,\n",
       "                       0.0344,  0.0487, -0.0792,  0.0329,  0.0211, -0.0025,  0.0760, -0.0372],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[ 0.0798]],\n",
       "              \n",
       "                       [[ 0.0711]],\n",
       "              \n",
       "                       [[-0.0586]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0573]],\n",
       "              \n",
       "                       [[ 0.0915]],\n",
       "              \n",
       "                       [[-0.0105]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0014]],\n",
       "              \n",
       "                       [[ 0.0195]],\n",
       "              \n",
       "                       [[ 0.0085]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0029]],\n",
       "              \n",
       "                       [[-0.0032]],\n",
       "              \n",
       "                       [[ 0.0332]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0084]],\n",
       "              \n",
       "                       [[ 0.0027]],\n",
       "              \n",
       "                       [[ 0.0083]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0019]],\n",
       "              \n",
       "                       [[ 0.0105]],\n",
       "              \n",
       "                       [[-0.0166]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0179]],\n",
       "              \n",
       "                       [[-0.0090]],\n",
       "              \n",
       "                       [[ 0.0112]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0002]],\n",
       "              \n",
       "                       [[-0.0016]],\n",
       "              \n",
       "                       [[-0.0486]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0263]],\n",
       "              \n",
       "                       [[ 0.0289]],\n",
       "              \n",
       "                       [[ 0.0606]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0254]],\n",
       "              \n",
       "                       [[-0.0152]],\n",
       "              \n",
       "                       [[-0.0098]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0028]],\n",
       "              \n",
       "                       [[-0.0137]],\n",
       "              \n",
       "                       [[-0.0159]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0016]],\n",
       "              \n",
       "                       [[-0.0040]],\n",
       "              \n",
       "                       [[ 0.0304]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 5.3916e-02]],\n",
       "              \n",
       "                       [[ 1.5393e-03]],\n",
       "              \n",
       "                       [[ 8.1740e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.6908e-04]],\n",
       "              \n",
       "                       [[-2.1805e-03]],\n",
       "              \n",
       "                       [[-9.1104e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.0677e-02]],\n",
       "              \n",
       "                       [[-2.7242e-02]],\n",
       "              \n",
       "                       [[ 8.8453e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.8764e-02]],\n",
       "              \n",
       "                       [[-3.7060e-02]],\n",
       "              \n",
       "                       [[-9.1109e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1332e-02]],\n",
       "              \n",
       "                       [[-5.4590e-05]],\n",
       "              \n",
       "                       [[-1.0172e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.8215e-03]],\n",
       "              \n",
       "                       [[-2.4043e-03]],\n",
       "              \n",
       "                       [[ 8.2847e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.7097e-02]],\n",
       "              \n",
       "                       [[ 3.7717e-02]],\n",
       "              \n",
       "                       [[-1.3211e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.6200e-02]],\n",
       "              \n",
       "                       [[ 2.3308e-02]],\n",
       "              \n",
       "                       [[ 2.6662e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3655e-02]],\n",
       "              \n",
       "                       [[ 2.5475e-02]],\n",
       "              \n",
       "                       [[-3.6385e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-9.0632e-03]],\n",
       "              \n",
       "                       [[ 5.3914e-02]],\n",
       "              \n",
       "                       [[-2.6701e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.3779e-02]],\n",
       "              \n",
       "                       [[-1.4212e-02]],\n",
       "              \n",
       "                       [[ 3.0032e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.1895e-02]],\n",
       "              \n",
       "                       [[ 3.7768e-02]],\n",
       "              \n",
       "                       [[-1.1165e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.weight',\n",
       "              tensor([1.1054, 1.1511, 1.0664, 0.9040, 1.0082, 1.0295, 1.1073, 0.9133, 1.0410,\n",
       "                      1.0208, 1.1337, 0.8969, 0.9677, 1.2035, 1.0768, 0.7993],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.bias',\n",
       "              tensor([ 0.1988, -0.2750, -0.1118, -0.2227,  0.1499,  0.0590, -0.2481, -0.2295,\n",
       "                      -0.0928, -0.0842, -0.2164, -0.3037,  0.1987, -0.2047,  0.2430, -0.1181],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.running_mean',\n",
       "              tensor([ 0.2856, -0.0600,  0.5987, -0.2531, -0.0353,  0.0325,  0.3678,  0.2210,\n",
       "                       0.1100,  0.1901,  0.0466, -0.0457,  0.3137,  0.0964,  0.2658,  0.3119],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.running_var',\n",
       "              tensor([0.4747, 0.0823, 0.8476, 0.2195, 0.2464, 0.1994, 0.2122, 0.2085, 0.3317,\n",
       "                      0.1368, 0.2625, 0.1724, 0.9772, 0.3630, 0.6400, 0.2184],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.0.original.weight',\n",
       "              tensor([[[[ 0.0822, -0.0377,  0.0059],\n",
       "                        [ 0.0794,  0.0372, -0.0810],\n",
       "                        [-0.0373, -0.0271, -0.0356]],\n",
       "              \n",
       "                       [[-0.0375,  0.0713,  0.0004],\n",
       "                        [ 0.0248, -0.0061, -0.0143],\n",
       "                        [-0.0075,  0.0213, -0.0453]],\n",
       "              \n",
       "                       [[ 0.0487, -0.0811, -0.0805],\n",
       "                        [-0.0045,  0.0527, -0.0162],\n",
       "                        [ 0.0105,  0.0687, -0.0581]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0284, -0.0127,  0.0114],\n",
       "                        [ 0.0102,  0.0049,  0.0163],\n",
       "                        [ 0.0763, -0.0089, -0.0252]],\n",
       "              \n",
       "                       [[-0.0271, -0.0783,  0.0627],\n",
       "                        [-0.0336,  0.0760, -0.0194],\n",
       "                        [-0.0591, -0.0466, -0.0343]],\n",
       "              \n",
       "                       [[-0.0043,  0.0170,  0.0076],\n",
       "                        [-0.0822,  0.0591,  0.0436],\n",
       "                        [-0.0571,  0.0225, -0.0424]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0529,  0.0056, -0.0679],\n",
       "                        [ 0.0691, -0.0829, -0.0078],\n",
       "                        [ 0.0229, -0.0030,  0.0234]],\n",
       "              \n",
       "                       [[ 0.0375, -0.0461,  0.0328],\n",
       "                        [-0.0679, -0.0406,  0.0525],\n",
       "                        [ 0.0771,  0.0538, -0.0815]],\n",
       "              \n",
       "                       [[ 0.0169, -0.0257,  0.0298],\n",
       "                        [-0.0726,  0.0216, -0.0170],\n",
       "                        [-0.0475,  0.0040,  0.0536]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0451, -0.0819,  0.0020],\n",
       "                        [ 0.0414,  0.0681,  0.0336],\n",
       "                        [ 0.0662,  0.0168,  0.0505]],\n",
       "              \n",
       "                       [[ 0.0187, -0.0135, -0.0452],\n",
       "                        [ 0.0679,  0.0481,  0.0566],\n",
       "                        [-0.0592,  0.0045,  0.0528]],\n",
       "              \n",
       "                       [[ 0.0831, -0.0164,  0.0026],\n",
       "                        [ 0.0653,  0.0547, -0.0559],\n",
       "                        [-0.0233, -0.0681,  0.0038]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0509, -0.0652,  0.0628],\n",
       "                        [ 0.0801, -0.0021,  0.0375],\n",
       "                        [-0.0129, -0.0464, -0.0425]],\n",
       "              \n",
       "                       [[ 0.0705,  0.0501, -0.0677],\n",
       "                        [ 0.0655, -0.0780, -0.0566],\n",
       "                        [ 0.0306, -0.0831,  0.0796]],\n",
       "              \n",
       "                       [[-0.0339, -0.0130, -0.0443],\n",
       "                        [ 0.0569, -0.0702, -0.0286],\n",
       "                        [-0.0731, -0.0694, -0.0617]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0664, -0.0352,  0.0342],\n",
       "                        [ 0.0679, -0.0506,  0.0054],\n",
       "                        [ 0.0668, -0.0451, -0.0119]],\n",
       "              \n",
       "                       [[ 0.0381,  0.0156, -0.0487],\n",
       "                        [ 0.0226, -0.0619, -0.0664],\n",
       "                        [-0.0824,  0.0632, -0.0465]],\n",
       "              \n",
       "                       [[ 0.0335, -0.0434, -0.0330],\n",
       "                        [-0.0353, -0.0365,  0.0559],\n",
       "                        [-0.0120, -0.0219,  0.0204]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0759, -0.0257,  0.0654],\n",
       "                        [ 0.0475,  0.0514, -0.0052],\n",
       "                        [-0.0819, -0.0215,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0731,  0.0509, -0.0799],\n",
       "                        [ 0.0430, -0.0199,  0.0215],\n",
       "                        [ 0.0085, -0.0355, -0.0389]],\n",
       "              \n",
       "                       [[ 0.0100, -0.0430, -0.0186],\n",
       "                        [-0.0757,  0.0696,  0.0687],\n",
       "                        [-0.0366, -0.0492, -0.0240]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0604, -0.0023, -0.0516],\n",
       "                        [ 0.0255, -0.0178, -0.0222],\n",
       "                        [ 0.0612, -0.0100, -0.0012]],\n",
       "              \n",
       "                       [[-0.0076,  0.0287, -0.0269],\n",
       "                        [ 0.0716, -0.0525,  0.0010],\n",
       "                        [-0.0078, -0.0393,  0.0027]],\n",
       "              \n",
       "                       [[ 0.0247, -0.0100, -0.0098],\n",
       "                        [ 0.0588,  0.0602,  0.0127],\n",
       "                        [-0.0709, -0.0091, -0.0230]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0648,  0.0167,  0.0809],\n",
       "                        [-0.0202,  0.0227,  0.0503],\n",
       "                        [ 0.0091,  0.0584, -0.0505]],\n",
       "              \n",
       "                       [[-0.0260, -0.0611,  0.0681],\n",
       "                        [-0.0168,  0.0553, -0.0377],\n",
       "                        [-0.0445, -0.0579,  0.0498]],\n",
       "              \n",
       "                       [[-0.0026,  0.0361,  0.0445],\n",
       "                        [ 0.0187, -0.0585,  0.0561],\n",
       "                        [-0.0166,  0.0130,  0.0252]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0624, -0.0186,  0.0251],\n",
       "                        [ 0.0208, -0.0599,  0.0581],\n",
       "                        [-0.0074, -0.0511, -0.0675]],\n",
       "              \n",
       "                       [[-0.0521, -0.0620, -0.0802],\n",
       "                        [-0.0019, -0.0382, -0.0777],\n",
       "                        [ 0.0540, -0.0170, -0.0805]],\n",
       "              \n",
       "                       [[-0.0371,  0.0505, -0.0071],\n",
       "                        [ 0.0330,  0.0021, -0.0506],\n",
       "                        [ 0.0518, -0.0695, -0.0338]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0771, -0.0699,  0.0339],\n",
       "                        [ 0.0469,  0.0034,  0.0452],\n",
       "                        [-0.0105, -0.0240, -0.0733]],\n",
       "              \n",
       "                       [[ 0.0032, -0.0403, -0.0170],\n",
       "                        [ 0.0085, -0.0149,  0.0413],\n",
       "                        [ 0.0324, -0.0059,  0.0443]],\n",
       "              \n",
       "                       [[-0.0393,  0.0644,  0.0606],\n",
       "                        [ 0.0370, -0.0637, -0.0147],\n",
       "                        [-0.0665,  0.0371, -0.0427]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0736,  0.0636,  0.0166],\n",
       "                        [ 0.0539,  0.0475, -0.0650],\n",
       "                        [-0.0099,  0.0456,  0.0561]],\n",
       "              \n",
       "                       [[ 0.0797,  0.0669,  0.0152],\n",
       "                        [ 0.0213, -0.0328, -0.0067],\n",
       "                        [-0.0812,  0.0251,  0.0582]],\n",
       "              \n",
       "                       [[-0.0727,  0.0232,  0.0541],\n",
       "                        [ 0.0500, -0.0071, -0.0817],\n",
       "                        [ 0.0273,  0.0162, -0.0552]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.0.original.bias',\n",
       "              tensor([-0.0383,  0.0791,  0.0033, -0.0435, -0.0171,  0.0378,  0.0442,  0.0489,\n",
       "                      -0.0810, -0.0147, -0.0331, -0.0668, -0.0669,  0.0234, -0.0509, -0.0046,\n",
       "                      -0.0608, -0.0692, -0.0245,  0.0302, -0.0634, -0.0776, -0.0506,  0.0312,\n",
       "                       0.0133, -0.0529, -0.0715, -0.0065,  0.0363,  0.0555,  0.0437, -0.0424],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-0.0051]],\n",
       "              \n",
       "                       [[ 0.0284]],\n",
       "              \n",
       "                       [[-0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0063]],\n",
       "              \n",
       "                       [[ 0.0120]],\n",
       "              \n",
       "                       [[ 0.0171]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0044]],\n",
       "              \n",
       "                       [[ 0.0242]],\n",
       "              \n",
       "                       [[-0.0171]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0067]],\n",
       "              \n",
       "                       [[ 0.0091]],\n",
       "              \n",
       "                       [[ 0.0117]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0199]],\n",
       "              \n",
       "                       [[-0.0058]],\n",
       "              \n",
       "                       [[ 0.0149]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0035]],\n",
       "              \n",
       "                       [[ 0.0027]],\n",
       "              \n",
       "                       [[ 0.0058]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0051]],\n",
       "              \n",
       "                       [[-0.0204]],\n",
       "              \n",
       "                       [[ 0.0183]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0080]],\n",
       "              \n",
       "                       [[-0.0088]],\n",
       "              \n",
       "                       [[-0.0142]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0215]],\n",
       "              \n",
       "                       [[-0.0106]],\n",
       "              \n",
       "                       [[ 0.0239]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0008]],\n",
       "              \n",
       "                       [[-0.0017]],\n",
       "              \n",
       "                       [[ 0.0039]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0141]],\n",
       "              \n",
       "                       [[-0.0023]],\n",
       "              \n",
       "                       [[ 0.0163]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0080]],\n",
       "              \n",
       "                       [[-0.0015]],\n",
       "              \n",
       "                       [[ 0.0016]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[-1.1729e-03]],\n",
       "              \n",
       "                       [[-2.3230e-03]],\n",
       "              \n",
       "                       [[-6.5608e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4870e-03]],\n",
       "              \n",
       "                       [[-1.4277e-02]],\n",
       "              \n",
       "                       [[-1.5847e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1934e-03]],\n",
       "              \n",
       "                       [[ 1.9761e-03]],\n",
       "              \n",
       "                       [[-9.3219e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2275e-04]],\n",
       "              \n",
       "                       [[ 2.8321e-03]],\n",
       "              \n",
       "                       [[-6.1373e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7604e-03]],\n",
       "              \n",
       "                       [[ 3.6457e-04]],\n",
       "              \n",
       "                       [[ 2.1406e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.5029e-03]],\n",
       "              \n",
       "                       [[ 2.0790e-02]],\n",
       "              \n",
       "                       [[ 1.1024e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 9.4152e-03]],\n",
       "              \n",
       "                       [[ 1.0644e-02]],\n",
       "              \n",
       "                       [[-3.6998e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0746e-02]],\n",
       "              \n",
       "                       [[ 7.9840e-03]],\n",
       "              \n",
       "                       [[-3.3110e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2926e-03]],\n",
       "              \n",
       "                       [[-1.6256e-03]],\n",
       "              \n",
       "                       [[-7.6942e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.1875e-03]],\n",
       "              \n",
       "                       [[-7.3470e-05]],\n",
       "              \n",
       "                       [[ 5.5258e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6355e-02]],\n",
       "              \n",
       "                       [[-1.5507e-02]],\n",
       "              \n",
       "                       [[-6.2123e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.5868e-02]],\n",
       "              \n",
       "                       [[-7.8378e-03]],\n",
       "              \n",
       "                       [[ 2.5043e-03]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.weight',\n",
       "              tensor([1.0134, 1.0141, 0.8128, 0.9600, 1.0121, 0.6756, 1.0371, 1.0361, 0.9781,\n",
       "                      1.1106, 1.0957, 0.7359, 0.7054, 0.7603, 1.1498, 0.9075, 1.3136, 1.0130,\n",
       "                      1.1828, 0.6956, 1.1640, 1.0071, 0.7761, 1.0732, 0.9785, 0.9934, 0.9098,\n",
       "                      1.0380, 1.0530, 1.0912, 0.9698, 1.1279], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.bias',\n",
       "              tensor([-0.3118, -0.0433, -0.4426,  0.0209, -0.1717, -0.3020, -0.3278, -0.3015,\n",
       "                      -0.2880, -0.1414, -0.1558, -0.3230, -0.2474, -0.4782, -0.3181, -0.4456,\n",
       "                      -0.3990, -0.4008, -0.2686, -0.2041, -0.1412, -0.2161, -0.3425, -0.0161,\n",
       "                      -0.0711, -0.2769, -0.3983, -0.0149, -0.3402, -0.2542, -0.3353, -0.0765],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.running_mean',\n",
       "              tensor([-0.4919,  0.1474,  0.0514,  0.0250, -0.3955,  0.3761,  0.4749,  0.5500,\n",
       "                      -0.2984, -0.0602, -0.5478,  0.4031, -0.0975,  0.2896, -0.6134, -0.2073,\n",
       "                       0.1025, -0.1070, -0.1582, -0.3792, -0.1428,  0.5676, -0.0518, -0.5007,\n",
       "                      -0.5687, -0.2649, -0.0971,  0.3126,  0.1964, -0.4032, -0.5313, -0.6068],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.running_var',\n",
       "              tensor([0.7237, 0.1014, 0.0956, 0.0744, 0.7016, 0.4434, 0.6212, 0.6012, 0.3485,\n",
       "                      0.1784, 1.0100, 0.6188, 0.1253, 0.3997, 0.9913, 0.2216, 0.1555, 0.1628,\n",
       "                      0.1451, 0.6559, 0.1682, 1.2359, 0.1643, 0.9298, 0.8490, 0.3321, 0.0846,\n",
       "                      0.4841, 0.2372, 0.7125, 0.7579, 1.0950], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.4.original.weight',\n",
       "              tensor([[[[-4.7856e-02,  3.2929e-02, -3.0285e-02],\n",
       "                        [-2.3930e-02, -1.6060e-02,  2.8790e-02],\n",
       "                        [-2.4449e-02, -5.7573e-02,  2.0050e-02]],\n",
       "              \n",
       "                       [[-1.0287e-02,  4.8558e-02, -6.5335e-03],\n",
       "                        [ 4.6520e-02, -5.8211e-02, -1.4668e-02],\n",
       "                        [ 5.3822e-02, -1.6057e-02,  8.8599e-03]],\n",
       "              \n",
       "                       [[ 1.7737e-02,  4.2374e-02,  1.7189e-02],\n",
       "                        [-3.1058e-02,  4.3664e-02,  4.1628e-02],\n",
       "                        [ 1.5780e-02, -4.3132e-02, -2.4976e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.4099e-02, -7.5199e-03,  2.4348e-02],\n",
       "                        [ 5.4660e-02,  3.9525e-02, -3.4733e-02],\n",
       "                        [ 4.9531e-02,  4.2260e-03, -2.9341e-02]],\n",
       "              \n",
       "                       [[-1.2785e-02,  3.1226e-02, -4.5452e-02],\n",
       "                        [-2.0202e-02,  3.9707e-02,  9.1487e-03],\n",
       "                        [-2.1344e-02,  1.1561e-02,  2.7999e-02]],\n",
       "              \n",
       "                       [[-3.8656e-04,  2.9811e-02, -1.9728e-02],\n",
       "                        [ 2.4626e-02, -2.3418e-02, -5.2523e-02],\n",
       "                        [-1.4426e-02,  2.9925e-02,  2.8472e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.6878e-02,  5.0141e-02, -3.7065e-02],\n",
       "                        [ 2.6230e-04,  1.3831e-02, -4.9657e-02],\n",
       "                        [-4.7188e-02, -2.9758e-02, -4.8967e-03]],\n",
       "              \n",
       "                       [[-4.9680e-02, -5.8748e-02, -2.1983e-03],\n",
       "                        [-3.2971e-02,  5.1117e-02,  4.3018e-02],\n",
       "                        [ 5.2374e-02,  2.1690e-03, -2.3150e-02]],\n",
       "              \n",
       "                       [[-3.3344e-02,  6.9805e-03, -2.9579e-02],\n",
       "                        [-5.2316e-02,  1.5181e-02,  5.6787e-02],\n",
       "                        [ 1.0102e-02,  5.5236e-02, -4.6893e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5454e-02, -2.5685e-02, -3.8896e-03],\n",
       "                        [ 3.8313e-02, -5.5281e-02,  4.8677e-03],\n",
       "                        [-4.6116e-02, -1.3590e-02, -4.7573e-02]],\n",
       "              \n",
       "                       [[-1.7094e-02, -4.6666e-02, -2.2499e-04],\n",
       "                        [-5.2638e-03, -3.8507e-03,  2.8269e-02],\n",
       "                        [-3.7400e-03, -2.5969e-02, -5.8810e-02]],\n",
       "              \n",
       "                       [[ 4.1358e-04, -1.2177e-02,  4.1089e-02],\n",
       "                        [ 3.7446e-02, -3.0407e-02, -4.6148e-02],\n",
       "                        [-2.8747e-02, -3.5110e-02, -5.7027e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3206e-02,  9.8188e-04, -4.7161e-02],\n",
       "                        [ 3.2185e-02, -4.2098e-02, -1.8392e-02],\n",
       "                        [-4.5128e-02, -5.4931e-02, -2.8362e-02]],\n",
       "              \n",
       "                       [[ 3.5420e-02, -3.0529e-02,  2.4776e-02],\n",
       "                        [-1.5116e-02, -3.4720e-02, -4.6691e-02],\n",
       "                        [-1.3990e-02, -2.9503e-02,  3.7998e-02]],\n",
       "              \n",
       "                       [[ 5.2899e-02,  2.0860e-02,  2.5901e-02],\n",
       "                        [ 4.1642e-03,  2.0251e-02,  5.6427e-02],\n",
       "                        [ 5.3644e-02,  5.1056e-02,  4.2107e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.6980e-02, -4.7513e-02,  3.0024e-02],\n",
       "                        [-1.7473e-02,  2.5010e-02, -1.5959e-02],\n",
       "                        [ 4.7592e-03,  1.8154e-03, -3.4779e-02]],\n",
       "              \n",
       "                       [[-3.1525e-02,  4.4692e-02, -4.4128e-02],\n",
       "                        [-3.2165e-02, -4.0819e-03,  5.1697e-02],\n",
       "                        [-3.3152e-02, -2.7993e-02, -5.7207e-02]],\n",
       "              \n",
       "                       [[-6.4421e-03,  3.7891e-02,  4.8436e-02],\n",
       "                        [-1.6296e-02, -1.5022e-02,  1.2017e-02],\n",
       "                        [ 6.8042e-04, -3.5924e-02, -3.6198e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6984e-02, -1.7852e-02, -4.0403e-02],\n",
       "                        [-2.1759e-02,  8.9202e-05, -3.0914e-02],\n",
       "                        [ 1.6920e-02,  1.9511e-02, -3.0237e-02]],\n",
       "              \n",
       "                       [[-1.0407e-02, -7.7031e-03, -5.3221e-02],\n",
       "                        [-5.5365e-02,  4.9778e-03,  3.5389e-02],\n",
       "                        [-1.9390e-02,  3.9237e-04,  2.0430e-02]],\n",
       "              \n",
       "                       [[-5.4539e-02, -1.3532e-02, -7.3757e-03],\n",
       "                        [-4.1689e-02, -3.4323e-03, -1.6697e-02],\n",
       "                        [-4.1629e-02,  5.8677e-02,  5.3738e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0329e-03,  1.2446e-02,  5.1607e-02],\n",
       "                        [-2.0876e-03,  5.5026e-02, -5.2180e-02],\n",
       "                        [-5.7943e-02,  6.0771e-03,  3.1161e-02]],\n",
       "              \n",
       "                       [[ 5.3915e-02, -1.9182e-02, -4.1938e-02],\n",
       "                        [ 2.6196e-02, -6.5702e-03, -3.6896e-02],\n",
       "                        [-2.9896e-02, -3.1898e-02,  5.7671e-02]],\n",
       "              \n",
       "                       [[ 2.2487e-02, -1.3793e-02,  5.2618e-02],\n",
       "                        [-3.1664e-02, -5.2127e-02,  2.2962e-02],\n",
       "                        [ 3.2559e-02,  2.7692e-02,  2.3870e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4695e-02, -1.5230e-02,  2.9586e-02],\n",
       "                        [-3.8763e-03,  5.4576e-03, -2.5774e-02],\n",
       "                        [ 5.6368e-03, -1.7733e-02,  1.4486e-02]],\n",
       "              \n",
       "                       [[ 4.0137e-02,  4.8066e-02,  1.2951e-02],\n",
       "                        [-2.8563e-02,  1.9179e-02, -5.4978e-02],\n",
       "                        [-9.4148e-03, -9.6845e-03,  1.1146e-02]],\n",
       "              \n",
       "                       [[-1.0745e-02, -3.0561e-02, -1.6796e-02],\n",
       "                        [-3.2985e-03, -2.4629e-02, -9.8970e-03],\n",
       "                        [ 3.1879e-02, -3.4094e-02,  8.9072e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.4221e-03,  1.8198e-02,  5.8100e-02],\n",
       "                        [-3.7542e-02,  1.8749e-02,  1.1722e-02],\n",
       "                        [-3.2736e-02, -5.3078e-02, -2.8485e-02]],\n",
       "              \n",
       "                       [[ 5.6168e-02, -9.4790e-03,  2.5628e-02],\n",
       "                        [-1.0758e-02, -9.7120e-03, -4.2928e-02],\n",
       "                        [ 1.5751e-02,  1.3422e-02,  3.1109e-02]],\n",
       "              \n",
       "                       [[-4.2866e-02,  5.2928e-04,  1.3077e-02],\n",
       "                        [ 1.8658e-02, -1.2634e-02,  8.5860e-03],\n",
       "                        [ 5.0777e-02,  2.5626e-02,  2.6579e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2315e-02,  5.5384e-02, -1.3155e-02],\n",
       "                        [ 4.5140e-02, -2.8097e-02,  4.2454e-03],\n",
       "                        [-4.4898e-03,  3.7384e-02,  1.2270e-02]],\n",
       "              \n",
       "                       [[ 1.5046e-02, -5.6101e-02,  3.3287e-02],\n",
       "                        [-3.8105e-03,  3.9916e-02, -3.6756e-02],\n",
       "                        [-4.9552e-02, -3.5513e-02,  5.3240e-02]],\n",
       "              \n",
       "                       [[-3.2647e-02,  2.6562e-02, -4.3133e-02],\n",
       "                        [ 5.3583e-02,  3.5964e-02, -3.5300e-03],\n",
       "                        [ 1.4114e-02, -2.3715e-02, -1.7814e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.1526e-03, -3.6435e-02,  3.1257e-02],\n",
       "                        [-1.8458e-02, -3.0330e-02, -7.8919e-03],\n",
       "                        [ 1.3369e-02, -4.4594e-02,  1.9295e-02]],\n",
       "              \n",
       "                       [[-5.5692e-04, -5.7327e-02, -2.0580e-02],\n",
       "                        [-2.9240e-03,  2.6121e-02, -5.1554e-03],\n",
       "                        [ 2.7243e-02, -3.3734e-03, -5.0573e-02]],\n",
       "              \n",
       "                       [[-3.1937e-02,  5.4073e-02, -8.5710e-03],\n",
       "                        [-5.5505e-02, -3.2912e-02,  4.6462e-02],\n",
       "                        [ 5.8680e-02, -4.0091e-02, -3.0363e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.4.original.bias',\n",
       "              tensor([-0.0272,  0.0125,  0.0056, -0.0174,  0.0068,  0.0486,  0.0354, -0.0333,\n",
       "                      -0.0302,  0.0274,  0.0343, -0.0473, -0.0128,  0.0076,  0.0037,  0.0524,\n",
       "                      -0.0559,  0.0107, -0.0073, -0.0211, -0.0233,  0.0085, -0.0116,  0.0537,\n",
       "                       0.0531,  0.0499,  0.0388, -0.0242, -0.0525,  0.0489, -0.0130, -0.0491],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-0.1354]],\n",
       "              \n",
       "                       [[ 0.0989]],\n",
       "              \n",
       "                       [[ 0.1201]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1660]],\n",
       "              \n",
       "                       [[-0.0999]],\n",
       "              \n",
       "                       [[-0.1935]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0265]],\n",
       "              \n",
       "                       [[ 0.0162]],\n",
       "              \n",
       "                       [[-0.0062]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0019]],\n",
       "              \n",
       "                       [[-0.0125]],\n",
       "              \n",
       "                       [[-0.0481]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1559]],\n",
       "              \n",
       "                       [[ 0.0668]],\n",
       "              \n",
       "                       [[ 0.0862]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1795]],\n",
       "              \n",
       "                       [[-0.0908]],\n",
       "              \n",
       "                       [[-0.1710]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0509]],\n",
       "              \n",
       "                       [[ 0.0641]],\n",
       "              \n",
       "                       [[ 0.0910]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0930]],\n",
       "              \n",
       "                       [[-0.0797]],\n",
       "              \n",
       "                       [[-0.1354]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295]],\n",
       "              \n",
       "                       [[ 0.0468]],\n",
       "              \n",
       "                       [[-0.0172]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0011]],\n",
       "              \n",
       "                       [[-0.0114]],\n",
       "              \n",
       "                       [[-0.0534]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0006]],\n",
       "              \n",
       "                       [[-0.0377]],\n",
       "              \n",
       "                       [[ 0.0152]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0107]],\n",
       "              \n",
       "                       [[-0.0009]],\n",
       "              \n",
       "                       [[ 0.0167]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.1091]],\n",
       "              \n",
       "                       [[ 0.0229]],\n",
       "              \n",
       "                       [[ 0.1441]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0367]],\n",
       "              \n",
       "                       [[ 0.0241]],\n",
       "              \n",
       "                       [[ 0.0414]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0981]],\n",
       "              \n",
       "                       [[-0.0103]],\n",
       "              \n",
       "                       [[ 0.0826]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0757]],\n",
       "              \n",
       "                       [[-0.0295]],\n",
       "              \n",
       "                       [[ 0.0235]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2431]],\n",
       "              \n",
       "                       [[-0.0055]],\n",
       "              \n",
       "                       [[-0.2068]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1663]],\n",
       "              \n",
       "                       [[ 0.0008]],\n",
       "              \n",
       "                       [[-0.0131]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0414]],\n",
       "              \n",
       "                       [[-0.0278]],\n",
       "              \n",
       "                       [[-0.0026]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0521]],\n",
       "              \n",
       "                       [[-0.0356]],\n",
       "              \n",
       "                       [[ 0.0287]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0204]],\n",
       "              \n",
       "                       [[ 0.0080]],\n",
       "              \n",
       "                       [[ 0.0352]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0417]],\n",
       "              \n",
       "                       [[ 0.0154]],\n",
       "              \n",
       "                       [[-0.0107]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1277]],\n",
       "              \n",
       "                       [[ 0.0205]],\n",
       "              \n",
       "                       [[ 0.1455]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0637]],\n",
       "              \n",
       "                       [[ 0.0300]],\n",
       "              \n",
       "                       [[-0.0094]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.weight',\n",
       "              tensor([1.0802, 0.7496, 0.9876, 0.9577, 1.0574, 1.0519, 1.0342, 0.7835, 0.9143,\n",
       "                      1.0449, 0.8070, 0.7641, 0.9642, 1.0456, 0.7009, 0.9717, 1.1109, 0.9535,\n",
       "                      0.9695, 0.8278, 0.8549, 0.8455, 0.8006, 0.7878, 0.8033, 0.9867, 0.8694,\n",
       "                      1.0782, 0.8654, 1.2270, 0.8021, 0.9929], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.bias',\n",
       "              tensor([-0.5265,  0.0747, -0.0632, -0.3122, -0.4094, -0.3104, -0.2893, -0.4515,\n",
       "                       0.2309, -0.2482, -0.4992, -0.4440, -0.4335, -0.1778,  0.1018, -0.6688,\n",
       "                      -0.3381, -0.2245, -0.3751, -0.5793, -0.3478, -0.3914, -0.2619, -0.5873,\n",
       "                      -0.5494, -0.4839, -0.3741, -0.3645, -0.1689, -0.3808, -0.4509, -0.4127],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.running_mean',\n",
       "              tensor([ 2.7770e-01, -8.0113e-02, -1.0278e-01, -1.8978e-01,  3.7394e-01,\n",
       "                       1.1819e-01, -4.5350e-01, -1.9951e-01, -1.6716e-01,  7.2382e-02,\n",
       "                       3.5387e-01, -1.6327e-01,  1.2290e-02,  2.3416e-02, -1.9966e-04,\n",
       "                      -9.3985e-02, -2.2020e-01,  9.9585e-02, -1.4419e-01, -1.1225e-01,\n",
       "                       1.1145e-01,  2.4456e-01, -1.2091e-01, -8.4160e-02,  1.3077e-01,\n",
       "                      -3.2485e-02, -1.2402e-02, -2.2139e-01, -3.8480e-01, -3.4281e-02,\n",
       "                      -5.3931e-02,  9.0122e-02], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.running_var',\n",
       "              tensor([0.2217, 0.3055, 0.8130, 0.5905, 0.4883, 0.5753, 0.5006, 0.0544, 0.3088,\n",
       "                      0.4463, 0.4598, 0.0812, 0.4018, 0.7202, 0.0774, 0.1833, 0.5066, 0.0959,\n",
       "                      0.3651, 0.0641, 0.1125, 0.3009, 0.5455, 0.2334, 0.1885, 0.2156, 0.1612,\n",
       "                      0.8619, 0.8967, 0.2324, 0.1293, 0.4723], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.0.original.weight',\n",
       "              tensor([[[[ 4.0992e-02,  5.6540e-02, -4.7886e-02],\n",
       "                        [-5.7729e-02, -1.4251e-02, -1.9184e-02],\n",
       "                        [ 4.9671e-02,  4.2946e-02,  5.5659e-02]],\n",
       "              \n",
       "                       [[ 8.8315e-04,  4.3254e-02, -1.5015e-02],\n",
       "                        [ 1.4686e-02, -4.2380e-02, -3.7060e-02],\n",
       "                        [ 7.4299e-03,  1.8727e-02,  5.4327e-02]],\n",
       "              \n",
       "                       [[ 5.8499e-02,  3.8097e-03,  8.0408e-03],\n",
       "                        [-3.4338e-02,  3.9382e-02,  3.0243e-02],\n",
       "                        [-5.7195e-02,  5.7063e-03, -5.8376e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9893e-02, -3.2350e-02, -4.9949e-02],\n",
       "                        [ 5.6764e-02, -4.5716e-02, -2.3867e-02],\n",
       "                        [ 9.3782e-03,  4.8721e-02, -5.6603e-02]],\n",
       "              \n",
       "                       [[ 2.4771e-02, -9.4198e-05,  1.2029e-02],\n",
       "                        [ 2.0117e-02,  2.0729e-02,  4.7911e-02],\n",
       "                        [-3.9815e-02,  4.3539e-02,  1.8294e-02]],\n",
       "              \n",
       "                       [[-2.8527e-02, -4.2713e-02, -3.1796e-02],\n",
       "                        [ 2.4249e-03,  5.4299e-02, -5.4756e-02],\n",
       "                        [ 3.8202e-02, -2.2597e-02,  5.3337e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1571e-02,  4.1297e-02, -3.0792e-03],\n",
       "                        [-2.8538e-02,  1.3446e-02, -1.0842e-02],\n",
       "                        [-3.2766e-02, -3.7029e-02,  5.4351e-02]],\n",
       "              \n",
       "                       [[-3.0830e-02, -1.4891e-02,  5.3965e-03],\n",
       "                        [-4.6173e-02,  3.3290e-02,  1.3173e-02],\n",
       "                        [-5.7454e-02,  7.3414e-03, -1.7837e-02]],\n",
       "              \n",
       "                       [[-2.4053e-02,  3.0088e-02,  4.0010e-02],\n",
       "                        [ 8.5957e-03,  2.6913e-02, -4.1386e-02],\n",
       "                        [-6.8059e-03, -5.8513e-02, -3.0708e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.1645e-02,  4.5118e-02, -2.2273e-02],\n",
       "                        [ 6.3635e-03, -4.6441e-02, -5.1788e-02],\n",
       "                        [-5.8918e-02,  1.4972e-02,  3.9909e-02]],\n",
       "              \n",
       "                       [[-3.9210e-02,  4.6959e-02, -4.9502e-02],\n",
       "                        [-4.1835e-02,  4.4419e-02, -1.7702e-02],\n",
       "                        [-5.8035e-02,  4.4581e-02,  5.6782e-02]],\n",
       "              \n",
       "                       [[-3.6542e-03, -1.6102e-02, -4.3602e-02],\n",
       "                        [-1.6952e-02,  8.2112e-03, -4.0897e-02],\n",
       "                        [-8.6908e-03,  4.0107e-02, -3.6690e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.0917e-03, -5.0341e-02, -1.7917e-02],\n",
       "                        [-2.2156e-02, -5.1066e-02, -1.2312e-03],\n",
       "                        [-9.1731e-03, -5.2811e-02, -5.1697e-02]],\n",
       "              \n",
       "                       [[-5.4666e-02, -5.5338e-03,  5.0193e-02],\n",
       "                        [ 3.1096e-02, -4.8174e-02,  5.0443e-02],\n",
       "                        [-3.6112e-02,  3.5156e-03,  1.9384e-02]],\n",
       "              \n",
       "                       [[ 5.7443e-02, -2.1240e-02,  4.3881e-02],\n",
       "                        [-2.8120e-02, -1.3739e-02, -2.9444e-02],\n",
       "                        [ 8.3117e-03,  5.5709e-02,  1.1082e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.1783e-02,  4.6806e-02, -4.1962e-03],\n",
       "                        [-1.8574e-02,  1.2984e-02,  3.5449e-02],\n",
       "                        [-9.3201e-03,  5.5848e-02, -7.4351e-03]],\n",
       "              \n",
       "                       [[-4.0037e-02,  8.2369e-03,  2.8970e-02],\n",
       "                        [ 3.7621e-02, -3.2473e-02,  1.9318e-02],\n",
       "                        [-4.5173e-02, -9.9492e-03, -2.2231e-02]],\n",
       "              \n",
       "                       [[-1.8980e-02, -5.5805e-02, -9.0552e-03],\n",
       "                        [-2.2056e-02,  5.0449e-02, -5.1429e-02],\n",
       "                        [-1.8808e-03,  4.9386e-02, -4.4323e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.1865e-03, -1.0374e-02,  1.1058e-02],\n",
       "                        [-9.5257e-03, -2.1715e-02,  4.2139e-02],\n",
       "                        [-2.4292e-02,  2.7900e-02, -1.5294e-02]],\n",
       "              \n",
       "                       [[ 8.8792e-03, -2.8717e-02, -1.3956e-03],\n",
       "                        [ 5.0135e-02,  6.9728e-03,  7.8172e-03],\n",
       "                        [ 5.2708e-02,  4.7167e-02,  5.7319e-02]],\n",
       "              \n",
       "                       [[ 1.3235e-02, -3.8346e-02, -3.1878e-04],\n",
       "                        [-4.3744e-02,  3.3102e-02, -2.3570e-02],\n",
       "                        [-5.6052e-02, -4.3927e-02,  9.7141e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.6258e-02,  2.9435e-02,  1.2375e-02],\n",
       "                        [-2.8387e-02, -5.6064e-03,  2.5100e-03],\n",
       "                        [-5.2718e-02, -1.7928e-03, -1.3143e-02]],\n",
       "              \n",
       "                       [[-5.2138e-02,  2.8048e-02, -2.2787e-02],\n",
       "                        [-8.7998e-03, -2.6952e-02, -6.4773e-03],\n",
       "                        [-4.1986e-02,  1.1572e-02, -4.5631e-02]],\n",
       "              \n",
       "                       [[-2.8919e-02,  7.0902e-04,  2.2585e-02],\n",
       "                        [ 4.0855e-02,  4.8583e-02,  4.0603e-02],\n",
       "                        [-2.0832e-02, -3.0252e-02,  2.9766e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3528e-02, -1.7415e-02, -6.7281e-03],\n",
       "                        [-4.8765e-02, -4.4322e-02, -5.7901e-02],\n",
       "                        [-2.1329e-02,  4.4490e-02,  4.0077e-02]],\n",
       "              \n",
       "                       [[-3.6785e-02, -5.1075e-02,  1.2645e-02],\n",
       "                        [-2.5944e-03, -1.5318e-02, -3.1610e-02],\n",
       "                        [-4.5328e-03, -5.3681e-02,  4.0366e-02]],\n",
       "              \n",
       "                       [[-2.1634e-02, -4.2168e-02, -6.1944e-03],\n",
       "                        [-5.3504e-02, -5.1260e-02, -9.8679e-03],\n",
       "                        [-3.6464e-02,  4.6582e-02, -1.0814e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.2578e-02, -3.1585e-02, -4.0496e-02],\n",
       "                        [ 6.1058e-03,  2.8145e-02,  1.0691e-02],\n",
       "                        [ 4.8837e-02, -3.1400e-02, -6.9201e-03]],\n",
       "              \n",
       "                       [[ 2.5596e-02, -5.2583e-02, -4.5670e-02],\n",
       "                        [-5.7487e-02,  4.1544e-02, -4.9774e-03],\n",
       "                        [-5.0208e-02, -5.5299e-02,  3.1031e-02]],\n",
       "              \n",
       "                       [[-4.5895e-02, -1.7756e-02, -1.4733e-02],\n",
       "                        [ 1.3965e-02,  1.8682e-02,  5.1562e-03],\n",
       "                        [-3.8793e-02, -5.6955e-02, -5.8279e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.9310e-02, -4.8297e-02,  3.7630e-02],\n",
       "                        [-1.7800e-02, -5.1143e-02,  3.3314e-02],\n",
       "                        [-3.5935e-02, -4.9845e-02, -1.4949e-02]],\n",
       "              \n",
       "                       [[ 4.7932e-02,  2.5695e-03,  1.4611e-02],\n",
       "                        [-5.4929e-02,  2.2809e-02,  4.2184e-02],\n",
       "                        [-3.3021e-02, -3.6605e-02, -3.3308e-02]],\n",
       "              \n",
       "                       [[-3.5957e-02, -3.1300e-02,  6.8994e-03],\n",
       "                        [-4.3257e-02, -6.8798e-03,  8.6650e-04],\n",
       "                        [-1.6022e-02, -1.0615e-02,  2.1654e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.2627e-02, -4.6412e-02,  2.1681e-02],\n",
       "                        [-7.3306e-03, -2.2319e-02,  2.3060e-02],\n",
       "                        [-3.3394e-02,  1.8743e-02, -2.4403e-02]],\n",
       "              \n",
       "                       [[-1.1023e-02,  4.6091e-02,  3.3115e-02],\n",
       "                        [ 4.4729e-02,  2.9854e-03,  2.7621e-02],\n",
       "                        [-5.5587e-02, -3.8664e-02, -4.6150e-02]],\n",
       "              \n",
       "                       [[ 3.6434e-02, -4.9661e-02, -4.0837e-02],\n",
       "                        [ 2.4252e-02,  4.0306e-02,  3.5250e-03],\n",
       "                        [-4.5607e-02, -3.0471e-02, -3.1894e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.0.original.bias',\n",
       "              tensor([ 0.0500, -0.0425,  0.0408,  0.0401, -0.0346, -0.0462, -0.0070, -0.0058,\n",
       "                       0.0329, -0.0584,  0.0289, -0.0529, -0.0572, -0.0121, -0.0117,  0.0013,\n",
       "                      -0.0403, -0.0170,  0.0163, -0.0062, -0.0429, -0.0513, -0.0058, -0.0077,\n",
       "                       0.0425,  0.0415,  0.0074, -0.0587,  0.0120, -0.0141,  0.0109,  0.0044],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[ 0.0010]],\n",
       "              \n",
       "                       [[ 0.0234]],\n",
       "              \n",
       "                       [[ 0.0029]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0140]],\n",
       "              \n",
       "                       [[ 0.0037]],\n",
       "              \n",
       "                       [[-0.0045]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0282]],\n",
       "              \n",
       "                       [[ 0.0332]],\n",
       "              \n",
       "                       [[-0.2287]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0104]],\n",
       "              \n",
       "                       [[ 0.0072]],\n",
       "              \n",
       "                       [[-0.0675]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0086]],\n",
       "              \n",
       "                       [[ 0.0150]],\n",
       "              \n",
       "                       [[ 0.0113]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0306]],\n",
       "              \n",
       "                       [[ 0.0226]],\n",
       "              \n",
       "                       [[-0.0066]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0046]],\n",
       "              \n",
       "                       [[-0.0345]],\n",
       "              \n",
       "                       [[ 0.1372]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0286]],\n",
       "              \n",
       "                       [[ 0.0235]],\n",
       "              \n",
       "                       [[ 0.0260]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0082]],\n",
       "              \n",
       "                       [[ 0.0239]],\n",
       "              \n",
       "                       [[-0.0052]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0119]],\n",
       "              \n",
       "                       [[-0.0089]],\n",
       "              \n",
       "                       [[ 0.0026]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0039]],\n",
       "              \n",
       "                       [[-0.0334]],\n",
       "              \n",
       "                       [[-0.0034]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0064]],\n",
       "              \n",
       "                       [[-0.0013]],\n",
       "              \n",
       "                       [[ 0.0031]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[-0.0095]],\n",
       "              \n",
       "                       [[ 0.1632]],\n",
       "              \n",
       "                       [[ 0.0054]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0812]],\n",
       "              \n",
       "                       [[-0.0090]],\n",
       "              \n",
       "                       [[ 0.0061]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0192]],\n",
       "              \n",
       "                       [[-0.0373]],\n",
       "              \n",
       "                       [[-0.0106]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0110]],\n",
       "              \n",
       "                       [[ 0.0174]],\n",
       "              \n",
       "                       [[-0.0169]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0059]],\n",
       "              \n",
       "                       [[-0.0687]],\n",
       "              \n",
       "                       [[-0.0196]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0252]],\n",
       "              \n",
       "                       [[ 0.0014]],\n",
       "              \n",
       "                       [[ 0.0105]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0124]],\n",
       "              \n",
       "                       [[-0.0574]],\n",
       "              \n",
       "                       [[-0.0289]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0116]],\n",
       "              \n",
       "                       [[-0.0115]],\n",
       "              \n",
       "                       [[ 0.0223]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0134]],\n",
       "              \n",
       "                       [[-0.0621]],\n",
       "              \n",
       "                       [[-0.0123]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0197]],\n",
       "              \n",
       "                       [[ 0.0073]],\n",
       "              \n",
       "                       [[-0.0098]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0065]],\n",
       "              \n",
       "                       [[-0.0099]],\n",
       "              \n",
       "                       [[-0.0298]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0146]],\n",
       "              \n",
       "                       [[-0.0024]],\n",
       "              \n",
       "                       [[ 0.0158]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.weight',\n",
       "              tensor([1.0375, 1.0764, 1.0531, 0.6979, 0.9139, 1.0278, 0.8562, 0.9206, 0.8194,\n",
       "                      0.8864, 0.7883, 0.8075, 0.9479, 1.0579, 1.0451, 0.9979, 1.1076, 0.9029,\n",
       "                      0.9954, 1.1381, 1.0117, 0.8514, 0.8643, 1.0778, 0.9577, 0.9141, 0.9684,\n",
       "                      0.9776, 0.8291, 1.0702, 1.1192, 0.7653], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.bias',\n",
       "              tensor([-0.2946, -0.2842, -0.3467, -0.3136, -0.3024, -0.1448, -0.3847, -0.3373,\n",
       "                      -0.4570, -0.4604, -0.3715, -0.4840, -0.4915, -0.3742, -0.3148, -0.2415,\n",
       "                      -0.3409, -0.4140, -0.0422, -0.2652, -0.1386, -0.2627, -0.4362, -0.2377,\n",
       "                      -0.4334, -0.4688, -0.4684, -0.2662, -0.3675, -0.1374, -0.1229, -0.2075],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.running_mean',\n",
       "              tensor([-0.3397, -0.0438,  0.2821,  0.2860, -0.0147, -0.2716, -0.5016,  0.0757,\n",
       "                      -0.4976, -0.4798,  0.0486, -0.2449, -0.0727, -0.3410,  0.0326, -0.0583,\n",
       "                      -0.5374, -0.2570, -0.5994,  0.2309, -0.3840, -0.4217, -0.3417, -0.4705,\n",
       "                      -0.2363,  0.0691,  0.2514,  0.0417, -0.0207, -0.1087, -0.1175,  0.0183],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.running_var',\n",
       "              tensor([0.3546, 0.2224, 0.3521, 0.2188, 0.0909, 0.4277, 0.3488, 0.3922, 0.2840,\n",
       "                      0.4122, 0.1594, 0.2793, 0.1145, 0.2871, 0.0659, 0.2737, 0.6385, 0.2656,\n",
       "                      0.5650, 0.3953, 0.5267, 0.4384, 0.2443, 0.5456, 0.0984, 0.1646, 0.2710,\n",
       "                      0.2012, 0.2019, 0.3833, 0.4408, 0.2590], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.4.original.weight',\n",
       "              tensor([[[[ 0.0587,  0.0267, -0.0377],\n",
       "                        [ 0.0417,  0.0181,  0.0491],\n",
       "                        [ 0.0354, -0.0499, -0.0524]],\n",
       "              \n",
       "                       [[-0.0263, -0.0022,  0.0363],\n",
       "                        [ 0.0526,  0.0449, -0.0258],\n",
       "                        [-0.0465,  0.0040, -0.0182]],\n",
       "              \n",
       "                       [[ 0.0381,  0.0094, -0.0185],\n",
       "                        [-0.0254, -0.0561,  0.0196],\n",
       "                        [ 0.0501, -0.0024, -0.0239]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0027, -0.0405,  0.0315],\n",
       "                        [-0.0082,  0.0460, -0.0075],\n",
       "                        [ 0.0152,  0.0426,  0.0337]],\n",
       "              \n",
       "                       [[ 0.0231,  0.0440, -0.0132],\n",
       "                        [ 0.0021,  0.0415,  0.0174],\n",
       "                        [ 0.0332, -0.0490,  0.0121]],\n",
       "              \n",
       "                       [[-0.0037, -0.0503,  0.0156],\n",
       "                        [-0.0522,  0.0164, -0.0277],\n",
       "                        [ 0.0448, -0.0074,  0.0472]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0041, -0.0423, -0.0491],\n",
       "                        [-0.0233, -0.0256,  0.0396],\n",
       "                        [-0.0311,  0.0537,  0.0092]],\n",
       "              \n",
       "                       [[ 0.0322, -0.0557, -0.0579],\n",
       "                        [-0.0550,  0.0474, -0.0576],\n",
       "                        [-0.0175, -0.0183,  0.0300]],\n",
       "              \n",
       "                       [[-0.0486, -0.0256, -0.0059],\n",
       "                        [-0.0179,  0.0029,  0.0459],\n",
       "                        [ 0.0255,  0.0098,  0.0181]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0339,  0.0222, -0.0198],\n",
       "                        [ 0.0525, -0.0182, -0.0523],\n",
       "                        [-0.0215,  0.0424, -0.0576]],\n",
       "              \n",
       "                       [[ 0.0168, -0.0428,  0.0284],\n",
       "                        [ 0.0200,  0.0583,  0.0047],\n",
       "                        [-0.0162, -0.0068,  0.0446]],\n",
       "              \n",
       "                       [[ 0.0115, -0.0525,  0.0187],\n",
       "                        [-0.0571,  0.0072,  0.0043],\n",
       "                        [ 0.0307, -0.0236,  0.0301]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0489, -0.0507,  0.0241],\n",
       "                        [ 0.0335,  0.0318,  0.0200],\n",
       "                        [ 0.0360,  0.0308, -0.0392]],\n",
       "              \n",
       "                       [[-0.0345,  0.0343,  0.0368],\n",
       "                        [ 0.0252, -0.0342,  0.0302],\n",
       "                        [ 0.0044,  0.0530,  0.0107]],\n",
       "              \n",
       "                       [[-0.0530,  0.0093,  0.0120],\n",
       "                        [-0.0449, -0.0374,  0.0578],\n",
       "                        [ 0.0003,  0.0532,  0.0200]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0307,  0.0138, -0.0277],\n",
       "                        [-0.0006, -0.0467, -0.0127],\n",
       "                        [-0.0235, -0.0460,  0.0218]],\n",
       "              \n",
       "                       [[ 0.0415, -0.0429,  0.0584],\n",
       "                        [-0.0039, -0.0077, -0.0486],\n",
       "                        [ 0.0032, -0.0196, -0.0544]],\n",
       "              \n",
       "                       [[ 0.0295, -0.0372, -0.0559],\n",
       "                        [ 0.0243,  0.0030, -0.0223],\n",
       "                        [-0.0364,  0.0204,  0.0508]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0136, -0.0284, -0.0133],\n",
       "                        [ 0.0236, -0.0550, -0.0464],\n",
       "                        [-0.0049,  0.0256,  0.0060]],\n",
       "              \n",
       "                       [[ 0.0159,  0.0132,  0.0149],\n",
       "                        [ 0.0134, -0.0271, -0.0269],\n",
       "                        [ 0.0407, -0.0284, -0.0331]],\n",
       "              \n",
       "                       [[-0.0202,  0.0026, -0.0170],\n",
       "                        [-0.0274, -0.0524,  0.0556],\n",
       "                        [-0.0411, -0.0142, -0.0083]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0139, -0.0295, -0.0236],\n",
       "                        [ 0.0195,  0.0263,  0.0323],\n",
       "                        [ 0.0506,  0.0119, -0.0157]],\n",
       "              \n",
       "                       [[-0.0003,  0.0513,  0.0554],\n",
       "                        [ 0.0410, -0.0574, -0.0168],\n",
       "                        [ 0.0349,  0.0487,  0.0321]],\n",
       "              \n",
       "                       [[-0.0574, -0.0187, -0.0561],\n",
       "                        [ 0.0126, -0.0448,  0.0557],\n",
       "                        [-0.0179, -0.0474, -0.0094]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0028,  0.0221, -0.0022],\n",
       "                        [-0.0292,  0.0441,  0.0251],\n",
       "                        [ 0.0061, -0.0368, -0.0133]],\n",
       "              \n",
       "                       [[-0.0473,  0.0040, -0.0248],\n",
       "                        [-0.0359, -0.0528, -0.0537],\n",
       "                        [ 0.0263,  0.0275,  0.0410]],\n",
       "              \n",
       "                       [[-0.0527,  0.0499,  0.0584],\n",
       "                        [ 0.0410, -0.0563, -0.0222],\n",
       "                        [ 0.0428,  0.0480,  0.0355]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0484,  0.0011,  0.0403],\n",
       "                        [-0.0071, -0.0274,  0.0345],\n",
       "                        [-0.0037,  0.0147, -0.0220]],\n",
       "              \n",
       "                       [[-0.0494,  0.0129,  0.0231],\n",
       "                        [ 0.0005, -0.0327, -0.0572],\n",
       "                        [-0.0529,  0.0263,  0.0491]],\n",
       "              \n",
       "                       [[ 0.0238,  0.0311,  0.0443],\n",
       "                        [-0.0058,  0.0410,  0.0097],\n",
       "                        [-0.0183, -0.0256, -0.0157]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0497, -0.0301, -0.0266],\n",
       "                        [-0.0003, -0.0393,  0.0187],\n",
       "                        [-0.0222,  0.0020,  0.0484]],\n",
       "              \n",
       "                       [[-0.0440, -0.0234,  0.0540],\n",
       "                        [ 0.0246, -0.0348,  0.0109],\n",
       "                        [ 0.0530,  0.0251,  0.0404]],\n",
       "              \n",
       "                       [[-0.0581,  0.0121, -0.0528],\n",
       "                        [ 0.0302, -0.0212,  0.0181],\n",
       "                        [ 0.0455,  0.0257,  0.0515]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0490, -0.0137, -0.0487],\n",
       "                        [-0.0215,  0.0575,  0.0548],\n",
       "                        [ 0.0396,  0.0573, -0.0208]],\n",
       "              \n",
       "                       [[ 0.0074,  0.0305,  0.0243],\n",
       "                        [-0.0411, -0.0245, -0.0400],\n",
       "                        [ 0.0581,  0.0171, -0.0345]],\n",
       "              \n",
       "                       [[-0.0548,  0.0214, -0.0263],\n",
       "                        [ 0.0535, -0.0581,  0.0432],\n",
       "                        [ 0.0075,  0.0057,  0.0510]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.4.original.bias',\n",
       "              tensor([ 0.0530, -0.0066, -0.0576, -0.0365,  0.0222,  0.0118, -0.0320, -0.0461,\n",
       "                      -0.0400,  0.0304, -0.0555, -0.0414, -0.0123,  0.0347,  0.0369,  0.0330,\n",
       "                      -0.0107,  0.0452,  0.0392, -0.0147,  0.0380, -0.0226,  0.0037,  0.0033,\n",
       "                       0.0076,  0.0283, -0.0118,  0.0142,  0.0534,  0.0268, -0.0146,  0.0417],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-1.6089e-02]],\n",
       "              \n",
       "                       [[ 1.5685e-01]],\n",
       "              \n",
       "                       [[ 1.3850e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.1263e-01]],\n",
       "              \n",
       "                       [[ 2.4729e-01]],\n",
       "              \n",
       "                       [[ 1.9814e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5363e-02]],\n",
       "              \n",
       "                       [[-1.6721e-02]],\n",
       "              \n",
       "                       [[-6.5390e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2054e-02]],\n",
       "              \n",
       "                       [[ 2.1075e-03]],\n",
       "              \n",
       "                       [[-1.3609e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0940e-02]],\n",
       "              \n",
       "                       [[-1.0644e-02]],\n",
       "              \n",
       "                       [[ 6.5431e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.8631e-02]],\n",
       "              \n",
       "                       [[-5.1214e-02]],\n",
       "              \n",
       "                       [[-2.4106e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 6.1527e-02]],\n",
       "              \n",
       "                       [[-1.2689e-01]],\n",
       "              \n",
       "                       [[-1.0540e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.6798e-02]],\n",
       "              \n",
       "                       [[-1.8309e-01]],\n",
       "              \n",
       "                       [[-1.3878e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.6879e-02]],\n",
       "              \n",
       "                       [[-3.8914e-02]],\n",
       "              \n",
       "                       [[-8.2546e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.5871e-02]],\n",
       "              \n",
       "                       [[-1.0554e-01]],\n",
       "              \n",
       "                       [[-1.0402e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.6076e-03]],\n",
       "              \n",
       "                       [[ 1.2142e-02]],\n",
       "              \n",
       "                       [[ 8.3928e-05]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5671e-04]],\n",
       "              \n",
       "                       [[ 1.5044e-02]],\n",
       "              \n",
       "                       [[-1.0913e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.1517]],\n",
       "              \n",
       "                       [[ 0.0264]],\n",
       "              \n",
       "                       [[ 0.0009]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1354]],\n",
       "              \n",
       "                       [[-0.0521]],\n",
       "              \n",
       "                       [[ 0.0212]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1161]],\n",
       "              \n",
       "                       [[ 0.0221]],\n",
       "              \n",
       "                       [[ 0.0213]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0867]],\n",
       "              \n",
       "                       [[-0.0063]],\n",
       "              \n",
       "                       [[-0.0223]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0470]],\n",
       "              \n",
       "                       [[ 0.0100]],\n",
       "              \n",
       "                       [[ 0.0069]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0378]],\n",
       "              \n",
       "                       [[ 0.0188]],\n",
       "              \n",
       "                       [[ 0.0129]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0449]],\n",
       "              \n",
       "                       [[ 0.0398]],\n",
       "              \n",
       "                       [[ 0.0574]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0219]],\n",
       "              \n",
       "                       [[ 0.0130]],\n",
       "              \n",
       "                       [[ 0.0009]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1461]],\n",
       "              \n",
       "                       [[ 0.0139]],\n",
       "              \n",
       "                       [[ 0.0061]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1372]],\n",
       "              \n",
       "                       [[-0.0787]],\n",
       "              \n",
       "                       [[ 0.0158]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0802]],\n",
       "              \n",
       "                       [[-0.0146]],\n",
       "              \n",
       "                       [[-0.0259]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0894]],\n",
       "              \n",
       "                       [[ 0.0067]],\n",
       "              \n",
       "                       [[-0.0119]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.weight',\n",
       "              tensor([1.0129, 1.0008, 1.0340, 1.0419, 0.8157, 0.9287, 1.1636, 1.0492, 1.0395,\n",
       "                      0.9117, 0.8745, 1.2123, 1.0518, 1.0612, 0.7748, 1.0755, 1.0289, 0.7953,\n",
       "                      1.1411, 1.0187, 1.0647, 0.7865, 0.8982, 0.9976, 1.0632, 0.9892, 0.8850,\n",
       "                      0.9911, 1.0205, 1.0375, 1.0654, 0.9222], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.bias',\n",
       "              tensor([-0.2969, -0.0855,  0.0189, -0.0224, -0.1316, -0.2554, -0.3078, -0.0547,\n",
       "                      -0.1326, -0.1148, -0.2188,  0.0335, -0.1522, -0.1695, -0.2466, -0.2233,\n",
       "                      -0.1684, -0.2024, -0.0289, -0.2044,  0.1872, -0.0651, -0.0269, -0.4588,\n",
       "                      -0.3597, -0.0724, -0.2079, -0.2491, -0.5101, -0.1933, -0.2028, -0.3234],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.running_mean',\n",
       "              tensor([ 0.0307, -0.4223, -0.3127,  0.0242, -0.1081,  0.1097, -0.4479, -0.3429,\n",
       "                      -0.2314, -0.2901, -0.3500,  0.1882, -0.2091, -0.4207, -0.1790, -0.2238,\n",
       "                       0.0344, -0.3045, -0.3811, -0.2015, -0.1046, -0.1501, -0.1709,  0.1132,\n",
       "                      -0.1975, -0.0697, -0.1588, -0.0609,  0.0524, -0.2854, -0.0445,  0.2111],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.running_var',\n",
       "              tensor([0.3023, 0.3687, 0.5259, 0.1958, 0.5626, 0.4523, 0.4221, 0.3046, 0.0962,\n",
       "                      0.4312, 0.3679, 0.8595, 0.6683, 0.4860, 0.3492, 0.3147, 0.8004, 0.4114,\n",
       "                      0.5212, 0.6998, 0.0853, 0.1356, 0.3440, 0.2632, 0.1042, 0.5370, 0.3846,\n",
       "                      0.1374, 0.3162, 0.4920, 0.3819, 0.4546], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.0.original.weight',\n",
       "              tensor([[[[-0.0033, -0.0466, -0.0397],\n",
       "                        [-0.0329, -0.0139, -0.0158],\n",
       "                        [ 0.0102,  0.0575, -0.0085]],\n",
       "              \n",
       "                       [[-0.0465, -0.0384,  0.0153],\n",
       "                        [-0.0278,  0.0309, -0.0379],\n",
       "                        [-0.0169,  0.0009, -0.0580]],\n",
       "              \n",
       "                       [[-0.0315,  0.0572, -0.0156],\n",
       "                        [ 0.0057,  0.0457,  0.0549],\n",
       "                        [ 0.0333,  0.0083,  0.0076]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0203, -0.0140, -0.0424],\n",
       "                        [ 0.0033,  0.0069, -0.0157],\n",
       "                        [-0.0171, -0.0106,  0.0095]],\n",
       "              \n",
       "                       [[-0.0297, -0.0556, -0.0091],\n",
       "                        [-0.0070, -0.0137,  0.0482],\n",
       "                        [-0.0380,  0.0334,  0.0092]],\n",
       "              \n",
       "                       [[ 0.0031,  0.0241,  0.0215],\n",
       "                        [ 0.0279, -0.0066, -0.0267],\n",
       "                        [-0.0073, -0.0083,  0.0289]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0028,  0.0036, -0.0069],\n",
       "                        [-0.0259,  0.0142,  0.0141],\n",
       "                        [ 0.0036,  0.0480, -0.0116]],\n",
       "              \n",
       "                       [[-0.0229,  0.0403, -0.0582],\n",
       "                        [-0.0083,  0.0585,  0.0004],\n",
       "                        [ 0.0499,  0.0171,  0.0008]],\n",
       "              \n",
       "                       [[ 0.0398, -0.0546, -0.0104],\n",
       "                        [-0.0466,  0.0415,  0.0084],\n",
       "                        [ 0.0007,  0.0074,  0.0068]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0378, -0.0376, -0.0430],\n",
       "                        [-0.0039,  0.0252,  0.0575],\n",
       "                        [-0.0339,  0.0463,  0.0440]],\n",
       "              \n",
       "                       [[-0.0216,  0.0075, -0.0364],\n",
       "                        [-0.0479,  0.0480,  0.0053],\n",
       "                        [-0.0476, -0.0372,  0.0557]],\n",
       "              \n",
       "                       [[ 0.0426, -0.0077,  0.0010],\n",
       "                        [-0.0400,  0.0298,  0.0084],\n",
       "                        [ 0.0481, -0.0076, -0.0158]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0165, -0.0126, -0.0576],\n",
       "                        [-0.0390,  0.0236,  0.0019],\n",
       "                        [-0.0441,  0.0071, -0.0454]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0212,  0.0064],\n",
       "                        [ 0.0453,  0.0374,  0.0101],\n",
       "                        [-0.0462,  0.0556,  0.0158]],\n",
       "              \n",
       "                       [[-0.0015, -0.0064,  0.0390],\n",
       "                        [-0.0356,  0.0077, -0.0106],\n",
       "                        [ 0.0382, -0.0163, -0.0343]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0122,  0.0517, -0.0377],\n",
       "                        [-0.0467,  0.0421, -0.0448],\n",
       "                        [-0.0526, -0.0084, -0.0510]],\n",
       "              \n",
       "                       [[ 0.0333, -0.0324, -0.0429],\n",
       "                        [ 0.0545,  0.0234,  0.0281],\n",
       "                        [ 0.0147, -0.0382, -0.0460]],\n",
       "              \n",
       "                       [[-0.0325, -0.0521,  0.0498],\n",
       "                        [-0.0551,  0.0144,  0.0189],\n",
       "                        [-0.0534, -0.0522,  0.0588]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0021, -0.0113, -0.0002],\n",
       "                        [ 0.0163,  0.0107, -0.0080],\n",
       "                        [ 0.0548, -0.0011,  0.0573]],\n",
       "              \n",
       "                       [[-0.0042,  0.0455, -0.0246],\n",
       "                        [ 0.0091,  0.0462,  0.0067],\n",
       "                        [-0.0379, -0.0275,  0.0153]],\n",
       "              \n",
       "                       [[-0.0068, -0.0313, -0.0246],\n",
       "                        [-0.0226,  0.0124,  0.0340],\n",
       "                        [-0.0478,  0.0184, -0.0497]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0492,  0.0547, -0.0321],\n",
       "                        [-0.0417, -0.0133, -0.0297],\n",
       "                        [ 0.0427,  0.0411, -0.0480]],\n",
       "              \n",
       "                       [[-0.0269, -0.0264,  0.0173],\n",
       "                        [ 0.0380, -0.0273, -0.0338],\n",
       "                        [ 0.0247, -0.0510, -0.0256]],\n",
       "              \n",
       "                       [[ 0.0384, -0.0166,  0.0170],\n",
       "                        [ 0.0143, -0.0505,  0.0566],\n",
       "                        [-0.0563, -0.0432,  0.0188]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0329, -0.0143, -0.0074],\n",
       "                        [ 0.0521, -0.0353,  0.0289],\n",
       "                        [-0.0267,  0.0240, -0.0215]],\n",
       "              \n",
       "                       [[ 0.0230,  0.0547,  0.0198],\n",
       "                        [-0.0182, -0.0571,  0.0558],\n",
       "                        [-0.0159,  0.0295, -0.0521]],\n",
       "              \n",
       "                       [[-0.0056,  0.0430,  0.0172],\n",
       "                        [-0.0134,  0.0278,  0.0382],\n",
       "                        [-0.0527,  0.0568, -0.0060]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0204,  0.0276, -0.0038],\n",
       "                        [ 0.0308, -0.0138, -0.0056],\n",
       "                        [-0.0479,  0.0113,  0.0290]],\n",
       "              \n",
       "                       [[ 0.0393,  0.0497, -0.0344],\n",
       "                        [ 0.0181,  0.0013,  0.0505],\n",
       "                        [ 0.0037, -0.0587,  0.0107]],\n",
       "              \n",
       "                       [[ 0.0179, -0.0257, -0.0516],\n",
       "                        [ 0.0261,  0.0268, -0.0491],\n",
       "                        [-0.0140, -0.0152,  0.0009]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0084, -0.0045, -0.0463],\n",
       "                        [ 0.0257,  0.0266, -0.0172],\n",
       "                        [ 0.0456,  0.0401, -0.0535]],\n",
       "              \n",
       "                       [[ 0.0110,  0.0371, -0.0432],\n",
       "                        [-0.0309,  0.0256, -0.0275],\n",
       "                        [-0.0209, -0.0424,  0.0075]],\n",
       "              \n",
       "                       [[ 0.0545,  0.0191,  0.0240],\n",
       "                        [-0.0136, -0.0511,  0.0341],\n",
       "                        [-0.0039,  0.0515, -0.0222]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0024, -0.0405,  0.0528],\n",
       "                        [-0.0445, -0.0308,  0.0050],\n",
       "                        [-0.0098,  0.0196,  0.0205]],\n",
       "              \n",
       "                       [[ 0.0293, -0.0424,  0.0055],\n",
       "                        [ 0.0286,  0.0079,  0.0037],\n",
       "                        [-0.0056,  0.0449,  0.0378]],\n",
       "              \n",
       "                       [[-0.0328, -0.0390, -0.0193],\n",
       "                        [ 0.0132, -0.0101,  0.0028],\n",
       "                        [-0.0554, -0.0032,  0.0574]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.0.original.bias',\n",
       "              tensor([-0.0295,  0.0056, -0.0154, -0.0331,  0.0555,  0.0026, -0.0543, -0.0290,\n",
       "                       0.0528, -0.0265,  0.0584,  0.0551,  0.0465,  0.0341,  0.0211, -0.0218,\n",
       "                       0.0562,  0.0486, -0.0421, -0.0463,  0.0321,  0.0156, -0.0012,  0.0348,\n",
       "                       0.0087, -0.0531,  0.0288,  0.0251,  0.0422, -0.0259, -0.0574, -0.0084],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[ 0.0008]],\n",
       "              \n",
       "                       [[-0.0104]],\n",
       "              \n",
       "                       [[ 0.0040]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0325]],\n",
       "              \n",
       "                       [[ 0.0875]],\n",
       "              \n",
       "                       [[-0.0109]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0039]],\n",
       "              \n",
       "                       [[-0.0003]],\n",
       "              \n",
       "                       [[ 0.0126]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0006]],\n",
       "              \n",
       "                       [[ 0.0080]],\n",
       "              \n",
       "                       [[ 0.0280]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2008]],\n",
       "              \n",
       "                       [[-0.0521]],\n",
       "              \n",
       "                       [[ 0.0809]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0248]],\n",
       "              \n",
       "                       [[-0.2140]],\n",
       "              \n",
       "                       [[ 0.0617]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0062]],\n",
       "              \n",
       "                       [[-0.0046]],\n",
       "              \n",
       "                       [[-0.0092]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0302]],\n",
       "              \n",
       "                       [[ 0.0018]],\n",
       "              \n",
       "                       [[ 0.0406]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0961]],\n",
       "              \n",
       "                       [[-0.0243]],\n",
       "              \n",
       "                       [[ 0.1081]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0048]],\n",
       "              \n",
       "                       [[-0.0419]],\n",
       "              \n",
       "                       [[ 0.0340]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0488]],\n",
       "              \n",
       "                       [[-0.0629]],\n",
       "              \n",
       "                       [[ 0.0353]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008]],\n",
       "              \n",
       "                       [[ 0.0928]],\n",
       "              \n",
       "                       [[-0.0317]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.0366]],\n",
       "              \n",
       "                       [[-0.0205]],\n",
       "              \n",
       "                       [[-0.1753]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0078]],\n",
       "              \n",
       "                       [[-0.1243]],\n",
       "              \n",
       "                       [[-0.0181]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0485]],\n",
       "              \n",
       "                       [[ 0.0081]],\n",
       "              \n",
       "                       [[-0.0110]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0376]],\n",
       "              \n",
       "                       [[-0.0008]],\n",
       "              \n",
       "                       [[ 0.0272]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0063]],\n",
       "              \n",
       "                       [[ 0.0187]],\n",
       "              \n",
       "                       [[ 0.1150]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0056]],\n",
       "              \n",
       "                       [[ 0.0240]],\n",
       "              \n",
       "                       [[ 0.0129]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0418]],\n",
       "              \n",
       "                       [[ 0.0321]],\n",
       "              \n",
       "                       [[ 0.1046]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0836]],\n",
       "              \n",
       "                       [[ 0.0885]],\n",
       "              \n",
       "                       [[ 0.0687]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0870]],\n",
       "              \n",
       "                       [[ 0.0146]],\n",
       "              \n",
       "                       [[-0.0074]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0007]],\n",
       "              \n",
       "                       [[-0.0062]],\n",
       "              \n",
       "                       [[ 0.0896]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0312]],\n",
       "              \n",
       "                       [[ 0.0264]],\n",
       "              \n",
       "                       [[ 0.1961]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0180]],\n",
       "              \n",
       "                       [[ 0.0825]],\n",
       "              \n",
       "                       [[-0.0343]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.weight',\n",
       "              tensor([0.9976, 0.9982, 0.7829, 0.9369, 1.0097, 0.9289, 0.9347, 0.9270, 0.9270,\n",
       "                      0.9931, 1.1067, 0.9074, 0.8080, 1.0625, 1.0513, 1.0937, 1.0308, 0.9570,\n",
       "                      0.9114, 1.0577, 0.9804, 0.9650, 1.0450, 0.9841, 0.9373, 0.9694, 0.9245,\n",
       "                      0.9628, 0.9976, 0.9646, 0.9843, 0.8325], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.bias',\n",
       "              tensor([-0.2737, -0.2628, -0.2565, -0.1178, -0.3913, -0.3105, -0.4429, -0.2228,\n",
       "                      -0.1433, -0.2727,  0.1562, -0.1603, -0.0365, -0.1738, -0.4016, -0.0843,\n",
       "                      -0.1355, -0.1944, -0.2513, -0.2896, -0.2841, -0.3642, -0.2824, -0.3106,\n",
       "                      -0.3247, -0.2935, -0.2592, -0.2417, -0.2410, -0.2214, -0.4076, -0.1018],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.running_mean',\n",
       "              tensor([ 0.0032,  0.0169, -0.0858,  0.2632,  0.1325,  0.0287, -0.0619, -0.3325,\n",
       "                      -0.2113, -0.2125, -0.1223, -0.0481,  0.1208, -0.0814, -0.1147, -0.2953,\n",
       "                       0.0863, -0.1226,  0.4124, -0.0100, -0.1940, -0.2539, -0.1525, -0.0364,\n",
       "                       0.0439,  0.1527, -0.0145, -0.1963, -0.1172, -0.4066, -0.3007,  0.2109],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.running_var',\n",
       "              tensor([0.6309, 0.1830, 0.2165, 0.1778, 0.3800, 0.1173, 0.5607, 0.1972, 0.2804,\n",
       "                      0.4059, 0.3082, 0.2399, 0.1331, 0.7438, 0.7136, 0.3105, 0.6643, 0.1390,\n",
       "                      0.7233, 1.0506, 0.4647, 0.3133, 0.5862, 0.4698, 0.5117, 0.5884, 0.2049,\n",
       "                      0.1572, 0.3424, 0.2971, 0.2159, 0.8669], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.4.original.weight',\n",
       "              tensor([[[[ 0.0043, -0.0040, -0.0336],\n",
       "                        [ 0.0148, -0.0473,  0.0197],\n",
       "                        [ 0.0236, -0.0172, -0.0373]],\n",
       "              \n",
       "                       [[-0.0386,  0.0167, -0.0451],\n",
       "                        [-0.0357, -0.0020, -0.0082],\n",
       "                        [-0.0520,  0.0417,  0.0526]],\n",
       "              \n",
       "                       [[ 0.0009, -0.0525,  0.0027],\n",
       "                        [ 0.0523,  0.0084, -0.0173],\n",
       "                        [-0.0552, -0.0103, -0.0044]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0193, -0.0120, -0.0237],\n",
       "                        [ 0.0218,  0.0410,  0.0329],\n",
       "                        [-0.0143, -0.0270,  0.0404]],\n",
       "              \n",
       "                       [[ 0.0110, -0.0432, -0.0359],\n",
       "                        [-0.0485, -0.0046, -0.0269],\n",
       "                        [ 0.0227, -0.0200, -0.0395]],\n",
       "              \n",
       "                       [[ 0.0528, -0.0543,  0.0549],\n",
       "                        [-0.0003, -0.0502, -0.0404],\n",
       "                        [-0.0251,  0.0351,  0.0332]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0304,  0.0401, -0.0106],\n",
       "                        [ 0.0179, -0.0436, -0.0125],\n",
       "                        [-0.0395, -0.0564,  0.0558]],\n",
       "              \n",
       "                       [[ 0.0467,  0.0379,  0.0054],\n",
       "                        [-0.0020,  0.0476, -0.0272],\n",
       "                        [ 0.0075,  0.0236,  0.0300]],\n",
       "              \n",
       "                       [[-0.0367, -0.0067, -0.0377],\n",
       "                        [ 0.0213,  0.0428,  0.0453],\n",
       "                        [ 0.0162,  0.0009,  0.0063]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0346,  0.0174, -0.0316],\n",
       "                        [ 0.0492, -0.0510, -0.0272],\n",
       "                        [ 0.0295, -0.0071, -0.0486]],\n",
       "              \n",
       "                       [[ 0.0403, -0.0409,  0.0445],\n",
       "                        [ 0.0553,  0.0195, -0.0075],\n",
       "                        [ 0.0476, -0.0539, -0.0462]],\n",
       "              \n",
       "                       [[ 0.0151,  0.0098, -0.0265],\n",
       "                        [ 0.0099, -0.0563,  0.0553],\n",
       "                        [ 0.0494,  0.0560,  0.0329]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0136, -0.0070, -0.0186],\n",
       "                        [ 0.0269, -0.0508, -0.0562],\n",
       "                        [-0.0480,  0.0193, -0.0242]],\n",
       "              \n",
       "                       [[-0.0144,  0.0479, -0.0087],\n",
       "                        [-0.0336, -0.0030, -0.0187],\n",
       "                        [-0.0566, -0.0256, -0.0434]],\n",
       "              \n",
       "                       [[-0.0073,  0.0200,  0.0332],\n",
       "                        [ 0.0110,  0.0569,  0.0245],\n",
       "                        [-0.0579, -0.0544, -0.0574]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0204, -0.0465, -0.0005],\n",
       "                        [ 0.0282, -0.0091,  0.0239],\n",
       "                        [-0.0083,  0.0112, -0.0275]],\n",
       "              \n",
       "                       [[ 0.0530, -0.0475, -0.0197],\n",
       "                        [ 0.0225, -0.0294,  0.0049],\n",
       "                        [ 0.0176, -0.0310, -0.0032]],\n",
       "              \n",
       "                       [[ 0.0499, -0.0271, -0.0439],\n",
       "                        [ 0.0333, -0.0560,  0.0213],\n",
       "                        [-0.0279, -0.0358, -0.0579]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0371, -0.0068, -0.0226],\n",
       "                        [-0.0318,  0.0232, -0.0306],\n",
       "                        [-0.0508, -0.0130,  0.0569]],\n",
       "              \n",
       "                       [[-0.0283, -0.0452,  0.0155],\n",
       "                        [ 0.0057,  0.0197, -0.0370],\n",
       "                        [ 0.0172,  0.0043, -0.0049]],\n",
       "              \n",
       "                       [[ 0.0223,  0.0057,  0.0282],\n",
       "                        [ 0.0316, -0.0283, -0.0196],\n",
       "                        [-0.0182,  0.0289,  0.0445]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0523, -0.0226,  0.0374],\n",
       "                        [ 0.0276,  0.0511, -0.0514],\n",
       "                        [ 0.0267, -0.0219,  0.0314]],\n",
       "              \n",
       "                       [[-0.0391,  0.0485, -0.0211],\n",
       "                        [ 0.0296, -0.0489, -0.0327],\n",
       "                        [ 0.0149,  0.0215, -0.0486]],\n",
       "              \n",
       "                       [[ 0.0567, -0.0076,  0.0471],\n",
       "                        [ 0.0526,  0.0531,  0.0174],\n",
       "                        [ 0.0485,  0.0062,  0.0129]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0081, -0.0243,  0.0030],\n",
       "                        [ 0.0053,  0.0172, -0.0167],\n",
       "                        [ 0.0300,  0.0077,  0.0355]],\n",
       "              \n",
       "                       [[ 0.0161, -0.0105, -0.0111],\n",
       "                        [-0.0150, -0.0437, -0.0264],\n",
       "                        [-0.0426,  0.0100, -0.0311]],\n",
       "              \n",
       "                       [[ 0.0458, -0.0571,  0.0565],\n",
       "                        [-0.0095,  0.0395,  0.0392],\n",
       "                        [ 0.0293,  0.0235,  0.0019]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0113, -0.0069, -0.0142],\n",
       "                        [ 0.0511,  0.0497, -0.0105],\n",
       "                        [ 0.0446,  0.0402, -0.0086]],\n",
       "              \n",
       "                       [[ 0.0472, -0.0264,  0.0271],\n",
       "                        [ 0.0100, -0.0508, -0.0066],\n",
       "                        [ 0.0397, -0.0024, -0.0194]],\n",
       "              \n",
       "                       [[-0.0183, -0.0230, -0.0006],\n",
       "                        [-0.0273,  0.0153,  0.0271],\n",
       "                        [ 0.0269, -0.0525,  0.0216]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0023,  0.0353, -0.0407],\n",
       "                        [ 0.0189, -0.0107,  0.0263],\n",
       "                        [ 0.0104,  0.0474,  0.0548]],\n",
       "              \n",
       "                       [[ 0.0242,  0.0493,  0.0377],\n",
       "                        [-0.0003, -0.0506, -0.0442],\n",
       "                        [ 0.0504,  0.0286,  0.0544]],\n",
       "              \n",
       "                       [[ 0.0133, -0.0184, -0.0541],\n",
       "                        [ 0.0402,  0.0244,  0.0008],\n",
       "                        [-0.0160,  0.0209,  0.0344]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0237,  0.0204,  0.0324],\n",
       "                        [ 0.0526,  0.0038, -0.0298],\n",
       "                        [ 0.0558, -0.0132,  0.0110]],\n",
       "              \n",
       "                       [[-0.0111, -0.0432, -0.0355],\n",
       "                        [ 0.0536, -0.0534,  0.0293],\n",
       "                        [ 0.0345,  0.0281,  0.0061]],\n",
       "              \n",
       "                       [[-0.0517, -0.0225,  0.0149],\n",
       "                        [ 0.0377,  0.0283,  0.0239],\n",
       "                        [-0.0075, -0.0543,  0.0182]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.4.original.bias',\n",
       "              tensor([-0.0404,  0.0170, -0.0257,  0.0125, -0.0555, -0.0526, -0.0157,  0.0022,\n",
       "                       0.0013, -0.0411, -0.0432,  0.0068, -0.0440,  0.0370, -0.0564, -0.0075,\n",
       "                       0.0479,  0.0282, -0.0208, -0.0100, -0.0288,  0.0402,  0.0200, -0.0192,\n",
       "                      -0.0326, -0.0451,  0.0545, -0.0202,  0.0544, -0.0400,  0.0278, -0.0363],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-0.2013]],\n",
       "              \n",
       "                       [[-0.0732]],\n",
       "              \n",
       "                       [[-0.0394]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1146]],\n",
       "              \n",
       "                       [[-0.0508]],\n",
       "              \n",
       "                       [[-0.0687]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0272]],\n",
       "              \n",
       "                       [[-0.0579]],\n",
       "              \n",
       "                       [[ 0.0429]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0822]],\n",
       "              \n",
       "                       [[ 0.0419]],\n",
       "              \n",
       "                       [[ 0.0902]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0288]],\n",
       "              \n",
       "                       [[-0.0657]],\n",
       "              \n",
       "                       [[-0.0757]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0038]],\n",
       "              \n",
       "                       [[ 0.0303]],\n",
       "              \n",
       "                       [[-0.0454]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.1290]],\n",
       "              \n",
       "                       [[ 0.0530]],\n",
       "              \n",
       "                       [[ 0.0532]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1437]],\n",
       "              \n",
       "                       [[-0.0675]],\n",
       "              \n",
       "                       [[ 0.1280]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0269]],\n",
       "              \n",
       "                       [[ 0.0167]],\n",
       "              \n",
       "                       [[ 0.0023]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0105]],\n",
       "              \n",
       "                       [[ 0.0129]],\n",
       "              \n",
       "                       [[-0.0105]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0758]],\n",
       "              \n",
       "                       [[-0.0459]],\n",
       "              \n",
       "                       [[-0.0446]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0237]],\n",
       "              \n",
       "                       [[-0.0063]],\n",
       "              \n",
       "                       [[-0.0345]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.0316]],\n",
       "              \n",
       "                       [[-0.0473]],\n",
       "              \n",
       "                       [[-0.0131]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1051]],\n",
       "              \n",
       "                       [[ 0.0110]],\n",
       "              \n",
       "                       [[-0.0166]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1689]],\n",
       "              \n",
       "                       [[-0.0460]],\n",
       "              \n",
       "                       [[ 0.0085]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0380]],\n",
       "              \n",
       "                       [[-0.0167]],\n",
       "              \n",
       "                       [[ 0.0685]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0446]],\n",
       "              \n",
       "                       [[ 0.0401]],\n",
       "              \n",
       "                       [[ 0.0372]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1434]],\n",
       "              \n",
       "                       [[-0.0160]],\n",
       "              \n",
       "                       [[-0.0421]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0655]],\n",
       "              \n",
       "                       [[-0.0314]],\n",
       "              \n",
       "                       [[ 0.0178]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1225]],\n",
       "              \n",
       "                       [[-0.0298]],\n",
       "              \n",
       "                       [[ 0.0007]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0847]],\n",
       "              \n",
       "                       [[ 0.0090]],\n",
       "              \n",
       "                       [[ 0.0405]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0888]],\n",
       "              \n",
       "                       [[-0.0015]],\n",
       "              \n",
       "                       [[-0.0741]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1339]],\n",
       "              \n",
       "                       [[-0.0948]],\n",
       "              \n",
       "                       [[-0.0128]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0503]],\n",
       "              \n",
       "                       [[ 0.0118]],\n",
       "              \n",
       "                       [[ 0.1900]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.weight',\n",
       "              tensor([0.9582, 0.9958, 0.9362, 1.0709, 1.1220, 1.0453, 0.9592, 1.0156, 1.0295,\n",
       "                      0.9675, 1.0132, 0.9926, 0.9858, 0.9792, 1.0658, 1.0114, 0.9963, 1.0673,\n",
       "                      1.0578, 1.0882, 0.9917, 1.0441, 1.0200, 1.0210, 1.0624, 1.0150, 1.0154,\n",
       "                      0.9520, 0.9894, 1.0523, 0.8768, 0.9767], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.bias',\n",
       "              tensor([ 0.0205, -0.1797, -0.1316,  0.0248, -0.0076, -0.1178, -0.1601, -0.1660,\n",
       "                      -0.1558, -0.1763, -0.2130,  0.0301, -0.0604, -0.0774, -0.1052,  0.0106,\n",
       "                      -0.1473,  0.0595, -0.1071, -0.0493,  0.0226, -0.2728, -0.2564,  0.0286,\n",
       "                      -0.0311, -0.0524, -0.0493, -0.1468, -0.2396, -0.0657, -0.0578,  0.1355],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.running_mean',\n",
       "              tensor([-0.0460, -0.4522, -0.2402, -0.3761, -0.1880, -0.0181, -0.0093, -0.2206,\n",
       "                      -0.1252, -0.2153, -0.2170,  0.1187,  0.1426,  0.2072, -0.1240, -0.2472,\n",
       "                      -0.0987, -0.1817,  0.1191, -0.1570, -0.2562, -0.1801,  0.0328, -0.3645,\n",
       "                      -0.0663, -0.1554, -0.2320, -0.0376, -0.0474, -0.1199,  0.0027, -0.1574],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.running_var',\n",
       "              tensor([0.5433, 0.3576, 0.1918, 0.4767, 0.5436, 0.1341, 0.2246, 0.1768, 0.6090,\n",
       "                      0.2463, 0.2035, 0.1083, 0.2904, 0.1576, 0.1161, 0.2399, 0.2229, 0.3056,\n",
       "                      0.6716, 0.1440, 0.2732, 0.1602, 0.1057, 0.3002, 0.1720, 0.1245, 0.2847,\n",
       "                      0.1426, 0.1553, 0.2471, 0.2319, 0.1396], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.0.original.weight',\n",
       "              tensor([[[[-1.9470e-03,  5.3163e-02,  2.8977e-02],\n",
       "                        [ 3.1710e-02, -3.0833e-02,  4.4052e-02],\n",
       "                        [-2.4877e-02, -2.4929e-03,  1.9134e-02]],\n",
       "              \n",
       "                       [[-9.9955e-03, -4.1365e-02,  3.9505e-02],\n",
       "                        [-5.1833e-02, -1.8024e-02,  1.0134e-02],\n",
       "                        [ 5.5045e-02, -8.9848e-03,  3.8989e-02]],\n",
       "              \n",
       "                       [[ 1.1897e-02,  3.6886e-02,  7.1317e-03],\n",
       "                        [-4.5641e-03,  2.9112e-02, -8.7059e-03],\n",
       "                        [ 4.4762e-02, -2.3664e-02, -3.9175e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5648e-02, -1.6411e-02,  4.6867e-02],\n",
       "                        [ 4.7375e-02, -4.7902e-02, -3.1389e-03],\n",
       "                        [-1.5284e-02,  4.2869e-02, -3.8145e-02]],\n",
       "              \n",
       "                       [[ 3.5236e-02, -5.6156e-02,  3.9419e-02],\n",
       "                        [ 5.0258e-02, -2.1676e-02, -3.6642e-02],\n",
       "                        [-3.1214e-02,  5.5292e-02,  5.2685e-03]],\n",
       "              \n",
       "                       [[ 1.3663e-02,  4.5897e-02, -5.2374e-02],\n",
       "                        [ 3.9617e-02, -4.1875e-02,  3.3458e-02],\n",
       "                        [ 7.0674e-04, -3.8848e-02,  5.7728e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4878e-02,  2.8564e-02,  1.0109e-02],\n",
       "                        [ 1.2157e-02,  2.7393e-02, -4.2419e-02],\n",
       "                        [ 7.0532e-03,  3.7441e-02, -4.5260e-02]],\n",
       "              \n",
       "                       [[-5.2987e-02,  6.9967e-03, -5.5313e-02],\n",
       "                        [-1.3309e-02, -5.7471e-02, -4.3218e-02],\n",
       "                        [ 3.3373e-03,  4.1452e-02, -1.9792e-02]],\n",
       "              \n",
       "                       [[-2.0345e-02, -1.3575e-03, -1.5886e-02],\n",
       "                        [ 1.1404e-02, -9.5958e-03,  3.7892e-02],\n",
       "                        [-3.1053e-02,  4.9568e-02, -5.2646e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0416e-02, -3.7466e-02, -5.1478e-02],\n",
       "                        [ 2.9491e-02,  9.4521e-03, -1.9542e-02],\n",
       "                        [ 2.5559e-02, -5.7616e-02,  1.4104e-03]],\n",
       "              \n",
       "                       [[-3.1824e-02, -5.8450e-06, -4.5201e-02],\n",
       "                        [ 1.8326e-02,  4.3478e-03,  5.2395e-02],\n",
       "                        [-2.7495e-02,  7.7698e-03, -4.4875e-02]],\n",
       "              \n",
       "                       [[ 3.4698e-02, -5.7911e-02,  1.0991e-02],\n",
       "                        [ 3.7885e-02, -2.9425e-02, -2.5638e-02],\n",
       "                        [ 1.1281e-03,  1.6944e-02, -5.6787e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4778e-02, -6.9237e-03,  3.1375e-02],\n",
       "                        [ 5.8161e-02,  3.2075e-02, -2.8062e-02],\n",
       "                        [-2.2419e-02, -5.0626e-02, -3.5877e-02]],\n",
       "              \n",
       "                       [[ 1.7296e-02,  5.1880e-02, -6.4204e-03],\n",
       "                        [ 5.1569e-02, -2.8681e-02,  2.6556e-02],\n",
       "                        [-5.5275e-02,  7.6281e-03, -5.3473e-03]],\n",
       "              \n",
       "                       [[ 9.1566e-04,  3.2297e-02,  5.2085e-03],\n",
       "                        [ 2.6599e-03, -5.2116e-02, -2.3369e-02],\n",
       "                        [ 9.1995e-03, -3.5879e-02,  2.5556e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.0984e-02, -3.0586e-02,  1.3761e-02],\n",
       "                        [ 5.8654e-02,  3.8361e-02, -3.1609e-02],\n",
       "                        [ 7.1132e-03, -4.2692e-02,  1.9398e-03]],\n",
       "              \n",
       "                       [[ 5.7449e-02, -2.0609e-02, -3.7413e-02],\n",
       "                        [ 3.9289e-02,  4.5868e-02, -1.4679e-02],\n",
       "                        [ 2.1835e-02,  3.7654e-02, -2.3596e-02]],\n",
       "              \n",
       "                       [[ 6.4708e-04,  5.1952e-02, -8.7980e-03],\n",
       "                        [-4.2758e-02,  3.8696e-02, -1.2486e-02],\n",
       "                        [-4.3535e-02, -2.6859e-02, -4.0888e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8703e-02, -4.5961e-02, -3.8632e-02],\n",
       "                        [-4.0833e-03,  2.1234e-02, -1.6818e-02],\n",
       "                        [ 2.6032e-02, -5.1953e-02,  1.6078e-02]],\n",
       "              \n",
       "                       [[ 4.9231e-02,  1.3032e-02,  4.3237e-02],\n",
       "                        [-3.9061e-02,  4.8711e-02,  5.1038e-03],\n",
       "                        [-4.0904e-02, -4.1115e-02, -3.1583e-02]],\n",
       "              \n",
       "                       [[-4.8132e-03,  1.2002e-03,  1.0364e-02],\n",
       "                        [-3.6997e-02,  1.9856e-02, -4.6781e-03],\n",
       "                        [-1.1971e-02, -3.6891e-03,  4.9297e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.8159e-02,  3.5908e-02,  1.4939e-02],\n",
       "                        [-2.9288e-02, -4.7313e-02, -2.2152e-02],\n",
       "                        [-5.0100e-02,  4.4756e-02,  3.9485e-02]],\n",
       "              \n",
       "                       [[ 2.7564e-02,  3.0946e-02,  1.7802e-02],\n",
       "                        [-4.6763e-02, -2.5299e-02, -1.7436e-02],\n",
       "                        [-2.0969e-02,  4.5338e-02, -4.0771e-02]],\n",
       "              \n",
       "                       [[-4.7586e-02, -5.2237e-02,  3.5978e-03],\n",
       "                        [ 2.9921e-02, -3.8876e-02,  3.3479e-02],\n",
       "                        [ 8.5086e-03,  5.7432e-03,  9.3366e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.9572e-03,  2.4797e-02, -4.2754e-03],\n",
       "                        [ 3.1248e-02, -3.8404e-03,  4.4088e-02],\n",
       "                        [ 5.8698e-02, -1.6033e-02,  3.9496e-02]],\n",
       "              \n",
       "                       [[ 5.0394e-02, -7.5146e-03,  2.3211e-02],\n",
       "                        [-4.8096e-02, -3.0818e-02, -1.0730e-02],\n",
       "                        [ 4.9121e-02,  2.9197e-02, -5.3798e-02]],\n",
       "              \n",
       "                       [[ 1.2863e-03, -3.1358e-02,  9.8385e-03],\n",
       "                        [ 2.8861e-02,  4.2651e-02,  2.7799e-02],\n",
       "                        [-5.0533e-02,  2.4406e-02, -2.6508e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.0616e-04,  6.8771e-03, -1.0522e-02],\n",
       "                        [ 1.4064e-03, -1.3917e-02, -1.5401e-02],\n",
       "                        [-4.8726e-02, -4.7092e-02,  4.5690e-02]],\n",
       "              \n",
       "                       [[-2.1634e-02, -1.6634e-02,  3.4795e-04],\n",
       "                        [-2.3486e-02, -7.3030e-03, -1.9565e-02],\n",
       "                        [-3.3583e-03, -3.8276e-02,  7.5001e-03]],\n",
       "              \n",
       "                       [[ 2.8177e-02,  5.3894e-02,  3.3712e-02],\n",
       "                        [-4.0338e-02, -2.9827e-02, -5.0618e-02],\n",
       "                        [-1.6005e-02, -4.0207e-02,  5.4201e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4477e-03,  2.0325e-02,  2.1487e-02],\n",
       "                        [-5.2469e-02, -2.7806e-02, -5.4960e-02],\n",
       "                        [-1.9466e-02, -3.4146e-02,  2.6203e-02]],\n",
       "              \n",
       "                       [[-3.5770e-02, -5.4651e-02, -1.0921e-02],\n",
       "                        [-3.2557e-02, -2.4368e-02, -2.1397e-02],\n",
       "                        [ 7.0530e-03,  3.8575e-02,  2.0831e-02]],\n",
       "              \n",
       "                       [[-5.7956e-03,  1.7585e-02, -1.6625e-02],\n",
       "                        [ 6.0791e-03,  2.6158e-04,  3.3333e-03],\n",
       "                        [-4.7674e-02, -5.5400e-02, -9.1633e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.1868e-02,  2.6820e-02, -6.5004e-03],\n",
       "                        [ 3.9689e-02,  9.6638e-03,  4.7643e-02],\n",
       "                        [-5.0082e-03, -3.7882e-03, -3.5668e-02]],\n",
       "              \n",
       "                       [[-2.3686e-02, -1.8771e-02,  4.3066e-03],\n",
       "                        [-3.0142e-02, -1.9072e-03,  2.3350e-02],\n",
       "                        [-3.3365e-02, -4.7118e-04,  1.5152e-02]],\n",
       "              \n",
       "                       [[ 2.9114e-02, -1.9400e-02,  9.9738e-03],\n",
       "                        [-2.2314e-02, -2.7034e-02, -1.8504e-02],\n",
       "                        [-4.3680e-02,  2.2176e-02,  5.2239e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.0.original.bias',\n",
       "              tensor([-0.0521,  0.0022,  0.0538, -0.0278, -0.0084,  0.0097,  0.0471,  0.0199,\n",
       "                       0.0389,  0.0380, -0.0407, -0.0292,  0.0261, -0.0013,  0.0432,  0.0040,\n",
       "                      -0.0066, -0.0071, -0.0507, -0.0346, -0.0543, -0.0154,  0.0430, -0.0493,\n",
       "                       0.0335, -0.0345,  0.0305,  0.0123, -0.0099, -0.0141,  0.0186,  0.0107],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[ 1.7399e-02]],\n",
       "              \n",
       "                       [[ 7.2052e-03]],\n",
       "              \n",
       "                       [[-4.3838e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.8361e-03]],\n",
       "              \n",
       "                       [[ 2.3901e-02]],\n",
       "              \n",
       "                       [[ 1.0433e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.1205e-03]],\n",
       "              \n",
       "                       [[ 4.0984e-02]],\n",
       "              \n",
       "                       [[ 2.7428e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5849e-03]],\n",
       "              \n",
       "                       [[-5.7653e-02]],\n",
       "              \n",
       "                       [[ 6.5577e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7195e-02]],\n",
       "              \n",
       "                       [[-2.4234e-02]],\n",
       "              \n",
       "                       [[-1.1284e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.0594e-02]],\n",
       "              \n",
       "                       [[ 1.0865e-02]],\n",
       "              \n",
       "                       [[ 9.4836e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 7.8288e-02]],\n",
       "              \n",
       "                       [[-2.2642e-02]],\n",
       "              \n",
       "                       [[-6.5730e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.5937e-03]],\n",
       "              \n",
       "                       [[-7.2412e-02]],\n",
       "              \n",
       "                       [[ 6.1925e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7648e-03]],\n",
       "              \n",
       "                       [[ 3.8509e-02]],\n",
       "              \n",
       "                       [[-1.0312e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.7221e-01]],\n",
       "              \n",
       "                       [[-2.1714e-01]],\n",
       "              \n",
       "                       [[-3.6125e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4607e-02]],\n",
       "              \n",
       "                       [[ 7.0329e-05]],\n",
       "              \n",
       "                       [[-5.2880e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.9036e-03]],\n",
       "              \n",
       "                       [[ 1.3296e-02]],\n",
       "              \n",
       "                       [[-6.3706e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[-0.0626]],\n",
       "              \n",
       "                       [[ 0.0336]],\n",
       "              \n",
       "                       [[ 0.1738]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0675]],\n",
       "              \n",
       "                       [[ 0.0480]],\n",
       "              \n",
       "                       [[-0.0058]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0324]],\n",
       "              \n",
       "                       [[-0.0300]],\n",
       "              \n",
       "                       [[ 0.1015]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0633]],\n",
       "              \n",
       "                       [[-0.0585]],\n",
       "              \n",
       "                       [[ 0.0438]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0373]],\n",
       "              \n",
       "                       [[ 0.0702]],\n",
       "              \n",
       "                       [[-0.0009]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0800]],\n",
       "              \n",
       "                       [[ 0.0749]],\n",
       "              \n",
       "                       [[-0.0143]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0103]],\n",
       "              \n",
       "                       [[ 0.0273]],\n",
       "              \n",
       "                       [[-0.1444]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0284]],\n",
       "              \n",
       "                       [[ 0.0422]],\n",
       "              \n",
       "                       [[ 0.0459]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0886]],\n",
       "              \n",
       "                       [[-0.0330]],\n",
       "              \n",
       "                       [[-0.0615]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1237]],\n",
       "              \n",
       "                       [[ 0.1997]],\n",
       "              \n",
       "                       [[ 0.0420]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0378]],\n",
       "              \n",
       "                       [[-0.0366]],\n",
       "              \n",
       "                       [[ 0.0474]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0683]],\n",
       "              \n",
       "                       [[-0.0068]],\n",
       "              \n",
       "                       [[-0.0241]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.weight',\n",
       "              tensor([0.9453, 0.8956, 0.9675, 0.8536, 1.0331, 0.9866, 0.8630, 0.9112, 1.0605,\n",
       "                      1.1232, 1.1283, 0.9429, 0.8716, 0.9758, 0.9941, 1.0772, 0.9792, 1.0126,\n",
       "                      0.9086, 1.0405, 1.0637, 0.9284, 1.0164, 1.0883, 0.9892, 0.9427, 0.9547,\n",
       "                      0.9235, 1.0137, 0.9828, 0.9754, 1.0911], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.bias',\n",
       "              tensor([-0.3943, -0.2570, -0.1644, -0.2119, -0.3531, -0.2765, -0.3575, -0.2470,\n",
       "                      -0.1200, -0.2333, -0.1919, -0.1214, -0.0267, -0.2706, -0.2674, -0.2011,\n",
       "                      -0.3189, -0.1708, -0.1634, -0.3021, -0.2303, -0.1696, -0.1179, -0.1505,\n",
       "                      -0.1960, -0.1096, -0.1830, -0.2718, -0.0879, -0.0799, -0.2430, -0.2483],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.running_mean',\n",
       "              tensor([-0.4003, -0.3299, -0.0025, -0.3249, -0.2637, -0.4067, -0.4734,  0.2201,\n",
       "                      -0.3866, -0.1888, -0.3196, -0.0017,  0.0362, -0.1177, -0.4600, -0.3323,\n",
       "                      -0.2863, -0.2930, -0.2065, -0.4338, -0.4512, -0.1187, -0.1793, -0.4265,\n",
       "                      -0.3314, -0.2127, -0.3760, -0.3760, -0.2719,  0.0431, -0.3772, -0.4690],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.running_var',\n",
       "              tensor([0.3974, 0.6857, 0.2073, 0.7533, 0.6869, 0.5903, 0.8243, 1.2501, 0.7246,\n",
       "                      0.7550, 0.4399, 0.8233, 0.5689, 1.0520, 0.5586, 0.2261, 0.6820, 0.4993,\n",
       "                      0.3150, 0.3357, 0.9107, 0.3417, 0.3448, 0.8113, 0.8249, 0.5821, 0.6058,\n",
       "                      0.3974, 0.8816, 0.5658, 1.0337, 0.4408], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.num_batches_tracked',\n",
       "              tensor(231215, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.4.original.weight',\n",
       "              tensor([[[[ 5.5057e-02,  1.0020e-03, -5.3069e-02],\n",
       "                        [ 2.2962e-02,  5.4711e-02, -5.5751e-02],\n",
       "                        [-2.5863e-02,  4.8709e-02,  3.1115e-02]],\n",
       "              \n",
       "                       [[-3.8575e-02,  4.6954e-02, -2.7934e-02],\n",
       "                        [-3.3603e-02,  1.8553e-02,  3.4508e-04],\n",
       "                        [ 3.7186e-02, -4.5227e-02, -2.2577e-02]],\n",
       "              \n",
       "                       [[-3.0329e-02,  1.7590e-02, -1.6223e-02],\n",
       "                        [-2.2077e-02,  5.1657e-02, -2.2189e-02],\n",
       "                        [-4.4397e-02, -2.0414e-02,  1.6604e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.1096e-02, -4.7887e-02, -3.3026e-02],\n",
       "                        [ 4.4423e-02,  2.3592e-02,  2.9180e-02],\n",
       "                        [ 5.1116e-02, -3.1916e-02,  1.0890e-02]],\n",
       "              \n",
       "                       [[-5.4257e-02, -2.5764e-02, -2.1845e-02],\n",
       "                        [-8.9662e-03, -2.2859e-02, -1.9789e-03],\n",
       "                        [ 2.8713e-02,  2.3153e-02, -3.8147e-02]],\n",
       "              \n",
       "                       [[-2.5700e-03,  2.9608e-02,  3.4795e-02],\n",
       "                        [-3.1727e-02,  4.1719e-02, -8.9484e-03],\n",
       "                        [ 1.7765e-02, -3.7870e-02,  3.0859e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.0616e-02,  4.2195e-02, -8.9989e-04],\n",
       "                        [-4.4405e-02, -7.5867e-03,  4.2507e-02],\n",
       "                        [ 4.0809e-02, -2.9271e-02,  5.8214e-02]],\n",
       "              \n",
       "                       [[-5.5219e-02, -3.9951e-03,  1.7955e-03],\n",
       "                        [ 4.9014e-02,  1.5546e-02,  1.2869e-02],\n",
       "                        [ 1.5569e-02, -1.3117e-02, -4.4682e-02]],\n",
       "              \n",
       "                       [[-3.7497e-03, -3.2830e-03,  2.5257e-02],\n",
       "                        [-3.4769e-02,  3.9417e-04, -3.1093e-02],\n",
       "                        [ 1.9086e-02,  2.1307e-02, -5.8297e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.1363e-02, -4.1838e-02,  5.2978e-04],\n",
       "                        [ 1.9177e-02, -4.0227e-02,  1.6830e-02],\n",
       "                        [ 4.4178e-02, -3.3207e-02, -1.9655e-03]],\n",
       "              \n",
       "                       [[ 3.5874e-02,  3.7301e-02,  2.0425e-02],\n",
       "                        [ 3.3543e-02,  1.0273e-02,  5.0876e-02],\n",
       "                        [-3.4464e-02,  7.8506e-03,  5.6910e-02]],\n",
       "              \n",
       "                       [[ 3.3254e-02, -5.8685e-02,  9.2760e-05],\n",
       "                        [ 5.2730e-02, -2.2779e-02, -1.6383e-02],\n",
       "                        [-4.8188e-02, -1.5514e-04, -5.2924e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2914e-02, -5.6244e-02, -5.3816e-02],\n",
       "                        [ 2.1250e-02, -7.8339e-03,  5.7500e-02],\n",
       "                        [-3.6775e-02, -1.6391e-03, -2.7185e-02]],\n",
       "              \n",
       "                       [[ 2.4215e-02, -1.5833e-02, -1.4779e-03],\n",
       "                        [ 5.2834e-02, -2.6279e-02, -2.7361e-03],\n",
       "                        [ 5.1185e-02, -1.9227e-02, -1.4249e-02]],\n",
       "              \n",
       "                       [[ 1.0917e-02, -9.5450e-04, -3.8261e-02],\n",
       "                        [-2.5333e-02, -5.0212e-02, -1.5785e-02],\n",
       "                        [ 3.2765e-02,  3.1697e-02,  5.2985e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.6150e-02, -5.7729e-03, -7.3448e-03],\n",
       "                        [ 6.3362e-03, -3.2480e-02,  1.0269e-03],\n",
       "                        [ 4.4210e-02,  5.6836e-02,  4.7610e-02]],\n",
       "              \n",
       "                       [[ 2.8942e-02, -1.5078e-03, -2.9251e-02],\n",
       "                        [ 3.9022e-02, -4.7208e-02,  1.4219e-02],\n",
       "                        [-4.4593e-02, -1.9909e-02, -4.5022e-02]],\n",
       "              \n",
       "                       [[ 1.3759e-02, -1.0797e-02,  4.0133e-02],\n",
       "                        [-1.1351e-02, -3.4520e-02,  3.1890e-02],\n",
       "                        [-5.7872e-02,  4.9425e-02,  2.1504e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7560e-02, -1.7005e-02,  3.5921e-02],\n",
       "                        [ 7.7148e-03, -1.5877e-02,  5.3129e-02],\n",
       "                        [-2.8353e-02, -5.2387e-02, -1.1028e-03]],\n",
       "              \n",
       "                       [[ 3.8464e-03, -1.0150e-02, -3.3926e-02],\n",
       "                        [-4.8020e-02, -3.2464e-02,  4.0836e-02],\n",
       "                        [ 4.4621e-02,  2.3065e-02, -3.6983e-02]],\n",
       "              \n",
       "                       [[ 7.7679e-03, -5.1881e-02,  4.2674e-02],\n",
       "                        [ 5.5924e-02, -1.6619e-02, -2.2332e-02],\n",
       "                        [ 1.2269e-02, -5.0492e-03,  3.1909e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.0453e-02,  2.3582e-02, -4.2736e-02],\n",
       "                        [-2.9101e-02,  1.1858e-02, -3.4374e-02],\n",
       "                        [ 9.9184e-03, -2.6569e-02, -4.6135e-02]],\n",
       "              \n",
       "                       [[-6.5239e-03,  2.6402e-02, -2.6674e-02],\n",
       "                        [-3.1708e-02, -3.5945e-02,  4.6931e-02],\n",
       "                        [ 2.7551e-02, -3.3608e-02, -3.0132e-02]],\n",
       "              \n",
       "                       [[ 3.0676e-02, -2.6875e-02, -4.8777e-02],\n",
       "                        [-3.4659e-02,  2.7334e-02,  9.3209e-03],\n",
       "                        [-5.5218e-02, -4.1750e-02, -1.2141e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3229e-03,  1.2844e-03, -5.2147e-02],\n",
       "                        [ 1.0473e-02,  2.8069e-02,  2.2598e-02],\n",
       "                        [-4.9096e-02, -4.4999e-02, -1.3540e-02]],\n",
       "              \n",
       "                       [[-4.1097e-02,  2.5775e-04,  3.8834e-02],\n",
       "                        [ 1.2081e-03,  1.5490e-02,  4.4344e-02],\n",
       "                        [ 4.2413e-02,  2.8368e-02, -4.8052e-02]],\n",
       "              \n",
       "                       [[-5.5442e-02,  4.8058e-02, -2.8782e-02],\n",
       "                        [ 4.0299e-02, -2.6157e-03, -4.2243e-03],\n",
       "                        [ 3.0623e-02, -5.0516e-03, -2.9337e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.9641e-02,  4.4306e-02, -5.2346e-02],\n",
       "                        [ 2.4182e-03,  3.4783e-02, -5.7171e-02],\n",
       "                        [-3.8742e-02,  4.1094e-02,  2.4344e-02]],\n",
       "              \n",
       "                       [[ 4.7281e-02,  2.8850e-02,  2.2860e-02],\n",
       "                        [ 3.5052e-02, -5.4328e-03,  1.1515e-02],\n",
       "                        [-1.3174e-02,  4.0750e-02,  1.5492e-02]],\n",
       "              \n",
       "                       [[ 4.5466e-02, -8.2191e-03, -3.9038e-02],\n",
       "                        [-4.2079e-02,  3.9576e-02,  1.9629e-02],\n",
       "                        [ 3.4291e-02,  3.3420e-02, -1.1163e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.0328e-03,  1.1123e-02,  1.4767e-02],\n",
       "                        [-3.7769e-02, -6.9897e-03, -2.1603e-02],\n",
       "                        [-1.6568e-02, -4.4239e-02, -2.1405e-02]],\n",
       "              \n",
       "                       [[ 2.2313e-02, -2.0821e-02, -3.1610e-02],\n",
       "                        [ 2.1211e-02,  1.4493e-02, -5.0445e-02],\n",
       "                        [ 4.9898e-02,  5.2242e-02, -2.5109e-02]],\n",
       "              \n",
       "                       [[-1.3531e-02,  1.3099e-02,  8.2086e-04],\n",
       "                        [ 1.2422e-02, -2.5890e-02,  3.7083e-02],\n",
       "                        [ 7.0021e-03,  4.2413e-02, -1.4582e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.9682e-03,  3.9432e-02,  5.0660e-02],\n",
       "                        [-4.4608e-02, -1.4544e-02,  2.7129e-02],\n",
       "                        [ 4.4130e-02, -1.6556e-02, -4.5247e-02]],\n",
       "              \n",
       "                       [[ 4.9869e-02,  5.1529e-02,  9.9915e-03],\n",
       "                        [ 3.9543e-02,  6.9448e-03,  3.6584e-03],\n",
       "                        [-1.5280e-02,  1.4700e-02, -2.2916e-02]],\n",
       "              \n",
       "                       [[ 5.0161e-04, -2.4591e-02, -2.3048e-02],\n",
       "                        [-1.0146e-02, -4.7465e-02, -3.8384e-02],\n",
       "                        [-5.7934e-02,  4.5933e-02,  7.7088e-03]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.4.original.bias',\n",
       "              tensor([-0.0131,  0.0044,  0.0415, -0.0342, -0.0567,  0.0291,  0.0420, -0.0138,\n",
       "                      -0.0264,  0.0530,  0.0286, -0.0259, -0.0339,  0.0125,  0.0029, -0.0560,\n",
       "                       0.0083, -0.0093, -0.0031, -0.0407,  0.0494,  0.0367, -0.0474,  0.0559,\n",
       "                       0.0226, -0.0176,  0.0005,  0.0182,  0.0250,  0.0204, -0.0431,  0.0092],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-0.0104]],\n",
       "              \n",
       "                       [[-0.0088]],\n",
       "              \n",
       "                       [[-0.0121]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0174]],\n",
       "              \n",
       "                       [[-0.0584]],\n",
       "              \n",
       "                       [[-0.0786]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0082]],\n",
       "              \n",
       "                       [[ 0.0479]],\n",
       "              \n",
       "                       [[-0.0481]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0351]],\n",
       "              \n",
       "                       [[-0.0350]],\n",
       "              \n",
       "                       [[-0.0420]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1562]],\n",
       "              \n",
       "                       [[-0.0197]],\n",
       "              \n",
       "                       [[ 0.0672]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1768]],\n",
       "              \n",
       "                       [[-0.0536]],\n",
       "              \n",
       "                       [[ 0.0039]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1268]],\n",
       "              \n",
       "                       [[ 0.0513]],\n",
       "              \n",
       "                       [[ 0.0455]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0216]],\n",
       "              \n",
       "                       [[ 0.0052]],\n",
       "              \n",
       "                       [[-0.0015]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0250]],\n",
       "              \n",
       "                       [[-0.0075]],\n",
       "              \n",
       "                       [[-0.0109]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0337]],\n",
       "              \n",
       "                       [[ 0.0059]],\n",
       "              \n",
       "                       [[ 0.0152]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1281]],\n",
       "              \n",
       "                       [[-0.0778]],\n",
       "              \n",
       "                       [[-0.0070]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0332]],\n",
       "              \n",
       "                       [[-0.0188]],\n",
       "              \n",
       "                       [[ 0.0827]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.0613]],\n",
       "              \n",
       "                       [[ 0.0043]],\n",
       "              \n",
       "                       [[-0.1060]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0059]],\n",
       "              \n",
       "                       [[ 0.0057]],\n",
       "              \n",
       "                       [[ 0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0434]],\n",
       "              \n",
       "                       [[-0.0305]],\n",
       "              \n",
       "                       [[ 0.0534]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0403]],\n",
       "              \n",
       "                       [[ 0.0127]],\n",
       "              \n",
       "                       [[-0.1252]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1019]],\n",
       "              \n",
       "                       [[-0.0276]],\n",
       "              \n",
       "                       [[ 0.0640]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0868]],\n",
       "              \n",
       "                       [[ 0.0127]],\n",
       "              \n",
       "                       [[-0.1865]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0300]],\n",
       "              \n",
       "                       [[ 0.0465]],\n",
       "              \n",
       "                       [[ 0.1428]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0356]],\n",
       "              \n",
       "                       [[-0.0467]],\n",
       "              \n",
       "                       [[-0.0266]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0182]],\n",
       "              \n",
       "                       [[-0.0274]],\n",
       "              \n",
       "                       [[ 0.0181]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0900]],\n",
       "              \n",
       "                       [[ 0.0207]],\n",
       "              \n",
       "                       [[-0.0351]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1143]],\n",
       "              \n",
       "                       [[ 0.0222]],\n",
       "              \n",
       "                       [[-0.0181]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0888]],\n",
       "              \n",
       "                       [[-0.0367]],\n",
       "              \n",
       "                       [[ 0.0262]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.weight',\n",
       "              tensor([1.8744, 1.8840, 2.0721, 1.8210, 1.9963, 1.9973, 2.0481, 2.0528, 1.8316,\n",
       "                      1.9424, 1.8975, 1.9322, 2.0675, 1.9676, 1.9353, 1.8272, 2.2679, 1.9188,\n",
       "                      2.1717, 1.9546, 1.9991, 1.9596, 1.8475, 1.9886, 1.9425, 1.8574, 1.8879,\n",
       "                      2.0204, 1.8442, 1.8093, 1.9786, 1.9419], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.bias',\n",
       "              tensor([0.4936, 0.5033, 0.6569, 0.4249, 0.7301, 0.4452, 0.5156, 0.6567, 0.4986,\n",
       "                      0.5188, 0.5833, 0.5722, 0.4800, 0.4556, 0.5090, 0.4750, 0.6698, 0.6941,\n",
       "                      0.7459, 0.6077, 0.6315, 0.6126, 0.4794, 0.6112, 0.4907, 0.7054, 0.5258,\n",
       "                      0.6339, 0.4726, 0.4331, 0.5492, 0.6075], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.running_mean',\n",
       "              tensor([-0.1640, -0.0538, -0.0642, -0.0985, -0.0942, -0.0816,  0.0892, -0.0865,\n",
       "                      -0.0229, -0.1600, -0.0979, -0.1991,  0.0093,  0.0502, -0.0673,  0.0655,\n",
       "                      -0.1382,  0.2011,  0.2475, -0.0648, -0.0358,  0.0719, -0.0527, -0.1216,\n",
       "                      -0.1081, -0.1959, -0.0968, -0.0842, -0.1467, -0.2236, -0.0582, -0.0644],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.running_var',\n",
       "              tensor([0.0872, 0.1320, 0.0777, 0.0931, 0.0887, 0.0875, 0.1799, 0.1392, 0.1272,\n",
       "                      0.1370, 0.0973, 0.1431, 0.1257, 0.1434, 0.0868, 0.0862, 0.1245, 0.1728,\n",
       "                      0.3069, 0.0950, 0.1337, 0.1621, 0.1057, 0.1169, 0.1241, 0.1020, 0.1128,\n",
       "                      0.1904, 0.1136, 0.0853, 0.1062, 0.0965], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.num_batches_tracked',\n",
       "              tensor(231215, device='cuda:0')),\n",
       "             ('fully_connected_blocks.0.0.lora_apl_v1_linear_lora_A',\n",
       "              tensor([[ 0.0934, -0.0967,  0.0898,  ..., -0.0777, -0.0227,  0.1726],\n",
       "                      [-0.0589,  0.2438, -0.1656,  ...,  0.2962,  0.0455, -0.2932],\n",
       "                      [-0.0646,  0.0273, -0.1994,  ...,  0.0093, -0.1441, -0.1067],\n",
       "                      ...,\n",
       "                      [ 0.1174,  0.0143,  0.0727,  ...,  0.0048,  0.1466, -0.0295],\n",
       "                      [ 0.0841, -0.0111,  0.0715,  ...,  0.0254, -0.0206, -0.1193],\n",
       "                      [ 0.0801, -0.0837, -0.0309,  ...,  0.0092, -0.0316,  0.1020]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.0.0.lora_apl_v1_linear_lora_B',\n",
       "              tensor([[-0.0494, -0.0358,  0.1683,  ..., -0.0434, -0.2268,  0.1624],\n",
       "                      [-0.0591, -0.0117,  0.1632,  ..., -0.1325, -0.2226,  0.0528],\n",
       "                      [ 0.1944, -0.2144, -0.1496,  ...,  0.0017, -0.0685, -0.2353],\n",
       "                      ...,\n",
       "                      [-0.0306, -0.0932,  0.1506,  ..., -0.0898, -0.1198, -0.0114],\n",
       "                      [ 0.1148, -0.1774, -0.0831,  ...,  0.0370,  0.0384,  0.1904],\n",
       "                      [ 0.0835,  0.0604,  0.0004,  ..., -0.0363, -0.1717,  0.1433]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.0.0.original.weight',\n",
       "              tensor([[-0.0841, -0.0469,  0.0778,  ..., -0.0188, -0.0214, -0.0829],\n",
       "                      [-0.0620,  0.0245, -0.0521,  ..., -0.0114,  0.0819, -0.0506],\n",
       "                      [-0.0305, -0.0858,  0.0054,  ...,  0.0301,  0.0157, -0.0449],\n",
       "                      ...,\n",
       "                      [ 0.0456,  0.0716, -0.0777,  ...,  0.0726, -0.0473,  0.0762],\n",
       "                      [-0.0704, -0.0194, -0.0145,  ...,  0.0346, -0.0595, -0.0148],\n",
       "                      [-0.0136,  0.0217, -0.0777,  ..., -0.0141,  0.0812,  0.0807]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.0.0.original.bias',\n",
       "              tensor([ 0.0882, -0.0695,  0.0445,  0.0378,  0.0662,  0.0051, -0.0370, -0.0756,\n",
       "                      -0.0226,  0.0535,  0.0628,  0.0238,  0.0606,  0.0228,  0.0771,  0.0536,\n",
       "                      -0.0576, -0.0748, -0.0741,  0.0083, -0.0194, -0.0251, -0.0787,  0.0753,\n",
       "                       0.0561, -0.0385, -0.0298, -0.0695, -0.0859, -0.0255, -0.0679,  0.0368,\n",
       "                      -0.0772,  0.0150,  0.0346, -0.0674, -0.0406,  0.0108,  0.0869,  0.0426,\n",
       "                      -0.0460,  0.0807, -0.0554,  0.0595,  0.0433,  0.0880, -0.0289,  0.0776,\n",
       "                       0.0079, -0.0640,  0.0877, -0.0310,  0.0305,  0.0096, -0.0729, -0.0816,\n",
       "                       0.0180,  0.0554,  0.0292, -0.0271, -0.0097,  0.0283,  0.0391, -0.0749,\n",
       "                      -0.0321, -0.0646, -0.0563, -0.0445,  0.0526, -0.0431,  0.0539,  0.0871,\n",
       "                      -0.0228, -0.0841,  0.0131, -0.0597, -0.0758,  0.0466, -0.0517,  0.0556,\n",
       "                      -0.0640,  0.0102, -0.0348, -0.0659,  0.0622, -0.0875,  0.0879, -0.0610,\n",
       "                       0.0686, -0.0174,  0.0443,  0.0764, -0.0197, -0.0022, -0.0353, -0.0255,\n",
       "                       0.0293, -0.0592,  0.0517, -0.0843,  0.0623,  0.0210,  0.0814, -0.0063,\n",
       "                      -0.0583,  0.0123,  0.0681, -0.0103,  0.0881,  0.0300, -0.0296, -0.0825,\n",
       "                       0.0100,  0.0588,  0.0668, -0.0173, -0.0228,  0.0401, -0.0408, -0.0884,\n",
       "                      -0.0285, -0.0616, -0.0309,  0.0192,  0.0573, -0.0882,  0.0650, -0.0027],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.1.0.lora_apl_v1_linear_lora_A',\n",
       "              tensor([[-0.0732, -0.0263,  0.1206,  ...,  0.0215,  0.2626, -0.0564],\n",
       "                      [-0.1754,  0.1313, -0.0765,  ...,  0.0935, -0.0838, -0.2180],\n",
       "                      [-0.0281, -0.0794,  0.1095,  ..., -0.0742,  0.2948, -0.2872],\n",
       "                      ...,\n",
       "                      [-0.1243,  0.1911, -0.0617,  ...,  0.0276, -0.0402, -0.2284],\n",
       "                      [-0.0122, -0.1133,  0.2361,  ..., -0.0634,  0.0739, -0.0328],\n",
       "                      [-0.0151,  0.0101, -0.0013,  ...,  0.0594,  0.0424, -0.1841]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.1.0.lora_apl_v1_linear_lora_B',\n",
       "              tensor([[-3.4221e-02, -8.4895e-02,  3.0234e-02,  ..., -1.0110e-01,\n",
       "                       -5.6573e-02, -1.7187e-01],\n",
       "                      [ 8.0814e-03,  1.1622e-01, -5.7952e-03,  ..., -5.6968e-02,\n",
       "                       -1.6821e-01,  2.1802e-01],\n",
       "                      [ 1.1502e-01,  6.1365e-03, -8.0811e-02,  ...,  2.0844e-02,\n",
       "                       -1.8266e-01, -1.1528e-02],\n",
       "                      ...,\n",
       "                      [ 6.8722e-03,  1.2760e-02,  2.6412e-02,  ...,  3.3569e-03,\n",
       "                        2.2414e-03,  6.1040e-03],\n",
       "                      [ 3.5300e-03,  9.5965e-05,  6.7678e-03,  ...,  1.9539e-03,\n",
       "                        4.7535e-03,  2.3841e-03],\n",
       "                      [ 1.1261e-02,  4.9472e-03,  1.6738e-02,  ...,  1.0675e-02,\n",
       "                        2.0964e-03,  6.4690e-03]], device='cuda:0')),\n",
       "             ('fully_connected_blocks.1.0.original.weight',\n",
       "              tensor([[ 0.0046, -0.0063, -0.0247,  ..., -0.0552,  0.0708,  0.0146],\n",
       "                      [ 0.0065,  0.0270,  0.0550,  ..., -0.0754,  0.0871,  0.0691],\n",
       "                      [-0.0061,  0.0635,  0.0864,  ..., -0.0515, -0.0364, -0.0007],\n",
       "                      ...,\n",
       "                      [-0.0846, -0.0531,  0.0708,  ...,  0.0496, -0.0416,  0.0663],\n",
       "                      [-0.0474,  0.0463, -0.0019,  ...,  0.0805, -0.0179,  0.0129],\n",
       "                      [ 0.0875,  0.0103, -0.0772,  ..., -0.0554,  0.0013, -0.0008]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.1.0.original.bias',\n",
       "              tensor([ 0.0146,  0.0270, -0.0092, -0.0250, -0.0728,  0.0572,  0.0088, -0.0553,\n",
       "                      -0.0005, -0.0729,  0.0835,  0.0179,  0.0217, -0.0220,  0.0371,  0.0851,\n",
       "                       0.0877,  0.0763, -0.0695, -0.0424, -0.0574,  0.0341, -0.0649, -0.0789,\n",
       "                       0.0399,  0.0087,  0.0378, -0.0389,  0.0313, -0.0455, -0.0625, -0.0140,\n",
       "                       0.0259, -0.0846,  0.0020, -0.0643,  0.0654, -0.0548, -0.0519, -0.0771,\n",
       "                      -0.0021,  0.0369,  0.0618,  0.0561,  0.0541,  0.0012, -0.0554,  0.0199,\n",
       "                       0.0841,  0.0854, -0.0839, -0.0279,  0.0247,  0.0149,  0.0752, -0.0701,\n",
       "                      -0.0838, -0.0206, -0.0746, -0.0614, -0.0684, -0.0353,  0.0081, -0.0540,\n",
       "                      -0.0460,  0.0825, -0.0543, -0.0756, -0.0343, -0.0006,  0.0523,  0.0377,\n",
       "                       0.0115, -0.0844,  0.0864,  0.0421,  0.0404,  0.0205, -0.0732, -0.0441,\n",
       "                      -0.0524,  0.0166,  0.0497, -0.0092,  0.0626, -0.0196, -0.0852,  0.0855,\n",
       "                      -0.0516, -0.0675, -0.0775, -0.0317,  0.0491,  0.0432, -0.0107, -0.0114,\n",
       "                       0.0037, -0.0538, -0.0820, -0.0700,  0.0171,  0.0354,  0.0844,  0.0793,\n",
       "                      -0.0641,  0.0407,  0.0733,  0.0417,  0.0708, -0.0286, -0.0026, -0.0834,\n",
       "                      -0.0105,  0.0156, -0.0664,  0.0462,  0.0570,  0.0517,  0.0299,  0.0706,\n",
       "                       0.0567,  0.0764, -0.0468,  0.0863,  0.0679, -0.0155, -0.0566, -0.0802,\n",
       "                      -0.0384,  0.0644, -0.0271,  0.0382,  0.0395, -0.0215, -0.0853,  0.0235,\n",
       "                      -0.0543,  0.0776,  0.0378, -0.0225, -0.0024, -0.0167, -0.0633, -0.0045,\n",
       "                       0.0590,  0.0686, -0.0682, -0.0206, -0.0030,  0.0665, -0.0750,  0.0002,\n",
       "                       0.0164,  0.0068, -0.0174,  0.0208, -0.0333, -0.0209, -0.0149, -0.0607,\n",
       "                       0.0869, -0.0474, -0.0857, -0.0221, -0.0541, -0.0145, -0.0758,  0.0038,\n",
       "                       0.0690,  0.0354,  0.0100,  0.0603,  0.0227, -0.0013,  0.0303,  0.0779,\n",
       "                      -0.0662, -0.0262, -0.0850,  0.0592,  0.0525,  0.0757,  0.0606,  0.0270,\n",
       "                      -0.0809, -0.0691, -0.0559,  0.0109,  0.0157,  0.0756, -0.0804, -0.0058,\n",
       "                      -0.0442,  0.0383,  0.0379,  0.0298,  0.0558,  0.0470,  0.0279,  0.0711,\n",
       "                      -0.0572, -0.0017, -0.0499, -0.0377,  0.0221,  0.0723, -0.0778,  0.0353,\n",
       "                       0.0008,  0.0144,  0.0123,  0.0219,  0.0443, -0.0345,  0.0112, -0.0648,\n",
       "                      -0.0689,  0.0407,  0.0220, -0.0757, -0.0407, -0.0827, -0.0877,  0.0436,\n",
       "                      -0.0606,  0.0430, -0.0273, -0.0574,  0.0848, -0.0722,  0.0718,  0.0341,\n",
       "                       0.0162, -0.0715, -0.0314,  0.0131,  0.0021, -0.0595,  0.0690, -0.0227,\n",
       "                       0.0117,  0.0742, -0.0320,  0.0625,  0.0584, -0.0286,  0.0541, -0.0290,\n",
       "                       0.0135, -0.0735, -0.0621,  0.0522,  0.0050,  0.0471,  0.0807,  0.0122],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fully_connected_blocks.0.0.lora_apl_v1 → A norm: 4.7168, B norm: 6.5293, scaling: 1.0000\n",
      "fully_connected_blocks.1.0.lora_apl_v1 → A norm: 4.6882, B norm: 11.8058, scaling: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for name, module in cnn_model.named_modules():\n",
    "    if isinstance(module, LoRALinearWrapper):\n",
    "        for adapter_name, adapter in module.lora_adapters.items():\n",
    "            A, B = adapter[\"A\"], adapter[\"B\"]\n",
    "            A_norm = A.norm().item()\n",
    "            B_norm = B.norm().item()\n",
    "            print(f\"{name}.{adapter_name} → A norm: {A_norm:.4f}, B norm: {B_norm:.4f}, scaling: {module.active_scalings[adapter_name]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularisation (weight decay) loss: 0.3051\n"
     ]
    }
   ],
   "source": [
    "decay_total = 0.0\n",
    "for name, param in cnn_model.named_parameters():\n",
    "    if param.requires_grad and param.grad is not None:\n",
    "        decay_total += (param ** 2).sum().item()\n",
    "\n",
    "# Multiply by your weight decay value (e.g. from the optimiser)\n",
    "weight_decay = optim.param_groups[0].get(\"weight_decay\", 0.0)\n",
    "reg_loss = 0.5 * weight_decay * decay_total\n",
    "\n",
    "print(f\"Regularisation (weight decay) loss: {reg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 44]                   --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 32, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
      "│    │    └─Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
      "│    │    └─LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
      "├─Sequential: 1-2                        [1, 128]                  --\n",
      "│    └─Flatten: 2-6                      [1, 128]                  --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-7                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-41                 [1, 64]                   8,256\n",
      "│    │    └─Dropout: 3-42                [1, 64]                   --\n",
      "│    │    └─LeakyReLU: 3-43              [1, 64]                   --\n",
      "│    └─Sequential: 2-8                   [1, 44]                   --\n",
      "│    │    └─Linear: 3-44                 [1, 44]                   2,860\n",
      "==========================================================================================\n",
      "Total params: 83,548\n",
      "Trainable params: 83,548\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 14.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.18\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 2.53\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "AllCNN2D                                 --\n",
       "├─ModuleList: 1-1                        --\n",
       "│    └─Sequential: 2-1                   --\n",
       "│    │    └─Conv2d: 3-1                  160\n",
       "│    │    └─Dropout2d: 3-2               --\n",
       "│    │    └─BatchNorm2d: 3-3             32\n",
       "│    │    └─LeakyReLU: 3-4               --\n",
       "│    │    └─Conv2d: 3-5                  2,320\n",
       "│    │    └─Dropout2d: 3-6               --\n",
       "│    │    └─BatchNorm2d: 3-7             32\n",
       "│    │    └─LeakyReLU: 3-8               --\n",
       "│    └─Sequential: 2-2                   --\n",
       "│    │    └─Conv2d: 3-9                  4,640\n",
       "│    │    └─Dropout2d: 3-10              --\n",
       "│    │    └─BatchNorm2d: 3-11            64\n",
       "│    │    └─LeakyReLU: 3-12              --\n",
       "│    │    └─Conv2d: 3-13                 9,248\n",
       "│    │    └─Dropout2d: 3-14              --\n",
       "│    │    └─BatchNorm2d: 3-15            64\n",
       "│    │    └─LeakyReLU: 3-16              --\n",
       "│    └─Sequential: 2-3                   --\n",
       "│    │    └─Conv2d: 3-17                 9,248\n",
       "│    │    └─Dropout2d: 3-18              --\n",
       "│    │    └─BatchNorm2d: 3-19            64\n",
       "│    │    └─LeakyReLU: 3-20              --\n",
       "│    │    └─Conv2d: 3-21                 9,248\n",
       "│    │    └─Dropout2d: 3-22              --\n",
       "│    │    └─BatchNorm2d: 3-23            64\n",
       "│    │    └─LeakyReLU: 3-24              --\n",
       "│    └─Sequential: 2-4                   --\n",
       "│    │    └─Conv2d: 3-25                 9,248\n",
       "│    │    └─Dropout2d: 3-26              --\n",
       "│    │    └─BatchNorm2d: 3-27            64\n",
       "│    │    └─LeakyReLU: 3-28              --\n",
       "│    │    └─Conv2d: 3-29                 9,248\n",
       "│    │    └─Dropout2d: 3-30              --\n",
       "│    │    └─BatchNorm2d: 3-31            64\n",
       "│    │    └─LeakyReLU: 3-32              --\n",
       "│    └─Sequential: 2-5                   --\n",
       "│    │    └─Conv2d: 3-33                 9,248\n",
       "│    │    └─Dropout2d: 3-34              --\n",
       "│    │    └─BatchNorm2d: 3-35            64\n",
       "│    │    └─LeakyReLU: 3-36              --\n",
       "│    │    └─Conv2d: 3-37                 9,248\n",
       "│    │    └─Dropout2d: 3-38              --\n",
       "│    │    └─BatchNorm2d: 3-39            64\n",
       "│    │    └─LeakyReLU: 3-40              --\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─Sequential: 2-6                   --\n",
       "│    │    └─Linear: 3-41                 8,256\n",
       "│    │    └─Dropout: 3-42                --\n",
       "│    │    └─LeakyReLU: 3-43              --\n",
       "│    └─Sequential: 2-7                   --\n",
       "│    │    └─Linear: 3-44                 2,860\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Flatten: 2-8                      --\n",
       "=================================================================\n",
       "Total params: 83,548\n",
       "Trainable params: 83,548\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model: AllCNN2D = AllCNN2D(\n",
    "    **{\n",
    "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
    "        \"fully_connected_features\": (64, 44),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.0,#0.075,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\models\\allcnn\\Indigo_epoch26_trainacc0.71327_valacc0.99057_Tloss0.072851_Vloss0.0056362_lr0.0007224999999999999.pkl\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m char, label \u001b[38;5;129;01min\u001b[39;00m val_char_dataset:\n\u001b[0;32m      2\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(char[\u001b[38;5;241m0\u001b[39m, :, :])\n\u001b[0;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:100\u001b[0m, in \u001b[0;36mCharImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     97\u001b[0m image \u001b[38;5;241m=\u001b[39m reduce(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc h w -> 1 h w\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Apply random transformations\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_random_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# One-hot encode the label\u001b[39;00m\n\u001b[0;32m    105\u001b[0m one_hot_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_set),\n\u001b[0;32m    107\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m    108\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:128\u001b[0m, in \u001b[0;36mCharImageDataset._apply_random_transformations\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Pad the image to prevent cropping during transformations\u001b[39;00m\n\u001b[0;32m    127\u001b[0m pad_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Adjust padding size as needed\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Random rotation\u001b[39;00m\n\u001b[0;32m    131\u001b[0m rotation_angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m365\u001b[39m,\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m365\u001b[39m\n\u001b[0;32m    134\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: pad() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "for char, label in val_char_dataset:\n",
    "    plt.imshow(char[0, :, :])\n",
    "    plt.show()\n",
    "    pred: torch.Tensor = model.forward(char.unsqueeze(0)).squeeze()\n",
    "    pred_index: int = torch.argmax(pred).item()\n",
    "    print(chr(int(alphabet[pred_index][1:], base=16)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
