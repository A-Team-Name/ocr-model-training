{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from typing import Any\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from torchinfo import summary\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import EpochLogs, grid_search, LogPoint\n",
    "from dataset.character_dataset import CharImageDataset\n",
    "from models.allcnn2d import AllCNN2D\n",
    "from models.allcnn2d_rnn import CNNRNNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE: int = 4\n",
    "DATASET_SPLIT: float = 0.75\n",
    "MODEL_NAME: str = \"KrudLoRA_APL\"\n",
    "LOAD_CHECKPOINT: str = r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn_lora\\20250409_024444__KrudLoRA_APL__Epoch17_tLoss5.62363_tL12483.67551_tMSE25184.53417_tAcc0.06857_vLoss4.38120_vL12105.55193_vMSE17849.22644_vAcc0.03797.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths\n",
    "Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir: str = os.path.abspath(\".\")\n",
    "root_dir: str = os.path.join(\n",
    "    notebook_dir,\n",
    "    os.pardir,\n",
    "    os.pardir\n",
    ")\n",
    "\n",
    "data_dir: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"data\",\n",
    "    \"apl_lora\"\n",
    ")\n",
    "\n",
    "model_save_dirpath: str = os.path.join(\n",
    "    root_dir,\n",
    "    \"models\",\n",
    "    MODEL_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "images_path_glob: str = os.path.join(\n",
    "    data_dir,\n",
    "    \"u*.png\"\n",
    ")\n",
    "images_path_regex: str = r\"(u[0-9a-f]+)[-]+([0-9a-zA-Z]+)\\.png\"\n",
    "\n",
    "image_paths: list[str] = glob.glob(images_path_glob)\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Labels From File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164, 1164)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "labeled_image_paths: list[tuple[str, str]] = []\n",
    "\n",
    "class_counts: dict[str, int] = defaultdict(lambda: 0)\n",
    "\n",
    "file_path: str\n",
    "for file_path in image_paths:\n",
    "    match = re.search(images_path_regex, file_path)\n",
    "    \n",
    "    if not match:\n",
    "        continue\n",
    "    \n",
    "    u_hexvalue: str = match.group(1)[1:]\n",
    "    \n",
    "    char: str = chr(int(u_hexvalue, base=16))\n",
    "    \n",
    "    \n",
    "    class_counts[char] += 1\n",
    "    \n",
    "    \n",
    "    labeled_image_paths.append((char, file_path))\n",
    "\n",
    "labels: list[str]\n",
    "image_paths: list[str]\n",
    "labels, image_paths =  list(zip(*labeled_image_paths))\n",
    "\n",
    "len(labels), len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'∣': 10,\n",
       "         '⋄': 10,\n",
       "         ']': 10,\n",
       "         ':': 10,\n",
       "         '⎕': 10,\n",
       "         '←': 10,\n",
       "         '⍞': 10,\n",
       "         '#': 10,\n",
       "         '\"': 10,\n",
       "         '⍷': 10,\n",
       "         '⍝': 10,\n",
       "         '@': 10,\n",
       "         '`': 10,\n",
       "         '´': 10,\n",
       "         '⍣': 10,\n",
       "         '&': 10,\n",
       "         '→': 10,\n",
       "         '^': 10,\n",
       "         ')': 10,\n",
       "         '⌶': 8,\n",
       "         'N': 7,\n",
       "         '⍫': 7,\n",
       "         '6': 7,\n",
       "         'Y': 7,\n",
       "         '⍬': 7,\n",
       "         '⌽': 7,\n",
       "         'G': 7,\n",
       "         '?': 7,\n",
       "         '∊': 7,\n",
       "         '⍺': 7,\n",
       "         '>': 7,\n",
       "         'q': 7,\n",
       "         'X': 7,\n",
       "         'f': 7,\n",
       "         '¯': 7,\n",
       "         'e': 7,\n",
       "         '⌷': 7,\n",
       "         '⍨': 7,\n",
       "         'P': 7,\n",
       "         'a': 7,\n",
       "         't': 7,\n",
       "         '+': 7,\n",
       "         '!': 7,\n",
       "         'F': 7,\n",
       "         'b': 7,\n",
       "         ';': 7,\n",
       "         '5': 7,\n",
       "         'x': 7,\n",
       "         'j': 7,\n",
       "         'T': 7,\n",
       "         '≥': 7,\n",
       "         '⊥': 7,\n",
       "         '∩': 7,\n",
       "         'K': 7,\n",
       "         'c': 7,\n",
       "         '=': 7,\n",
       "         '(': 7,\n",
       "         '~': 7,\n",
       "         'y': 7,\n",
       "         '\\\\': 7,\n",
       "         'B': 7,\n",
       "         '⍀': 7,\n",
       "         '⍴': 7,\n",
       "         '9': 7,\n",
       "         'o': 7,\n",
       "         '≠': 7,\n",
       "         '2': 7,\n",
       "         '¨': 7,\n",
       "         '⍲': 7,\n",
       "         '⌿': 7,\n",
       "         'V': 7,\n",
       "         '↑': 7,\n",
       "         'Q': 7,\n",
       "         '⊤': 7,\n",
       "         'O': 7,\n",
       "         'g': 7,\n",
       "         '⍎': 7,\n",
       "         '.': 7,\n",
       "         'u': 7,\n",
       "         '⍋': 7,\n",
       "         'S': 7,\n",
       "         '<': 7,\n",
       "         'A': 7,\n",
       "         '⍱': 7,\n",
       "         '⍒': 7,\n",
       "         'Z': 7,\n",
       "         '}': 7,\n",
       "         '·': 7,\n",
       "         '_': 7,\n",
       "         '⊂': 7,\n",
       "         '↓': 7,\n",
       "         '∆': 7,\n",
       "         'd': 7,\n",
       "         'h': 7,\n",
       "         '∧': 7,\n",
       "         '○': 7,\n",
       "         '⍳': 7,\n",
       "         'W': 7,\n",
       "         'E': 7,\n",
       "         'R': 7,\n",
       "         \"'\": 7,\n",
       "         '×': 7,\n",
       "         '⊃': 7,\n",
       "         '⍉': 7,\n",
       "         '3': 7,\n",
       "         'M': 7,\n",
       "         '⌊': 7,\n",
       "         '⊖': 7,\n",
       "         '1': 7,\n",
       "         'C': 7,\n",
       "         '%': 7,\n",
       "         'w': 7,\n",
       "         'l': 7,\n",
       "         'n': 7,\n",
       "         '|': 7,\n",
       "         ',': 7,\n",
       "         'D': 7,\n",
       "         '∪': 7,\n",
       "         'H': 7,\n",
       "         '⍟': 7,\n",
       "         '*': 7,\n",
       "         'J': 7,\n",
       "         '≤': 7,\n",
       "         '-': 7,\n",
       "         '⍪': 7,\n",
       "         'r': 7,\n",
       "         'i': 7,\n",
       "         'U': 7,\n",
       "         '∘': 7,\n",
       "         '[': 7,\n",
       "         's': 7,\n",
       "         '⍙': 7,\n",
       "         'I': 7,\n",
       "         '⌹': 7,\n",
       "         '⌈': 7,\n",
       "         '4': 7,\n",
       "         'L': 7,\n",
       "         'v': 7,\n",
       "         'k': 7,\n",
       "         '⊣': 7,\n",
       "         '7': 7,\n",
       "         'z': 7,\n",
       "         '8': 7,\n",
       "         '∨': 7,\n",
       "         '⊢': 7,\n",
       "         '÷': 7,\n",
       "         '0': 7,\n",
       "         '{': 7,\n",
       "         '≢': 7,\n",
       "         'p': 7,\n",
       "         '≡': 7,\n",
       "         'm': 7,\n",
       "         '⍵': 7,\n",
       "         '⍕': 7,\n",
       "         '∇': 7,\n",
       "         '/': 7,\n",
       "         '£': 7,\n",
       "         '$': 7})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Classes Using Oversample/Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts: list[tuple[str, int]] = sorted(\n",
    "    class_counts.items(), \n",
    "    key=lambda x: x[0]\n",
    ")\n",
    "\n",
    "counts: list[int] = [pair[1] for pair in sorted_counts]\n",
    "\n",
    "max_count: int = max(counts)\n",
    "min_count: int = min(counts)\n",
    "\n",
    "to_add_counts: dict[str, int] = {\n",
    "    uid: max_count - count \n",
    "    for uid, count in \n",
    "    sorted_counts\n",
    "}\n",
    "\n",
    "to_undersample_counts: dict[str, int] = {\n",
    "    uid: min_count\n",
    "    for uid, count in \n",
    "    sorted_counts\n",
    "}\n",
    "\n",
    "total_items = sum(x[1] for x in sorted_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 10, 1164)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count, max_count, total_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(*to_add_counts.items())\n",
    "#print(sorted([(chr(int(pair[0][1:], 16)), pair[1]) for pair in to_remove_counts.items()], key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_add_labels: list[str] = []\n",
    "#to_add_file_paths: list[str] = []\n",
    "#\n",
    "#while True in [to_add_count>0 for to_add_count in to_add_counts.values()]:  \n",
    "#    for label, image_path in zip(labels, image_paths):\n",
    "#        remaining: int = to_add_counts[label]\n",
    "#        \n",
    "#        if remaining > 0:\n",
    "#            to_add_labels.append(label)\n",
    "#            to_add_file_paths.append(image_path)\n",
    "#            to_add_counts[label] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep_labels: list[str] = []\n",
    "to_keep_file_paths: list[str] = []\n",
    "\n",
    "while True in [to_add_count>0 for to_add_count in to_undersample_counts.values()]:  \n",
    "    for label, image_path in zip(labels, image_paths):\n",
    "        remaining: int = to_undersample_counts[label]\n",
    "        \n",
    "        if remaining > 0:\n",
    "            to_keep_labels.append(label)\n",
    "            to_keep_file_paths.append(image_path)\n",
    "            to_undersample_counts[label] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, ⍫, 6, Y, ∣, ⍬, ⌽, G, ⋄, ?, ∊, ], ⍺, >, q, X, f, ¯, e, ⌷, 6, ⍨, P, a, :, t, G, +, !, F, b, ⌶, ⎕, ;, 5, x, j, T, +, ≥, ⍬, ⍺, ⊥, G, a, ∩, K, a, c, =, (, e, q, ~, ←, y, T, \\, B, ⍀, ?, ⍴, K, 9, ⍞, o, P, #, ≠, 2, ¨, ⍲, ⌿, ∣, V, F, ↑, b, Q, Y, \", q, ⍷, 9, ⊤, O, ⌶, g, ≠, y, ⍝, ⍎, ., @, `, j, ¨, u, ], ←, ⍋, S, ?, <, A, ¨, ⍱, 5, ⍒, Z, }, \\, ´, ·, _, F, ⊂, ., \\, ←, S, ↓, `, ⍬, =, ∆, d, h, ∧, \", 6, (, ○, :, Y, ⍳, W, o, e, ∣, ↑, E, +, ;, +, ⍨, ⍒, R, ∣, ', h, <, ×, u, ∧, ⊃, ⍉, ⍫, 3, Y, \", M, V, ·, ⌊, t, ⍳, ⊖, E, ⍣, #, ≥, ○, ⍬, 1, C, %, &, w, ⎕, l, ⊂, ?, ⌽, y, Q, n, |, ∩, ,, ⌿, D, ≠, →, ∪, H, ⍟, ×, ⍝, x, *, W, ⍲, J, ∊, E, ⍫, ∆, ≤, S, -, \", ⍎, O, ⍞, R, ⋄, +, ⍪, D, r, ↑, ⍒, #, &, i, U, ∘, \\, X, [, ≠, ⌽, ^, ⌽, ∩, w, b, ↑, s, (, ⍙, I, U, H, ∊, >, ⊃, ∆, ⊥, ⍪, =, ⍴, ⍉, ⌹, →, ⍝, C, J, ⌈, }, N, ∪, #, _, >, ⍣, ⊂, ∘, h, ⍪, ↓, ⍋, n, →, ⎕, J, ', 4, ⍪, S, -, ⌷, ', ≥, ⍳, G, L, M, ≥, *, +, v, ≤, %, ¯, k, :, ∧, ⊣, ∪, 7, f, 5, ≤, ⍣, z, ⍒, ⍣, y, E, =, }, ⍀, 8, R, ∨, ;, @, q, ⍱, 4, _, s, [, 1, t, ⊢, A, 3, ÷, R, ⍎, 0, >, ⋄, ∪, 8, v, Q, s, ⌹, t, i, ⍣, :, &, N, l, \", ∨, ⌿, 6, ⍉, {, Q, b, ⍳, ≢, G, x, U, ], ], p, ←, r, (, <, D, R, ⌶, ⍷, 8, V, \", ≡, ], P, ⍷, ⍫, ⌈, :, ⌷, ⍀, I, ≤, T, D, ⍫, ∧, w, e, H, k, ⍝, ⊣, ⌈, ·, ¨, ', m, ⊢, ⍞, ⌽, v, ¯, u, *, ⍀, ⊢, l, ⍳, ⍋, t, ×, =, z, }, 0, ⍲, ⍣, M, W, j, `, *, ↓, ∨, I, 8, ⊤, l, ⍎, ⎕, y, ⍎, e, n, X, ⍵, N, %, ⍪, m, Z, ⍕, ∣, ⊤, q, p, D, ⌶, A, *, Z, ⍟, G, ∇, Y, ∘, ´, ←, -, T, ≡, `, ⍱, ?, ~, i, ↓, ⍞, y, ⊢, →, ⍀, ⍬, K, `, \", ⍷, ≡, :, /, ⍱, ·, ), R, ., ⊖, ), ⌊, ∩, ⊖, @, L, k, £, v, ⎕, Y, s, |, I, ´, B, b, ´, L, ○, →, T, e, p, ⍵, ⍟, 2, →, u, H, ⍉, 5, ), k, X, ^, ⍒, ⍨, u, [, ⍱, ↑, ⍲, X, #, ∇, ⍷, &, >, ⍵, O, l, h, ⊂, ⍲, ⌶, ⊂, ≤, Z, w, Z, O, 9, a, ∣, $, ⍉, V, ), ., M, l, ⌿, %, 7, ⊃, %, ;, ⍺, ,, a, ⍝, 4, [, <, ≢, ○, ≡, d, 3, [, &, ., ⊣, x, z, P, !, J, ⌷, B, *, £, ⊥, 6, ⍷, £, z, p, S, F, ≥, ⋄, l, ⍙, Y, `, ⍟, -, ⍋, ∣, ⊢, |, s, ], :, n, ~, ⍝, \\, I, j, ⍎, ⍕, !, 2, ⍵, ⍕, 5, ;, ×, ^, ⍺, ´, n, Q, ⍒, d, |, ⍵, ⍙, ,, U, ≡, @, =, i, n, z, ⍫, ⋄, 1, ., ·, m, M, ⌽, ], g, ⍲, B, -, ⎕, {, ⍣, ⎕, 9, o, E, S, 7, ⊣, W, |, →, ⍞, c, ⍴, ,, ?, ⍨, C, ∊, b, ⍞, m, ⊥, p, v, ⌊, ⍕, ⍨, &, ⋄, ⌈, ', s, ⍱, ∪, £, ⍀, c, W, ⍷, ⍟, ⊣, ⊣, ⊖, o, <, _, 4, f, ∩, B, b, E, U, ⍪, X, ⍫, ⍙, w, ´, ≥, 3, 7, S, ↓, 2, ⊂, F, a, {, U, 4, H, 2, $, ⊃, ⌿, ?, ≢, ⍟, !, x, ^, N, ∧, ∆, ⌽, ), ,, q, >, E, ⋄, J, #, ⍋, ⍉, ⊃, 3, N, ∩, r, ⌿, ≢, ∩, B, ⍕, k, C, ←, ¯, e, ;, ⍕, H, 1, m, Z, ⍋, ⍬, ⌹, Z, ⍨, h, d, ,, _, 0, ∘, ∨, 4, <, {, ←, ∘, O, g, &, ⍕, @, m, ≢, ⍳, i, ⌷, [, J, w, ¯, ⌿, u, ., 4, 7, A, }, <, ↓, 9, £, ⌹, 5, ≠, ⍵, ⌶, D, j, 9, q, ⊤, ,, `, r, /, v, (, 7, ∇, ⍝, t, j, 1, M, 7, ∇, ⌈, ⍒, c, ⊂, ), ¯, B, ~, ^, L, G, f, z, ○, g, T, p, ⍳, !, ⍱, ⊖, x, ⍴, _, #, ), h, g, ⊖, ⌶, O, ∧, [, 1, @, ÷, ~, ÷, ^, c, W, $, ∘, ¨, i, ⊤, z, ≤, %, 0, f, ⊥, ⌹, ∪, ^, V, K, ⍴, ∇, ∨, @, A, ´, ∆, L, ', o, ⍨, A, ∨, x, ⊥, ⍵, W, g, T, ⌷, ', 6, 5, a, £, {, n, r, C, y, ⌷, -, k, ⍞, d, ∊, v, ∇, {, H, ∘, ⌈, k, 3, 8, ↑, ⍟, {, ⌊, ⌹, ≠, ○, -, c, $, ⍬, C, ⍴, ⍙, I, F, ~, O, ¨, h, m, ⍺, /, ⍀, ⊖, 2, j, (, A, ≢, ≡, Q, 0, ~, o, ∊, X, L, ⊢, ¨, ≠, (, ;, K, ⌊, ↓, o, !, N, w, ·, 9, t, ⍪, r, /, !, d, _, 8, ÷, }, ⌊, ↑, +, i, Q, R, ≡, ×, ⍙, ⌈, ∨, ⊣, p, u, ⍉, |, K, V, /, *, ÷, /, ⍎, f, U, r, ⍺, =, ⍺, ≢, 0, V, >, ×, ∪, $, 1, P, g, ÷, |, ≥, 0, I, M, L, d, ¯, ·, ⊃, 6, ○, ∧, ≤, ⍲, K, 8, ⊃, P, ⌹, }, f, /, F, J, ⊥, P, ⊤, ÷, C, ⍙, D, 3, c, $, \\, ×, ⍴, ∆, s, $, ⊤, ∇, ∊, \\, ⊢, £, ⍋, %, 2, ∆, ⌊\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(to_keep_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1106, 1106)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = to_keep_file_paths\n",
    "labels = to_keep_labels\n",
    "len(image_paths), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stratified_split(file_paths, labels, test_size=0.15, val_size=0.15, min_val_samples=1, random_state=42):\n",
    "    \"\"\"\n",
    "    Stratified split with minimum samples per class in all splits\n",
    "    \n",
    "    Args:\n",
    "        file_paths: List of lists of paths - [[class1_paths], [class2_paths], ...]\n",
    "        labels: List of class labels corresponding to file_paths\n",
    "        test_size: Proportion for test split\n",
    "        val_size: Proportion for validation split (relative to remaining after test)\n",
    "        min_samples: Minimum samples per class in each split (default=1)\n",
    "    \"\"\"\n",
    "    # Flatten structure and create label array\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(file_paths)\n",
    "    y = np.array(labels)\n",
    "    unique_classes = np.unique(y)\n",
    "    \n",
    "    # First split: test with min samples per class\n",
    "    test_indices = []\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        n_test = int(test_size * len(cls_indices))\n",
    "        test_indices.extend(np.random.choice(cls_indices, n_test, replace=False))\n",
    "    \n",
    "    # Remaining indices for train/val\n",
    "    remaining_mask = ~np.isin(np.arange(len(X)), test_indices)\n",
    "    X_remaining, y_remaining = X[remaining_mask], y[remaining_mask]\n",
    "    \n",
    "    # Second split: validation from remaining\n",
    "    val_indices = []\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y_remaining == cls)[0]\n",
    "        n_val = max(min_val_samples, int(val_size * len(cls_indices)))\n",
    "        val_indices.extend(np.random.choice(cls_indices, n_val, replace=False))\n",
    "    \n",
    "    # Final indices\n",
    "    train_mask = ~np.isin(np.arange(len(X_remaining)), val_indices)\n",
    "    return (\n",
    "        X_remaining[train_mask].tolist(), y_remaining[train_mask].tolist(),  # Train\n",
    "        X_remaining[val_indices].tolist(), y_remaining[val_indices].tolist(),  # Val\n",
    "        X[test_indices].tolist(), y[test_indices].tolist()  # Test\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (948): ['c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u21-0ba0e7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u21-42642791.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u21-42978592.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u21-66289430.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u21-bfa10e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u21-d84cfa.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2190-55215127.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2190-58393585.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2190-61503191.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2190-67210239.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2190-70015157.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2190-99260323.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2191-304c53.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2191-3dc589.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2191-46075384.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2191-69561941.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2191-91964355.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2191-e56a10.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2192-25343310.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2192-3802196.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2192-46578328.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2192-58730536.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2192-74684310.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2192-80177598.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2193-202dd2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2193-39928459.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2193-44648359.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2193-45520262.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2193-8e3c87.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2193-f022d5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22-23000995.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22-45985003.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22-50385949.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22-53334101.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22-82590010.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22-99178174.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2206-42429311.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2206-5b2b0f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2206-6ecab9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2206-7574627.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2206-b97c9a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2206-fe9dbc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2207-0d3ed4.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2207-42681604.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2207-9088968.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2207-b6c238.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2207-d0d157.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2207-f85c46.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u220a-1f8db1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u220a-52809335.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u220a-59577638.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u220a-66198852.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u220a-871485.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u220a-ebe759.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2218-507714.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2218-64029741.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2218-87696064.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2218-8f9bcf.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2218-99321169.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2218-a1b0fb.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2223-37992029.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2223-38578694.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2223-40082477.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2223-62497694.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2223-76589945.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2223-76822126.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2227-035454.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2227-37266612.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2227-39402187.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2227-697179.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2227-6bba7c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2227-bbcb81.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2228-148f6b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2228-19718218.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2228-37109284.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2228-3f66ab.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2228-90160152.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2228-afbd45.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2229-0010e0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2229-58137752.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2229-66603057.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2229-ca9a6f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2229-d17415.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2229-f11cc3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u222a-12d42c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u222a-35695099.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u222a-61737a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u222a-62388859.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u222a-64061422.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u222a-818b4b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2260-19181737.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2260-269a75.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2260-27748770.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2260-5c78ef.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2260-64880231.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2260-ad1ff9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2261-34091755.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2261-401976.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2261-41090096.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2261-48c6cb.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2261-80232083.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2261-d7c356.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2262-24747982.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2262-24778439.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2262-526416.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2262-5eaf38.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2262-84d691.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2262-b82868.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2264-73900244.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2264-79092646.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2264-82e301.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2264-b6c8ca.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2264-b8c7de.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2264-dd5f25.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2265-261d2d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2265-59878862.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2265-66324444.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2265-8ea8cc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2265-e0963c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2265-e6bdb3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2282-663740.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2282-702bdd.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2282-77805052.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2282-95833313.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2282-ee67ae.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2282-f6c9c4.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2283-0ddc31.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2283-2bc620.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2283-3dc242.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2283-72332168.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2283-7620228.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2283-91327464.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2296-10540839.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2296-52200b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2296-55098302.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2296-77143170.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2296-7bfef5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2296-fc6b5c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a2-10380968.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a2-26613401.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a2-31926772.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a2-9a4807.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a2-cace93.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a2-cf25b4.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a3-3596916.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a3-64370d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a3-79418277.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a3-9482706.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a3-9ff606.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a3-b1a34a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a4-03698b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a4-204ea3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a4-56815563.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a4-58631832.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a4-65c2f2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a4-6f7e7e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a5-0e7542.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a5-49649835.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a5-52617625.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a5-72547538.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a5-da05e8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a5-e8a960.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22c4-20762229.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22c4-23724809.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22c4-34999720.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22c4-57555730.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22c4-74773176.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22c4-95720964.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u23-21021987.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u23-24419795.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u23-2757942.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u23-34782062.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u23-67114088.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u23-77048301.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2308-16230440.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2308-43347008.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2308-4a41c6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2308-58145f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2308-8f1ca3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2308-aa0261.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u230a-3942f5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u230a-76584f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u230a-78193088.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u230a-91705914.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u230a-ae6490.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u230a-e31666.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2336-2011ae.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2336-23247904.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2336-23512461.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2336-23701198.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2336-5e4560.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2336-adc4ec.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2337-042695.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2337-0a795d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2337-33735742.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2337-39713543.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2337-ba2cba.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2337-c7b5a1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2339-361765.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2339-61145578.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2339-68845743.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2339-7117de.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2339-79990412.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2339-a2ed12.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233d-11c5d6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233d-274c7b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233d-38a480.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233d-4189497.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233d-7dcf5d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233d-86643372.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233f-19018037.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233f-2800761.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233f-2ac6b2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233f-72481910.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233f-9c8d2b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233f-f45105.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2340-0a5550.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2340-16006873.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2340-50143997.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2340-72759025.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2340-8cec13.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2340-9fe27d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2349-2398c9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2349-91939900.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2349-97254032.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2349-d9d22a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2349-f91850.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2349-f95839.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234b-29234073.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234b-50471782.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234b-5143ef.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234b-569aa9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234b-88326f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234b-f0dc63.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234e-46741429.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234e-64955903.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234e-6e5df4.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234e-85123010.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234e-c3bbaa.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234e-f4ff83.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2352-079644.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2352-2101153.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2352-27df1e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2352-6739240.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2352-75791181.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2352-cade73.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2355-482a14.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2355-6188a5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2355-68327785.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2355-77484765.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2355-c25d15.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2355-e29f50.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2359-3e9e2d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2359-5f8177.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2359-61083649.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2359-69972118.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2359-8e4868.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2359-ffe4fb.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235d-13449076.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235d-21336209.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235d-56614105.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235d-5711742.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235d-8284775.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235d-84230058.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235e-22908037.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235e-48168613.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235e-55944206.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235e-70867940.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235e-81778273.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235e-90688838.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235f-34da88.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235f-60887326.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235f-82933441.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235f-82ad67.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235f-a026a7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235f-d4a086.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2363-16934219.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2363-36470288.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2363-50817861.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2363-55273623.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2363-72353393.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2363-86109459.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2368-33135947.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2368-362338.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2368-5b9428.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2368-73491a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2368-89211068.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2368-edf03b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236a-14898369.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236a-36f37f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236a-65157372.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236a-6aaa68.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236a-c89027.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236a-ebf362.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236b-06c176.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236b-12047871.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236b-30172923.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236b-5cfd42.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236b-5eb7c6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236b-64432101.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236c-1039bc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236c-2f684a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236c-43977219.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236c-6e92fa.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236c-89055457.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236c-d84ff2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2371-2880ba.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2371-336be7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2371-50024671.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2371-78306088.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2371-91601522.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2371-cb9402.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2372-29353980.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2372-35603102.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2372-7331ad.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2372-7facb4.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2372-88850967.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2372-c93e7a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2373-0382a3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2373-14138439.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2373-3b03d1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2373-3c2e71.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2373-45259696.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2373-cb509b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2374-37030743.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2374-38519713.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2374-3c737e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2374-413ee1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2374-789850.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2374-81291511.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2375-240641.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2375-44844946.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2375-494dc5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2375-5bfe9e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2375-6249498.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2375-794415.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2377-21292791.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2377-36168423.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2377-52832317.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2377-60887278.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2377-66540935.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2377-74743355.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u237a-54248441.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u237a-54965273.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u237a-67493610.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u237a-90bbe0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u237a-b72ed6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u237a-e11db1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2395-35174415.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2395-4781560.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2395-59220967.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2395-59357010.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2395-65998989.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2395-75540688.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u24-14097460.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u24-1b376f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u24-30a7dd.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u24-432e38.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u24-7f92a6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u24-98320456.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25-63c53d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25-713721.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25-74554300.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25-77301966.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25-a73520.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25-a78e22.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25cb-23591b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25cb-67544696.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25cb-72d505.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25cb-87027951.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25cb-eff6e3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25cb-f291a2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u26-2251275.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u26-24383181.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u26-40324244.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u26-67050259.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u26-81290968.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u26-90574850.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u27-105f9a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u27-24911589.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u27-36637283.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u27-4517977.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u27-bace06.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u27-c74251.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u28-63435184.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u28-85623900.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u28-b265c5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u28-ed4fdd.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u28-efe5af.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u28-ff1ff7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u29-22486720.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u29-27453405.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u29-49217834.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u29-51742068.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u29-66799680.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u29-78288428.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2a-13988744.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2a-2f87f6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2a-58163609.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2a-63498263.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2a-697e74.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2a-8a60ff.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2b-14610617.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2b-17de03.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2b-38259633.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2b-89410222.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2b-cf8499.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2b-da2980.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2c-59963174.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2c-61913660.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2c-85058473.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2c-87b760.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2c-9441be.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2c-f30460.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2d-15663639.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2d-1f634c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2d-3f7a61.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2d-6ac69c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2d-94756345.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2d-fff4f6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2e-0b211c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2e-29982497.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2e-36929226.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2e-6f86c8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2e-945755.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2e-96607748.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2f-18856048.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2f-24995519.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2f-257bd2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2f-30340436.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2f-402682.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2f-81edc3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u30-33268581.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u30-62216699.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u30-70827145.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u30-792f2a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u30-c7b01f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u30-d04e81.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u31-3b2fbc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u31-5901ee.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u31-5f8fa9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u31-6715012.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u31-85935674.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u31-e9dd1e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u32-25339528.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u32-25c098.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u32-48b3c4.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u32-504553.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u32-72599614.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u32-83737148.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u33-19428597.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u33-6759ce.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u33-7a3404.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u33-83036336.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u33-98250999.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u33-d0066d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u34-16007729.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u34-19c843.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u34-53502402.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u34-536df7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u34-92438028.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u34-e99a2f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u35-26611143.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u35-45048274.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u35-45ef33.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u35-52031597.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u35-946325.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u35-ea21ea.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u36-0c83bc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u36-39ef04.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u36-59832855.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u36-78144257.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u36-95473694.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u36-a31f57.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u37-0cebdb.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u37-1831d8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u37-28304135.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u37-44670638.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u37-b55af7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u37-b733a8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u38-0472c8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u38-0a7d17.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u38-11150832.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u38-15181204.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u38-73489702.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u38-c3d1f6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u39-11255399.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u39-20089879.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u39-a0dc43.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u39-c1dd49.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u39-e75b56.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u39-eee500.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3a-10471161.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3a-2918876.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3a-39502089.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3a-53441905.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3a-68736877.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3a-8817106.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3b-21802942.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3b-29417211.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3b-96628114.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3b-b61557.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3b-de8135.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3b-fe56ae.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3c-009251.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3c-33272858.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3c-39292780.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3c-4419466.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3c-83c1f8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3c-b51c8d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3d-11699c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3d-3ac447.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3d-538dde.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3d-62059632.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3d-98785120.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3d-b2d0ad.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3e-5d78ff.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3e-633359.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3e-85124482.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3e-96445944.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3e-98ebaa.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3e-cdadcc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3f-1ec112.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3f-51586643.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3f-80157843.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3f-93319330.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3f-e19baf.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3f-e643ae.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u40-13382017.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u40-17531949.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u40-28461474.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u40-42483226.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u40-72676948.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u40-77579762.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u41-2d6e58.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u41-52589103.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u41-801ce2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u41-96884674.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u41-9a02e3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u41-9d4a25.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u42-25997128.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u42-4cc0c5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u42-53360992.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u42-89116142.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u42-b45587.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u42-e28293.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u43-12d9d3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u43-14677078.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u43-57847546.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u43-78a5f8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u43-813a1d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u43-8592882.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u44-0e5fed.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u44-26214268.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u44-62503908.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u44-9caabc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u44-bc32ef.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u44-da4397.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u45-636aed.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u45-65955133.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u45-76914759.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u45-bb5ab2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u45-de1f4f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u45-fa9002.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u46-4641d8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u46-6451bb.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u46-7a1978.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u46-84919288.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u46-90727146.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u46-a66e25.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u47-33445443.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u47-36706200.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u47-3729fb.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u47-a5c01c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u47-a8c1e3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u47-b299fd.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u48-28428632.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u48-3cc8cd.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u48-446c52.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u48-5f4fec.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u48-79090697.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u48-9e3d25.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u49-24e44d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u49-38beba.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u49-47283339.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u49-85519820.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u49-88303234.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u49-af72b6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4a-090ad8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4a-40342519.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4a-8329988.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4a-90331581.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4a-982f46.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4a-a10486.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4b-2cb16a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4b-424e16.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4b-47597709.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4b-77189623.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4b-781912.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4b-b871ac.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4c-22425684.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4c-35668714.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4c-7c9a79.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4c-89143583.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4c-da99d9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4c-fa681a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4d-21bab1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4d-4d4b1e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4d-55017225.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4d-5a511c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4d-67486505.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4d-67863938.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4e-25779864.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4e-49201228.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4e-557f6c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4e-7d4b87.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4e-8c40b8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4e-ba3e0e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4f-20813b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4f-25190439.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4f-36310192.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4f-602d3c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4f-98213157.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4f-a14cab.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u50-10094378.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u50-206b1b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u50-215cae.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u50-42427368.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u50-5c510f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u50-740483.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u51-071b5c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u51-25883202.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u51-34d3af.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u51-37015680.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u51-df314b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u51-fe7cbf.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u52-382b71.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u52-40581258.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u52-51444494.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u52-69629622.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u52-8e592b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u52-9e2a67.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u53-5610f1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u53-63862532.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u53-672fa5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u53-69468268.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u53-83195493.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u53-fea9ce.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u54-4330255.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u54-43992178.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u54-53369261.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u54-5cfe00.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u54-c4066c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u54-ebad4f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u55-17082721.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u55-46278188.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u55-83c3dc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u55-90761967.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u55-d1ba59.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u55-f4eb94.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u56-23515229.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u56-45830905.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u56-64131413.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u56-e064ed.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u56-e8afc8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u56-ff5c75.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u57-18307941.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u57-46958357.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u57-565788.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u57-722cdc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u57-8c5f9b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u57-f112d2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u58-25907692.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u58-4f161c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u58-5a804b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u58-74202864.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u58-83960663.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u58-8ca5c0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u59-15883333.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u59-3de5e8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u59-45243790.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u59-68367453.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u59-73d764.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u59-b03c71.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5a-2d7f67.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5a-37773921.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5a-52121031.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5a-8938cd.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5a-c9f59d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5a-e25472.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5b-034e63.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5b-43ab98.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5b-6216731.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5b-670362.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5b-71864307.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5b-92281704.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5c-12187962.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5c-59093587.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5c-654b71.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5c-66449673.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5c-67ec25.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5c-76b8cc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5d-23701464.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5d-53110161.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5d-60865224.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5d-63209136.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5d-76958575.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5d-86779785.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5e-39319109.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5e-56975202.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5e-57816506.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5e-77927634.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5e-83273169.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5e-86793575.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5f-501a8b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5f-58408779.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5f-800497.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5f-83610581.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5f-91574567.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5f-faa1a2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u60-28121762.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u60-46681649.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u60-83958929.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u60-86392790.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u60-91964064.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u60-97815120.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u61-447a63.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u61-5405128.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u61-87487744.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u61-96924571.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u61-b4c875.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u61-de80e0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u62-18006350.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u62-1f24a6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u62-392ad9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u62-8636419.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u62-dbe280.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u62-e5f5b0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u63-1e5901.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u63-47857227.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u63-67035003.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u63-8664568.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u63-b52aa7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u63-b705ee.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u64-11178077.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u64-18112140.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u64-68627573.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u64-907ac7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u64-b9d78d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u64-d4654b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u65-079f37.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u65-3960301.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u65-42732412.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u65-43106826.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u65-83abc6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u65-9580dc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u66-46013082.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u66-681b57.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u66-710a0d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u66-72225335.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u66-7667c7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u66-d5973d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u67-15672451.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u67-1664a8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u67-2f5ae0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u67-560af6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u67-8547535.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u67-b01926.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u68-14011773.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u68-28f1a4.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u68-53662008.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u68-56803131.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u68-58f009.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u68-e02ce9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u69-2fc13b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u69-39659474.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u69-55f375.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u69-8944921.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u69-95459970.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u69-f5d049.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6a-13033753.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6a-24351279.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6a-5e7d13.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6a-a00c19.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6a-b3313a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6a-e8c250.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6b-2c9d96.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6b-39488941.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6b-55343688.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6b-76067607.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6b-7a41a5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6b-8a3913.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6c-2c6705.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6c-38307994.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6c-3b891e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6c-4771384.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6c-50782292.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6c-9e7b36.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6d-3b4c5d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6d-4f865a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6d-56170102.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6d-58330229.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6d-5e0b1d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6d-94736021.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6e-15005822.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6e-1871e4.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6e-21dd34.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6e-99360915.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6e-b6e4d1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6e-d04d82.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6f-55109178.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6f-587b6f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6f-59015080.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6f-692eca.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6f-98365037.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6f-da5385.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u70-16180735.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u70-17407707.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u70-46bd55.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u70-86415880.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u70-97c3cf.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u70-c9c63f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u71-19388058.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u71-2521a3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u71-5a7cc3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u71-70257993.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u71-71498374.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u71-93125c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u72-1cfe05.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u72-40282136.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u72-5d89e8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u72-70205c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u72-8a36b2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u72-93882311.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u73-0c49ac.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u73-29911b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u73-75774992.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u73-8255db.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u73-98889660.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u73-ed988f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u74-17874820.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u74-21374006.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u74-67ed4d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u74-78912a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u74-8528077.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u74-99cb97.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u75-1a8a18.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u75-30650130.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u75-47587569.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u75-4fd31f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u75-e6868a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u75-e957ba.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u76-36332902.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u76-41112045.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u76-77538239.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u76-899a87.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u76-89e7c0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u76-aabf24.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u77-06e6a1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u77-3c52ac.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u77-86162327.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u77-956c8a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u77-97814988.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u77-9b1008.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u78-145e4a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u78-14917444.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u78-322045.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u78-42036683.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u78-56809140.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u78-8fa3bf.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u79-25337537.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u79-55541551.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u79-654bca.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u79-655f85.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u79-9d5dc0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u79-a0647d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7a-21006470.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7a-36338421.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7a-a25c8b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7a-a5018a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7a-af33a5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7a-f45693.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7b-1172745.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7b-52578920.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7b-5606789.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7b-596dd3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7b-6995f3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7b-a4d131.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7c-85884771.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7c-95273137.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7c-a7ac9b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7c-b2d001.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7c-c4ed3e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7c-e827b6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7d-04cdf9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7d-12157469.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7d-3930ec.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7d-80650206.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7d-99810258.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7d-b75a9b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7e-1253300.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7e-5b3bdb.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7e-813916.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7e-97811138.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7e-e2e14d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7e-ebcf97.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua3-0fe6c2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua3-22020387.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua3-40495167.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua3-75957630.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua3-8d2da0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua3-b1feb9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua8-2197f7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua8-23886549.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua8-59373844.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua8-61091988.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua8-aaeffc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua8-e3688a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uaf-19590923.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uaf-1fe8a2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uaf-5139448.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uaf-51813404.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uaf-65e5d6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uaf-d8ae60.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub4-27380720.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub4-31075468.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub4-40595583.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub4-75849320.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub4-80090702.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub4-91215735.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub7-16212206.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub7-1938ad.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub7-3518919.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub7-5248d4.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub7-646b2d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub7-88164665.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ud7-06f44b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ud7-10085415.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ud7-592dfe.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ud7-64006131.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ud7-82aa4b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ud7-c62dcc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uf7-19806161.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uf7-33188985.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uf7-39852802.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uf7-5590c9.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uf7-e5cf14.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uf7-ec8bd0.png'] ['N', '⍫', '6', 'Y', '∣', '⍬', '⌽', 'G', '⋄', '?', '∊', ']', '⍺', '>', 'q', 'X', 'f', '¯', 'e', '⌷', '6', '⍨', 'a', ':', 't', 'G', 'F', 'b', '⌶', '⎕', ';', '5', 'x', 'j', 'T', '+', '≥', '⍬', '⍺', '⊥', 'G', 'a', '∩', 'K', 'a', 'c', '=', '~', '←', '\\\\', 'B', '?', '⍴', 'K', '9', '⍞', 'o', 'P', '#', '≠', '2', '⍲', '⌿', '∣', 'V', 'F', '↑', 'Q', 'Y', 'q', '⍷', '9', '⊤', '⌶', '≠', 'y', '⍝', '⍎', '`', '¨', ']', '←', 'S', '?', '<', 'A', '¨', '5', 'Z', '}', '\\\\', '´', '·', '_', 'F', '⊂', '.', '\\\\', '←', 'S', '↓', '`', '⍬', '=', '∆', 'd', 'h', '\"', '6', '(', '○', ':', 'Y', '⍳', 'W', 'o', 'e', '∣', '↑', 'E', '+', ';', '+', '⍨', '⍒', 'R', '∣', \"'\", 'h', '<', '×', 'u', '∧', '⍉', '⍫', '3', '\"', 'M', 'V', '·', '⍣', '#', '≥', '○', '⍬', '1', 'C', '&', '⎕', 'l', '⊂', '?', 'y', 'Q', 'n', '|', '∩', ',', 'D', '≠', '→', '∪', 'H', '⍟', '×', '*', '⍲', 'J', '∊', 'E', '⍫', '∆', 'S', '-', '\"', '⍎', 'O', '⍞', 'R', '⋄', '+', '⍪', 'r', '⍒', '#', '&', 'i', 'U', '∘', '\\\\', '[', '≠', '⌽', '^', '⌽', '∩', 'w', 'b', '↑', 's', '(', 'I', 'U', '∊', '>', '⊃', '∆', '=', '⍴', '⍉', '→', '⍝', 'C', 'J', '⌈', '}', '∪', '#', '_', '>', '⍣', '⊂', '∘', 'h', '⍪', '↓', '⍋', 'n', '⎕', 'J', \"'\", '4', '⍪', 'S', '-', \"'\", '≥', '⍳', 'G', 'L', 'M', '*', '+', 'v', '≤', '%', '¯', 'k', '∧', '⊣', '7', 'f', '5', '≤', '⍣', 'z', '⍒', 'y', 'E', '⍀', '8', 'R', '∨', ';', '@', 'q', '⍱', '_', 's', '1', 't', '⊢', 'A', '3', '÷', 'R', '0', '>', '⋄', '∪', '8', 'v', 'Q', 's', '⌹', 't', 'i', '⍣', ':', '&', 'N', 'l', '\"', '∨', '⌿', '6', '⍉', '{', 'Q', 'b', '⍳', '≢', 'G', 'x', 'U', ']', 'p', '←', 'r', '(', 'D', '⌶', '⍷', 'V', '\"', '≡', ']', 'P', '⍷', '⍫', '⌈', ':', '⌷', '⍀', 'I', '≤', 'T', 'D', '⍫', '∧', 'w', 'e', 'H', 'k', '⍝', '⊣', '⌈', '·', '¨', \"'\", 'm', '⊢', '⍞', '⌽', 'v', '¯', 'u', '⍀', '⊢', '⍳', '⍋', 't', '×', '=', 'z', '}', '0', '⍲', '⍣', 'W', 'j', '`', '*', '↓', '∨', '8', '⊤', 'l', '⍎', '⎕', 'y', '⍎', 'e', 'n', 'X', 'N', '%', '⍪', 'm', 'Z', '⊤', 'q', 'p', 'D', '⌶', 'A', '*', 'Z', '⍟', '∇', 'Y', '´', '←', '-', 'T', '≡', '`', '⍱', '?', '~', 'i', 'y', '⊢', '→', '⍀', '⍬', 'K', '`', '\"', '⍷', '≡', ':', '/', '⍱', '·', ')', 'R', '.', '⊖', ')', '⌊', '∩', '⊖', '@', 'L', 'k', '£', 'v', '⎕', 'Y', 'I', '´', 'B', 'b', '○', '→', 'T', 'e', 'p', '⍵', '⍟', '2', '→', 'u', 'H', '5', ')', 'k', 'X', '^', '⍒', '⍨', 'u', '[', '⍱', '↑', '⍲', 'X', '#', '∇', '⍷', '&', '⍵', 'O', 'l', 'h', '⊂', '⌶', '⊂', '≤', 'w', 'Z', 'O', '9', 'a', '∣', '⍉', 'V', ')', '.', 'M', 'l', '⌿', '%', '7', '⊃', '%', ';', '⍺', 'a', '⍝', '4', '[', '<', '≢', '○', 'd', '3', '[', '&', '.', '⊣', 'x', 'z', 'P', '!', 'J', '⌷', 'B', '*', '£', '⊥', '£', 'S', 'F', '≥', '⋄', 'l', '⍙', 'Y', '⍟', '⍋', '∣', '|', 's', ']', ':', 'n', '~', '⍝', '\\\\', 'I', 'j', '⍎', '⍕', '!', '2', '⍵', '⍕', '5', ';', '^', '´', 'n', '⍒', 'd', '|', '⍵', '⍙', ',', '≡', '@', '=', 'z', '⍫', '.', '·', 'm', 'M', '⌽', ']', 'g', '⍲', 'B', '-', '{', '⍣', '⎕', '9', 'o', 'E', '7', '⊣', 'W', '|', '→', '⍞', 'c', '⍴', ',', 'C', '∊', 'b', '⍞', 'm', '⊥', 'p', 'v', '⌊', '⍕', '⍨', '&', '⋄', '⌈', \"'\", 's', '⍱', '∪', '£', '⍀', 'c', 'W', '⍷', '⍟', '⊣', '⊖', 'o', '<', '_', '4', 'f', '∩', 'B', 'b', 'E', 'U', '⍪', 'X', '⍙', 'w', '´', '≥', '3', '7', 'S', '↓', 'F', 'U', '4', 'H', '2', '$', '⊃', '⌿', '?', '≢', '!', 'x', 'N', '∧', '∆', '⌽', ')', ',', 'q', '>', 'E', '⋄', 'J', '⍋', '⍉', '⊃', '3', 'N', '∩', 'r', '⌿', '≢', 'B', '⍕', 'k', 'C', '¯', 'e', '⍕', 'H', '1', 'Z', '⍋', '⍬', '⌹', 'Z', '⍨', 'h', 'd', ',', '_', '∘', '∨', '4', '<', '{', '←', '∘', 'O', 'g', '⍕', '@', 'm', '≢', '⍳', 'i', '⌷', '[', 'w', '⌿', 'u', '.', '4', '}', '<', '↓', '9', '£', '⌹', '5', '⍵', '⌶', 'D', 'j', 'q', '⊤', ',', '`', 'r', '(', '7', '∇', '⍝', 't', 'j', '1', 'M', '7', '∇', '⌈', '⍒', '⊂', ')', '¯', '~', '^', 'L', 'G', 'z', 'g', 'T', 'p', '⍳', '!', '⍱', '⊖', 'x', '⍴', '#', 'g', '⊖', 'O', '∧', '[', '1', '@', '÷', '÷', '^', 'c', 'W', '$', '∘', '¨', 'i', '⊤', 'z', '≤', '%', '0', 'f', '⊥', '⌹', '∪', '^', 'K', '∇', '∨', '@', 'A', '´', '∆', 'L', \"'\", 'o', '⍨', 'A', '∨', 'x', '⊥', '⍵', 'W', 'g', 'T', '⌷', '6', 'a', '{', 'n', 'r', 'C', 'y', '⌷', '-', 'k', '⍞', '∊', 'v', '{', 'H', '∘', '3', '8', '↑', '⍟', '{', '⌊', '⌹', '≠', '○', '-', 'c', '$', 'C', '⍴', '⍙', 'I', '~', 'O', '¨', 'h', 'm', '⍺', '/', '⍀', '⊖', '2', 'j', '(', 'A', '≢', '≡', 'Q', '0', '~', 'o', '∊', 'X', 'L', '⊢', '¨', '≠', '(', ';', 'K', '⌊', '↓', '!', 'N', 'w', '9', 't', '⍪', 'r', '/', '!', 'd', '_', '8', '}', '⌊', '↑', '+', 'i', 'Q', 'R', '≡', '×', '⍙', '⌈', '⊣', 'p', 'u', '⍉', '|', 'V', '/', '*', '÷', '/', '⍎', 'f', 'U', '⍺', '=', '⍺', '0', 'V', '>', '×', '∪', '$', '1', 'P', 'g', '÷', '|', '≥', '0', 'I', 'M', 'L', 'd', '¯', '·', '⊃', '6', '○', '∧', '≤', '⍲', 'K', '8', '⊃', 'P', '⌹', '}', 'f', '/', 'F', 'J', '⊥', 'P', '÷', '⍙', 'D', 'c', '$', '×', '⍴', '∆', 's', '$', '⊤', '∇', '\\\\', '⊢', '£', '⍋', '%', '2', '⌊']\n",
      "Val   (158): ['c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u21-68bb9b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2190-39013164.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2191-37975b.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2192-96214854.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2193-34633d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22-94754808.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2206-3554674.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2207-47046714.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u220a-1332ba.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2218-af7110.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2223-69665312.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2227-65362279.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2228-0a8af0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2229-94555105.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u222a-ff4675.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2260-90230e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2261-23cd3f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2262-77536410.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2264-77811817.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2265-99164409.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2282-44130863.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2283-80a72f.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2296-c15e91.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a2-08a8dd.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a3-4c3d74.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a4-42205149.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22a5-2a53c6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u22c4-10463900.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u23-58365718.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2308-62262513.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u230a-8504615.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2336-d04bbd.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2337-21693757.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2339-f38d33.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233d-6133155.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u233f-a9a75a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2340-d05802.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2349-81198048.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234b-36621030.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u234e-dfc7b1.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2352-c52fe5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2355-80794043.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2359-43202090.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235d-28313191.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235e-29035095.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u235f-52818791.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2363-68875635.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2368-56801823.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236a-79991272.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236b-252ca3.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u236c-80056070.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2371-ae75ef.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2372-044329.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2373-70017412.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2374-b4a903.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2375-80578945.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2377-38644381.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u237a-0b5d13.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2395-79787536.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u24-42943254.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25-12826560.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u25cb-88440491.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u26-13651063.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u27-f9ae7c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u28-47203194.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u29-11664566.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2a-0ebb5e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2b-60388c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2c-0d459c.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2d-75736465.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2e-c4731a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u2f-a53d4a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u30-f48ec8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u31-26560436.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u32-106468.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u33-849deb.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u34-a7dcaa.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u35-e1a748.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u36-68045a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u37-59039152.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u38-b68cae.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u39-4456935.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3a-86792886.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3b-75d6a2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3c-ceb1d5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3d-93506274.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3e-91768959.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u3f-b860f8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u40-89694804.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u41-99871129.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u42-2fdcb2.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u43-f15d5d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u44-54937137.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u45-14179488.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u46-7416765.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u47-42775433.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u48-11841543.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u49-07f9a7.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4a-154f40.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4b-43319104.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4c-999a9a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4d-769b78.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4e-31964180.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u4f-05d0db.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u50-78255716.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u51-32387126.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u52-d50aff.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u53-f777f6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u54-bf7365.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u55-d1fa11.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u56-6b5fb6.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u57-f53416.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u58-ba1e98.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u59-464d60.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5a-66953452.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5b-273102.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5c-452198.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5d-95282848.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5e-32491643.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u5f-32b90d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u60-68628793.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u61-e2100e.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u62-20786193.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u63-557d75.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u64-b9cdcc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u65-79c935.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u66-42445880.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u67-61499467.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u68-f5e3e8.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u69-a966a5.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6a-96210528.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6b-f167fd.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6c-00aea0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6d-53dc99.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6e-43801270.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u6f-36323d.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u70-928667.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u71-a3f895.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u72-26656402.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u73-27173011.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u74-e05ee0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u75-16072911.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u76-be0051.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u77-16818846.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u78-baa2fc.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u79-40693621.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7a-93238136.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7b-bf52e0.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7c-66721889.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7d-f2772a.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\u7e-63466481.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua3-c31bea.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ua8-f9f490.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uaf-fb0942.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub4-62019701.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ub7-413f76.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\ud7-91031238.png', 'c:\\\\Users\\\\Leon\\\\visual-studio\\\\repos\\\\Le-o-n\\\\ocr-model-training\\\\src\\\\cnn_lora\\\\..\\\\..\\\\data\\\\apl_lora\\\\uf7-f18e64.png'] ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '£', '¨', '¯', '´', '·', '×', '÷', '←', '↑', '→', '↓', '∆', '∇', '∊', '∘', '∣', '∧', '∨', '∩', '∪', '≠', '≡', '≢', '≤', '≥', '⊂', '⊃', '⊖', '⊢', '⊣', '⊤', '⊥', '⋄', '⌈', '⌊', '⌶', '⌷', '⌹', '⌽', '⌿', '⍀', '⍉', '⍋', '⍎', '⍒', '⍕', '⍙', '⍝', '⍞', '⍟', '⍣', '⍨', '⍪', '⍫', '⍬', '⍱', '⍲', '⍳', '⍴', '⍵', '⍷', '⍺', '⎕', '○']\n",
      "Test  (0): [] []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_x, train_y, val_x, val_y, test_x, test_y = stratified_split(image_paths, labels, val_size=0, min_val_samples=1, test_size=0)\n",
    "\n",
    "print(f\"Train ({len(train_x)}): {sorted(train_x)} {train_y}\")\n",
    "print(f\"Val   ({len(val_x)}): {sorted(val_x)} {val_y}\")\n",
    "print(f\"Test  ({len(test_x)}): {sorted(test_x)} {test_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_label_classes = sorted(set(to_keep_labels))\n",
    "len(all_label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'!','\"','#','$','%','&',''','(',')','*','+',',','-','.','/','0','1','2','3','4','5','6','7','8','9',':',';','<','=','>','?','@','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','[','\\',']','^','_','`','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','{','|','}','~','£','¨','¯','´','·','×','÷','←','↑','→','↓','∆','∇','∊','∘','∣','∧','∨','∩','∪','≠','≡','≢','≤','≥','⊂','⊃','⊖','⊢','⊣','⊤','⊥','⋄','⌈','⌊','⌶','⌷','⌹','⌽','⌿','⍀','⍉','⍋','⍎','⍒','⍕','⍙','⍝','⍞','⍟','⍣','⍨','⍪','⍫','⍬','⍱','⍲','⍳','⍴','⍵','⍷','⍺','⎕','○'\n"
     ]
    }
   ],
   "source": [
    "print(','.join([\"\\'\" + str(x) + \"\\'\" for x in all_label_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_old_alphabet = ['(',')','+','-','.','0','1','2','3','4','5','6','7','8','9',':','<','=','>','[',']','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','{','}','×','÷','λ']\n",
    "_new_added_alphabet = [x for x in all_label_classes if x not in _old_alphabet]\n",
    "\n",
    "all_label_classes = _old_alphabet + _new_added_alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=train_x, #list(image_paths[:split_index]) + to_add_file_paths,\n",
    "    labels=train_y, #list(labels[:split_index]) + to_add_labels,\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.05,\n",
    "    translation_limit=0.2,\n",
    "    skew_limit=0.025,\n",
    "    zoom_change=1.2,\n",
    "    min_zoom=0.8,\n",
    "    thicken_sigma=-4.9,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "val_char_dataset: CharImageDataset = CharImageDataset(\n",
    "    file_paths=val_x,\n",
    "    labels=val_y,\n",
    "    all_label_classes=all_label_classes,\n",
    "    rotation_limit=0.0,\n",
    "    translation_limit=0.0,\n",
    "    skew_limit=0.00,\n",
    "    zoom_change=0.0,\n",
    "    min_zoom=1.0,\n",
    "    thicken_sigma=0.0,\n",
    "    image_dims=(64, 64)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "N\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "⍫\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Y\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "∣\n"
     ]
    }
   ],
   "source": [
    "for i, (im, lab) in enumerate(train_char_dataset):\n",
    "    \n",
    "    \n",
    "    plt.imshow(\n",
    "        rearrange(im, \"1 h w -> h w\")*255, \n",
    "        cmap=\"gray\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(lab)\n",
    "    print(all_label_classes[np.argmax(lab)])\n",
    "    if i > 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function to pad sequences to the same length.\n",
    "    \"\"\"\n",
    "    # Separate images and labels\n",
    "    images, labels = zip(*batch)\n",
    "\n",
    "    # Pad image sequences\n",
    "    images_padded = pad_sequence(images, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    # Pad label sequences\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    return images_padded, labels_padded\n",
    "\n",
    "train_dataloader: DataLoader = DataLoader(\n",
    "    train_char_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_dataloader: DataLoader = DataLoader(\n",
    "    val_char_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Pretrained CNN Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: encoder_conv_blocks.0.0.weight\n",
      "Loaded: encoder_conv_blocks.0.0.bias\n",
      "Loaded: encoder_conv_blocks.0.2.weight\n",
      "Loaded: encoder_conv_blocks.0.2.bias\n",
      "Loaded: encoder_conv_blocks.0.2.running_mean\n",
      "Loaded: encoder_conv_blocks.0.2.running_var\n",
      "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.0.4.weight\n",
      "Loaded: encoder_conv_blocks.0.4.bias\n",
      "Loaded: encoder_conv_blocks.0.6.weight\n",
      "Loaded: encoder_conv_blocks.0.6.bias\n",
      "Loaded: encoder_conv_blocks.0.6.running_mean\n",
      "Loaded: encoder_conv_blocks.0.6.running_var\n",
      "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.0.weight\n",
      "Loaded: encoder_conv_blocks.1.0.bias\n",
      "Loaded: encoder_conv_blocks.1.2.weight\n",
      "Loaded: encoder_conv_blocks.1.2.bias\n",
      "Loaded: encoder_conv_blocks.1.2.running_mean\n",
      "Loaded: encoder_conv_blocks.1.2.running_var\n",
      "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.1.4.weight\n",
      "Loaded: encoder_conv_blocks.1.4.bias\n",
      "Loaded: encoder_conv_blocks.1.6.weight\n",
      "Loaded: encoder_conv_blocks.1.6.bias\n",
      "Loaded: encoder_conv_blocks.1.6.running_mean\n",
      "Loaded: encoder_conv_blocks.1.6.running_var\n",
      "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.0.weight\n",
      "Loaded: encoder_conv_blocks.2.0.bias\n",
      "Loaded: encoder_conv_blocks.2.2.weight\n",
      "Loaded: encoder_conv_blocks.2.2.bias\n",
      "Loaded: encoder_conv_blocks.2.2.running_mean\n",
      "Loaded: encoder_conv_blocks.2.2.running_var\n",
      "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.2.4.weight\n",
      "Loaded: encoder_conv_blocks.2.4.bias\n",
      "Loaded: encoder_conv_blocks.2.6.weight\n",
      "Loaded: encoder_conv_blocks.2.6.bias\n",
      "Loaded: encoder_conv_blocks.2.6.running_mean\n",
      "Loaded: encoder_conv_blocks.2.6.running_var\n",
      "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.0.weight\n",
      "Loaded: encoder_conv_blocks.3.0.bias\n",
      "Loaded: encoder_conv_blocks.3.2.weight\n",
      "Loaded: encoder_conv_blocks.3.2.bias\n",
      "Loaded: encoder_conv_blocks.3.2.running_mean\n",
      "Loaded: encoder_conv_blocks.3.2.running_var\n",
      "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.3.4.weight\n",
      "Loaded: encoder_conv_blocks.3.4.bias\n",
      "Loaded: encoder_conv_blocks.3.6.weight\n",
      "Loaded: encoder_conv_blocks.3.6.bias\n",
      "Loaded: encoder_conv_blocks.3.6.running_mean\n",
      "Loaded: encoder_conv_blocks.3.6.running_var\n",
      "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.0.weight\n",
      "Loaded: encoder_conv_blocks.4.0.bias\n",
      "Loaded: encoder_conv_blocks.4.2.weight\n",
      "Loaded: encoder_conv_blocks.4.2.bias\n",
      "Loaded: encoder_conv_blocks.4.2.running_mean\n",
      "Loaded: encoder_conv_blocks.4.2.running_var\n",
      "Loaded: encoder_conv_blocks.4.2.num_batches_tracked\n",
      "Loaded: encoder_conv_blocks.4.4.weight\n",
      "Loaded: encoder_conv_blocks.4.4.bias\n",
      "Loaded: encoder_conv_blocks.4.6.weight\n",
      "Loaded: encoder_conv_blocks.4.6.bias\n",
      "Loaded: encoder_conv_blocks.4.6.running_mean\n",
      "Loaded: encoder_conv_blocks.4.6.running_var\n",
      "Loaded: encoder_conv_blocks.4.6.num_batches_tracked\n",
      "Loaded: fully_connected_blocks.0.0.weight\n",
      "Loaded: fully_connected_blocks.0.0.bias\n",
      "Loaded: fully_connected_blocks.1.0.weight\n",
      "Loaded: fully_connected_blocks.1.0.bias\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 256]                  --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           (160)\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           (32)\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           (2,320)\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           (32)\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           (4,640)\n",
      "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           (64)\n",
      "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           (9,248)\n",
      "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           (64)\n",
      "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           (9,248)\n",
      "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           (64)\n",
      "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             (9,248)\n",
      "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             (64)\n",
      "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             (9,248)\n",
      "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             (64)\n",
      "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             (9,248)\n",
      "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             (64)\n",
      "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 32, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 32, 4, 4]             (9,248)\n",
      "│    │    └─Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 32, 4, 4]             (64)\n",
      "│    │    └─LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
      "│    │    └─Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
      "│    │    └─LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
      "├─Sequential: 1-2                        [1, 128]                  --\n",
      "│    └─Flatten: 2-6                      [1, 128]                  --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-7                   [1, 128]                  --\n",
      "│    │    └─Linear: 3-41                 [1, 128]                  16,512\n",
      "│    │    └─Dropout: 3-42                [1, 128]                  --\n",
      "│    │    └─LeakyReLU: 3-43              [1, 128]                  --\n",
      "│    └─Sequential: 2-8                   [1, 256]                  --\n",
      "│    │    └─Linear: 3-44                 [1, 256]                  33,024\n",
      "==========================================================================================\n",
      "Total params: 121,968\n",
      "Trainable params: 58,848\n",
      "Non-trainable params: 63,120\n",
      "Total mult-adds (M): 14.08\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.18\n",
      "Params size (MB): 0.49\n",
      "Estimated Total Size (MB): 2.69\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "cnn_model: nn.Module = AllCNN2D(\n",
    "    **{\n",
    "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
    "        \"fully_connected_features\": (128, 256),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.075,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": LOAD_CHECKPOINT,\n",
    "        \"use_lora\": False,\n",
    "        \"frozen_layer_prefixes\": [\n",
    "            \"encoder_conv_blocks.0\", \n",
    "            \"encoder_conv_blocks.1\",\n",
    "            \"encoder_conv_blocks.2\", \n",
    "            \"encoder_conv_blocks.3\",\n",
    "            \"encoder_conv_blocks.4.0\",\n",
    "            \"encoder_conv_blocks.4.2\"\n",
    "        ],\n",
    "        \"lora_configs\": [\n",
    "            {\n",
    "                \"name\": \"lora_apl_v2\",\n",
    "                \"rank\": 4,\n",
    "                \"alpha\": 0.1\n",
    "            }\n",
    "        ],\n",
    "        \"default_lora_name\": \"lora_apl_v2\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze Non-LoRA Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozen]   encoder_conv_blocks.0.0.weight\n",
      "[frozen]   encoder_conv_blocks.0.0.bias\n",
      "[frozen]   encoder_conv_blocks.0.2.weight\n",
      "[frozen]   encoder_conv_blocks.0.2.bias\n",
      "[frozen]   encoder_conv_blocks.0.4.weight\n",
      "[frozen]   encoder_conv_blocks.0.4.bias\n",
      "[frozen]   encoder_conv_blocks.0.6.weight\n",
      "[frozen]   encoder_conv_blocks.0.6.bias\n",
      "[frozen]   encoder_conv_blocks.1.0.weight\n",
      "[frozen]   encoder_conv_blocks.1.0.bias\n",
      "[frozen]   encoder_conv_blocks.1.2.weight\n",
      "[frozen]   encoder_conv_blocks.1.2.bias\n",
      "[frozen]   encoder_conv_blocks.1.4.weight\n",
      "[frozen]   encoder_conv_blocks.1.4.bias\n",
      "[frozen]   encoder_conv_blocks.1.6.weight\n",
      "[frozen]   encoder_conv_blocks.1.6.bias\n",
      "[frozen]   encoder_conv_blocks.2.0.weight\n",
      "[frozen]   encoder_conv_blocks.2.0.bias\n",
      "[frozen]   encoder_conv_blocks.2.2.weight\n",
      "[frozen]   encoder_conv_blocks.2.2.bias\n",
      "[frozen]   encoder_conv_blocks.2.4.weight\n",
      "[frozen]   encoder_conv_blocks.2.4.bias\n",
      "[frozen]   encoder_conv_blocks.2.6.weight\n",
      "[frozen]   encoder_conv_blocks.2.6.bias\n",
      "[frozen]   encoder_conv_blocks.3.0.weight\n",
      "[frozen]   encoder_conv_blocks.3.0.bias\n",
      "[frozen]   encoder_conv_blocks.3.2.weight\n",
      "[frozen]   encoder_conv_blocks.3.2.bias\n",
      "[frozen]   encoder_conv_blocks.3.4.weight\n",
      "[frozen]   encoder_conv_blocks.3.4.bias\n",
      "[frozen]   encoder_conv_blocks.3.6.weight\n",
      "[frozen]   encoder_conv_blocks.3.6.bias\n",
      "[frozen]   encoder_conv_blocks.4.0.weight\n",
      "[frozen]   encoder_conv_blocks.4.0.bias\n",
      "[frozen]   encoder_conv_blocks.4.2.weight\n",
      "[frozen]   encoder_conv_blocks.4.2.bias\n",
      "[unfrozen] encoder_conv_blocks.4.4.weight\n",
      "[unfrozen] encoder_conv_blocks.4.4.bias\n",
      "[unfrozen] encoder_conv_blocks.4.6.weight\n",
      "[unfrozen] encoder_conv_blocks.4.6.bias\n",
      "[unfrozen] fully_connected_blocks.0.0.weight\n",
      "[unfrozen] fully_connected_blocks.0.0.bias\n",
      "[unfrozen] fully_connected_blocks.1.0.weight\n",
      "[unfrozen] fully_connected_blocks.1.0.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in cnn_model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        print(f\"[frozen]   {name}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"[unfrozen] {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(model):\n",
    "    l2_reg = 0.0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            l2_reg += torch.sum(param**2)\n",
    "    return l2_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "optim: AdamW = AdamW(\n",
    "    cnn_model.parameters(),\n",
    "    lr = 0.001,\n",
    "    weight_decay=5e-3\n",
    ")\n",
    "\n",
    "scheduler: torch.optim.lr_scheduler.LRScheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optim,\n",
    "    T_0=5,\n",
    "    T_mult=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1467, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_regularization(cnn_model) * 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trainable] encoder_conv_blocks.4.4.weight\n",
      "[trainable] encoder_conv_blocks.4.4.bias\n",
      "[trainable] encoder_conv_blocks.4.6.weight\n",
      "[trainable] encoder_conv_blocks.4.6.bias\n",
      "[trainable] fully_connected_blocks.0.0.weight\n",
      "[trainable] fully_connected_blocks.0.0.bias\n",
      "[trainable] fully_connected_blocks.1.0.weight\n",
      "[trainable] fully_connected_blocks.1.0.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in cnn_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"[trainable] {name}\")\n",
    "        #print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.allcnn2d import LoRALinearWrapper, LoRAConv2DWrapper\n",
    "\n",
    "\n",
    "for name, module in cnn_model.named_modules():\n",
    "    if isinstance(module, LoRALinearWrapper) or isinstance(module, LoRAConv2DWrapper):\n",
    "        print(f\"{name}: adapters={list(module.lora_adapters.keys())}, scalings={module.active_scalings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84 - Training:  14%|█▎        | 32/237 [00:15<01:39,  2.07it/s, L2Reg=0.6352, Loss (Total)=5.3499, Loss (L1)=832.4261, Loss (MSE)=3238.4941]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup\n",
    "SESSION_STARTTIME_STR = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "CSV_LOG_FILE = f\"{SESSION_STARTTIME_STR}__{MODEL_NAME}__training_metric.csv\"\n",
    "\n",
    "# Write CSV header if file doesn't exist\n",
    "if not os.path.isfile(CSV_LOG_FILE):\n",
    "    with open(CSV_LOG_FILE, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\n",
    "            \"epoch\",\n",
    "            \"train_loss\", \"train_l1\", \"train_mse\", \"train_acc\",\n",
    "            \"val_loss\", \"val_l1\", \"val_mse\", \"val_acc\"\n",
    "        ])\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    train_loss_total: float = 0\n",
    "    train_l1_total: float = 0\n",
    "    train_mse_total: float = 0\n",
    "    train_correct: int = 0\n",
    "    train_samples: int = 0\n",
    "\n",
    "    train_loader = tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch+1} - Training\", leave=False)\n",
    "    for X, y in train_loader:\n",
    "        X: torch.Tensor = X.to(DEVICE)\n",
    "        y: torch.Tensor = y.to(DEVICE)\n",
    "\n",
    "        y_pred: torch.Tensor = cnn_model(X)\n",
    "\n",
    "        y_padded: torch.Tensor = F.pad(y, (0, y_pred.shape[1] - y.shape[1]))\n",
    "\n",
    "        loss: torch.Tensor = F.cross_entropy(y_pred, y.argmax(dim=1), reduction='sum')\n",
    "        l1_loss: torch.Tensor = F.l1_loss(y_pred, y_padded, reduction='sum')\n",
    "        mse_loss: torch.Tensor = F.mse_loss(y_pred, y_padded, reduction='sum')\n",
    "\n",
    "        \n",
    "        reg = optim.param_groups[0][\"weight_decay\"] * l2_regularization(cnn_model) \n",
    "\n",
    "        \n",
    "        loss = loss / X.size(0) + reg\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        \n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "        train_loss_total += loss.item() * X.size(0)\n",
    "        train_l1_total += l1_loss.item()\n",
    "        train_mse_total += mse_loss.item()\n",
    "        \n",
    "        \n",
    "        preds = y_pred.argmax(dim=1)\n",
    "        targets = y.argmax(dim=1).long()\n",
    "        train_correct += (preds == targets).sum().item()\n",
    "        train_samples += X.size(0)\n",
    "\n",
    "        scheduler.step(epoch + train_samples / len(train_dataloader.dataset))\n",
    "\n",
    "        train_loader.set_postfix({\n",
    "            \"L2Reg\": f\"{reg:.4f}\",\n",
    "            \"Loss (Total)\": f\"{loss.item():.4f}\",\n",
    "            \"Loss (L1)\": f\"{l1_loss.item()/X.size(0):.4f}\",\n",
    "            \"Loss (MSE)\": f\"{mse_loss.item()/X.size(0):.4f}\"\n",
    "        })\n",
    "\n",
    "    # Validation\n",
    "    cnn_model.eval()\n",
    "    val_loss_total: float = 0\n",
    "    val_l1_total: float = 0\n",
    "    val_mse_total: float = 0\n",
    "    val_correct: int = 0\n",
    "    val_samples: int = 0\n",
    "\n",
    "    val_loader = tqdm.tqdm(val_dataloader, desc=f\"Epoch {epoch+1} - Validation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val: torch.Tensor = X_val.to(DEVICE)\n",
    "            y_val: torch.Tensor = y_val.to(DEVICE)\n",
    "\n",
    "            y_val_pred: torch.Tensor = cnn_model(X_val)\n",
    "            y_val_padded: torch.Tensor = F.pad(y_val, (0, y_val_pred.shape[1] - y_val.shape[1]))\n",
    "\n",
    "            val_loss: torch.Tensor = F.cross_entropy(y_val_pred, y_val.argmax(dim=1), reduction='sum')\n",
    "            val_l1: torch.Tensor = F.l1_loss(y_val_pred, y_val_padded, reduction='sum')\n",
    "            val_mse: torch.Tensor = F.mse_loss(y_val_pred, y_val_padded, reduction='sum')\n",
    "\n",
    "            val_loss_total += val_loss.item()\n",
    "            val_l1_total += val_l1.item()\n",
    "            val_mse_total += val_mse.item()\n",
    "\n",
    "            val_preds = y_val_pred.argmax(dim=1)\n",
    "            val_targets = y_val.argmax(dim=1).long()\n",
    "            val_correct += (val_preds == val_targets).sum().item()\n",
    "            val_samples += X_val.size(0)\n",
    "\n",
    "            val_loader.set_postfix({\n",
    "                \"Loss\": f\"{val_loss.item() / X_val.size(0):.4f}\",\n",
    "                \"L1\": f\"{val_l1.item() / X_val.size(0):.4f}\",\n",
    "                \"MSE\": f\"{val_mse.item() / X_val.size(0):.4f}\"\n",
    "            })\n",
    "    # Averages\n",
    "    train_loss_avg = train_loss_total / train_samples if train_samples > 0 else -1\n",
    "    train_l1_avg = train_l1_total / train_samples if train_samples > 0 else -1\n",
    "    train_mse_avg = train_mse_total / train_samples if train_samples > 0 else -1\n",
    "    train_acc = train_correct / train_samples if train_samples > 0 else -1\n",
    "\n",
    "    val_loss_avg = val_loss_total / val_samples if val_samples > 0 else -1\n",
    "    val_l1_avg = val_l1_total / val_samples if val_samples > 0 else -1\n",
    "    val_mse_avg = val_mse_total / val_samples if val_samples > 0 else -1\n",
    "    val_acc = val_correct / val_samples if val_samples > 0 else -1\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    with open(CSV_LOG_FILE, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\n",
    "            epoch + 1,\n",
    "            train_loss_avg, train_l1_avg, train_mse_avg, train_acc,\n",
    "            val_loss_avg, val_l1_avg, val_mse_avg, val_acc\n",
    "        ])\n",
    "\n",
    "    # Save model\n",
    "    model_filename = (\n",
    "        f\"{SESSION_STARTTIME_STR}__{MODEL_NAME}__\"\n",
    "        f\"Epoch{epoch+1}_\"\n",
    "        f\"tLoss{train_loss_avg:.5f}_tL1{train_l1_avg:.5f}_tMSE{train_mse_avg:.5f}_tAcc{train_acc:.5f}_\"\n",
    "        f\"vLoss{val_loss_avg:.5f}_vL1{val_l1_avg:.5f}_vMSE{val_mse_avg:.5f}_vAcc{val_acc:.5f}.pt\"\n",
    "    )\n",
    "    try:\n",
    "        print(\"Saving model\")\n",
    "        torch.save(cnn_model.state_dict(), model_filename)\n",
    "        print(model_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error skipping... {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder_conv_blocks.0.0.original.weight',\n",
       "              tensor([[[[ 0.2740,  0.2949,  0.1547],\n",
       "                        [-0.2473,  0.1952,  0.0204],\n",
       "                        [-0.2675,  0.1130,  0.1736]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2254, -0.3073,  0.2675],\n",
       "                        [-0.1299,  0.0767,  0.2313],\n",
       "                        [ 0.0535, -0.1954, -0.1494]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1853,  0.2320,  0.1130],\n",
       "                        [ 0.1332, -0.1923,  0.1763],\n",
       "                        [ 0.1956,  0.3145,  0.1967]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1237,  0.2570, -0.0376],\n",
       "                        [-0.1617,  0.1369,  0.1147],\n",
       "                        [ 0.1059, -0.1323,  0.2945]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0822, -0.3164,  0.1172],\n",
       "                        [-0.0444, -0.2802, -0.3248],\n",
       "                        [ 0.1585, -0.1598, -0.0478]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2215, -0.3077, -0.1132],\n",
       "                        [ 0.1584,  0.3051, -0.2879],\n",
       "                        [-0.0756, -0.2539,  0.2468]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0485,  0.2291,  0.0525],\n",
       "                        [ 0.1137,  0.2694, -0.2377],\n",
       "                        [ 0.2547,  0.1293,  0.3277]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2767,  0.2067, -0.2432],\n",
       "                        [-0.0620,  0.3267,  0.1080],\n",
       "                        [-0.1666,  0.2270, -0.0361]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3321,  0.0428, -0.0677],\n",
       "                        [-0.2624, -0.3182, -0.3021],\n",
       "                        [-0.1693, -0.1113, -0.2265]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3055,  0.0148,  0.1519],\n",
       "                        [-0.0391,  0.2853, -0.3239],\n",
       "                        [ 0.0462,  0.0657, -0.0307]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0198, -0.2685,  0.1583],\n",
       "                        [ 0.2726, -0.1221, -0.2841],\n",
       "                        [ 0.1155,  0.3312, -0.1069]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2196,  0.1378, -0.0630],\n",
       "                        [-0.1681, -0.2022,  0.2297],\n",
       "                        [ 0.3243,  0.2457,  0.1123]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2669,  0.1241,  0.0876],\n",
       "                        [ 0.3025,  0.1234,  0.0148],\n",
       "                        [-0.1498,  0.0813,  0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0579, -0.1749, -0.2864],\n",
       "                        [-0.0445, -0.2565, -0.0260],\n",
       "                        [ 0.0860,  0.2270, -0.2719]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0793,  0.2322,  0.0780],\n",
       "                        [-0.2256,  0.2590, -0.2806],\n",
       "                        [-0.2775,  0.0020,  0.0089]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1326,  0.1171, -0.2682],\n",
       "                        [-0.1023,  0.0957,  0.0722],\n",
       "                        [ 0.2547, -0.0195,  0.2282]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.0.original.bias',\n",
       "              tensor([ 0.1374,  0.2693,  0.1668,  0.2459,  0.2702, -0.2257, -0.0631, -0.1948,\n",
       "                       0.1776,  0.0589,  0.2904, -0.2657, -0.2081, -0.2792, -0.1413,  0.1979],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-1.2316e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5083e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8695e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9500e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1312e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0931e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7483e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.0659e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2492e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7330e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7963e-05]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.3223e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2045e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6161e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4063e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3837e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2828e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.4095e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5254e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9101e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0948e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5603e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0790e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2577e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6268e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1672e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.8136e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2740e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1664e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2024e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6474e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7134e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6136e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6311e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.8135e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7295e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4068e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9993e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.9236e-05]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7514e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8610e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.3322e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4840e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.3413e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7530e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3188e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.7264e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3191e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3945e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2658e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2647e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.1231e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.6776e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8827e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7003e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.4534e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3649e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2886e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2008e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1518e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2013e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5378e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5495e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1083e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2942e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4640e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4544e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4757e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6933e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.0819e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.3238e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0233e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0039e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0176e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4933e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1095e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3976e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5823e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3690e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9962e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1283e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.4834e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.4892e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3515e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0037e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5571e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1956e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.4704e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4661e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.3156e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5246e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6667e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6928e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.4180e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6915e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.5251e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5617e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3125e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8996e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9253e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2979e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0630e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4784e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.6671e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7187e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6956e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9372e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6639e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1159e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3212e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.9336e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.9629e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1302e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1630e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0817e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.0312e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1841e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7921e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6665e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1297e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6597e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.6103e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2481e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4852e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5659e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8376e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7148e-05]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8419e-03]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 6.4479e-03]],\n",
       "              \n",
       "                       [[-9.8954e-04]],\n",
       "              \n",
       "                       [[-2.2635e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5363e-02]],\n",
       "              \n",
       "                       [[-1.7757e-04]],\n",
       "              \n",
       "                       [[ 2.2564e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0576e-02]],\n",
       "              \n",
       "                       [[ 2.5806e-03]],\n",
       "              \n",
       "                       [[ 5.1797e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.4507e-02]],\n",
       "              \n",
       "                       [[ 6.8729e-05]],\n",
       "              \n",
       "                       [[-2.9701e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0922e-02]],\n",
       "              \n",
       "                       [[ 2.4098e-03]],\n",
       "              \n",
       "                       [[ 4.0756e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.0115e-02]],\n",
       "              \n",
       "                       [[ 6.7385e-04]],\n",
       "              \n",
       "                       [[-3.5443e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 6.9486e-03]],\n",
       "              \n",
       "                       [[ 1.7256e-03]],\n",
       "              \n",
       "                       [[-1.0919e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.3744e-03]],\n",
       "              \n",
       "                       [[ 5.8388e-05]],\n",
       "              \n",
       "                       [[-6.1531e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0429e-01]],\n",
       "              \n",
       "                       [[-2.5364e-03]],\n",
       "              \n",
       "                       [[ 5.9545e-05]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5045e-01]],\n",
       "              \n",
       "                       [[-5.4927e-04]],\n",
       "              \n",
       "                       [[ 1.7566e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7770e-02]],\n",
       "              \n",
       "                       [[-2.8487e-03]],\n",
       "              \n",
       "                       [[-6.1460e-06]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.0371e-02]],\n",
       "              \n",
       "                       [[-1.2995e-03]],\n",
       "              \n",
       "                       [[ 7.0958e-04]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.weight',\n",
       "              tensor([1.0185, 1.1374, 1.0385, 0.9431, 1.1595, 0.9680, 1.1423, 1.2673, 1.1990,\n",
       "                      1.0115, 1.0030, 1.0278, 0.9815, 1.1700, 0.9411, 1.1512],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.bias',\n",
       "              tensor([-0.1333, -0.1129,  0.0586,  0.0626, -0.0852, -0.2463, -0.1423, -0.3704,\n",
       "                      -0.0401,  0.0354,  0.3304, -0.0737,  0.0164, -0.2029,  0.2965,  0.0013],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.running_mean',\n",
       "              tensor([ 0.3011,  0.2721,  0.4038,  0.3415,  0.0807, -0.3448,  0.2059, -0.0414,\n",
       "                      -0.0703,  0.1771,  0.3030, -0.0894, -0.1068, -0.4313, -0.1983,  0.3269],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.running_var',\n",
       "              tensor([0.1034, 0.0173, 0.1572, 0.0368, 0.1230, 0.0619, 0.2211, 0.0812, 0.2103,\n",
       "                      0.0517, 0.0269, 0.0821, 0.0364, 0.0989, 0.0237, 0.0570],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.2.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.4.original.weight',\n",
       "              tensor([[[[ 0.0681,  0.0665, -0.0344],\n",
       "                        [ 0.0169, -0.0294,  0.0593],\n",
       "                        [ 0.0611,  0.0535, -0.0366]],\n",
       "              \n",
       "                       [[-0.0602,  0.0124,  0.0762],\n",
       "                        [-0.0644, -0.0262, -0.0219],\n",
       "                        [-0.0351, -0.0100, -0.0116]],\n",
       "              \n",
       "                       [[ 0.0406, -0.0204,  0.0716],\n",
       "                        [ 0.0767, -0.0057,  0.0756],\n",
       "                        [-0.0577,  0.0784,  0.0372]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0816,  0.0420, -0.0583],\n",
       "                        [-0.0830,  0.0452, -0.0438],\n",
       "                        [-0.0823, -0.0377,  0.0788]],\n",
       "              \n",
       "                       [[-0.0340,  0.0522, -0.0026],\n",
       "                        [ 0.0666, -0.0173, -0.0502],\n",
       "                        [-0.0052,  0.0810, -0.0686]],\n",
       "              \n",
       "                       [[-0.0324, -0.0186,  0.0107],\n",
       "                        [ 0.0186,  0.0330,  0.0778],\n",
       "                        [-0.0810,  0.0641,  0.0422]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0763, -0.0153, -0.0730],\n",
       "                        [ 0.0131, -0.0243,  0.0205],\n",
       "                        [ 0.0230, -0.0457, -0.0432]],\n",
       "              \n",
       "                       [[-0.0011, -0.0570,  0.0777],\n",
       "                        [ 0.0577,  0.0140, -0.0056],\n",
       "                        [ 0.0231, -0.0769, -0.0312]],\n",
       "              \n",
       "                       [[ 0.0603, -0.0591, -0.0214],\n",
       "                        [ 0.0306,  0.0473,  0.0428],\n",
       "                        [-0.0105,  0.0410, -0.0084]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0694,  0.0047,  0.0097],\n",
       "                        [-0.0794,  0.0799, -0.0721],\n",
       "                        [ 0.0426,  0.0117,  0.0565]],\n",
       "              \n",
       "                       [[ 0.0449, -0.0026,  0.0363],\n",
       "                        [ 0.0644,  0.0822,  0.0197],\n",
       "                        [ 0.0510,  0.0107,  0.0459]],\n",
       "              \n",
       "                       [[ 0.0760,  0.0829, -0.0693],\n",
       "                        [-0.0309, -0.0283, -0.0830],\n",
       "                        [ 0.0277, -0.0202,  0.0753]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0542,  0.0657,  0.0048],\n",
       "                        [ 0.0539, -0.0446,  0.0393],\n",
       "                        [ 0.0776,  0.0698,  0.0665]],\n",
       "              \n",
       "                       [[-0.0094,  0.0022,  0.0062],\n",
       "                        [ 0.0491,  0.0203,  0.0296],\n",
       "                        [-0.0410,  0.0425, -0.0271]],\n",
       "              \n",
       "                       [[-0.0312,  0.0753,  0.0456],\n",
       "                        [ 0.0408, -0.0507, -0.0246],\n",
       "                        [ 0.0123, -0.0425, -0.0212]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0490, -0.0073,  0.0527],\n",
       "                        [-0.0818, -0.0536,  0.0588],\n",
       "                        [-0.0605, -0.0205, -0.0415]],\n",
       "              \n",
       "                       [[ 0.0186, -0.0776,  0.0021],\n",
       "                        [ 0.0353,  0.0316,  0.0655],\n",
       "                        [-0.0048,  0.0454, -0.0059]],\n",
       "              \n",
       "                       [[ 0.0595,  0.0830, -0.0701],\n",
       "                        [ 0.0482,  0.0500, -0.0171],\n",
       "                        [ 0.0498, -0.0572,  0.0277]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0681, -0.0124,  0.0168],\n",
       "                        [ 0.0312,  0.0054, -0.0408],\n",
       "                        [ 0.0287,  0.0084,  0.0480]],\n",
       "              \n",
       "                       [[-0.0449, -0.0681, -0.0479],\n",
       "                        [ 0.0548,  0.0607, -0.0246],\n",
       "                        [-0.0716,  0.0722, -0.0255]],\n",
       "              \n",
       "                       [[ 0.0819, -0.0364,  0.0203],\n",
       "                        [-0.0098, -0.0211, -0.0414],\n",
       "                        [-0.0755, -0.0383,  0.0148]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0522, -0.0645,  0.0454],\n",
       "                        [-0.0095, -0.0205,  0.0683],\n",
       "                        [ 0.0533, -0.0246, -0.0470]],\n",
       "              \n",
       "                       [[-0.0431, -0.0582,  0.0599],\n",
       "                        [-0.0245, -0.0335, -0.0196],\n",
       "                        [-0.0171, -0.0616, -0.0168]],\n",
       "              \n",
       "                       [[ 0.0192,  0.0031,  0.0760],\n",
       "                        [ 0.0615,  0.0432,  0.0754],\n",
       "                        [-0.0384, -0.0646,  0.0590]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0410, -0.0330,  0.0314],\n",
       "                        [-0.0019, -0.0200,  0.0809],\n",
       "                        [ 0.0652,  0.0225,  0.0351]],\n",
       "              \n",
       "                       [[ 0.0226, -0.0705,  0.0402],\n",
       "                        [ 0.0038,  0.0302, -0.0614],\n",
       "                        [-0.0160,  0.0179, -0.0477]],\n",
       "              \n",
       "                       [[-0.0808, -0.0087,  0.0495],\n",
       "                        [ 0.0826,  0.0299, -0.0544],\n",
       "                        [ 0.0693, -0.0357, -0.0091]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0029,  0.0626, -0.0473],\n",
       "                        [-0.0500, -0.0291,  0.0546],\n",
       "                        [-0.0186,  0.0058,  0.0571]],\n",
       "              \n",
       "                       [[ 0.0289, -0.0085,  0.0407],\n",
       "                        [ 0.0174, -0.0045,  0.0320],\n",
       "                        [ 0.0240,  0.0809,  0.0720]],\n",
       "              \n",
       "                       [[-0.0556,  0.0508, -0.0820],\n",
       "                        [ 0.0241,  0.0759,  0.0718],\n",
       "                        [-0.0472,  0.0334, -0.0413]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0368, -0.0051, -0.0691],\n",
       "                        [ 0.0520,  0.0105,  0.0152],\n",
       "                        [-0.0595,  0.0412, -0.0117]],\n",
       "              \n",
       "                       [[-0.0571,  0.0287, -0.0205],\n",
       "                        [ 0.0805,  0.0243,  0.0637],\n",
       "                        [ 0.0246,  0.0530,  0.0047]],\n",
       "              \n",
       "                       [[ 0.0610, -0.0385, -0.0315],\n",
       "                        [-0.0796, -0.0592, -0.0720],\n",
       "                        [ 0.0148, -0.0338, -0.0038]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0304,  0.0291, -0.0145],\n",
       "                        [ 0.0315,  0.0808, -0.0244],\n",
       "                        [ 0.0058, -0.0672, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0363,  0.0811,  0.0755],\n",
       "                        [ 0.0810, -0.0222, -0.0492],\n",
       "                        [ 0.0832,  0.0815,  0.0821]],\n",
       "              \n",
       "                       [[-0.0601,  0.0512,  0.0497],\n",
       "                        [ 0.0354,  0.0565,  0.0831],\n",
       "                        [-0.0371, -0.0387,  0.0131]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.4.original.bias',\n",
       "              tensor([ 0.0097, -0.0131, -0.0170, -0.0476, -0.0690, -0.0073,  0.0174, -0.0034,\n",
       "                       0.0344,  0.0487, -0.0792,  0.0329,  0.0211, -0.0025,  0.0760, -0.0372],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[ 0.0798]],\n",
       "              \n",
       "                       [[ 0.0711]],\n",
       "              \n",
       "                       [[-0.0586]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0573]],\n",
       "              \n",
       "                       [[ 0.0915]],\n",
       "              \n",
       "                       [[-0.0105]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0014]],\n",
       "              \n",
       "                       [[ 0.0195]],\n",
       "              \n",
       "                       [[ 0.0085]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0029]],\n",
       "              \n",
       "                       [[-0.0032]],\n",
       "              \n",
       "                       [[ 0.0332]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0084]],\n",
       "              \n",
       "                       [[ 0.0027]],\n",
       "              \n",
       "                       [[ 0.0083]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0019]],\n",
       "              \n",
       "                       [[ 0.0105]],\n",
       "              \n",
       "                       [[-0.0166]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0179]],\n",
       "              \n",
       "                       [[-0.0090]],\n",
       "              \n",
       "                       [[ 0.0112]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0002]],\n",
       "              \n",
       "                       [[-0.0016]],\n",
       "              \n",
       "                       [[-0.0486]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0263]],\n",
       "              \n",
       "                       [[ 0.0289]],\n",
       "              \n",
       "                       [[ 0.0606]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0254]],\n",
       "              \n",
       "                       [[-0.0152]],\n",
       "              \n",
       "                       [[-0.0098]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0028]],\n",
       "              \n",
       "                       [[-0.0137]],\n",
       "              \n",
       "                       [[-0.0159]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0016]],\n",
       "              \n",
       "                       [[-0.0040]],\n",
       "              \n",
       "                       [[ 0.0304]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 5.3916e-02]],\n",
       "              \n",
       "                       [[ 1.5393e-03]],\n",
       "              \n",
       "                       [[ 8.1740e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.6908e-04]],\n",
       "              \n",
       "                       [[-2.1805e-03]],\n",
       "              \n",
       "                       [[-9.1104e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.0677e-02]],\n",
       "              \n",
       "                       [[-2.7242e-02]],\n",
       "              \n",
       "                       [[ 8.8453e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.8764e-02]],\n",
       "              \n",
       "                       [[-3.7060e-02]],\n",
       "              \n",
       "                       [[-9.1109e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1332e-02]],\n",
       "              \n",
       "                       [[-5.4590e-05]],\n",
       "              \n",
       "                       [[-1.0172e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.8215e-03]],\n",
       "              \n",
       "                       [[-2.4043e-03]],\n",
       "              \n",
       "                       [[ 8.2847e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.7097e-02]],\n",
       "              \n",
       "                       [[ 3.7717e-02]],\n",
       "              \n",
       "                       [[-1.3211e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.6200e-02]],\n",
       "              \n",
       "                       [[ 2.3308e-02]],\n",
       "              \n",
       "                       [[ 2.6662e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3655e-02]],\n",
       "              \n",
       "                       [[ 2.5475e-02]],\n",
       "              \n",
       "                       [[-3.6385e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-9.0632e-03]],\n",
       "              \n",
       "                       [[ 5.3914e-02]],\n",
       "              \n",
       "                       [[-2.6701e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.3779e-02]],\n",
       "              \n",
       "                       [[-1.4212e-02]],\n",
       "              \n",
       "                       [[ 3.0032e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.1895e-02]],\n",
       "              \n",
       "                       [[ 3.7768e-02]],\n",
       "              \n",
       "                       [[-1.1165e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.weight',\n",
       "              tensor([1.1054, 1.1511, 1.0664, 0.9040, 1.0082, 1.0295, 1.1073, 0.9133, 1.0410,\n",
       "                      1.0208, 1.1337, 0.8969, 0.9677, 1.2035, 1.0768, 0.7993],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.bias',\n",
       "              tensor([ 0.1988, -0.2750, -0.1118, -0.2227,  0.1499,  0.0590, -0.2481, -0.2295,\n",
       "                      -0.0928, -0.0842, -0.2164, -0.3037,  0.1987, -0.2047,  0.2430, -0.1181],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.running_mean',\n",
       "              tensor([ 0.2856, -0.0600,  0.5987, -0.2531, -0.0353,  0.0325,  0.3678,  0.2210,\n",
       "                       0.1100,  0.1901,  0.0466, -0.0457,  0.3137,  0.0964,  0.2658,  0.3119],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.running_var',\n",
       "              tensor([0.4747, 0.0823, 0.8476, 0.2195, 0.2464, 0.1994, 0.2122, 0.2085, 0.3317,\n",
       "                      0.1368, 0.2625, 0.1724, 0.9772, 0.3630, 0.6400, 0.2184],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.0.6.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.0.original.weight',\n",
       "              tensor([[[[ 0.0822, -0.0377,  0.0059],\n",
       "                        [ 0.0794,  0.0372, -0.0810],\n",
       "                        [-0.0373, -0.0271, -0.0356]],\n",
       "              \n",
       "                       [[-0.0375,  0.0713,  0.0004],\n",
       "                        [ 0.0248, -0.0061, -0.0143],\n",
       "                        [-0.0075,  0.0213, -0.0453]],\n",
       "              \n",
       "                       [[ 0.0487, -0.0811, -0.0805],\n",
       "                        [-0.0045,  0.0527, -0.0162],\n",
       "                        [ 0.0105,  0.0687, -0.0581]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0284, -0.0127,  0.0114],\n",
       "                        [ 0.0102,  0.0049,  0.0163],\n",
       "                        [ 0.0763, -0.0089, -0.0252]],\n",
       "              \n",
       "                       [[-0.0271, -0.0783,  0.0627],\n",
       "                        [-0.0336,  0.0760, -0.0194],\n",
       "                        [-0.0591, -0.0466, -0.0343]],\n",
       "              \n",
       "                       [[-0.0043,  0.0170,  0.0076],\n",
       "                        [-0.0822,  0.0591,  0.0436],\n",
       "                        [-0.0571,  0.0225, -0.0424]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0529,  0.0056, -0.0679],\n",
       "                        [ 0.0691, -0.0829, -0.0078],\n",
       "                        [ 0.0229, -0.0030,  0.0234]],\n",
       "              \n",
       "                       [[ 0.0375, -0.0461,  0.0328],\n",
       "                        [-0.0679, -0.0406,  0.0525],\n",
       "                        [ 0.0771,  0.0538, -0.0815]],\n",
       "              \n",
       "                       [[ 0.0169, -0.0257,  0.0298],\n",
       "                        [-0.0726,  0.0216, -0.0170],\n",
       "                        [-0.0475,  0.0040,  0.0536]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0451, -0.0819,  0.0020],\n",
       "                        [ 0.0414,  0.0681,  0.0336],\n",
       "                        [ 0.0662,  0.0168,  0.0505]],\n",
       "              \n",
       "                       [[ 0.0187, -0.0135, -0.0452],\n",
       "                        [ 0.0679,  0.0481,  0.0566],\n",
       "                        [-0.0592,  0.0045,  0.0528]],\n",
       "              \n",
       "                       [[ 0.0831, -0.0164,  0.0026],\n",
       "                        [ 0.0653,  0.0547, -0.0559],\n",
       "                        [-0.0233, -0.0681,  0.0038]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0509, -0.0652,  0.0628],\n",
       "                        [ 0.0801, -0.0021,  0.0375],\n",
       "                        [-0.0129, -0.0464, -0.0425]],\n",
       "              \n",
       "                       [[ 0.0705,  0.0501, -0.0677],\n",
       "                        [ 0.0655, -0.0780, -0.0566],\n",
       "                        [ 0.0306, -0.0831,  0.0796]],\n",
       "              \n",
       "                       [[-0.0339, -0.0130, -0.0443],\n",
       "                        [ 0.0569, -0.0702, -0.0286],\n",
       "                        [-0.0731, -0.0694, -0.0617]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0664, -0.0352,  0.0342],\n",
       "                        [ 0.0679, -0.0506,  0.0054],\n",
       "                        [ 0.0668, -0.0451, -0.0119]],\n",
       "              \n",
       "                       [[ 0.0381,  0.0156, -0.0487],\n",
       "                        [ 0.0226, -0.0619, -0.0664],\n",
       "                        [-0.0824,  0.0632, -0.0465]],\n",
       "              \n",
       "                       [[ 0.0335, -0.0434, -0.0330],\n",
       "                        [-0.0353, -0.0365,  0.0559],\n",
       "                        [-0.0120, -0.0219,  0.0204]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0759, -0.0257,  0.0654],\n",
       "                        [ 0.0475,  0.0514, -0.0052],\n",
       "                        [-0.0819, -0.0215,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0731,  0.0509, -0.0799],\n",
       "                        [ 0.0430, -0.0199,  0.0215],\n",
       "                        [ 0.0085, -0.0355, -0.0389]],\n",
       "              \n",
       "                       [[ 0.0100, -0.0430, -0.0186],\n",
       "                        [-0.0757,  0.0696,  0.0687],\n",
       "                        [-0.0366, -0.0492, -0.0240]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0604, -0.0023, -0.0516],\n",
       "                        [ 0.0255, -0.0178, -0.0222],\n",
       "                        [ 0.0612, -0.0100, -0.0012]],\n",
       "              \n",
       "                       [[-0.0076,  0.0287, -0.0269],\n",
       "                        [ 0.0716, -0.0525,  0.0010],\n",
       "                        [-0.0078, -0.0393,  0.0027]],\n",
       "              \n",
       "                       [[ 0.0247, -0.0100, -0.0098],\n",
       "                        [ 0.0588,  0.0602,  0.0127],\n",
       "                        [-0.0709, -0.0091, -0.0230]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0648,  0.0167,  0.0809],\n",
       "                        [-0.0202,  0.0227,  0.0503],\n",
       "                        [ 0.0091,  0.0584, -0.0505]],\n",
       "              \n",
       "                       [[-0.0260, -0.0611,  0.0681],\n",
       "                        [-0.0168,  0.0553, -0.0377],\n",
       "                        [-0.0445, -0.0579,  0.0498]],\n",
       "              \n",
       "                       [[-0.0026,  0.0361,  0.0445],\n",
       "                        [ 0.0187, -0.0585,  0.0561],\n",
       "                        [-0.0166,  0.0130,  0.0252]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0624, -0.0186,  0.0251],\n",
       "                        [ 0.0208, -0.0599,  0.0581],\n",
       "                        [-0.0074, -0.0511, -0.0675]],\n",
       "              \n",
       "                       [[-0.0521, -0.0620, -0.0802],\n",
       "                        [-0.0019, -0.0382, -0.0777],\n",
       "                        [ 0.0540, -0.0170, -0.0805]],\n",
       "              \n",
       "                       [[-0.0371,  0.0505, -0.0071],\n",
       "                        [ 0.0330,  0.0021, -0.0506],\n",
       "                        [ 0.0518, -0.0695, -0.0338]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0771, -0.0699,  0.0339],\n",
       "                        [ 0.0469,  0.0034,  0.0452],\n",
       "                        [-0.0105, -0.0240, -0.0733]],\n",
       "              \n",
       "                       [[ 0.0032, -0.0403, -0.0170],\n",
       "                        [ 0.0085, -0.0149,  0.0413],\n",
       "                        [ 0.0324, -0.0059,  0.0443]],\n",
       "              \n",
       "                       [[-0.0393,  0.0644,  0.0606],\n",
       "                        [ 0.0370, -0.0637, -0.0147],\n",
       "                        [-0.0665,  0.0371, -0.0427]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0736,  0.0636,  0.0166],\n",
       "                        [ 0.0539,  0.0475, -0.0650],\n",
       "                        [-0.0099,  0.0456,  0.0561]],\n",
       "              \n",
       "                       [[ 0.0797,  0.0669,  0.0152],\n",
       "                        [ 0.0213, -0.0328, -0.0067],\n",
       "                        [-0.0812,  0.0251,  0.0582]],\n",
       "              \n",
       "                       [[-0.0727,  0.0232,  0.0541],\n",
       "                        [ 0.0500, -0.0071, -0.0817],\n",
       "                        [ 0.0273,  0.0162, -0.0552]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.0.original.bias',\n",
       "              tensor([-0.0383,  0.0791,  0.0033, -0.0435, -0.0171,  0.0378,  0.0442,  0.0489,\n",
       "                      -0.0810, -0.0147, -0.0331, -0.0668, -0.0669,  0.0234, -0.0509, -0.0046,\n",
       "                      -0.0608, -0.0692, -0.0245,  0.0302, -0.0634, -0.0776, -0.0506,  0.0312,\n",
       "                       0.0133, -0.0529, -0.0715, -0.0065,  0.0363,  0.0555,  0.0437, -0.0424],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-0.0051]],\n",
       "              \n",
       "                       [[ 0.0284]],\n",
       "              \n",
       "                       [[-0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0063]],\n",
       "              \n",
       "                       [[ 0.0120]],\n",
       "              \n",
       "                       [[ 0.0171]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0044]],\n",
       "              \n",
       "                       [[ 0.0242]],\n",
       "              \n",
       "                       [[-0.0171]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0067]],\n",
       "              \n",
       "                       [[ 0.0091]],\n",
       "              \n",
       "                       [[ 0.0117]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0199]],\n",
       "              \n",
       "                       [[-0.0058]],\n",
       "              \n",
       "                       [[ 0.0149]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0035]],\n",
       "              \n",
       "                       [[ 0.0027]],\n",
       "              \n",
       "                       [[ 0.0058]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0051]],\n",
       "              \n",
       "                       [[-0.0204]],\n",
       "              \n",
       "                       [[ 0.0183]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0080]],\n",
       "              \n",
       "                       [[-0.0088]],\n",
       "              \n",
       "                       [[-0.0142]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0215]],\n",
       "              \n",
       "                       [[-0.0106]],\n",
       "              \n",
       "                       [[ 0.0239]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0008]],\n",
       "              \n",
       "                       [[-0.0017]],\n",
       "              \n",
       "                       [[ 0.0039]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0141]],\n",
       "              \n",
       "                       [[-0.0023]],\n",
       "              \n",
       "                       [[ 0.0163]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0080]],\n",
       "              \n",
       "                       [[-0.0015]],\n",
       "              \n",
       "                       [[ 0.0016]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[-1.1729e-03]],\n",
       "              \n",
       "                       [[-2.3230e-03]],\n",
       "              \n",
       "                       [[-6.5608e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4870e-03]],\n",
       "              \n",
       "                       [[-1.4277e-02]],\n",
       "              \n",
       "                       [[-1.5847e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1934e-03]],\n",
       "              \n",
       "                       [[ 1.9761e-03]],\n",
       "              \n",
       "                       [[-9.3219e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2275e-04]],\n",
       "              \n",
       "                       [[ 2.8321e-03]],\n",
       "              \n",
       "                       [[-6.1373e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7604e-03]],\n",
       "              \n",
       "                       [[ 3.6457e-04]],\n",
       "              \n",
       "                       [[ 2.1406e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.5029e-03]],\n",
       "              \n",
       "                       [[ 2.0790e-02]],\n",
       "              \n",
       "                       [[ 1.1024e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 9.4152e-03]],\n",
       "              \n",
       "                       [[ 1.0644e-02]],\n",
       "              \n",
       "                       [[-3.6998e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0746e-02]],\n",
       "              \n",
       "                       [[ 7.9840e-03]],\n",
       "              \n",
       "                       [[-3.3110e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2926e-03]],\n",
       "              \n",
       "                       [[-1.6256e-03]],\n",
       "              \n",
       "                       [[-7.6942e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.1875e-03]],\n",
       "              \n",
       "                       [[-7.3470e-05]],\n",
       "              \n",
       "                       [[ 5.5258e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6355e-02]],\n",
       "              \n",
       "                       [[-1.5507e-02]],\n",
       "              \n",
       "                       [[-6.2123e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.5868e-02]],\n",
       "              \n",
       "                       [[-7.8378e-03]],\n",
       "              \n",
       "                       [[ 2.5043e-03]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.weight',\n",
       "              tensor([1.0134, 1.0141, 0.8128, 0.9600, 1.0121, 0.6756, 1.0371, 1.0361, 0.9781,\n",
       "                      1.1106, 1.0957, 0.7359, 0.7054, 0.7603, 1.1498, 0.9075, 1.3136, 1.0130,\n",
       "                      1.1828, 0.6956, 1.1640, 1.0071, 0.7761, 1.0732, 0.9785, 0.9934, 0.9098,\n",
       "                      1.0380, 1.0530, 1.0912, 0.9698, 1.1279], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.bias',\n",
       "              tensor([-0.3118, -0.0433, -0.4426,  0.0209, -0.1717, -0.3020, -0.3278, -0.3015,\n",
       "                      -0.2880, -0.1414, -0.1558, -0.3230, -0.2474, -0.4782, -0.3181, -0.4456,\n",
       "                      -0.3990, -0.4008, -0.2686, -0.2041, -0.1412, -0.2161, -0.3425, -0.0161,\n",
       "                      -0.0711, -0.2769, -0.3983, -0.0149, -0.3402, -0.2542, -0.3353, -0.0765],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.running_mean',\n",
       "              tensor([-0.4919,  0.1474,  0.0514,  0.0250, -0.3955,  0.3761,  0.4749,  0.5500,\n",
       "                      -0.2984, -0.0602, -0.5478,  0.4031, -0.0975,  0.2896, -0.6134, -0.2073,\n",
       "                       0.1025, -0.1070, -0.1582, -0.3792, -0.1428,  0.5676, -0.0518, -0.5007,\n",
       "                      -0.5687, -0.2649, -0.0971,  0.3126,  0.1964, -0.4032, -0.5313, -0.6068],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.running_var',\n",
       "              tensor([0.7237, 0.1014, 0.0956, 0.0744, 0.7016, 0.4434, 0.6212, 0.6012, 0.3485,\n",
       "                      0.1784, 1.0100, 0.6188, 0.1253, 0.3997, 0.9913, 0.2216, 0.1555, 0.1628,\n",
       "                      0.1451, 0.6559, 0.1682, 1.2359, 0.1643, 0.9298, 0.8490, 0.3321, 0.0846,\n",
       "                      0.4841, 0.2372, 0.7125, 0.7579, 1.0950], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.2.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.4.original.weight',\n",
       "              tensor([[[[-4.7856e-02,  3.2929e-02, -3.0285e-02],\n",
       "                        [-2.3930e-02, -1.6060e-02,  2.8790e-02],\n",
       "                        [-2.4449e-02, -5.7573e-02,  2.0050e-02]],\n",
       "              \n",
       "                       [[-1.0287e-02,  4.8558e-02, -6.5335e-03],\n",
       "                        [ 4.6520e-02, -5.8211e-02, -1.4668e-02],\n",
       "                        [ 5.3822e-02, -1.6057e-02,  8.8599e-03]],\n",
       "              \n",
       "                       [[ 1.7737e-02,  4.2374e-02,  1.7189e-02],\n",
       "                        [-3.1058e-02,  4.3664e-02,  4.1628e-02],\n",
       "                        [ 1.5780e-02, -4.3132e-02, -2.4976e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.4099e-02, -7.5199e-03,  2.4348e-02],\n",
       "                        [ 5.4660e-02,  3.9525e-02, -3.4733e-02],\n",
       "                        [ 4.9531e-02,  4.2260e-03, -2.9341e-02]],\n",
       "              \n",
       "                       [[-1.2785e-02,  3.1226e-02, -4.5452e-02],\n",
       "                        [-2.0202e-02,  3.9707e-02,  9.1487e-03],\n",
       "                        [-2.1344e-02,  1.1561e-02,  2.7999e-02]],\n",
       "              \n",
       "                       [[-3.8656e-04,  2.9811e-02, -1.9728e-02],\n",
       "                        [ 2.4626e-02, -2.3418e-02, -5.2523e-02],\n",
       "                        [-1.4426e-02,  2.9925e-02,  2.8472e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.6878e-02,  5.0141e-02, -3.7065e-02],\n",
       "                        [ 2.6230e-04,  1.3831e-02, -4.9657e-02],\n",
       "                        [-4.7188e-02, -2.9758e-02, -4.8967e-03]],\n",
       "              \n",
       "                       [[-4.9680e-02, -5.8748e-02, -2.1983e-03],\n",
       "                        [-3.2971e-02,  5.1117e-02,  4.3018e-02],\n",
       "                        [ 5.2374e-02,  2.1690e-03, -2.3150e-02]],\n",
       "              \n",
       "                       [[-3.3344e-02,  6.9805e-03, -2.9579e-02],\n",
       "                        [-5.2316e-02,  1.5181e-02,  5.6787e-02],\n",
       "                        [ 1.0102e-02,  5.5236e-02, -4.6893e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5454e-02, -2.5685e-02, -3.8896e-03],\n",
       "                        [ 3.8313e-02, -5.5281e-02,  4.8677e-03],\n",
       "                        [-4.6116e-02, -1.3590e-02, -4.7573e-02]],\n",
       "              \n",
       "                       [[-1.7094e-02, -4.6666e-02, -2.2499e-04],\n",
       "                        [-5.2638e-03, -3.8507e-03,  2.8269e-02],\n",
       "                        [-3.7400e-03, -2.5969e-02, -5.8810e-02]],\n",
       "              \n",
       "                       [[ 4.1358e-04, -1.2177e-02,  4.1089e-02],\n",
       "                        [ 3.7446e-02, -3.0407e-02, -4.6148e-02],\n",
       "                        [-2.8747e-02, -3.5110e-02, -5.7027e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3206e-02,  9.8188e-04, -4.7161e-02],\n",
       "                        [ 3.2185e-02, -4.2098e-02, -1.8392e-02],\n",
       "                        [-4.5128e-02, -5.4931e-02, -2.8362e-02]],\n",
       "              \n",
       "                       [[ 3.5420e-02, -3.0529e-02,  2.4776e-02],\n",
       "                        [-1.5116e-02, -3.4720e-02, -4.6691e-02],\n",
       "                        [-1.3990e-02, -2.9503e-02,  3.7998e-02]],\n",
       "              \n",
       "                       [[ 5.2899e-02,  2.0860e-02,  2.5901e-02],\n",
       "                        [ 4.1642e-03,  2.0251e-02,  5.6427e-02],\n",
       "                        [ 5.3644e-02,  5.1056e-02,  4.2107e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.6980e-02, -4.7513e-02,  3.0024e-02],\n",
       "                        [-1.7473e-02,  2.5010e-02, -1.5959e-02],\n",
       "                        [ 4.7592e-03,  1.8154e-03, -3.4779e-02]],\n",
       "              \n",
       "                       [[-3.1525e-02,  4.4692e-02, -4.4128e-02],\n",
       "                        [-3.2165e-02, -4.0819e-03,  5.1697e-02],\n",
       "                        [-3.3152e-02, -2.7993e-02, -5.7207e-02]],\n",
       "              \n",
       "                       [[-6.4421e-03,  3.7891e-02,  4.8436e-02],\n",
       "                        [-1.6296e-02, -1.5022e-02,  1.2017e-02],\n",
       "                        [ 6.8042e-04, -3.5924e-02, -3.6198e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6984e-02, -1.7852e-02, -4.0403e-02],\n",
       "                        [-2.1759e-02,  8.9202e-05, -3.0914e-02],\n",
       "                        [ 1.6920e-02,  1.9511e-02, -3.0237e-02]],\n",
       "              \n",
       "                       [[-1.0407e-02, -7.7031e-03, -5.3221e-02],\n",
       "                        [-5.5365e-02,  4.9778e-03,  3.5389e-02],\n",
       "                        [-1.9390e-02,  3.9237e-04,  2.0430e-02]],\n",
       "              \n",
       "                       [[-5.4539e-02, -1.3532e-02, -7.3757e-03],\n",
       "                        [-4.1689e-02, -3.4323e-03, -1.6697e-02],\n",
       "                        [-4.1629e-02,  5.8677e-02,  5.3738e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0329e-03,  1.2446e-02,  5.1607e-02],\n",
       "                        [-2.0876e-03,  5.5026e-02, -5.2180e-02],\n",
       "                        [-5.7943e-02,  6.0771e-03,  3.1161e-02]],\n",
       "              \n",
       "                       [[ 5.3915e-02, -1.9182e-02, -4.1938e-02],\n",
       "                        [ 2.6196e-02, -6.5702e-03, -3.6896e-02],\n",
       "                        [-2.9896e-02, -3.1898e-02,  5.7671e-02]],\n",
       "              \n",
       "                       [[ 2.2487e-02, -1.3793e-02,  5.2618e-02],\n",
       "                        [-3.1664e-02, -5.2127e-02,  2.2962e-02],\n",
       "                        [ 3.2559e-02,  2.7692e-02,  2.3870e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4695e-02, -1.5230e-02,  2.9586e-02],\n",
       "                        [-3.8763e-03,  5.4576e-03, -2.5774e-02],\n",
       "                        [ 5.6368e-03, -1.7733e-02,  1.4486e-02]],\n",
       "              \n",
       "                       [[ 4.0137e-02,  4.8066e-02,  1.2951e-02],\n",
       "                        [-2.8563e-02,  1.9179e-02, -5.4978e-02],\n",
       "                        [-9.4148e-03, -9.6845e-03,  1.1146e-02]],\n",
       "              \n",
       "                       [[-1.0745e-02, -3.0561e-02, -1.6796e-02],\n",
       "                        [-3.2985e-03, -2.4629e-02, -9.8970e-03],\n",
       "                        [ 3.1879e-02, -3.4094e-02,  8.9072e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.4221e-03,  1.8198e-02,  5.8100e-02],\n",
       "                        [-3.7542e-02,  1.8749e-02,  1.1722e-02],\n",
       "                        [-3.2736e-02, -5.3078e-02, -2.8485e-02]],\n",
       "              \n",
       "                       [[ 5.6168e-02, -9.4790e-03,  2.5628e-02],\n",
       "                        [-1.0758e-02, -9.7120e-03, -4.2928e-02],\n",
       "                        [ 1.5751e-02,  1.3422e-02,  3.1109e-02]],\n",
       "              \n",
       "                       [[-4.2866e-02,  5.2928e-04,  1.3077e-02],\n",
       "                        [ 1.8658e-02, -1.2634e-02,  8.5860e-03],\n",
       "                        [ 5.0777e-02,  2.5626e-02,  2.6579e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2315e-02,  5.5384e-02, -1.3155e-02],\n",
       "                        [ 4.5140e-02, -2.8097e-02,  4.2454e-03],\n",
       "                        [-4.4898e-03,  3.7384e-02,  1.2270e-02]],\n",
       "              \n",
       "                       [[ 1.5046e-02, -5.6101e-02,  3.3287e-02],\n",
       "                        [-3.8105e-03,  3.9916e-02, -3.6756e-02],\n",
       "                        [-4.9552e-02, -3.5513e-02,  5.3240e-02]],\n",
       "              \n",
       "                       [[-3.2647e-02,  2.6562e-02, -4.3133e-02],\n",
       "                        [ 5.3583e-02,  3.5964e-02, -3.5300e-03],\n",
       "                        [ 1.4114e-02, -2.3715e-02, -1.7814e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.1526e-03, -3.6435e-02,  3.1257e-02],\n",
       "                        [-1.8458e-02, -3.0330e-02, -7.8919e-03],\n",
       "                        [ 1.3369e-02, -4.4594e-02,  1.9295e-02]],\n",
       "              \n",
       "                       [[-5.5692e-04, -5.7327e-02, -2.0580e-02],\n",
       "                        [-2.9240e-03,  2.6121e-02, -5.1554e-03],\n",
       "                        [ 2.7243e-02, -3.3734e-03, -5.0573e-02]],\n",
       "              \n",
       "                       [[-3.1937e-02,  5.4073e-02, -8.5710e-03],\n",
       "                        [-5.5505e-02, -3.2912e-02,  4.6462e-02],\n",
       "                        [ 5.8680e-02, -4.0091e-02, -3.0363e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.4.original.bias',\n",
       "              tensor([-0.0272,  0.0125,  0.0056, -0.0174,  0.0068,  0.0486,  0.0354, -0.0333,\n",
       "                      -0.0302,  0.0274,  0.0343, -0.0473, -0.0128,  0.0076,  0.0037,  0.0524,\n",
       "                      -0.0559,  0.0107, -0.0073, -0.0211, -0.0233,  0.0085, -0.0116,  0.0537,\n",
       "                       0.0531,  0.0499,  0.0388, -0.0242, -0.0525,  0.0489, -0.0130, -0.0491],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-0.1354]],\n",
       "              \n",
       "                       [[ 0.0989]],\n",
       "              \n",
       "                       [[ 0.1201]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1660]],\n",
       "              \n",
       "                       [[-0.0999]],\n",
       "              \n",
       "                       [[-0.1935]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0265]],\n",
       "              \n",
       "                       [[ 0.0162]],\n",
       "              \n",
       "                       [[-0.0062]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0019]],\n",
       "              \n",
       "                       [[-0.0125]],\n",
       "              \n",
       "                       [[-0.0481]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1559]],\n",
       "              \n",
       "                       [[ 0.0668]],\n",
       "              \n",
       "                       [[ 0.0862]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1795]],\n",
       "              \n",
       "                       [[-0.0908]],\n",
       "              \n",
       "                       [[-0.1710]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0509]],\n",
       "              \n",
       "                       [[ 0.0641]],\n",
       "              \n",
       "                       [[ 0.0910]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0930]],\n",
       "              \n",
       "                       [[-0.0797]],\n",
       "              \n",
       "                       [[-0.1354]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295]],\n",
       "              \n",
       "                       [[ 0.0468]],\n",
       "              \n",
       "                       [[-0.0172]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0011]],\n",
       "              \n",
       "                       [[-0.0114]],\n",
       "              \n",
       "                       [[-0.0534]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0006]],\n",
       "              \n",
       "                       [[-0.0377]],\n",
       "              \n",
       "                       [[ 0.0152]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0107]],\n",
       "              \n",
       "                       [[-0.0009]],\n",
       "              \n",
       "                       [[ 0.0167]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.1091]],\n",
       "              \n",
       "                       [[ 0.0229]],\n",
       "              \n",
       "                       [[ 0.1441]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0367]],\n",
       "              \n",
       "                       [[ 0.0241]],\n",
       "              \n",
       "                       [[ 0.0414]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0981]],\n",
       "              \n",
       "                       [[-0.0103]],\n",
       "              \n",
       "                       [[ 0.0826]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0757]],\n",
       "              \n",
       "                       [[-0.0295]],\n",
       "              \n",
       "                       [[ 0.0235]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2431]],\n",
       "              \n",
       "                       [[-0.0055]],\n",
       "              \n",
       "                       [[-0.2068]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1663]],\n",
       "              \n",
       "                       [[ 0.0008]],\n",
       "              \n",
       "                       [[-0.0131]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0414]],\n",
       "              \n",
       "                       [[-0.0278]],\n",
       "              \n",
       "                       [[-0.0026]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0521]],\n",
       "              \n",
       "                       [[-0.0356]],\n",
       "              \n",
       "                       [[ 0.0287]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0204]],\n",
       "              \n",
       "                       [[ 0.0080]],\n",
       "              \n",
       "                       [[ 0.0352]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0417]],\n",
       "              \n",
       "                       [[ 0.0154]],\n",
       "              \n",
       "                       [[-0.0107]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1277]],\n",
       "              \n",
       "                       [[ 0.0205]],\n",
       "              \n",
       "                       [[ 0.1455]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0637]],\n",
       "              \n",
       "                       [[ 0.0300]],\n",
       "              \n",
       "                       [[-0.0094]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.weight',\n",
       "              tensor([1.0802, 0.7496, 0.9876, 0.9577, 1.0574, 1.0519, 1.0342, 0.7835, 0.9143,\n",
       "                      1.0449, 0.8070, 0.7641, 0.9642, 1.0456, 0.7009, 0.9717, 1.1109, 0.9535,\n",
       "                      0.9695, 0.8278, 0.8549, 0.8455, 0.8006, 0.7878, 0.8033, 0.9867, 0.8694,\n",
       "                      1.0782, 0.8654, 1.2270, 0.8021, 0.9929], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.bias',\n",
       "              tensor([-0.5265,  0.0747, -0.0632, -0.3122, -0.4094, -0.3104, -0.2893, -0.4515,\n",
       "                       0.2309, -0.2482, -0.4992, -0.4440, -0.4335, -0.1778,  0.1018, -0.6688,\n",
       "                      -0.3381, -0.2245, -0.3751, -0.5793, -0.3478, -0.3914, -0.2619, -0.5873,\n",
       "                      -0.5494, -0.4839, -0.3741, -0.3645, -0.1689, -0.3808, -0.4509, -0.4127],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.running_mean',\n",
       "              tensor([ 2.7770e-01, -8.0113e-02, -1.0278e-01, -1.8978e-01,  3.7394e-01,\n",
       "                       1.1819e-01, -4.5350e-01, -1.9951e-01, -1.6716e-01,  7.2382e-02,\n",
       "                       3.5387e-01, -1.6327e-01,  1.2290e-02,  2.3416e-02, -1.9966e-04,\n",
       "                      -9.3985e-02, -2.2020e-01,  9.9585e-02, -1.4419e-01, -1.1225e-01,\n",
       "                       1.1145e-01,  2.4456e-01, -1.2091e-01, -8.4160e-02,  1.3077e-01,\n",
       "                      -3.2485e-02, -1.2402e-02, -2.2139e-01, -3.8480e-01, -3.4281e-02,\n",
       "                      -5.3931e-02,  9.0122e-02], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.running_var',\n",
       "              tensor([0.2217, 0.3055, 0.8130, 0.5905, 0.4883, 0.5753, 0.5006, 0.0544, 0.3088,\n",
       "                      0.4463, 0.4598, 0.0812, 0.4018, 0.7202, 0.0774, 0.1833, 0.5066, 0.0959,\n",
       "                      0.3651, 0.0641, 0.1125, 0.3009, 0.5455, 0.2334, 0.1885, 0.2156, 0.1612,\n",
       "                      0.8619, 0.8967, 0.2324, 0.1293, 0.4723], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.1.6.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.0.original.weight',\n",
       "              tensor([[[[ 4.0992e-02,  5.6540e-02, -4.7886e-02],\n",
       "                        [-5.7729e-02, -1.4251e-02, -1.9184e-02],\n",
       "                        [ 4.9671e-02,  4.2946e-02,  5.5659e-02]],\n",
       "              \n",
       "                       [[ 8.8315e-04,  4.3254e-02, -1.5015e-02],\n",
       "                        [ 1.4686e-02, -4.2380e-02, -3.7060e-02],\n",
       "                        [ 7.4299e-03,  1.8727e-02,  5.4327e-02]],\n",
       "              \n",
       "                       [[ 5.8499e-02,  3.8097e-03,  8.0408e-03],\n",
       "                        [-3.4338e-02,  3.9382e-02,  3.0243e-02],\n",
       "                        [-5.7195e-02,  5.7063e-03, -5.8376e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9893e-02, -3.2350e-02, -4.9949e-02],\n",
       "                        [ 5.6764e-02, -4.5716e-02, -2.3867e-02],\n",
       "                        [ 9.3782e-03,  4.8721e-02, -5.6603e-02]],\n",
       "              \n",
       "                       [[ 2.4771e-02, -9.4198e-05,  1.2029e-02],\n",
       "                        [ 2.0117e-02,  2.0729e-02,  4.7911e-02],\n",
       "                        [-3.9815e-02,  4.3539e-02,  1.8294e-02]],\n",
       "              \n",
       "                       [[-2.8527e-02, -4.2713e-02, -3.1796e-02],\n",
       "                        [ 2.4249e-03,  5.4299e-02, -5.4756e-02],\n",
       "                        [ 3.8202e-02, -2.2597e-02,  5.3337e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1571e-02,  4.1297e-02, -3.0792e-03],\n",
       "                        [-2.8538e-02,  1.3446e-02, -1.0842e-02],\n",
       "                        [-3.2766e-02, -3.7029e-02,  5.4351e-02]],\n",
       "              \n",
       "                       [[-3.0830e-02, -1.4891e-02,  5.3965e-03],\n",
       "                        [-4.6173e-02,  3.3290e-02,  1.3173e-02],\n",
       "                        [-5.7454e-02,  7.3414e-03, -1.7837e-02]],\n",
       "              \n",
       "                       [[-2.4053e-02,  3.0088e-02,  4.0010e-02],\n",
       "                        [ 8.5957e-03,  2.6913e-02, -4.1386e-02],\n",
       "                        [-6.8059e-03, -5.8513e-02, -3.0708e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.1645e-02,  4.5118e-02, -2.2273e-02],\n",
       "                        [ 6.3635e-03, -4.6441e-02, -5.1788e-02],\n",
       "                        [-5.8918e-02,  1.4972e-02,  3.9909e-02]],\n",
       "              \n",
       "                       [[-3.9210e-02,  4.6959e-02, -4.9502e-02],\n",
       "                        [-4.1835e-02,  4.4419e-02, -1.7702e-02],\n",
       "                        [-5.8035e-02,  4.4581e-02,  5.6782e-02]],\n",
       "              \n",
       "                       [[-3.6542e-03, -1.6102e-02, -4.3602e-02],\n",
       "                        [-1.6952e-02,  8.2112e-03, -4.0897e-02],\n",
       "                        [-8.6908e-03,  4.0107e-02, -3.6690e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.0917e-03, -5.0341e-02, -1.7917e-02],\n",
       "                        [-2.2156e-02, -5.1066e-02, -1.2312e-03],\n",
       "                        [-9.1731e-03, -5.2811e-02, -5.1697e-02]],\n",
       "              \n",
       "                       [[-5.4666e-02, -5.5338e-03,  5.0193e-02],\n",
       "                        [ 3.1096e-02, -4.8174e-02,  5.0443e-02],\n",
       "                        [-3.6112e-02,  3.5156e-03,  1.9384e-02]],\n",
       "              \n",
       "                       [[ 5.7443e-02, -2.1240e-02,  4.3881e-02],\n",
       "                        [-2.8120e-02, -1.3739e-02, -2.9444e-02],\n",
       "                        [ 8.3117e-03,  5.5709e-02,  1.1082e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.1783e-02,  4.6806e-02, -4.1962e-03],\n",
       "                        [-1.8574e-02,  1.2984e-02,  3.5449e-02],\n",
       "                        [-9.3201e-03,  5.5848e-02, -7.4351e-03]],\n",
       "              \n",
       "                       [[-4.0037e-02,  8.2369e-03,  2.8970e-02],\n",
       "                        [ 3.7621e-02, -3.2473e-02,  1.9318e-02],\n",
       "                        [-4.5173e-02, -9.9492e-03, -2.2231e-02]],\n",
       "              \n",
       "                       [[-1.8980e-02, -5.5805e-02, -9.0552e-03],\n",
       "                        [-2.2056e-02,  5.0449e-02, -5.1429e-02],\n",
       "                        [-1.8808e-03,  4.9386e-02, -4.4323e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.1865e-03, -1.0374e-02,  1.1058e-02],\n",
       "                        [-9.5257e-03, -2.1715e-02,  4.2139e-02],\n",
       "                        [-2.4292e-02,  2.7900e-02, -1.5294e-02]],\n",
       "              \n",
       "                       [[ 8.8792e-03, -2.8717e-02, -1.3956e-03],\n",
       "                        [ 5.0135e-02,  6.9728e-03,  7.8172e-03],\n",
       "                        [ 5.2708e-02,  4.7167e-02,  5.7319e-02]],\n",
       "              \n",
       "                       [[ 1.3235e-02, -3.8346e-02, -3.1878e-04],\n",
       "                        [-4.3744e-02,  3.3102e-02, -2.3570e-02],\n",
       "                        [-5.6052e-02, -4.3927e-02,  9.7141e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.6258e-02,  2.9435e-02,  1.2375e-02],\n",
       "                        [-2.8387e-02, -5.6064e-03,  2.5100e-03],\n",
       "                        [-5.2718e-02, -1.7928e-03, -1.3143e-02]],\n",
       "              \n",
       "                       [[-5.2138e-02,  2.8048e-02, -2.2787e-02],\n",
       "                        [-8.7998e-03, -2.6952e-02, -6.4773e-03],\n",
       "                        [-4.1986e-02,  1.1572e-02, -4.5631e-02]],\n",
       "              \n",
       "                       [[-2.8919e-02,  7.0902e-04,  2.2585e-02],\n",
       "                        [ 4.0855e-02,  4.8583e-02,  4.0603e-02],\n",
       "                        [-2.0832e-02, -3.0252e-02,  2.9766e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3528e-02, -1.7415e-02, -6.7281e-03],\n",
       "                        [-4.8765e-02, -4.4322e-02, -5.7901e-02],\n",
       "                        [-2.1329e-02,  4.4490e-02,  4.0077e-02]],\n",
       "              \n",
       "                       [[-3.6785e-02, -5.1075e-02,  1.2645e-02],\n",
       "                        [-2.5944e-03, -1.5318e-02, -3.1610e-02],\n",
       "                        [-4.5328e-03, -5.3681e-02,  4.0366e-02]],\n",
       "              \n",
       "                       [[-2.1634e-02, -4.2168e-02, -6.1944e-03],\n",
       "                        [-5.3504e-02, -5.1260e-02, -9.8679e-03],\n",
       "                        [-3.6464e-02,  4.6582e-02, -1.0814e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.2578e-02, -3.1585e-02, -4.0496e-02],\n",
       "                        [ 6.1058e-03,  2.8145e-02,  1.0691e-02],\n",
       "                        [ 4.8837e-02, -3.1400e-02, -6.9201e-03]],\n",
       "              \n",
       "                       [[ 2.5596e-02, -5.2583e-02, -4.5670e-02],\n",
       "                        [-5.7487e-02,  4.1544e-02, -4.9774e-03],\n",
       "                        [-5.0208e-02, -5.5299e-02,  3.1031e-02]],\n",
       "              \n",
       "                       [[-4.5895e-02, -1.7756e-02, -1.4733e-02],\n",
       "                        [ 1.3965e-02,  1.8682e-02,  5.1562e-03],\n",
       "                        [-3.8793e-02, -5.6955e-02, -5.8279e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.9310e-02, -4.8297e-02,  3.7630e-02],\n",
       "                        [-1.7800e-02, -5.1143e-02,  3.3314e-02],\n",
       "                        [-3.5935e-02, -4.9845e-02, -1.4949e-02]],\n",
       "              \n",
       "                       [[ 4.7932e-02,  2.5695e-03,  1.4611e-02],\n",
       "                        [-5.4929e-02,  2.2809e-02,  4.2184e-02],\n",
       "                        [-3.3021e-02, -3.6605e-02, -3.3308e-02]],\n",
       "              \n",
       "                       [[-3.5957e-02, -3.1300e-02,  6.8994e-03],\n",
       "                        [-4.3257e-02, -6.8798e-03,  8.6650e-04],\n",
       "                        [-1.6022e-02, -1.0615e-02,  2.1654e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.2627e-02, -4.6412e-02,  2.1681e-02],\n",
       "                        [-7.3306e-03, -2.2319e-02,  2.3060e-02],\n",
       "                        [-3.3394e-02,  1.8743e-02, -2.4403e-02]],\n",
       "              \n",
       "                       [[-1.1023e-02,  4.6091e-02,  3.3115e-02],\n",
       "                        [ 4.4729e-02,  2.9854e-03,  2.7621e-02],\n",
       "                        [-5.5587e-02, -3.8664e-02, -4.6150e-02]],\n",
       "              \n",
       "                       [[ 3.6434e-02, -4.9661e-02, -4.0837e-02],\n",
       "                        [ 2.4252e-02,  4.0306e-02,  3.5250e-03],\n",
       "                        [-4.5607e-02, -3.0471e-02, -3.1894e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.0.original.bias',\n",
       "              tensor([ 0.0500, -0.0425,  0.0408,  0.0401, -0.0346, -0.0462, -0.0070, -0.0058,\n",
       "                       0.0329, -0.0584,  0.0289, -0.0529, -0.0572, -0.0121, -0.0117,  0.0013,\n",
       "                      -0.0403, -0.0170,  0.0163, -0.0062, -0.0429, -0.0513, -0.0058, -0.0077,\n",
       "                       0.0425,  0.0415,  0.0074, -0.0587,  0.0120, -0.0141,  0.0109,  0.0044],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[ 0.0010]],\n",
       "              \n",
       "                       [[ 0.0234]],\n",
       "              \n",
       "                       [[ 0.0029]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0140]],\n",
       "              \n",
       "                       [[ 0.0037]],\n",
       "              \n",
       "                       [[-0.0045]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0282]],\n",
       "              \n",
       "                       [[ 0.0332]],\n",
       "              \n",
       "                       [[-0.2287]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0104]],\n",
       "              \n",
       "                       [[ 0.0072]],\n",
       "              \n",
       "                       [[-0.0675]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0086]],\n",
       "              \n",
       "                       [[ 0.0150]],\n",
       "              \n",
       "                       [[ 0.0113]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0306]],\n",
       "              \n",
       "                       [[ 0.0226]],\n",
       "              \n",
       "                       [[-0.0066]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0046]],\n",
       "              \n",
       "                       [[-0.0345]],\n",
       "              \n",
       "                       [[ 0.1372]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0286]],\n",
       "              \n",
       "                       [[ 0.0235]],\n",
       "              \n",
       "                       [[ 0.0260]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0082]],\n",
       "              \n",
       "                       [[ 0.0239]],\n",
       "              \n",
       "                       [[-0.0052]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0119]],\n",
       "              \n",
       "                       [[-0.0089]],\n",
       "              \n",
       "                       [[ 0.0026]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0039]],\n",
       "              \n",
       "                       [[-0.0334]],\n",
       "              \n",
       "                       [[-0.0034]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0064]],\n",
       "              \n",
       "                       [[-0.0013]],\n",
       "              \n",
       "                       [[ 0.0031]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[-0.0095]],\n",
       "              \n",
       "                       [[ 0.1632]],\n",
       "              \n",
       "                       [[ 0.0054]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0812]],\n",
       "              \n",
       "                       [[-0.0090]],\n",
       "              \n",
       "                       [[ 0.0061]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0192]],\n",
       "              \n",
       "                       [[-0.0373]],\n",
       "              \n",
       "                       [[-0.0106]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0110]],\n",
       "              \n",
       "                       [[ 0.0174]],\n",
       "              \n",
       "                       [[-0.0169]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0059]],\n",
       "              \n",
       "                       [[-0.0687]],\n",
       "              \n",
       "                       [[-0.0196]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0252]],\n",
       "              \n",
       "                       [[ 0.0014]],\n",
       "              \n",
       "                       [[ 0.0105]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0124]],\n",
       "              \n",
       "                       [[-0.0574]],\n",
       "              \n",
       "                       [[-0.0289]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0116]],\n",
       "              \n",
       "                       [[-0.0115]],\n",
       "              \n",
       "                       [[ 0.0223]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0134]],\n",
       "              \n",
       "                       [[-0.0621]],\n",
       "              \n",
       "                       [[-0.0123]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0197]],\n",
       "              \n",
       "                       [[ 0.0073]],\n",
       "              \n",
       "                       [[-0.0098]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0065]],\n",
       "              \n",
       "                       [[-0.0099]],\n",
       "              \n",
       "                       [[-0.0298]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0146]],\n",
       "              \n",
       "                       [[-0.0024]],\n",
       "              \n",
       "                       [[ 0.0158]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.weight',\n",
       "              tensor([1.0375, 1.0764, 1.0531, 0.6979, 0.9139, 1.0278, 0.8562, 0.9206, 0.8194,\n",
       "                      0.8864, 0.7883, 0.8075, 0.9479, 1.0579, 1.0451, 0.9979, 1.1076, 0.9029,\n",
       "                      0.9954, 1.1381, 1.0117, 0.8514, 0.8643, 1.0778, 0.9577, 0.9141, 0.9684,\n",
       "                      0.9776, 0.8291, 1.0702, 1.1192, 0.7653], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.bias',\n",
       "              tensor([-0.2946, -0.2842, -0.3467, -0.3136, -0.3024, -0.1448, -0.3847, -0.3373,\n",
       "                      -0.4570, -0.4604, -0.3715, -0.4840, -0.4915, -0.3742, -0.3148, -0.2415,\n",
       "                      -0.3409, -0.4140, -0.0422, -0.2652, -0.1386, -0.2627, -0.4362, -0.2377,\n",
       "                      -0.4334, -0.4688, -0.4684, -0.2662, -0.3675, -0.1374, -0.1229, -0.2075],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.running_mean',\n",
       "              tensor([-0.3397, -0.0438,  0.2821,  0.2860, -0.0147, -0.2716, -0.5016,  0.0757,\n",
       "                      -0.4976, -0.4798,  0.0486, -0.2449, -0.0727, -0.3410,  0.0326, -0.0583,\n",
       "                      -0.5374, -0.2570, -0.5994,  0.2309, -0.3840, -0.4217, -0.3417, -0.4705,\n",
       "                      -0.2363,  0.0691,  0.2514,  0.0417, -0.0207, -0.1087, -0.1175,  0.0183],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.running_var',\n",
       "              tensor([0.3546, 0.2224, 0.3521, 0.2188, 0.0909, 0.4277, 0.3488, 0.3922, 0.2840,\n",
       "                      0.4122, 0.1594, 0.2793, 0.1145, 0.2871, 0.0659, 0.2737, 0.6385, 0.2656,\n",
       "                      0.5650, 0.3953, 0.5267, 0.4384, 0.2443, 0.5456, 0.0984, 0.1646, 0.2710,\n",
       "                      0.2012, 0.2019, 0.3833, 0.4408, 0.2590], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.2.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.4.original.weight',\n",
       "              tensor([[[[ 0.0587,  0.0267, -0.0377],\n",
       "                        [ 0.0417,  0.0181,  0.0491],\n",
       "                        [ 0.0354, -0.0499, -0.0524]],\n",
       "              \n",
       "                       [[-0.0263, -0.0022,  0.0363],\n",
       "                        [ 0.0526,  0.0449, -0.0258],\n",
       "                        [-0.0465,  0.0040, -0.0182]],\n",
       "              \n",
       "                       [[ 0.0381,  0.0094, -0.0185],\n",
       "                        [-0.0254, -0.0561,  0.0196],\n",
       "                        [ 0.0501, -0.0024, -0.0239]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0027, -0.0405,  0.0315],\n",
       "                        [-0.0082,  0.0460, -0.0075],\n",
       "                        [ 0.0152,  0.0426,  0.0337]],\n",
       "              \n",
       "                       [[ 0.0231,  0.0440, -0.0132],\n",
       "                        [ 0.0021,  0.0415,  0.0174],\n",
       "                        [ 0.0332, -0.0490,  0.0121]],\n",
       "              \n",
       "                       [[-0.0037, -0.0503,  0.0156],\n",
       "                        [-0.0522,  0.0164, -0.0277],\n",
       "                        [ 0.0448, -0.0074,  0.0472]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0041, -0.0423, -0.0491],\n",
       "                        [-0.0233, -0.0256,  0.0396],\n",
       "                        [-0.0311,  0.0537,  0.0092]],\n",
       "              \n",
       "                       [[ 0.0322, -0.0557, -0.0579],\n",
       "                        [-0.0550,  0.0474, -0.0576],\n",
       "                        [-0.0175, -0.0183,  0.0300]],\n",
       "              \n",
       "                       [[-0.0486, -0.0256, -0.0059],\n",
       "                        [-0.0179,  0.0029,  0.0459],\n",
       "                        [ 0.0255,  0.0098,  0.0181]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0339,  0.0222, -0.0198],\n",
       "                        [ 0.0525, -0.0182, -0.0523],\n",
       "                        [-0.0215,  0.0424, -0.0576]],\n",
       "              \n",
       "                       [[ 0.0168, -0.0428,  0.0284],\n",
       "                        [ 0.0200,  0.0583,  0.0047],\n",
       "                        [-0.0162, -0.0068,  0.0446]],\n",
       "              \n",
       "                       [[ 0.0115, -0.0525,  0.0187],\n",
       "                        [-0.0571,  0.0072,  0.0043],\n",
       "                        [ 0.0307, -0.0236,  0.0301]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0489, -0.0507,  0.0241],\n",
       "                        [ 0.0335,  0.0318,  0.0200],\n",
       "                        [ 0.0360,  0.0308, -0.0392]],\n",
       "              \n",
       "                       [[-0.0345,  0.0343,  0.0368],\n",
       "                        [ 0.0252, -0.0342,  0.0302],\n",
       "                        [ 0.0044,  0.0530,  0.0107]],\n",
       "              \n",
       "                       [[-0.0530,  0.0093,  0.0120],\n",
       "                        [-0.0449, -0.0374,  0.0578],\n",
       "                        [ 0.0003,  0.0532,  0.0200]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0307,  0.0138, -0.0277],\n",
       "                        [-0.0006, -0.0467, -0.0127],\n",
       "                        [-0.0235, -0.0460,  0.0218]],\n",
       "              \n",
       "                       [[ 0.0415, -0.0429,  0.0584],\n",
       "                        [-0.0039, -0.0077, -0.0486],\n",
       "                        [ 0.0032, -0.0196, -0.0544]],\n",
       "              \n",
       "                       [[ 0.0295, -0.0372, -0.0559],\n",
       "                        [ 0.0243,  0.0030, -0.0223],\n",
       "                        [-0.0364,  0.0204,  0.0508]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0136, -0.0284, -0.0133],\n",
       "                        [ 0.0236, -0.0550, -0.0464],\n",
       "                        [-0.0049,  0.0256,  0.0060]],\n",
       "              \n",
       "                       [[ 0.0159,  0.0132,  0.0149],\n",
       "                        [ 0.0134, -0.0271, -0.0269],\n",
       "                        [ 0.0407, -0.0284, -0.0331]],\n",
       "              \n",
       "                       [[-0.0202,  0.0026, -0.0170],\n",
       "                        [-0.0274, -0.0524,  0.0556],\n",
       "                        [-0.0411, -0.0142, -0.0083]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0139, -0.0295, -0.0236],\n",
       "                        [ 0.0195,  0.0263,  0.0323],\n",
       "                        [ 0.0506,  0.0119, -0.0157]],\n",
       "              \n",
       "                       [[-0.0003,  0.0513,  0.0554],\n",
       "                        [ 0.0410, -0.0574, -0.0168],\n",
       "                        [ 0.0349,  0.0487,  0.0321]],\n",
       "              \n",
       "                       [[-0.0574, -0.0187, -0.0561],\n",
       "                        [ 0.0126, -0.0448,  0.0557],\n",
       "                        [-0.0179, -0.0474, -0.0094]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0028,  0.0221, -0.0022],\n",
       "                        [-0.0292,  0.0441,  0.0251],\n",
       "                        [ 0.0061, -0.0368, -0.0133]],\n",
       "              \n",
       "                       [[-0.0473,  0.0040, -0.0248],\n",
       "                        [-0.0359, -0.0528, -0.0537],\n",
       "                        [ 0.0263,  0.0275,  0.0410]],\n",
       "              \n",
       "                       [[-0.0527,  0.0499,  0.0584],\n",
       "                        [ 0.0410, -0.0563, -0.0222],\n",
       "                        [ 0.0428,  0.0480,  0.0355]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0484,  0.0011,  0.0403],\n",
       "                        [-0.0071, -0.0274,  0.0345],\n",
       "                        [-0.0037,  0.0147, -0.0220]],\n",
       "              \n",
       "                       [[-0.0494,  0.0129,  0.0231],\n",
       "                        [ 0.0005, -0.0327, -0.0572],\n",
       "                        [-0.0529,  0.0263,  0.0491]],\n",
       "              \n",
       "                       [[ 0.0238,  0.0311,  0.0443],\n",
       "                        [-0.0058,  0.0410,  0.0097],\n",
       "                        [-0.0183, -0.0256, -0.0157]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0497, -0.0301, -0.0266],\n",
       "                        [-0.0003, -0.0393,  0.0187],\n",
       "                        [-0.0222,  0.0020,  0.0484]],\n",
       "              \n",
       "                       [[-0.0440, -0.0234,  0.0540],\n",
       "                        [ 0.0246, -0.0348,  0.0109],\n",
       "                        [ 0.0530,  0.0251,  0.0404]],\n",
       "              \n",
       "                       [[-0.0581,  0.0121, -0.0528],\n",
       "                        [ 0.0302, -0.0212,  0.0181],\n",
       "                        [ 0.0455,  0.0257,  0.0515]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0490, -0.0137, -0.0487],\n",
       "                        [-0.0215,  0.0575,  0.0548],\n",
       "                        [ 0.0396,  0.0573, -0.0208]],\n",
       "              \n",
       "                       [[ 0.0074,  0.0305,  0.0243],\n",
       "                        [-0.0411, -0.0245, -0.0400],\n",
       "                        [ 0.0581,  0.0171, -0.0345]],\n",
       "              \n",
       "                       [[-0.0548,  0.0214, -0.0263],\n",
       "                        [ 0.0535, -0.0581,  0.0432],\n",
       "                        [ 0.0075,  0.0057,  0.0510]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.4.original.bias',\n",
       "              tensor([ 0.0530, -0.0066, -0.0576, -0.0365,  0.0222,  0.0118, -0.0320, -0.0461,\n",
       "                      -0.0400,  0.0304, -0.0555, -0.0414, -0.0123,  0.0347,  0.0369,  0.0330,\n",
       "                      -0.0107,  0.0452,  0.0392, -0.0147,  0.0380, -0.0226,  0.0037,  0.0033,\n",
       "                       0.0076,  0.0283, -0.0118,  0.0142,  0.0534,  0.0268, -0.0146,  0.0417],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-1.6089e-02]],\n",
       "              \n",
       "                       [[ 1.5685e-01]],\n",
       "              \n",
       "                       [[ 1.3850e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.1263e-01]],\n",
       "              \n",
       "                       [[ 2.4729e-01]],\n",
       "              \n",
       "                       [[ 1.9814e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5363e-02]],\n",
       "              \n",
       "                       [[-1.6721e-02]],\n",
       "              \n",
       "                       [[-6.5390e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2054e-02]],\n",
       "              \n",
       "                       [[ 2.1075e-03]],\n",
       "              \n",
       "                       [[-1.3609e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0940e-02]],\n",
       "              \n",
       "                       [[-1.0644e-02]],\n",
       "              \n",
       "                       [[ 6.5431e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.8631e-02]],\n",
       "              \n",
       "                       [[-5.1214e-02]],\n",
       "              \n",
       "                       [[-2.4106e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 6.1527e-02]],\n",
       "              \n",
       "                       [[-1.2689e-01]],\n",
       "              \n",
       "                       [[-1.0540e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.6798e-02]],\n",
       "              \n",
       "                       [[-1.8309e-01]],\n",
       "              \n",
       "                       [[-1.3878e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.6879e-02]],\n",
       "              \n",
       "                       [[-3.8914e-02]],\n",
       "              \n",
       "                       [[-8.2546e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.5871e-02]],\n",
       "              \n",
       "                       [[-1.0554e-01]],\n",
       "              \n",
       "                       [[-1.0402e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.6076e-03]],\n",
       "              \n",
       "                       [[ 1.2142e-02]],\n",
       "              \n",
       "                       [[ 8.3928e-05]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5671e-04]],\n",
       "              \n",
       "                       [[ 1.5044e-02]],\n",
       "              \n",
       "                       [[-1.0913e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.1517]],\n",
       "              \n",
       "                       [[ 0.0264]],\n",
       "              \n",
       "                       [[ 0.0009]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1354]],\n",
       "              \n",
       "                       [[-0.0521]],\n",
       "              \n",
       "                       [[ 0.0212]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1161]],\n",
       "              \n",
       "                       [[ 0.0221]],\n",
       "              \n",
       "                       [[ 0.0213]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0867]],\n",
       "              \n",
       "                       [[-0.0063]],\n",
       "              \n",
       "                       [[-0.0223]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0470]],\n",
       "              \n",
       "                       [[ 0.0100]],\n",
       "              \n",
       "                       [[ 0.0069]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0378]],\n",
       "              \n",
       "                       [[ 0.0188]],\n",
       "              \n",
       "                       [[ 0.0129]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0449]],\n",
       "              \n",
       "                       [[ 0.0398]],\n",
       "              \n",
       "                       [[ 0.0574]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0219]],\n",
       "              \n",
       "                       [[ 0.0130]],\n",
       "              \n",
       "                       [[ 0.0009]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1461]],\n",
       "              \n",
       "                       [[ 0.0139]],\n",
       "              \n",
       "                       [[ 0.0061]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1372]],\n",
       "              \n",
       "                       [[-0.0787]],\n",
       "              \n",
       "                       [[ 0.0158]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0802]],\n",
       "              \n",
       "                       [[-0.0146]],\n",
       "              \n",
       "                       [[-0.0259]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0894]],\n",
       "              \n",
       "                       [[ 0.0067]],\n",
       "              \n",
       "                       [[-0.0119]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.weight',\n",
       "              tensor([1.0129, 1.0008, 1.0340, 1.0419, 0.8157, 0.9287, 1.1636, 1.0492, 1.0395,\n",
       "                      0.9117, 0.8745, 1.2123, 1.0518, 1.0612, 0.7748, 1.0755, 1.0289, 0.7953,\n",
       "                      1.1411, 1.0187, 1.0647, 0.7865, 0.8982, 0.9976, 1.0632, 0.9892, 0.8850,\n",
       "                      0.9911, 1.0205, 1.0375, 1.0654, 0.9222], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.bias',\n",
       "              tensor([-0.2969, -0.0855,  0.0189, -0.0224, -0.1316, -0.2554, -0.3078, -0.0547,\n",
       "                      -0.1326, -0.1148, -0.2188,  0.0335, -0.1522, -0.1695, -0.2466, -0.2233,\n",
       "                      -0.1684, -0.2024, -0.0289, -0.2044,  0.1872, -0.0651, -0.0269, -0.4588,\n",
       "                      -0.3597, -0.0724, -0.2079, -0.2491, -0.5101, -0.1933, -0.2028, -0.3234],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.running_mean',\n",
       "              tensor([ 0.0307, -0.4223, -0.3127,  0.0242, -0.1081,  0.1097, -0.4479, -0.3429,\n",
       "                      -0.2314, -0.2901, -0.3500,  0.1882, -0.2091, -0.4207, -0.1790, -0.2238,\n",
       "                       0.0344, -0.3045, -0.3811, -0.2015, -0.1046, -0.1501, -0.1709,  0.1132,\n",
       "                      -0.1975, -0.0697, -0.1588, -0.0609,  0.0524, -0.2854, -0.0445,  0.2111],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.running_var',\n",
       "              tensor([0.3023, 0.3687, 0.5259, 0.1958, 0.5626, 0.4523, 0.4221, 0.3046, 0.0962,\n",
       "                      0.4312, 0.3679, 0.8595, 0.6683, 0.4860, 0.3492, 0.3147, 0.8004, 0.4114,\n",
       "                      0.5212, 0.6998, 0.0853, 0.1356, 0.3440, 0.2632, 0.1042, 0.5370, 0.3846,\n",
       "                      0.1374, 0.3162, 0.4920, 0.3819, 0.4546], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.2.6.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.0.original.weight',\n",
       "              tensor([[[[-0.0033, -0.0466, -0.0397],\n",
       "                        [-0.0329, -0.0139, -0.0158],\n",
       "                        [ 0.0102,  0.0575, -0.0085]],\n",
       "              \n",
       "                       [[-0.0465, -0.0384,  0.0153],\n",
       "                        [-0.0278,  0.0309, -0.0379],\n",
       "                        [-0.0169,  0.0009, -0.0580]],\n",
       "              \n",
       "                       [[-0.0315,  0.0572, -0.0156],\n",
       "                        [ 0.0057,  0.0457,  0.0549],\n",
       "                        [ 0.0333,  0.0083,  0.0076]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0203, -0.0140, -0.0424],\n",
       "                        [ 0.0033,  0.0069, -0.0157],\n",
       "                        [-0.0171, -0.0106,  0.0095]],\n",
       "              \n",
       "                       [[-0.0297, -0.0556, -0.0091],\n",
       "                        [-0.0070, -0.0137,  0.0482],\n",
       "                        [-0.0380,  0.0334,  0.0092]],\n",
       "              \n",
       "                       [[ 0.0031,  0.0241,  0.0215],\n",
       "                        [ 0.0279, -0.0066, -0.0267],\n",
       "                        [-0.0073, -0.0083,  0.0289]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0028,  0.0036, -0.0069],\n",
       "                        [-0.0259,  0.0142,  0.0141],\n",
       "                        [ 0.0036,  0.0480, -0.0116]],\n",
       "              \n",
       "                       [[-0.0229,  0.0403, -0.0582],\n",
       "                        [-0.0083,  0.0585,  0.0004],\n",
       "                        [ 0.0499,  0.0171,  0.0008]],\n",
       "              \n",
       "                       [[ 0.0398, -0.0546, -0.0104],\n",
       "                        [-0.0466,  0.0415,  0.0084],\n",
       "                        [ 0.0007,  0.0074,  0.0068]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0378, -0.0376, -0.0430],\n",
       "                        [-0.0039,  0.0252,  0.0575],\n",
       "                        [-0.0339,  0.0463,  0.0440]],\n",
       "              \n",
       "                       [[-0.0216,  0.0075, -0.0364],\n",
       "                        [-0.0479,  0.0480,  0.0053],\n",
       "                        [-0.0476, -0.0372,  0.0557]],\n",
       "              \n",
       "                       [[ 0.0426, -0.0077,  0.0010],\n",
       "                        [-0.0400,  0.0298,  0.0084],\n",
       "                        [ 0.0481, -0.0076, -0.0158]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0165, -0.0126, -0.0576],\n",
       "                        [-0.0390,  0.0236,  0.0019],\n",
       "                        [-0.0441,  0.0071, -0.0454]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0212,  0.0064],\n",
       "                        [ 0.0453,  0.0374,  0.0101],\n",
       "                        [-0.0462,  0.0556,  0.0158]],\n",
       "              \n",
       "                       [[-0.0015, -0.0064,  0.0390],\n",
       "                        [-0.0356,  0.0077, -0.0106],\n",
       "                        [ 0.0382, -0.0163, -0.0343]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0122,  0.0517, -0.0377],\n",
       "                        [-0.0467,  0.0421, -0.0448],\n",
       "                        [-0.0526, -0.0084, -0.0510]],\n",
       "              \n",
       "                       [[ 0.0333, -0.0324, -0.0429],\n",
       "                        [ 0.0545,  0.0234,  0.0281],\n",
       "                        [ 0.0147, -0.0382, -0.0460]],\n",
       "              \n",
       "                       [[-0.0325, -0.0521,  0.0498],\n",
       "                        [-0.0551,  0.0144,  0.0189],\n",
       "                        [-0.0534, -0.0522,  0.0588]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0021, -0.0113, -0.0002],\n",
       "                        [ 0.0163,  0.0107, -0.0080],\n",
       "                        [ 0.0548, -0.0011,  0.0573]],\n",
       "              \n",
       "                       [[-0.0042,  0.0455, -0.0246],\n",
       "                        [ 0.0091,  0.0462,  0.0067],\n",
       "                        [-0.0379, -0.0275,  0.0153]],\n",
       "              \n",
       "                       [[-0.0068, -0.0313, -0.0246],\n",
       "                        [-0.0226,  0.0124,  0.0340],\n",
       "                        [-0.0478,  0.0184, -0.0497]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0492,  0.0547, -0.0321],\n",
       "                        [-0.0417, -0.0133, -0.0297],\n",
       "                        [ 0.0427,  0.0411, -0.0480]],\n",
       "              \n",
       "                       [[-0.0269, -0.0264,  0.0173],\n",
       "                        [ 0.0380, -0.0273, -0.0338],\n",
       "                        [ 0.0247, -0.0510, -0.0256]],\n",
       "              \n",
       "                       [[ 0.0384, -0.0166,  0.0170],\n",
       "                        [ 0.0143, -0.0505,  0.0566],\n",
       "                        [-0.0563, -0.0432,  0.0188]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0329, -0.0143, -0.0074],\n",
       "                        [ 0.0521, -0.0353,  0.0289],\n",
       "                        [-0.0267,  0.0240, -0.0215]],\n",
       "              \n",
       "                       [[ 0.0230,  0.0547,  0.0198],\n",
       "                        [-0.0182, -0.0571,  0.0558],\n",
       "                        [-0.0159,  0.0295, -0.0521]],\n",
       "              \n",
       "                       [[-0.0056,  0.0430,  0.0172],\n",
       "                        [-0.0134,  0.0278,  0.0382],\n",
       "                        [-0.0527,  0.0568, -0.0060]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0204,  0.0276, -0.0038],\n",
       "                        [ 0.0308, -0.0138, -0.0056],\n",
       "                        [-0.0479,  0.0113,  0.0290]],\n",
       "              \n",
       "                       [[ 0.0393,  0.0497, -0.0344],\n",
       "                        [ 0.0181,  0.0013,  0.0505],\n",
       "                        [ 0.0037, -0.0587,  0.0107]],\n",
       "              \n",
       "                       [[ 0.0179, -0.0257, -0.0516],\n",
       "                        [ 0.0261,  0.0268, -0.0491],\n",
       "                        [-0.0140, -0.0152,  0.0009]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0084, -0.0045, -0.0463],\n",
       "                        [ 0.0257,  0.0266, -0.0172],\n",
       "                        [ 0.0456,  0.0401, -0.0535]],\n",
       "              \n",
       "                       [[ 0.0110,  0.0371, -0.0432],\n",
       "                        [-0.0309,  0.0256, -0.0275],\n",
       "                        [-0.0209, -0.0424,  0.0075]],\n",
       "              \n",
       "                       [[ 0.0545,  0.0191,  0.0240],\n",
       "                        [-0.0136, -0.0511,  0.0341],\n",
       "                        [-0.0039,  0.0515, -0.0222]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0024, -0.0405,  0.0528],\n",
       "                        [-0.0445, -0.0308,  0.0050],\n",
       "                        [-0.0098,  0.0196,  0.0205]],\n",
       "              \n",
       "                       [[ 0.0293, -0.0424,  0.0055],\n",
       "                        [ 0.0286,  0.0079,  0.0037],\n",
       "                        [-0.0056,  0.0449,  0.0378]],\n",
       "              \n",
       "                       [[-0.0328, -0.0390, -0.0193],\n",
       "                        [ 0.0132, -0.0101,  0.0028],\n",
       "                        [-0.0554, -0.0032,  0.0574]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.0.original.bias',\n",
       "              tensor([-0.0295,  0.0056, -0.0154, -0.0331,  0.0555,  0.0026, -0.0543, -0.0290,\n",
       "                       0.0528, -0.0265,  0.0584,  0.0551,  0.0465,  0.0341,  0.0211, -0.0218,\n",
       "                       0.0562,  0.0486, -0.0421, -0.0463,  0.0321,  0.0156, -0.0012,  0.0348,\n",
       "                       0.0087, -0.0531,  0.0288,  0.0251,  0.0422, -0.0259, -0.0574, -0.0084],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[ 0.0008]],\n",
       "              \n",
       "                       [[-0.0104]],\n",
       "              \n",
       "                       [[ 0.0040]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0325]],\n",
       "              \n",
       "                       [[ 0.0875]],\n",
       "              \n",
       "                       [[-0.0109]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0039]],\n",
       "              \n",
       "                       [[-0.0003]],\n",
       "              \n",
       "                       [[ 0.0126]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0006]],\n",
       "              \n",
       "                       [[ 0.0080]],\n",
       "              \n",
       "                       [[ 0.0280]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2008]],\n",
       "              \n",
       "                       [[-0.0521]],\n",
       "              \n",
       "                       [[ 0.0809]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0248]],\n",
       "              \n",
       "                       [[-0.2140]],\n",
       "              \n",
       "                       [[ 0.0617]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0062]],\n",
       "              \n",
       "                       [[-0.0046]],\n",
       "              \n",
       "                       [[-0.0092]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0302]],\n",
       "              \n",
       "                       [[ 0.0018]],\n",
       "              \n",
       "                       [[ 0.0406]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0961]],\n",
       "              \n",
       "                       [[-0.0243]],\n",
       "              \n",
       "                       [[ 0.1081]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0048]],\n",
       "              \n",
       "                       [[-0.0419]],\n",
       "              \n",
       "                       [[ 0.0340]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0488]],\n",
       "              \n",
       "                       [[-0.0629]],\n",
       "              \n",
       "                       [[ 0.0353]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008]],\n",
       "              \n",
       "                       [[ 0.0928]],\n",
       "              \n",
       "                       [[-0.0317]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.0366]],\n",
       "              \n",
       "                       [[-0.0205]],\n",
       "              \n",
       "                       [[-0.1753]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0078]],\n",
       "              \n",
       "                       [[-0.1243]],\n",
       "              \n",
       "                       [[-0.0181]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0485]],\n",
       "              \n",
       "                       [[ 0.0081]],\n",
       "              \n",
       "                       [[-0.0110]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0376]],\n",
       "              \n",
       "                       [[-0.0008]],\n",
       "              \n",
       "                       [[ 0.0272]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0063]],\n",
       "              \n",
       "                       [[ 0.0187]],\n",
       "              \n",
       "                       [[ 0.1150]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0056]],\n",
       "              \n",
       "                       [[ 0.0240]],\n",
       "              \n",
       "                       [[ 0.0129]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0418]],\n",
       "              \n",
       "                       [[ 0.0321]],\n",
       "              \n",
       "                       [[ 0.1046]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0836]],\n",
       "              \n",
       "                       [[ 0.0885]],\n",
       "              \n",
       "                       [[ 0.0687]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0870]],\n",
       "              \n",
       "                       [[ 0.0146]],\n",
       "              \n",
       "                       [[-0.0074]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0007]],\n",
       "              \n",
       "                       [[-0.0062]],\n",
       "              \n",
       "                       [[ 0.0896]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0312]],\n",
       "              \n",
       "                       [[ 0.0264]],\n",
       "              \n",
       "                       [[ 0.1961]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0180]],\n",
       "              \n",
       "                       [[ 0.0825]],\n",
       "              \n",
       "                       [[-0.0343]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.weight',\n",
       "              tensor([0.9976, 0.9982, 0.7829, 0.9369, 1.0097, 0.9289, 0.9347, 0.9270, 0.9270,\n",
       "                      0.9931, 1.1067, 0.9074, 0.8080, 1.0625, 1.0513, 1.0937, 1.0308, 0.9570,\n",
       "                      0.9114, 1.0577, 0.9804, 0.9650, 1.0450, 0.9841, 0.9373, 0.9694, 0.9245,\n",
       "                      0.9628, 0.9976, 0.9646, 0.9843, 0.8325], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.bias',\n",
       "              tensor([-0.2737, -0.2628, -0.2565, -0.1178, -0.3913, -0.3105, -0.4429, -0.2228,\n",
       "                      -0.1433, -0.2727,  0.1562, -0.1603, -0.0365, -0.1738, -0.4016, -0.0843,\n",
       "                      -0.1355, -0.1944, -0.2513, -0.2896, -0.2841, -0.3642, -0.2824, -0.3106,\n",
       "                      -0.3247, -0.2935, -0.2592, -0.2417, -0.2410, -0.2214, -0.4076, -0.1018],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.running_mean',\n",
       "              tensor([ 0.0032,  0.0169, -0.0858,  0.2632,  0.1325,  0.0287, -0.0619, -0.3325,\n",
       "                      -0.2113, -0.2125, -0.1223, -0.0481,  0.1208, -0.0814, -0.1147, -0.2953,\n",
       "                       0.0863, -0.1226,  0.4124, -0.0100, -0.1940, -0.2539, -0.1525, -0.0364,\n",
       "                       0.0439,  0.1527, -0.0145, -0.1963, -0.1172, -0.4066, -0.3007,  0.2109],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.running_var',\n",
       "              tensor([0.6309, 0.1830, 0.2165, 0.1778, 0.3800, 0.1173, 0.5607, 0.1972, 0.2804,\n",
       "                      0.4059, 0.3082, 0.2399, 0.1331, 0.7438, 0.7136, 0.3105, 0.6643, 0.1390,\n",
       "                      0.7233, 1.0506, 0.4647, 0.3133, 0.5862, 0.4698, 0.5117, 0.5884, 0.2049,\n",
       "                      0.1572, 0.3424, 0.2971, 0.2159, 0.8669], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.2.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.4.original.weight',\n",
       "              tensor([[[[ 0.0043, -0.0040, -0.0336],\n",
       "                        [ 0.0148, -0.0473,  0.0197],\n",
       "                        [ 0.0236, -0.0172, -0.0373]],\n",
       "              \n",
       "                       [[-0.0386,  0.0167, -0.0451],\n",
       "                        [-0.0357, -0.0020, -0.0082],\n",
       "                        [-0.0520,  0.0417,  0.0526]],\n",
       "              \n",
       "                       [[ 0.0009, -0.0525,  0.0027],\n",
       "                        [ 0.0523,  0.0084, -0.0173],\n",
       "                        [-0.0552, -0.0103, -0.0044]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0193, -0.0120, -0.0237],\n",
       "                        [ 0.0218,  0.0410,  0.0329],\n",
       "                        [-0.0143, -0.0270,  0.0404]],\n",
       "              \n",
       "                       [[ 0.0110, -0.0432, -0.0359],\n",
       "                        [-0.0485, -0.0046, -0.0269],\n",
       "                        [ 0.0227, -0.0200, -0.0395]],\n",
       "              \n",
       "                       [[ 0.0528, -0.0543,  0.0549],\n",
       "                        [-0.0003, -0.0502, -0.0404],\n",
       "                        [-0.0251,  0.0351,  0.0332]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0304,  0.0401, -0.0106],\n",
       "                        [ 0.0179, -0.0436, -0.0125],\n",
       "                        [-0.0395, -0.0564,  0.0558]],\n",
       "              \n",
       "                       [[ 0.0467,  0.0379,  0.0054],\n",
       "                        [-0.0020,  0.0476, -0.0272],\n",
       "                        [ 0.0075,  0.0236,  0.0300]],\n",
       "              \n",
       "                       [[-0.0367, -0.0067, -0.0377],\n",
       "                        [ 0.0213,  0.0428,  0.0453],\n",
       "                        [ 0.0162,  0.0009,  0.0063]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0346,  0.0174, -0.0316],\n",
       "                        [ 0.0492, -0.0510, -0.0272],\n",
       "                        [ 0.0295, -0.0071, -0.0486]],\n",
       "              \n",
       "                       [[ 0.0403, -0.0409,  0.0445],\n",
       "                        [ 0.0553,  0.0195, -0.0075],\n",
       "                        [ 0.0476, -0.0539, -0.0462]],\n",
       "              \n",
       "                       [[ 0.0151,  0.0098, -0.0265],\n",
       "                        [ 0.0099, -0.0563,  0.0553],\n",
       "                        [ 0.0494,  0.0560,  0.0329]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0136, -0.0070, -0.0186],\n",
       "                        [ 0.0269, -0.0508, -0.0562],\n",
       "                        [-0.0480,  0.0193, -0.0242]],\n",
       "              \n",
       "                       [[-0.0144,  0.0479, -0.0087],\n",
       "                        [-0.0336, -0.0030, -0.0187],\n",
       "                        [-0.0566, -0.0256, -0.0434]],\n",
       "              \n",
       "                       [[-0.0073,  0.0200,  0.0332],\n",
       "                        [ 0.0110,  0.0569,  0.0245],\n",
       "                        [-0.0579, -0.0544, -0.0574]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0204, -0.0465, -0.0005],\n",
       "                        [ 0.0282, -0.0091,  0.0239],\n",
       "                        [-0.0083,  0.0112, -0.0275]],\n",
       "              \n",
       "                       [[ 0.0530, -0.0475, -0.0197],\n",
       "                        [ 0.0225, -0.0294,  0.0049],\n",
       "                        [ 0.0176, -0.0310, -0.0032]],\n",
       "              \n",
       "                       [[ 0.0499, -0.0271, -0.0439],\n",
       "                        [ 0.0333, -0.0560,  0.0213],\n",
       "                        [-0.0279, -0.0358, -0.0579]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0371, -0.0068, -0.0226],\n",
       "                        [-0.0318,  0.0232, -0.0306],\n",
       "                        [-0.0508, -0.0130,  0.0569]],\n",
       "              \n",
       "                       [[-0.0283, -0.0452,  0.0155],\n",
       "                        [ 0.0057,  0.0197, -0.0370],\n",
       "                        [ 0.0172,  0.0043, -0.0049]],\n",
       "              \n",
       "                       [[ 0.0223,  0.0057,  0.0282],\n",
       "                        [ 0.0316, -0.0283, -0.0196],\n",
       "                        [-0.0182,  0.0289,  0.0445]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0523, -0.0226,  0.0374],\n",
       "                        [ 0.0276,  0.0511, -0.0514],\n",
       "                        [ 0.0267, -0.0219,  0.0314]],\n",
       "              \n",
       "                       [[-0.0391,  0.0485, -0.0211],\n",
       "                        [ 0.0296, -0.0489, -0.0327],\n",
       "                        [ 0.0149,  0.0215, -0.0486]],\n",
       "              \n",
       "                       [[ 0.0567, -0.0076,  0.0471],\n",
       "                        [ 0.0526,  0.0531,  0.0174],\n",
       "                        [ 0.0485,  0.0062,  0.0129]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0081, -0.0243,  0.0030],\n",
       "                        [ 0.0053,  0.0172, -0.0167],\n",
       "                        [ 0.0300,  0.0077,  0.0355]],\n",
       "              \n",
       "                       [[ 0.0161, -0.0105, -0.0111],\n",
       "                        [-0.0150, -0.0437, -0.0264],\n",
       "                        [-0.0426,  0.0100, -0.0311]],\n",
       "              \n",
       "                       [[ 0.0458, -0.0571,  0.0565],\n",
       "                        [-0.0095,  0.0395,  0.0392],\n",
       "                        [ 0.0293,  0.0235,  0.0019]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0113, -0.0069, -0.0142],\n",
       "                        [ 0.0511,  0.0497, -0.0105],\n",
       "                        [ 0.0446,  0.0402, -0.0086]],\n",
       "              \n",
       "                       [[ 0.0472, -0.0264,  0.0271],\n",
       "                        [ 0.0100, -0.0508, -0.0066],\n",
       "                        [ 0.0397, -0.0024, -0.0194]],\n",
       "              \n",
       "                       [[-0.0183, -0.0230, -0.0006],\n",
       "                        [-0.0273,  0.0153,  0.0271],\n",
       "                        [ 0.0269, -0.0525,  0.0216]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0023,  0.0353, -0.0407],\n",
       "                        [ 0.0189, -0.0107,  0.0263],\n",
       "                        [ 0.0104,  0.0474,  0.0548]],\n",
       "              \n",
       "                       [[ 0.0242,  0.0493,  0.0377],\n",
       "                        [-0.0003, -0.0506, -0.0442],\n",
       "                        [ 0.0504,  0.0286,  0.0544]],\n",
       "              \n",
       "                       [[ 0.0133, -0.0184, -0.0541],\n",
       "                        [ 0.0402,  0.0244,  0.0008],\n",
       "                        [-0.0160,  0.0209,  0.0344]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0237,  0.0204,  0.0324],\n",
       "                        [ 0.0526,  0.0038, -0.0298],\n",
       "                        [ 0.0558, -0.0132,  0.0110]],\n",
       "              \n",
       "                       [[-0.0111, -0.0432, -0.0355],\n",
       "                        [ 0.0536, -0.0534,  0.0293],\n",
       "                        [ 0.0345,  0.0281,  0.0061]],\n",
       "              \n",
       "                       [[-0.0517, -0.0225,  0.0149],\n",
       "                        [ 0.0377,  0.0283,  0.0239],\n",
       "                        [-0.0075, -0.0543,  0.0182]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.4.original.bias',\n",
       "              tensor([-0.0404,  0.0170, -0.0257,  0.0125, -0.0555, -0.0526, -0.0157,  0.0022,\n",
       "                       0.0013, -0.0411, -0.0432,  0.0068, -0.0440,  0.0370, -0.0564, -0.0075,\n",
       "                       0.0479,  0.0282, -0.0208, -0.0100, -0.0288,  0.0402,  0.0200, -0.0192,\n",
       "                      -0.0326, -0.0451,  0.0545, -0.0202,  0.0544, -0.0400,  0.0278, -0.0363],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-0.2013]],\n",
       "              \n",
       "                       [[-0.0732]],\n",
       "              \n",
       "                       [[-0.0394]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1146]],\n",
       "              \n",
       "                       [[-0.0508]],\n",
       "              \n",
       "                       [[-0.0687]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0272]],\n",
       "              \n",
       "                       [[-0.0579]],\n",
       "              \n",
       "                       [[ 0.0429]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0822]],\n",
       "              \n",
       "                       [[ 0.0419]],\n",
       "              \n",
       "                       [[ 0.0902]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0288]],\n",
       "              \n",
       "                       [[-0.0657]],\n",
       "              \n",
       "                       [[-0.0757]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0038]],\n",
       "              \n",
       "                       [[ 0.0303]],\n",
       "              \n",
       "                       [[-0.0454]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.1290]],\n",
       "              \n",
       "                       [[ 0.0530]],\n",
       "              \n",
       "                       [[ 0.0532]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1437]],\n",
       "              \n",
       "                       [[-0.0675]],\n",
       "              \n",
       "                       [[ 0.1280]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0269]],\n",
       "              \n",
       "                       [[ 0.0167]],\n",
       "              \n",
       "                       [[ 0.0023]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0105]],\n",
       "              \n",
       "                       [[ 0.0129]],\n",
       "              \n",
       "                       [[-0.0105]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0758]],\n",
       "              \n",
       "                       [[-0.0459]],\n",
       "              \n",
       "                       [[-0.0446]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0237]],\n",
       "              \n",
       "                       [[-0.0063]],\n",
       "              \n",
       "                       [[-0.0345]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.0316]],\n",
       "              \n",
       "                       [[-0.0473]],\n",
       "              \n",
       "                       [[-0.0131]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1051]],\n",
       "              \n",
       "                       [[ 0.0110]],\n",
       "              \n",
       "                       [[-0.0166]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1689]],\n",
       "              \n",
       "                       [[-0.0460]],\n",
       "              \n",
       "                       [[ 0.0085]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0380]],\n",
       "              \n",
       "                       [[-0.0167]],\n",
       "              \n",
       "                       [[ 0.0685]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0446]],\n",
       "              \n",
       "                       [[ 0.0401]],\n",
       "              \n",
       "                       [[ 0.0372]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1434]],\n",
       "              \n",
       "                       [[-0.0160]],\n",
       "              \n",
       "                       [[-0.0421]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0655]],\n",
       "              \n",
       "                       [[-0.0314]],\n",
       "              \n",
       "                       [[ 0.0178]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1225]],\n",
       "              \n",
       "                       [[-0.0298]],\n",
       "              \n",
       "                       [[ 0.0007]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0847]],\n",
       "              \n",
       "                       [[ 0.0090]],\n",
       "              \n",
       "                       [[ 0.0405]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0888]],\n",
       "              \n",
       "                       [[-0.0015]],\n",
       "              \n",
       "                       [[-0.0741]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1339]],\n",
       "              \n",
       "                       [[-0.0948]],\n",
       "              \n",
       "                       [[-0.0128]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0503]],\n",
       "              \n",
       "                       [[ 0.0118]],\n",
       "              \n",
       "                       [[ 0.1900]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.weight',\n",
       "              tensor([0.9582, 0.9958, 0.9362, 1.0709, 1.1220, 1.0453, 0.9592, 1.0156, 1.0295,\n",
       "                      0.9675, 1.0132, 0.9926, 0.9858, 0.9792, 1.0658, 1.0114, 0.9963, 1.0673,\n",
       "                      1.0578, 1.0882, 0.9917, 1.0441, 1.0200, 1.0210, 1.0624, 1.0150, 1.0154,\n",
       "                      0.9520, 0.9894, 1.0523, 0.8768, 0.9767], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.bias',\n",
       "              tensor([ 0.0205, -0.1797, -0.1316,  0.0248, -0.0076, -0.1178, -0.1601, -0.1660,\n",
       "                      -0.1558, -0.1763, -0.2130,  0.0301, -0.0604, -0.0774, -0.1052,  0.0106,\n",
       "                      -0.1473,  0.0595, -0.1071, -0.0493,  0.0226, -0.2728, -0.2564,  0.0286,\n",
       "                      -0.0311, -0.0524, -0.0493, -0.1468, -0.2396, -0.0657, -0.0578,  0.1355],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.running_mean',\n",
       "              tensor([-0.0460, -0.4522, -0.2402, -0.3761, -0.1880, -0.0181, -0.0093, -0.2206,\n",
       "                      -0.1252, -0.2153, -0.2170,  0.1187,  0.1426,  0.2072, -0.1240, -0.2472,\n",
       "                      -0.0987, -0.1817,  0.1191, -0.1570, -0.2562, -0.1801,  0.0328, -0.3645,\n",
       "                      -0.0663, -0.1554, -0.2320, -0.0376, -0.0474, -0.1199,  0.0027, -0.1574],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.running_var',\n",
       "              tensor([0.5433, 0.3576, 0.1918, 0.4767, 0.5436, 0.1341, 0.2246, 0.1768, 0.6090,\n",
       "                      0.2463, 0.2035, 0.1083, 0.2904, 0.1576, 0.1161, 0.2399, 0.2229, 0.3056,\n",
       "                      0.6716, 0.1440, 0.2732, 0.1602, 0.1057, 0.3002, 0.1720, 0.1245, 0.2847,\n",
       "                      0.1426, 0.1553, 0.2471, 0.2319, 0.1396], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.3.6.num_batches_tracked',\n",
       "              tensor(231368, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.0.original.weight',\n",
       "              tensor([[[[-1.9470e-03,  5.3163e-02,  2.8977e-02],\n",
       "                        [ 3.1710e-02, -3.0833e-02,  4.4052e-02],\n",
       "                        [-2.4877e-02, -2.4929e-03,  1.9134e-02]],\n",
       "              \n",
       "                       [[-9.9955e-03, -4.1365e-02,  3.9505e-02],\n",
       "                        [-5.1833e-02, -1.8024e-02,  1.0134e-02],\n",
       "                        [ 5.5045e-02, -8.9848e-03,  3.8989e-02]],\n",
       "              \n",
       "                       [[ 1.1897e-02,  3.6886e-02,  7.1317e-03],\n",
       "                        [-4.5641e-03,  2.9112e-02, -8.7059e-03],\n",
       "                        [ 4.4762e-02, -2.3664e-02, -3.9175e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5648e-02, -1.6411e-02,  4.6867e-02],\n",
       "                        [ 4.7375e-02, -4.7902e-02, -3.1389e-03],\n",
       "                        [-1.5284e-02,  4.2869e-02, -3.8145e-02]],\n",
       "              \n",
       "                       [[ 3.5236e-02, -5.6156e-02,  3.9419e-02],\n",
       "                        [ 5.0258e-02, -2.1676e-02, -3.6642e-02],\n",
       "                        [-3.1214e-02,  5.5292e-02,  5.2685e-03]],\n",
       "              \n",
       "                       [[ 1.3663e-02,  4.5897e-02, -5.2374e-02],\n",
       "                        [ 3.9617e-02, -4.1875e-02,  3.3458e-02],\n",
       "                        [ 7.0674e-04, -3.8848e-02,  5.7728e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4878e-02,  2.8564e-02,  1.0109e-02],\n",
       "                        [ 1.2157e-02,  2.7393e-02, -4.2419e-02],\n",
       "                        [ 7.0532e-03,  3.7441e-02, -4.5260e-02]],\n",
       "              \n",
       "                       [[-5.2987e-02,  6.9967e-03, -5.5313e-02],\n",
       "                        [-1.3309e-02, -5.7471e-02, -4.3218e-02],\n",
       "                        [ 3.3373e-03,  4.1452e-02, -1.9792e-02]],\n",
       "              \n",
       "                       [[-2.0345e-02, -1.3575e-03, -1.5886e-02],\n",
       "                        [ 1.1404e-02, -9.5958e-03,  3.7892e-02],\n",
       "                        [-3.1053e-02,  4.9568e-02, -5.2646e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0416e-02, -3.7466e-02, -5.1478e-02],\n",
       "                        [ 2.9491e-02,  9.4521e-03, -1.9542e-02],\n",
       "                        [ 2.5559e-02, -5.7616e-02,  1.4104e-03]],\n",
       "              \n",
       "                       [[-3.1824e-02, -5.8450e-06, -4.5201e-02],\n",
       "                        [ 1.8326e-02,  4.3478e-03,  5.2395e-02],\n",
       "                        [-2.7495e-02,  7.7698e-03, -4.4875e-02]],\n",
       "              \n",
       "                       [[ 3.4698e-02, -5.7911e-02,  1.0991e-02],\n",
       "                        [ 3.7885e-02, -2.9425e-02, -2.5638e-02],\n",
       "                        [ 1.1281e-03,  1.6944e-02, -5.6787e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4778e-02, -6.9237e-03,  3.1375e-02],\n",
       "                        [ 5.8161e-02,  3.2075e-02, -2.8062e-02],\n",
       "                        [-2.2419e-02, -5.0626e-02, -3.5877e-02]],\n",
       "              \n",
       "                       [[ 1.7296e-02,  5.1880e-02, -6.4204e-03],\n",
       "                        [ 5.1569e-02, -2.8681e-02,  2.6556e-02],\n",
       "                        [-5.5275e-02,  7.6281e-03, -5.3473e-03]],\n",
       "              \n",
       "                       [[ 9.1566e-04,  3.2297e-02,  5.2085e-03],\n",
       "                        [ 2.6599e-03, -5.2116e-02, -2.3369e-02],\n",
       "                        [ 9.1995e-03, -3.5879e-02,  2.5556e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.0984e-02, -3.0586e-02,  1.3761e-02],\n",
       "                        [ 5.8654e-02,  3.8361e-02, -3.1609e-02],\n",
       "                        [ 7.1132e-03, -4.2692e-02,  1.9398e-03]],\n",
       "              \n",
       "                       [[ 5.7449e-02, -2.0609e-02, -3.7413e-02],\n",
       "                        [ 3.9289e-02,  4.5868e-02, -1.4679e-02],\n",
       "                        [ 2.1835e-02,  3.7654e-02, -2.3596e-02]],\n",
       "              \n",
       "                       [[ 6.4708e-04,  5.1952e-02, -8.7980e-03],\n",
       "                        [-4.2758e-02,  3.8696e-02, -1.2486e-02],\n",
       "                        [-4.3535e-02, -2.6859e-02, -4.0888e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8703e-02, -4.5961e-02, -3.8632e-02],\n",
       "                        [-4.0833e-03,  2.1234e-02, -1.6818e-02],\n",
       "                        [ 2.6032e-02, -5.1953e-02,  1.6078e-02]],\n",
       "              \n",
       "                       [[ 4.9231e-02,  1.3032e-02,  4.3237e-02],\n",
       "                        [-3.9061e-02,  4.8711e-02,  5.1038e-03],\n",
       "                        [-4.0904e-02, -4.1115e-02, -3.1583e-02]],\n",
       "              \n",
       "                       [[-4.8132e-03,  1.2002e-03,  1.0364e-02],\n",
       "                        [-3.6997e-02,  1.9856e-02, -4.6781e-03],\n",
       "                        [-1.1971e-02, -3.6891e-03,  4.9297e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.8159e-02,  3.5908e-02,  1.4939e-02],\n",
       "                        [-2.9288e-02, -4.7313e-02, -2.2152e-02],\n",
       "                        [-5.0100e-02,  4.4756e-02,  3.9485e-02]],\n",
       "              \n",
       "                       [[ 2.7564e-02,  3.0946e-02,  1.7802e-02],\n",
       "                        [-4.6763e-02, -2.5299e-02, -1.7436e-02],\n",
       "                        [-2.0969e-02,  4.5338e-02, -4.0771e-02]],\n",
       "              \n",
       "                       [[-4.7586e-02, -5.2237e-02,  3.5978e-03],\n",
       "                        [ 2.9921e-02, -3.8876e-02,  3.3479e-02],\n",
       "                        [ 8.5086e-03,  5.7432e-03,  9.3366e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.9572e-03,  2.4797e-02, -4.2754e-03],\n",
       "                        [ 3.1248e-02, -3.8404e-03,  4.4088e-02],\n",
       "                        [ 5.8698e-02, -1.6033e-02,  3.9496e-02]],\n",
       "              \n",
       "                       [[ 5.0394e-02, -7.5146e-03,  2.3211e-02],\n",
       "                        [-4.8096e-02, -3.0818e-02, -1.0730e-02],\n",
       "                        [ 4.9121e-02,  2.9197e-02, -5.3798e-02]],\n",
       "              \n",
       "                       [[ 1.2863e-03, -3.1358e-02,  9.8385e-03],\n",
       "                        [ 2.8861e-02,  4.2651e-02,  2.7799e-02],\n",
       "                        [-5.0533e-02,  2.4406e-02, -2.6508e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.0616e-04,  6.8771e-03, -1.0522e-02],\n",
       "                        [ 1.4064e-03, -1.3917e-02, -1.5401e-02],\n",
       "                        [-4.8726e-02, -4.7092e-02,  4.5690e-02]],\n",
       "              \n",
       "                       [[-2.1634e-02, -1.6634e-02,  3.4795e-04],\n",
       "                        [-2.3486e-02, -7.3030e-03, -1.9565e-02],\n",
       "                        [-3.3583e-03, -3.8276e-02,  7.5001e-03]],\n",
       "              \n",
       "                       [[ 2.8177e-02,  5.3894e-02,  3.3712e-02],\n",
       "                        [-4.0338e-02, -2.9827e-02, -5.0618e-02],\n",
       "                        [-1.6005e-02, -4.0207e-02,  5.4201e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4477e-03,  2.0325e-02,  2.1487e-02],\n",
       "                        [-5.2469e-02, -2.7806e-02, -5.4960e-02],\n",
       "                        [-1.9466e-02, -3.4146e-02,  2.6203e-02]],\n",
       "              \n",
       "                       [[-3.5770e-02, -5.4651e-02, -1.0921e-02],\n",
       "                        [-3.2557e-02, -2.4368e-02, -2.1397e-02],\n",
       "                        [ 7.0530e-03,  3.8575e-02,  2.0831e-02]],\n",
       "              \n",
       "                       [[-5.7956e-03,  1.7585e-02, -1.6625e-02],\n",
       "                        [ 6.0791e-03,  2.6158e-04,  3.3333e-03],\n",
       "                        [-4.7674e-02, -5.5400e-02, -9.1633e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.1868e-02,  2.6820e-02, -6.5004e-03],\n",
       "                        [ 3.9689e-02,  9.6638e-03,  4.7643e-02],\n",
       "                        [-5.0082e-03, -3.7882e-03, -3.5668e-02]],\n",
       "              \n",
       "                       [[-2.3686e-02, -1.8771e-02,  4.3066e-03],\n",
       "                        [-3.0142e-02, -1.9072e-03,  2.3350e-02],\n",
       "                        [-3.3365e-02, -4.7118e-04,  1.5152e-02]],\n",
       "              \n",
       "                       [[ 2.9114e-02, -1.9400e-02,  9.9738e-03],\n",
       "                        [-2.2314e-02, -2.7034e-02, -1.8504e-02],\n",
       "                        [-4.3680e-02,  2.2176e-02,  5.2239e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.0.original.bias',\n",
       "              tensor([-0.0521,  0.0022,  0.0538, -0.0278, -0.0084,  0.0097,  0.0471,  0.0199,\n",
       "                       0.0389,  0.0380, -0.0407, -0.0292,  0.0261, -0.0013,  0.0432,  0.0040,\n",
       "                      -0.0066, -0.0071, -0.0507, -0.0346, -0.0543, -0.0154,  0.0430, -0.0493,\n",
       "                       0.0335, -0.0345,  0.0305,  0.0123, -0.0099, -0.0141,  0.0186,  0.0107],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.0.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[ 1.7399e-02]],\n",
       "              \n",
       "                       [[ 7.2052e-03]],\n",
       "              \n",
       "                       [[-4.3838e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.8361e-03]],\n",
       "              \n",
       "                       [[ 2.3901e-02]],\n",
       "              \n",
       "                       [[ 1.0433e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.1205e-03]],\n",
       "              \n",
       "                       [[ 4.0984e-02]],\n",
       "              \n",
       "                       [[ 2.7428e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5849e-03]],\n",
       "              \n",
       "                       [[-5.7653e-02]],\n",
       "              \n",
       "                       [[ 6.5577e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7195e-02]],\n",
       "              \n",
       "                       [[-2.4234e-02]],\n",
       "              \n",
       "                       [[-1.1284e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.0594e-02]],\n",
       "              \n",
       "                       [[ 1.0865e-02]],\n",
       "              \n",
       "                       [[ 9.4836e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 7.8288e-02]],\n",
       "              \n",
       "                       [[-2.2642e-02]],\n",
       "              \n",
       "                       [[-6.5730e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.5937e-03]],\n",
       "              \n",
       "                       [[-7.2412e-02]],\n",
       "              \n",
       "                       [[ 6.1925e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7648e-03]],\n",
       "              \n",
       "                       [[ 3.8509e-02]],\n",
       "              \n",
       "                       [[-1.0312e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.7221e-01]],\n",
       "              \n",
       "                       [[-2.1714e-01]],\n",
       "              \n",
       "                       [[-3.6125e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4607e-02]],\n",
       "              \n",
       "                       [[ 7.0329e-05]],\n",
       "              \n",
       "                       [[-5.2880e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.9036e-03]],\n",
       "              \n",
       "                       [[ 1.3296e-02]],\n",
       "              \n",
       "                       [[-6.3706e-02]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.0.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[-0.0626]],\n",
       "              \n",
       "                       [[ 0.0336]],\n",
       "              \n",
       "                       [[ 0.1738]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0675]],\n",
       "              \n",
       "                       [[ 0.0480]],\n",
       "              \n",
       "                       [[-0.0058]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0324]],\n",
       "              \n",
       "                       [[-0.0300]],\n",
       "              \n",
       "                       [[ 0.1015]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0633]],\n",
       "              \n",
       "                       [[-0.0585]],\n",
       "              \n",
       "                       [[ 0.0438]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0373]],\n",
       "              \n",
       "                       [[ 0.0702]],\n",
       "              \n",
       "                       [[-0.0009]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0800]],\n",
       "              \n",
       "                       [[ 0.0749]],\n",
       "              \n",
       "                       [[-0.0143]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0103]],\n",
       "              \n",
       "                       [[ 0.0273]],\n",
       "              \n",
       "                       [[-0.1444]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0284]],\n",
       "              \n",
       "                       [[ 0.0422]],\n",
       "              \n",
       "                       [[ 0.0459]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0886]],\n",
       "              \n",
       "                       [[-0.0330]],\n",
       "              \n",
       "                       [[-0.0615]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1237]],\n",
       "              \n",
       "                       [[ 0.1997]],\n",
       "              \n",
       "                       [[ 0.0420]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0378]],\n",
       "              \n",
       "                       [[-0.0366]],\n",
       "              \n",
       "                       [[ 0.0474]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0683]],\n",
       "              \n",
       "                       [[-0.0068]],\n",
       "              \n",
       "                       [[-0.0241]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.weight',\n",
       "              tensor([0.9453, 0.8956, 0.9675, 0.8536, 1.0331, 0.9866, 0.8630, 0.9112, 1.0605,\n",
       "                      1.1232, 1.1283, 0.9429, 0.8716, 0.9758, 0.9941, 1.0772, 0.9792, 1.0126,\n",
       "                      0.9086, 1.0405, 1.0637, 0.9284, 1.0164, 1.0883, 0.9892, 0.9427, 0.9547,\n",
       "                      0.9235, 1.0137, 0.9828, 0.9754, 1.0911], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.bias',\n",
       "              tensor([-0.3943, -0.2570, -0.1644, -0.2119, -0.3531, -0.2765, -0.3575, -0.2470,\n",
       "                      -0.1200, -0.2333, -0.1919, -0.1214, -0.0267, -0.2706, -0.2674, -0.2011,\n",
       "                      -0.3189, -0.1708, -0.1634, -0.3021, -0.2303, -0.1696, -0.1179, -0.1505,\n",
       "                      -0.1960, -0.1096, -0.1830, -0.2718, -0.0879, -0.0799, -0.2430, -0.2483],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.running_mean',\n",
       "              tensor([-0.4003, -0.3299, -0.0025, -0.3249, -0.2637, -0.4067, -0.4734,  0.2201,\n",
       "                      -0.3866, -0.1888, -0.3196, -0.0017,  0.0362, -0.1177, -0.4600, -0.3323,\n",
       "                      -0.2863, -0.2930, -0.2065, -0.4338, -0.4512, -0.1187, -0.1793, -0.4265,\n",
       "                      -0.3314, -0.2127, -0.3760, -0.3760, -0.2719,  0.0431, -0.3772, -0.4690],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.running_var',\n",
       "              tensor([0.3974, 0.6857, 0.2073, 0.7533, 0.6869, 0.5903, 0.8243, 1.2501, 0.7246,\n",
       "                      0.7550, 0.4399, 0.8233, 0.5689, 1.0520, 0.5586, 0.2261, 0.6820, 0.4993,\n",
       "                      0.3150, 0.3357, 0.9107, 0.3417, 0.3448, 0.8113, 0.8249, 0.5821, 0.6058,\n",
       "                      0.3974, 0.8816, 0.5658, 1.0337, 0.4408], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.2.num_batches_tracked',\n",
       "              tensor(231215, device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.4.original.weight',\n",
       "              tensor([[[[ 5.5057e-02,  1.0020e-03, -5.3069e-02],\n",
       "                        [ 2.2962e-02,  5.4711e-02, -5.5751e-02],\n",
       "                        [-2.5863e-02,  4.8709e-02,  3.1115e-02]],\n",
       "              \n",
       "                       [[-3.8575e-02,  4.6954e-02, -2.7934e-02],\n",
       "                        [-3.3603e-02,  1.8553e-02,  3.4508e-04],\n",
       "                        [ 3.7186e-02, -4.5227e-02, -2.2577e-02]],\n",
       "              \n",
       "                       [[-3.0329e-02,  1.7590e-02, -1.6223e-02],\n",
       "                        [-2.2077e-02,  5.1657e-02, -2.2189e-02],\n",
       "                        [-4.4397e-02, -2.0414e-02,  1.6604e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.1096e-02, -4.7887e-02, -3.3026e-02],\n",
       "                        [ 4.4423e-02,  2.3592e-02,  2.9180e-02],\n",
       "                        [ 5.1116e-02, -3.1916e-02,  1.0890e-02]],\n",
       "              \n",
       "                       [[-5.4257e-02, -2.5764e-02, -2.1845e-02],\n",
       "                        [-8.9662e-03, -2.2859e-02, -1.9789e-03],\n",
       "                        [ 2.8713e-02,  2.3153e-02, -3.8147e-02]],\n",
       "              \n",
       "                       [[-2.5700e-03,  2.9608e-02,  3.4795e-02],\n",
       "                        [-3.1727e-02,  4.1719e-02, -8.9484e-03],\n",
       "                        [ 1.7765e-02, -3.7870e-02,  3.0859e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.0616e-02,  4.2195e-02, -8.9989e-04],\n",
       "                        [-4.4405e-02, -7.5867e-03,  4.2507e-02],\n",
       "                        [ 4.0809e-02, -2.9271e-02,  5.8214e-02]],\n",
       "              \n",
       "                       [[-5.5219e-02, -3.9951e-03,  1.7955e-03],\n",
       "                        [ 4.9014e-02,  1.5546e-02,  1.2869e-02],\n",
       "                        [ 1.5569e-02, -1.3117e-02, -4.4682e-02]],\n",
       "              \n",
       "                       [[-3.7497e-03, -3.2830e-03,  2.5257e-02],\n",
       "                        [-3.4769e-02,  3.9417e-04, -3.1093e-02],\n",
       "                        [ 1.9086e-02,  2.1307e-02, -5.8297e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.1363e-02, -4.1838e-02,  5.2978e-04],\n",
       "                        [ 1.9177e-02, -4.0227e-02,  1.6830e-02],\n",
       "                        [ 4.4178e-02, -3.3207e-02, -1.9655e-03]],\n",
       "              \n",
       "                       [[ 3.5874e-02,  3.7301e-02,  2.0425e-02],\n",
       "                        [ 3.3543e-02,  1.0273e-02,  5.0876e-02],\n",
       "                        [-3.4464e-02,  7.8506e-03,  5.6910e-02]],\n",
       "              \n",
       "                       [[ 3.3254e-02, -5.8685e-02,  9.2760e-05],\n",
       "                        [ 5.2730e-02, -2.2779e-02, -1.6383e-02],\n",
       "                        [-4.8188e-02, -1.5514e-04, -5.2924e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2914e-02, -5.6244e-02, -5.3816e-02],\n",
       "                        [ 2.1250e-02, -7.8339e-03,  5.7500e-02],\n",
       "                        [-3.6775e-02, -1.6391e-03, -2.7185e-02]],\n",
       "              \n",
       "                       [[ 2.4215e-02, -1.5833e-02, -1.4779e-03],\n",
       "                        [ 5.2834e-02, -2.6279e-02, -2.7361e-03],\n",
       "                        [ 5.1185e-02, -1.9227e-02, -1.4249e-02]],\n",
       "              \n",
       "                       [[ 1.0917e-02, -9.5450e-04, -3.8261e-02],\n",
       "                        [-2.5333e-02, -5.0212e-02, -1.5785e-02],\n",
       "                        [ 3.2765e-02,  3.1697e-02,  5.2985e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.6150e-02, -5.7729e-03, -7.3448e-03],\n",
       "                        [ 6.3362e-03, -3.2480e-02,  1.0269e-03],\n",
       "                        [ 4.4210e-02,  5.6836e-02,  4.7610e-02]],\n",
       "              \n",
       "                       [[ 2.8942e-02, -1.5078e-03, -2.9251e-02],\n",
       "                        [ 3.9022e-02, -4.7208e-02,  1.4219e-02],\n",
       "                        [-4.4593e-02, -1.9909e-02, -4.5022e-02]],\n",
       "              \n",
       "                       [[ 1.3759e-02, -1.0797e-02,  4.0133e-02],\n",
       "                        [-1.1351e-02, -3.4520e-02,  3.1890e-02],\n",
       "                        [-5.7872e-02,  4.9425e-02,  2.1504e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7560e-02, -1.7005e-02,  3.5921e-02],\n",
       "                        [ 7.7148e-03, -1.5877e-02,  5.3129e-02],\n",
       "                        [-2.8353e-02, -5.2387e-02, -1.1028e-03]],\n",
       "              \n",
       "                       [[ 3.8464e-03, -1.0150e-02, -3.3926e-02],\n",
       "                        [-4.8020e-02, -3.2464e-02,  4.0836e-02],\n",
       "                        [ 4.4621e-02,  2.3065e-02, -3.6983e-02]],\n",
       "              \n",
       "                       [[ 7.7679e-03, -5.1881e-02,  4.2674e-02],\n",
       "                        [ 5.5924e-02, -1.6619e-02, -2.2332e-02],\n",
       "                        [ 1.2269e-02, -5.0492e-03,  3.1909e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.0453e-02,  2.3582e-02, -4.2736e-02],\n",
       "                        [-2.9101e-02,  1.1858e-02, -3.4374e-02],\n",
       "                        [ 9.9184e-03, -2.6569e-02, -4.6135e-02]],\n",
       "              \n",
       "                       [[-6.5239e-03,  2.6402e-02, -2.6674e-02],\n",
       "                        [-3.1708e-02, -3.5945e-02,  4.6931e-02],\n",
       "                        [ 2.7551e-02, -3.3608e-02, -3.0132e-02]],\n",
       "              \n",
       "                       [[ 3.0676e-02, -2.6875e-02, -4.8777e-02],\n",
       "                        [-3.4659e-02,  2.7334e-02,  9.3209e-03],\n",
       "                        [-5.5218e-02, -4.1750e-02, -1.2141e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3229e-03,  1.2844e-03, -5.2147e-02],\n",
       "                        [ 1.0473e-02,  2.8069e-02,  2.2598e-02],\n",
       "                        [-4.9096e-02, -4.4999e-02, -1.3540e-02]],\n",
       "              \n",
       "                       [[-4.1097e-02,  2.5775e-04,  3.8834e-02],\n",
       "                        [ 1.2081e-03,  1.5490e-02,  4.4344e-02],\n",
       "                        [ 4.2413e-02,  2.8368e-02, -4.8052e-02]],\n",
       "              \n",
       "                       [[-5.5442e-02,  4.8058e-02, -2.8782e-02],\n",
       "                        [ 4.0299e-02, -2.6157e-03, -4.2243e-03],\n",
       "                        [ 3.0623e-02, -5.0516e-03, -2.9337e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.9641e-02,  4.4306e-02, -5.2346e-02],\n",
       "                        [ 2.4182e-03,  3.4783e-02, -5.7171e-02],\n",
       "                        [-3.8742e-02,  4.1094e-02,  2.4344e-02]],\n",
       "              \n",
       "                       [[ 4.7281e-02,  2.8850e-02,  2.2860e-02],\n",
       "                        [ 3.5052e-02, -5.4328e-03,  1.1515e-02],\n",
       "                        [-1.3174e-02,  4.0750e-02,  1.5492e-02]],\n",
       "              \n",
       "                       [[ 4.5466e-02, -8.2191e-03, -3.9038e-02],\n",
       "                        [-4.2079e-02,  3.9576e-02,  1.9629e-02],\n",
       "                        [ 3.4291e-02,  3.3420e-02, -1.1163e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.0328e-03,  1.1123e-02,  1.4767e-02],\n",
       "                        [-3.7769e-02, -6.9897e-03, -2.1603e-02],\n",
       "                        [-1.6568e-02, -4.4239e-02, -2.1405e-02]],\n",
       "              \n",
       "                       [[ 2.2313e-02, -2.0821e-02, -3.1610e-02],\n",
       "                        [ 2.1211e-02,  1.4493e-02, -5.0445e-02],\n",
       "                        [ 4.9898e-02,  5.2242e-02, -2.5109e-02]],\n",
       "              \n",
       "                       [[-1.3531e-02,  1.3099e-02,  8.2086e-04],\n",
       "                        [ 1.2422e-02, -2.5890e-02,  3.7083e-02],\n",
       "                        [ 7.0021e-03,  4.2413e-02, -1.4582e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.9682e-03,  3.9432e-02,  5.0660e-02],\n",
       "                        [-4.4608e-02, -1.4544e-02,  2.7129e-02],\n",
       "                        [ 4.4130e-02, -1.6556e-02, -4.5247e-02]],\n",
       "              \n",
       "                       [[ 4.9869e-02,  5.1529e-02,  9.9915e-03],\n",
       "                        [ 3.9543e-02,  6.9448e-03,  3.6584e-03],\n",
       "                        [-1.5280e-02,  1.4700e-02, -2.2916e-02]],\n",
       "              \n",
       "                       [[ 5.0161e-04, -2.4591e-02, -2.3048e-02],\n",
       "                        [-1.0146e-02, -4.7465e-02, -3.8384e-02],\n",
       "                        [-5.7934e-02,  4.5933e-02,  7.7088e-03]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.4.original.bias',\n",
       "              tensor([-0.0131,  0.0044,  0.0415, -0.0342, -0.0567,  0.0291,  0.0420, -0.0138,\n",
       "                      -0.0264,  0.0530,  0.0286, -0.0259, -0.0339,  0.0125,  0.0029, -0.0560,\n",
       "                       0.0083, -0.0093, -0.0031, -0.0407,  0.0494,  0.0367, -0.0474,  0.0559,\n",
       "                       0.0226, -0.0176,  0.0005,  0.0182,  0.0250,  0.0204, -0.0431,  0.0092],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.4.lora_apl_v1_conv2d_lora_A.weight',\n",
       "              tensor([[[[-0.0104]],\n",
       "              \n",
       "                       [[-0.0088]],\n",
       "              \n",
       "                       [[-0.0121]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0174]],\n",
       "              \n",
       "                       [[-0.0584]],\n",
       "              \n",
       "                       [[-0.0786]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0082]],\n",
       "              \n",
       "                       [[ 0.0479]],\n",
       "              \n",
       "                       [[-0.0481]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0351]],\n",
       "              \n",
       "                       [[-0.0350]],\n",
       "              \n",
       "                       [[-0.0420]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1562]],\n",
       "              \n",
       "                       [[-0.0197]],\n",
       "              \n",
       "                       [[ 0.0672]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1768]],\n",
       "              \n",
       "                       [[-0.0536]],\n",
       "              \n",
       "                       [[ 0.0039]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1268]],\n",
       "              \n",
       "                       [[ 0.0513]],\n",
       "              \n",
       "                       [[ 0.0455]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0216]],\n",
       "              \n",
       "                       [[ 0.0052]],\n",
       "              \n",
       "                       [[-0.0015]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0250]],\n",
       "              \n",
       "                       [[-0.0075]],\n",
       "              \n",
       "                       [[-0.0109]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0337]],\n",
       "              \n",
       "                       [[ 0.0059]],\n",
       "              \n",
       "                       [[ 0.0152]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1281]],\n",
       "              \n",
       "                       [[-0.0778]],\n",
       "              \n",
       "                       [[-0.0070]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0332]],\n",
       "              \n",
       "                       [[-0.0188]],\n",
       "              \n",
       "                       [[ 0.0827]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.4.lora_apl_v1_conv2d_lora_B.weight',\n",
       "              tensor([[[[ 0.0613]],\n",
       "              \n",
       "                       [[ 0.0043]],\n",
       "              \n",
       "                       [[-0.1060]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0059]],\n",
       "              \n",
       "                       [[ 0.0057]],\n",
       "              \n",
       "                       [[ 0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0434]],\n",
       "              \n",
       "                       [[-0.0305]],\n",
       "              \n",
       "                       [[ 0.0534]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0403]],\n",
       "              \n",
       "                       [[ 0.0127]],\n",
       "              \n",
       "                       [[-0.1252]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1019]],\n",
       "              \n",
       "                       [[-0.0276]],\n",
       "              \n",
       "                       [[ 0.0640]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0868]],\n",
       "              \n",
       "                       [[ 0.0127]],\n",
       "              \n",
       "                       [[-0.1865]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0300]],\n",
       "              \n",
       "                       [[ 0.0465]],\n",
       "              \n",
       "                       [[ 0.1428]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0356]],\n",
       "              \n",
       "                       [[-0.0467]],\n",
       "              \n",
       "                       [[-0.0266]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0182]],\n",
       "              \n",
       "                       [[-0.0274]],\n",
       "              \n",
       "                       [[ 0.0181]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0900]],\n",
       "              \n",
       "                       [[ 0.0207]],\n",
       "              \n",
       "                       [[-0.0351]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1143]],\n",
       "              \n",
       "                       [[ 0.0222]],\n",
       "              \n",
       "                       [[-0.0181]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0888]],\n",
       "              \n",
       "                       [[-0.0367]],\n",
       "              \n",
       "                       [[ 0.0262]]]], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.weight',\n",
       "              tensor([1.8744, 1.8840, 2.0721, 1.8210, 1.9963, 1.9973, 2.0481, 2.0528, 1.8316,\n",
       "                      1.9424, 1.8975, 1.9322, 2.0675, 1.9676, 1.9353, 1.8272, 2.2679, 1.9188,\n",
       "                      2.1717, 1.9546, 1.9991, 1.9596, 1.8475, 1.9886, 1.9425, 1.8574, 1.8879,\n",
       "                      2.0204, 1.8442, 1.8093, 1.9786, 1.9419], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.bias',\n",
       "              tensor([0.4936, 0.5033, 0.6569, 0.4249, 0.7301, 0.4452, 0.5156, 0.6567, 0.4986,\n",
       "                      0.5188, 0.5833, 0.5722, 0.4800, 0.4556, 0.5090, 0.4750, 0.6698, 0.6941,\n",
       "                      0.7459, 0.6077, 0.6315, 0.6126, 0.4794, 0.6112, 0.4907, 0.7054, 0.5258,\n",
       "                      0.6339, 0.4726, 0.4331, 0.5492, 0.6075], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.running_mean',\n",
       "              tensor([-0.1640, -0.0538, -0.0642, -0.0985, -0.0942, -0.0816,  0.0892, -0.0865,\n",
       "                      -0.0229, -0.1600, -0.0979, -0.1991,  0.0093,  0.0502, -0.0673,  0.0655,\n",
       "                      -0.1382,  0.2011,  0.2475, -0.0648, -0.0358,  0.0719, -0.0527, -0.1216,\n",
       "                      -0.1081, -0.1959, -0.0968, -0.0842, -0.1467, -0.2236, -0.0582, -0.0644],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.running_var',\n",
       "              tensor([0.0872, 0.1320, 0.0777, 0.0931, 0.0887, 0.0875, 0.1799, 0.1392, 0.1272,\n",
       "                      0.1370, 0.0973, 0.1431, 0.1257, 0.1434, 0.0868, 0.0862, 0.1245, 0.1728,\n",
       "                      0.3069, 0.0950, 0.1337, 0.1621, 0.1057, 0.1169, 0.1241, 0.1020, 0.1128,\n",
       "                      0.1904, 0.1136, 0.0853, 0.1062, 0.0965], device='cuda:0')),\n",
       "             ('encoder_conv_blocks.4.6.num_batches_tracked',\n",
       "              tensor(231215, device='cuda:0')),\n",
       "             ('fully_connected_blocks.0.0.lora_apl_v1_linear_lora_A',\n",
       "              tensor([[ 0.0934, -0.0967,  0.0898,  ..., -0.0777, -0.0227,  0.1726],\n",
       "                      [-0.0589,  0.2438, -0.1656,  ...,  0.2962,  0.0455, -0.2932],\n",
       "                      [-0.0646,  0.0273, -0.1994,  ...,  0.0093, -0.1441, -0.1067],\n",
       "                      ...,\n",
       "                      [ 0.1174,  0.0143,  0.0727,  ...,  0.0048,  0.1466, -0.0295],\n",
       "                      [ 0.0841, -0.0111,  0.0715,  ...,  0.0254, -0.0206, -0.1193],\n",
       "                      [ 0.0801, -0.0837, -0.0309,  ...,  0.0092, -0.0316,  0.1020]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.0.0.lora_apl_v1_linear_lora_B',\n",
       "              tensor([[-0.0494, -0.0358,  0.1683,  ..., -0.0434, -0.2268,  0.1624],\n",
       "                      [-0.0591, -0.0117,  0.1632,  ..., -0.1325, -0.2226,  0.0528],\n",
       "                      [ 0.1944, -0.2144, -0.1496,  ...,  0.0017, -0.0685, -0.2353],\n",
       "                      ...,\n",
       "                      [-0.0306, -0.0932,  0.1506,  ..., -0.0898, -0.1198, -0.0114],\n",
       "                      [ 0.1148, -0.1774, -0.0831,  ...,  0.0370,  0.0384,  0.1904],\n",
       "                      [ 0.0835,  0.0604,  0.0004,  ..., -0.0363, -0.1717,  0.1433]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.0.0.original.weight',\n",
       "              tensor([[-0.0841, -0.0469,  0.0778,  ..., -0.0188, -0.0214, -0.0829],\n",
       "                      [-0.0620,  0.0245, -0.0521,  ..., -0.0114,  0.0819, -0.0506],\n",
       "                      [-0.0305, -0.0858,  0.0054,  ...,  0.0301,  0.0157, -0.0449],\n",
       "                      ...,\n",
       "                      [ 0.0456,  0.0716, -0.0777,  ...,  0.0726, -0.0473,  0.0762],\n",
       "                      [-0.0704, -0.0194, -0.0145,  ...,  0.0346, -0.0595, -0.0148],\n",
       "                      [-0.0136,  0.0217, -0.0777,  ..., -0.0141,  0.0812,  0.0807]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.0.0.original.bias',\n",
       "              tensor([ 0.0882, -0.0695,  0.0445,  0.0378,  0.0662,  0.0051, -0.0370, -0.0756,\n",
       "                      -0.0226,  0.0535,  0.0628,  0.0238,  0.0606,  0.0228,  0.0771,  0.0536,\n",
       "                      -0.0576, -0.0748, -0.0741,  0.0083, -0.0194, -0.0251, -0.0787,  0.0753,\n",
       "                       0.0561, -0.0385, -0.0298, -0.0695, -0.0859, -0.0255, -0.0679,  0.0368,\n",
       "                      -0.0772,  0.0150,  0.0346, -0.0674, -0.0406,  0.0108,  0.0869,  0.0426,\n",
       "                      -0.0460,  0.0807, -0.0554,  0.0595,  0.0433,  0.0880, -0.0289,  0.0776,\n",
       "                       0.0079, -0.0640,  0.0877, -0.0310,  0.0305,  0.0096, -0.0729, -0.0816,\n",
       "                       0.0180,  0.0554,  0.0292, -0.0271, -0.0097,  0.0283,  0.0391, -0.0749,\n",
       "                      -0.0321, -0.0646, -0.0563, -0.0445,  0.0526, -0.0431,  0.0539,  0.0871,\n",
       "                      -0.0228, -0.0841,  0.0131, -0.0597, -0.0758,  0.0466, -0.0517,  0.0556,\n",
       "                      -0.0640,  0.0102, -0.0348, -0.0659,  0.0622, -0.0875,  0.0879, -0.0610,\n",
       "                       0.0686, -0.0174,  0.0443,  0.0764, -0.0197, -0.0022, -0.0353, -0.0255,\n",
       "                       0.0293, -0.0592,  0.0517, -0.0843,  0.0623,  0.0210,  0.0814, -0.0063,\n",
       "                      -0.0583,  0.0123,  0.0681, -0.0103,  0.0881,  0.0300, -0.0296, -0.0825,\n",
       "                       0.0100,  0.0588,  0.0668, -0.0173, -0.0228,  0.0401, -0.0408, -0.0884,\n",
       "                      -0.0285, -0.0616, -0.0309,  0.0192,  0.0573, -0.0882,  0.0650, -0.0027],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.1.0.lora_apl_v1_linear_lora_A',\n",
       "              tensor([[-0.0732, -0.0263,  0.1206,  ...,  0.0215,  0.2626, -0.0564],\n",
       "                      [-0.1754,  0.1313, -0.0765,  ...,  0.0935, -0.0838, -0.2180],\n",
       "                      [-0.0281, -0.0794,  0.1095,  ..., -0.0742,  0.2948, -0.2872],\n",
       "                      ...,\n",
       "                      [-0.1243,  0.1911, -0.0617,  ...,  0.0276, -0.0402, -0.2284],\n",
       "                      [-0.0122, -0.1133,  0.2361,  ..., -0.0634,  0.0739, -0.0328],\n",
       "                      [-0.0151,  0.0101, -0.0013,  ...,  0.0594,  0.0424, -0.1841]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.1.0.lora_apl_v1_linear_lora_B',\n",
       "              tensor([[-3.4221e-02, -8.4895e-02,  3.0234e-02,  ..., -1.0110e-01,\n",
       "                       -5.6573e-02, -1.7187e-01],\n",
       "                      [ 8.0814e-03,  1.1622e-01, -5.7952e-03,  ..., -5.6968e-02,\n",
       "                       -1.6821e-01,  2.1802e-01],\n",
       "                      [ 1.1502e-01,  6.1365e-03, -8.0811e-02,  ...,  2.0844e-02,\n",
       "                       -1.8266e-01, -1.1528e-02],\n",
       "                      ...,\n",
       "                      [ 6.8722e-03,  1.2760e-02,  2.6412e-02,  ...,  3.3569e-03,\n",
       "                        2.2414e-03,  6.1040e-03],\n",
       "                      [ 3.5300e-03,  9.5965e-05,  6.7678e-03,  ...,  1.9539e-03,\n",
       "                        4.7535e-03,  2.3841e-03],\n",
       "                      [ 1.1261e-02,  4.9472e-03,  1.6738e-02,  ...,  1.0675e-02,\n",
       "                        2.0964e-03,  6.4690e-03]], device='cuda:0')),\n",
       "             ('fully_connected_blocks.1.0.original.weight',\n",
       "              tensor([[ 0.0046, -0.0063, -0.0247,  ..., -0.0552,  0.0708,  0.0146],\n",
       "                      [ 0.0065,  0.0270,  0.0550,  ..., -0.0754,  0.0871,  0.0691],\n",
       "                      [-0.0061,  0.0635,  0.0864,  ..., -0.0515, -0.0364, -0.0007],\n",
       "                      ...,\n",
       "                      [-0.0846, -0.0531,  0.0708,  ...,  0.0496, -0.0416,  0.0663],\n",
       "                      [-0.0474,  0.0463, -0.0019,  ...,  0.0805, -0.0179,  0.0129],\n",
       "                      [ 0.0875,  0.0103, -0.0772,  ..., -0.0554,  0.0013, -0.0008]],\n",
       "                     device='cuda:0')),\n",
       "             ('fully_connected_blocks.1.0.original.bias',\n",
       "              tensor([ 0.0146,  0.0270, -0.0092, -0.0250, -0.0728,  0.0572,  0.0088, -0.0553,\n",
       "                      -0.0005, -0.0729,  0.0835,  0.0179,  0.0217, -0.0220,  0.0371,  0.0851,\n",
       "                       0.0877,  0.0763, -0.0695, -0.0424, -0.0574,  0.0341, -0.0649, -0.0789,\n",
       "                       0.0399,  0.0087,  0.0378, -0.0389,  0.0313, -0.0455, -0.0625, -0.0140,\n",
       "                       0.0259, -0.0846,  0.0020, -0.0643,  0.0654, -0.0548, -0.0519, -0.0771,\n",
       "                      -0.0021,  0.0369,  0.0618,  0.0561,  0.0541,  0.0012, -0.0554,  0.0199,\n",
       "                       0.0841,  0.0854, -0.0839, -0.0279,  0.0247,  0.0149,  0.0752, -0.0701,\n",
       "                      -0.0838, -0.0206, -0.0746, -0.0614, -0.0684, -0.0353,  0.0081, -0.0540,\n",
       "                      -0.0460,  0.0825, -0.0543, -0.0756, -0.0343, -0.0006,  0.0523,  0.0377,\n",
       "                       0.0115, -0.0844,  0.0864,  0.0421,  0.0404,  0.0205, -0.0732, -0.0441,\n",
       "                      -0.0524,  0.0166,  0.0497, -0.0092,  0.0626, -0.0196, -0.0852,  0.0855,\n",
       "                      -0.0516, -0.0675, -0.0775, -0.0317,  0.0491,  0.0432, -0.0107, -0.0114,\n",
       "                       0.0037, -0.0538, -0.0820, -0.0700,  0.0171,  0.0354,  0.0844,  0.0793,\n",
       "                      -0.0641,  0.0407,  0.0733,  0.0417,  0.0708, -0.0286, -0.0026, -0.0834,\n",
       "                      -0.0105,  0.0156, -0.0664,  0.0462,  0.0570,  0.0517,  0.0299,  0.0706,\n",
       "                       0.0567,  0.0764, -0.0468,  0.0863,  0.0679, -0.0155, -0.0566, -0.0802,\n",
       "                      -0.0384,  0.0644, -0.0271,  0.0382,  0.0395, -0.0215, -0.0853,  0.0235,\n",
       "                      -0.0543,  0.0776,  0.0378, -0.0225, -0.0024, -0.0167, -0.0633, -0.0045,\n",
       "                       0.0590,  0.0686, -0.0682, -0.0206, -0.0030,  0.0665, -0.0750,  0.0002,\n",
       "                       0.0164,  0.0068, -0.0174,  0.0208, -0.0333, -0.0209, -0.0149, -0.0607,\n",
       "                       0.0869, -0.0474, -0.0857, -0.0221, -0.0541, -0.0145, -0.0758,  0.0038,\n",
       "                       0.0690,  0.0354,  0.0100,  0.0603,  0.0227, -0.0013,  0.0303,  0.0779,\n",
       "                      -0.0662, -0.0262, -0.0850,  0.0592,  0.0525,  0.0757,  0.0606,  0.0270,\n",
       "                      -0.0809, -0.0691, -0.0559,  0.0109,  0.0157,  0.0756, -0.0804, -0.0058,\n",
       "                      -0.0442,  0.0383,  0.0379,  0.0298,  0.0558,  0.0470,  0.0279,  0.0711,\n",
       "                      -0.0572, -0.0017, -0.0499, -0.0377,  0.0221,  0.0723, -0.0778,  0.0353,\n",
       "                       0.0008,  0.0144,  0.0123,  0.0219,  0.0443, -0.0345,  0.0112, -0.0648,\n",
       "                      -0.0689,  0.0407,  0.0220, -0.0757, -0.0407, -0.0827, -0.0877,  0.0436,\n",
       "                      -0.0606,  0.0430, -0.0273, -0.0574,  0.0848, -0.0722,  0.0718,  0.0341,\n",
       "                       0.0162, -0.0715, -0.0314,  0.0131,  0.0021, -0.0595,  0.0690, -0.0227,\n",
       "                       0.0117,  0.0742, -0.0320,  0.0625,  0.0584, -0.0286,  0.0541, -0.0290,\n",
       "                       0.0135, -0.0735, -0.0621,  0.0522,  0.0050,  0.0471,  0.0807,  0.0122],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fully_connected_blocks.0.0.lora_apl_v1 → A norm: 4.7168, B norm: 6.5293, scaling: 1.0000\n",
      "fully_connected_blocks.1.0.lora_apl_v1 → A norm: 4.6882, B norm: 11.8058, scaling: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for name, module in cnn_model.named_modules():\n",
    "    if isinstance(module, LoRALinearWrapper):\n",
    "        for adapter_name, adapter in module.lora_adapters.items():\n",
    "            A, B = adapter[\"A\"], adapter[\"B\"]\n",
    "            A_norm = A.norm().item()\n",
    "            B_norm = B.norm().item()\n",
    "            print(f\"{name}.{adapter_name} → A norm: {A_norm:.4f}, B norm: {B_norm:.4f}, scaling: {module.active_scalings[adapter_name]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularisation (weight decay) loss: 0.3051\n"
     ]
    }
   ],
   "source": [
    "decay_total = 0.0\n",
    "for name, param in cnn_model.named_parameters():\n",
    "    if param.requires_grad and param.grad is not None:\n",
    "        decay_total += (param ** 2).sum().item()\n",
    "\n",
    "# Multiply by your weight decay value (e.g. from the optimiser)\n",
    "weight_decay = optim.param_groups[0].get(\"weight_decay\", 0.0)\n",
    "reg_loss = 0.5 * weight_decay * decay_total\n",
    "\n",
    "print(f\"Regularisation (weight decay) loss: {reg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "AllCNN2D                                 [1, 44]                   --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
      "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
      "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
      "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
      "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
      "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
      "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
      "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
      "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
      "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
      "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
      "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
      "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
      "│    └─Sequential: 2-5                   [1, 32, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
      "│    │    └─Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
      "│    │    └─LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
      "│    │    └─Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
      "│    │    └─LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
      "├─Sequential: 1-2                        [1, 128]                  --\n",
      "│    └─Flatten: 2-6                      [1, 128]                  --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Sequential: 2-7                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-41                 [1, 64]                   8,256\n",
      "│    │    └─Dropout: 3-42                [1, 64]                   --\n",
      "│    │    └─LeakyReLU: 3-43              [1, 64]                   --\n",
      "│    └─Sequential: 2-8                   [1, 44]                   --\n",
      "│    │    └─Linear: 3-44                 [1, 44]                   2,860\n",
      "==========================================================================================\n",
      "Total params: 83,548\n",
      "Trainable params: 83,548\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 14.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.18\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 2.53\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "AllCNN2D                                 --\n",
       "├─ModuleList: 1-1                        --\n",
       "│    └─Sequential: 2-1                   --\n",
       "│    │    └─Conv2d: 3-1                  160\n",
       "│    │    └─Dropout2d: 3-2               --\n",
       "│    │    └─BatchNorm2d: 3-3             32\n",
       "│    │    └─LeakyReLU: 3-4               --\n",
       "│    │    └─Conv2d: 3-5                  2,320\n",
       "│    │    └─Dropout2d: 3-6               --\n",
       "│    │    └─BatchNorm2d: 3-7             32\n",
       "│    │    └─LeakyReLU: 3-8               --\n",
       "│    └─Sequential: 2-2                   --\n",
       "│    │    └─Conv2d: 3-9                  4,640\n",
       "│    │    └─Dropout2d: 3-10              --\n",
       "│    │    └─BatchNorm2d: 3-11            64\n",
       "│    │    └─LeakyReLU: 3-12              --\n",
       "│    │    └─Conv2d: 3-13                 9,248\n",
       "│    │    └─Dropout2d: 3-14              --\n",
       "│    │    └─BatchNorm2d: 3-15            64\n",
       "│    │    └─LeakyReLU: 3-16              --\n",
       "│    └─Sequential: 2-3                   --\n",
       "│    │    └─Conv2d: 3-17                 9,248\n",
       "│    │    └─Dropout2d: 3-18              --\n",
       "│    │    └─BatchNorm2d: 3-19            64\n",
       "│    │    └─LeakyReLU: 3-20              --\n",
       "│    │    └─Conv2d: 3-21                 9,248\n",
       "│    │    └─Dropout2d: 3-22              --\n",
       "│    │    └─BatchNorm2d: 3-23            64\n",
       "│    │    └─LeakyReLU: 3-24              --\n",
       "│    └─Sequential: 2-4                   --\n",
       "│    │    └─Conv2d: 3-25                 9,248\n",
       "│    │    └─Dropout2d: 3-26              --\n",
       "│    │    └─BatchNorm2d: 3-27            64\n",
       "│    │    └─LeakyReLU: 3-28              --\n",
       "│    │    └─Conv2d: 3-29                 9,248\n",
       "│    │    └─Dropout2d: 3-30              --\n",
       "│    │    └─BatchNorm2d: 3-31            64\n",
       "│    │    └─LeakyReLU: 3-32              --\n",
       "│    └─Sequential: 2-5                   --\n",
       "│    │    └─Conv2d: 3-33                 9,248\n",
       "│    │    └─Dropout2d: 3-34              --\n",
       "│    │    └─BatchNorm2d: 3-35            64\n",
       "│    │    └─LeakyReLU: 3-36              --\n",
       "│    │    └─Conv2d: 3-37                 9,248\n",
       "│    │    └─Dropout2d: 3-38              --\n",
       "│    │    └─BatchNorm2d: 3-39            64\n",
       "│    │    └─LeakyReLU: 3-40              --\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─Sequential: 2-6                   --\n",
       "│    │    └─Linear: 3-41                 8,256\n",
       "│    │    └─Dropout: 3-42                --\n",
       "│    │    └─LeakyReLU: 3-43              --\n",
       "│    └─Sequential: 2-7                   --\n",
       "│    │    └─Linear: 3-44                 2,860\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Flatten: 2-8                      --\n",
       "=================================================================\n",
       "Total params: 83,548\n",
       "Trainable params: 83,548\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model: AllCNN2D = AllCNN2D(\n",
    "    **{\n",
    "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
    "        \"fully_connected_features\": (64, 44),\n",
    "        \"expected_input_size\": (64, 64),\n",
    "        \"device\": \"cuda\",\n",
    "        \"conv_dropout\": 0.0,#0.075,\n",
    "        \"verbose\": True,\n",
    "        \"name_prefix\": MODEL_NAME,\n",
    "        \"checkpoint_path\": r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\models\\allcnn\\Indigo_epoch26_trainacc0.71327_valacc0.99057_Tloss0.072851_Vloss0.0056362_lr0.0007224999999999999.pkl\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m char, label \u001b[38;5;129;01min\u001b[39;00m val_char_dataset:\n\u001b[0;32m      2\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(char[\u001b[38;5;241m0\u001b[39m, :, :])\n\u001b[0;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:100\u001b[0m, in \u001b[0;36mCharImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     97\u001b[0m image \u001b[38;5;241m=\u001b[39m reduce(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc h w -> 1 h w\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Apply random transformations\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_random_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# One-hot encode the label\u001b[39;00m\n\u001b[0;32m    105\u001b[0m one_hot_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_set),\n\u001b[0;32m    107\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m    108\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn\\dataset\\character_dataset.py:128\u001b[0m, in \u001b[0;36mCharImageDataset._apply_random_transformations\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Pad the image to prevent cropping during transformations\u001b[39;00m\n\u001b[0;32m    127\u001b[0m pad_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Adjust padding size as needed\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Random rotation\u001b[39;00m\n\u001b[0;32m    131\u001b[0m rotation_angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m365\u001b[39m,\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m365\u001b[39m\n\u001b[0;32m    134\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: pad() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "for char, label in val_char_dataset:\n",
    "    plt.imshow(char[0, :, :])\n",
    "    plt.show()\n",
    "    pred: torch.Tensor = model.forward(char.unsqueeze(0)).squeeze()\n",
    "    pred_index: int = torch.argmax(pred).item()\n",
    "    print(chr(int(all_label_classes[pred_index][1:], base=16)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
