{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "from einops import rearrange\n",
                "from torch.utils.data import DataLoader\n",
                "from torch.optim import AdamW\n",
                "from torch import nn\n",
                "from typing import Any\n",
                "import glob\n",
                "import re\n",
                "from datetime import datetime\n",
                "import random\n",
                "from collections import defaultdict\n",
                "import numpy as np\n",
                "\n",
                "import torch.nn.functional as torch_func\n",
                "from torchvision.transforms.functional import rotate, affine, resize, center_crop\n",
                "from PIL import Image\n",
                "import cv2\n",
                "from models.allcnn2d_rnn import CNNRNNModel\n",
                "\n",
                "random.seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import onnxruntime"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from models.allcnn2d import AllCNN2D, AllCNN2D_Prod\n",
                "from drawing.interactive import draw_image"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Global"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "file_path: str = os.path.abspath(\".\")\n",
                "root_path: str = os.path.join(file_path, os.pardir, os.pardir)\n",
                "checkpoint_path: str = r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn_rnn\\20250409_235550__cnn_rnn_model__Epoch1_tLoss0.01280_tAcc0.97172_vLoss0.00152_vAcc0.99595.pt\"\n",
                "model_name: str = \"KrudCRNN_Prod\"\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Load Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "alphabet = [\n",
                "    '(',\n",
                "    ')',\n",
                "    '+',\n",
                "    '-',\n",
                "    '.',\n",
                "    '0',\n",
                "    '1',\n",
                "    '2',\n",
                "    '3',\n",
                "    '4',\n",
                "    '5',\n",
                "    '6',\n",
                "    '7',\n",
                "    '8',\n",
                "    '9',\n",
                "    ':',\n",
                "    '<',\n",
                "    '=',\n",
                "    '>',\n",
                "    '[',\n",
                "    ']',\n",
                "    'a',\n",
                "    'b',\n",
                "    'c',\n",
                "    'd',\n",
                "    'e',\n",
                "    'f',\n",
                "    'g',\n",
                "    'h',\n",
                "    'i',\n",
                "    'j',\n",
                "    'k',\n",
                "    'l',\n",
                "    'm',\n",
                "    'n',\n",
                "    'o',\n",
                "    'p',\n",
                "    'q',\n",
                "    'r',\n",
                "    's',\n",
                "    't',\n",
                "    'u',\n",
                "    'v',\n",
                "    'w',\n",
                "    'x',\n",
                "    'y',\n",
                "    'z',\n",
                "    '{',\n",
                "    '}',\n",
                "    '×',\n",
                "    '÷',\n",
                "    'λ'\n",
                "]\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==========================================================================================\n",
                        "Layer (type:depth-idx)                   Output Shape              Param #\n",
                        "==========================================================================================\n",
                        "AllCNN2D                                 [1, 256]                  --\n",
                        "├─ModuleList: 1-1                        --                        --\n",
                        "│    └─Sequential: 2-1                   [1, 16, 32, 32]           --\n",
                        "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
                        "│    │    └─Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
                        "│    │    └─BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
                        "│    │    └─LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
                        "│    │    └─Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
                        "│    │    └─Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
                        "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
                        "│    │    └─LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
                        "│    └─Sequential: 2-2                   [1, 32, 16, 16]           --\n",
                        "│    │    └─Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
                        "│    │    └─Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
                        "│    │    └─BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
                        "│    │    └─LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
                        "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
                        "│    │    └─Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
                        "│    │    └─BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
                        "│    │    └─LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
                        "│    └─Sequential: 2-3                   [1, 32, 8, 8]             --\n",
                        "│    │    └─Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
                        "│    │    └─Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
                        "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
                        "│    │    └─LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
                        "│    │    └─Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
                        "│    │    └─Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
                        "│    │    └─BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
                        "│    │    └─LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
                        "│    └─Sequential: 2-4                   [1, 32, 4, 4]             --\n",
                        "│    │    └─Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
                        "│    │    └─Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
                        "│    │    └─BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
                        "│    │    └─LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
                        "│    │    └─Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
                        "│    │    └─Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
                        "│    │    └─BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
                        "│    │    └─LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
                        "│    └─Sequential: 2-5                   [1, 32, 2, 2]             --\n",
                        "│    │    └─Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
                        "│    │    └─Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
                        "│    │    └─BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
                        "│    │    └─LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
                        "│    │    └─Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
                        "│    │    └─Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
                        "│    │    └─BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
                        "│    │    └─LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
                        "├─Sequential: 1-2                        [1, 128]                  --\n",
                        "│    └─Flatten: 2-6                      [1, 128]                  --\n",
                        "├─ModuleList: 1-3                        --                        --\n",
                        "│    └─Sequential: 2-7                   [1, 64]                   --\n",
                        "│    │    └─Linear: 3-41                 [1, 64]                   8,256\n",
                        "│    │    └─Dropout: 3-42                [1, 64]                   --\n",
                        "│    │    └─LeakyReLU: 3-43              [1, 64]                   --\n",
                        "│    └─Sequential: 2-8                   [1, 256]                  --\n",
                        "│    │    └─Linear: 3-44                 [1, 256]                  16,640\n",
                        "==========================================================================================\n",
                        "Total params: 97,328\n",
                        "Trainable params: 97,328\n",
                        "Non-trainable params: 0\n",
                        "Total mult-adds (M): 14.06\n",
                        "==========================================================================================\n",
                        "Input size (MB): 0.02\n",
                        "Forward/backward pass size (MB): 2.18\n",
                        "Params size (MB): 0.39\n",
                        "Estimated Total Size (MB): 2.59\n",
                        "==========================================================================================\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "cnn_model: nn.Module = AllCNN2D(\n",
                "    **{\n",
                "        \"conv_features\": (1, 16, 32, 32, 32, 32),\n",
                "        \"fully_connected_features\": (64, 256), \n",
                "        \"expected_input_size\": (64, 64),\n",
                "        \"device\": \"cuda\",\n",
                "        \"conv_dropout\": 0.075,\n",
                "        \"verbose\": True,\n",
                "        \"name_prefix\": model_name,\n",
                "    }\n",
                ")\n",
                "\n",
                "cnn_rnn_model: nn.Module = CNNRNNModel(\n",
                "    cnn_model,\n",
                "    rnn_type=\"rnn\",\n",
                "    rnn_num_layers = 1,\n",
                "    num_classes=len(alphabet)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<All keys matched successfully>"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "cnn_rnn_model.load_state_dict(torch.load(checkpoint_path, weights_only=True))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([1, 1, 128])\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4277: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with RNN_TANH can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved to KrudCRNN_LC_Prod.onnx\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# Create a dummy input tensor\n",
                "dummy_input = torch.randn(1,1, 1, 64, 64)  # Example input\n",
                "\n",
                "# Define the ONNX file path\n",
                "onnx_file_path = f\"KrudCRNN_LC_Prod.onnx\"\n",
                "\n",
                "# Export the model\n",
                "torch.onnx.export(\n",
                "    cnn_rnn_model.to(device=DEVICE),\n",
                "    dummy_input.to(device=DEVICE),\n",
                "    onnx_file_path,\n",
                "    input_names=[\"input\"],  # Name of the input layer\n",
                "    output_names=[\"logits\"],  # Names of the output layers\n",
                "    dynamic_axes={\"input\": {0: \"batch_size\", 1: \"sequence\"}, \"logits\": {0: \"batch_size\", 1: \"sequence\"}},\n",
                "    opset_version=11  # Specify the ONNX opset version\n",
                ")\n",
                "\n",
                "print(f\"Model saved to {onnx_file_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Load Onnx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "import onnxruntime\n",
                "import numpy as np\n",
                "import os\n",
                "from PIL import Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "onnx_file_path = f\"KrudCRNN_LC_Prod.onnx\"\n",
                "\n",
                "# Load the ONNX model\n",
                "model_path = onnx_file_path\n",
                "\n",
                "# Define the execution providers without TensorRT\n",
                "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
                "\n",
                "# Create the InferenceSession with the explicit providers\n",
                "session = onnxruntime.InferenceSession(model_path, providers=providers)\n",
                "\n",
                "# Prepare the input image\n",
                "input_image = np.random.random(\n",
                "    (\n",
                "        1,  # batch: stack as many images as you like here\n",
                "        1,  # sequence\n",
                "        1,  # channels: needs to be 1 (grayscale), pixels are 1.0 or 0.0\n",
                "        64, # height: fixed to 64 pixels for now\n",
                "        64  # width: fixed to 64 pixels for now\n",
                "    )\n",
                ").astype(np.float32)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "('input', ['logits'])"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "# Run inference\n",
                "inputs: list[onnxruntime.NodeArg] = session.get_inputs()\n",
                "outputs: list[onnxruntime.NodeArg] = session.get_outputs()\n",
                "\n",
                "input_name: list[str] = inputs[0].name\n",
                "output_names: list[str] = [out.name for out in outputs]\n",
                "input_name, output_names"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_im_path: str = r\"D:\\Users\\Leon\\Downloads\\test.png\"\n",
                "test_im: Image.Image = Image.open(test_im_path).convert(\"L\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_im_np: np.ndarray = np.expand_dims(np.expand_dims(1.0-np.asarray(test_im)/255, 0), 0)\n",
                "test_im_np = test_im_np.astype(np.float32)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(1, 1, 64, 64)"
                        ]
                    },
                    "execution_count": 41,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_im_np.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "softmax: np.ndarray\n",
                "softmax_ordered: np.ndarray\n",
                "logits: np.ndarray\n",
                "\n",
                "logits = session.run(\n",
                "    output_names, \n",
                "    {input_name: test_im_np}\n",
                ")[0]\n",
                "\n",
                "# logits.shape is shape (batch, character) for all character labels\n",
                "# softmax.shape is shape (batch, character) for all character labels\n",
                "# softmax_ordered is shape (batch, character, [label index, label prob, unicode character value])\n",
                "\n",
                "# character dim is 44 (there are 44 character labels)\n",
                "# label index is from 0 to 44 (corresponding to each ordered label index)\n",
                "# label prob is a softmaxed probability for this label prediction\n",
                "# unicode character value is the unicode character for this prediction\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": [
                "def softmax(x: np.ndarray) -> np.ndarray:\n",
                "    return np.exp(x)/(np.sum(np.exp(x)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "alphabet: list[str] = \"2, ⍺, P, 6, z, o, ⌷, ~, ⍲, ', X, 5, Q, o, w, u, ⍳, ⍀, E, ⍵, q, R, ⍳, 6, 3, ⍨, ;, ⊥, b, ⍎, T, ⌷, ⊥, ⌊, ∊, y, ⍕, ⍙, Z, ⌈, (, ⍕, *, ≤, ⊤, 1, F, ¨, s, ¯, R, c, W, w, Y, f, j, (, £, Z, F, i, 5, ⌹, ⍫, /, U, d, ⊃, n, O, T, ⊖, ↓, P, =, w, c, ⌶, *, ⍫, J, {, [, ⍵, F, ¯, ↑, 4, 7, ⍴, }, ⍬, Q, g, ÷, C, ∪, ⍋, Z, G, R, ∊, L, *, ,, {, ·, ⊢, ⍨, V, |, ⌿, ;, <, D, %, a, ≠, _, \\, ⍟, ○, w, K, d, u, d, s, ⌹, ∩, ⍳, j, ;, ∇, m, *, 7, ⌽, ∪, ., £, M, S, ↓, e, }, y, ∆, O, q, L, £, >, r, ≢, ⍨, ⍳, ⊃, 4, ⍱, ?, Q, ⍴, F, ∘, z, ⍕, 2, 0, ⍬, ⍪, ⊢, ⍒, H, i, ⊖, }, ≥, M, ×, u, ○, ⍋, V, l, $, {, A, L, ¨, !, ∇, $, ¨, f, ⊢, }, 7, k, U, D, J, 8, ⍴, ⍱, ≢, ⊂, N, ⍎, ⍙, 1, ⍱, t, k, ⍪, i, -, 8, ≥, ⍙, K, ⌶, ≥, f, ⍲, ×, g, ∇, O, +, ∊, ⍋, C, s, U, +, /, _, Q, ⍟, ∆, i, Y, y, ∆, p, ⍺, x, ∆, 2, >, ⊖, r, ∩, 3, <, ⍙, X, b, %, X, p, [, m, l, U, 2, E, B, ⊤, E, ≠, ↑, ÷, ?, -, ∩, >, p, E, ⌈, A, h, ., [, B, ⌊, ¯, ≢, I, ', ∧, ≡, ¯, _, (, M, t, ~, ≡, ≡, ⌊, (, z, ⍉, 1, ?, ?, ⊂, t, ⌹, P, v, ⍀, 6, G, ⍱, m, ∨, H, ·, r, !, ¨, n, m, \\, B, ↓, ⍲, a, ⌽, h, ≥, ., 7, -, T, J, n, ~, ⌶, q, j, b, D, _, h, ⊤, ÷, 1, K, ⊂, ⊂, 9, ∨, 3, ∪, x, k, ⍀, ∧, ⍀, ⍪, e, x, ↓, ÷, ⍬, C, !, 8, ;, ⊣, ⍺, c, ⌶, r, [, p, ⍨, G, ≢, 5, ⊥, 5, g, S, \\, !, v, z, ,, ⍟, ≤, ⍲, I, n, t, W, 9, s, ≤, S, b, ↑, <, ⍋, |, 0, a, $, %, ·, C, +, ~, \\, ⊣, G, ⊢, ≤, ∘, W, ≠, 4, 6, ⊃, o, ⍵, ', A, +, A, V, ⍎, 9, =, V, ⍉, y, ⍎, ⊖, /, I, ○, 4, J, k, l, |, j, >, ⌹, ∨, ⍒, ', ⍫, a, ∇, c, ⌿, ∧, Z, Y, e, ⍬, N, ⌽, =, |, H, ⍒, v, 0, u, ⍉, T, 9, ⊤, v, D, ∩, I, N, q, P, ⍒, L, ⌷, ⍴, ⍺, ⊣, ⍵, d, H, /, ×, $, ≡, h, ⌿, g, ∪, x, ⍟, Y, ⌿, K, ∊, ⊃, %, S, B, ⊣, W, ⍉, o, ≠, 8, O, R, ⌊, X, ⌈, ×, M, ,, ⍪, £, N, ·, ⍫, ↑, =, l, -, e, ○, ∘, {, 0, ,, ⌈, ∧, ∨, f, ⊥, ⌷, ⍕, ., 3, <, ∘, ⌽\"\n",
                "alphabet = list(alphabet[::3])\n",
                "alphabet.sort()\n",
                "alphabet = list(set(alphabet))\n",
                "len(alphabet)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['∃',\n",
                            " '(',\n",
                            " ')',\n",
                            " '.',\n",
                            " '0',\n",
                            " '1',\n",
                            " '2',\n",
                            " '3',\n",
                            " '4',\n",
                            " '5',\n",
                            " '6',\n",
                            " '7',\n",
                            " '8',\n",
                            " '9',\n",
                            " ':',\n",
                            " 'λ',\n",
                            " 'μ',\n",
                            " 'a',\n",
                            " 'b',\n",
                            " 'c',\n",
                            " 'd',\n",
                            " 'e',\n",
                            " 'f',\n",
                            " 'g',\n",
                            " 'h',\n",
                            " 'i',\n",
                            " 'j',\n",
                            " 'k',\n",
                            " 'l',\n",
                            " 'm',\n",
                            " 'n',\n",
                            " 'o',\n",
                            " 'p',\n",
                            " 'q',\n",
                            " 'r',\n",
                            " 's',\n",
                            " 't',\n",
                            " 'u',\n",
                            " 'v',\n",
                            " 'w',\n",
                            " 'x',\n",
                            " 'y',\n",
                            " 'z']"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "alphabet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[2.40075646e-13, 1.15206923e-07, 1.37380053e-14, 3.34124736e-13,\n",
                            "        4.11096668e-09, 7.14889302e-13, 1.07027153e-14, 1.68246889e-10,\n",
                            "        8.66545169e-11, 1.15027998e-14, 1.51031060e-07, 1.44396502e-15,\n",
                            "        1.83445363e-20, 2.37482412e-11, 8.82452260e-13, 7.99155680e-16,\n",
                            "        8.35734459e-15, 7.13140173e-16, 5.89413043e-15, 1.07718339e-13,\n",
                            "        1.14981783e-11, 3.17502136e-10, 5.48293355e-12, 1.92422033e-11,\n",
                            "        7.53038812e-11, 1.13980587e-11, 4.37636624e-21, 6.26497257e-11,\n",
                            "        1.17908020e-17, 3.87737526e-19, 2.63933891e-14, 1.44821948e-16,\n",
                            "        6.88685288e-14, 6.85964465e-15, 4.81195639e-06, 7.78162138e-15,\n",
                            "        1.45000017e-12, 1.73608098e-16, 1.12613145e-08, 1.23712876e-17,\n",
                            "        4.18045733e-17, 2.54574822e-18, 5.93416142e-16, 2.03718682e-18,\n",
                            "        3.93308337e-11, 1.44548343e-16, 1.81677456e-06, 4.88934404e-07,\n",
                            "        2.29401871e-12, 1.43134365e-13, 1.89051814e-08, 1.77917819e-11,\n",
                            "        1.62620140e-15, 1.93805423e-11, 4.32369400e-19, 2.41981817e-11,\n",
                            "        6.01218519e-11, 2.16705942e-09, 3.25512723e-16, 1.56579946e-12,\n",
                            "        1.27528172e-18, 2.22219326e-11, 3.05975130e-15, 1.73779574e-10,\n",
                            "        5.13835016e-11, 9.79093473e-10, 8.01901812e-14, 4.06848097e-11,\n",
                            "        1.60578547e-16, 1.34570521e-14, 2.11691754e-12, 2.42757247e-12,\n",
                            "        1.01956051e-04, 8.84144934e-15, 8.12445712e-15, 8.09917658e-14,\n",
                            "        1.44547970e-12, 2.38835797e-04, 5.34929982e-11, 8.13993996e-20,\n",
                            "        3.52898344e-17, 1.35368999e-11, 1.95888029e-16, 1.17658636e-13,\n",
                            "        5.63094406e-12, 1.54215932e-10, 1.33886988e-06, 9.77693412e-11,\n",
                            "        2.01393860e-07, 6.05779704e-10, 3.37337534e-20, 2.01501116e-01,\n",
                            "        5.59890967e-10, 7.06052161e-19, 1.10956153e-13, 1.15443333e-09,\n",
                            "        4.21780387e-17, 5.21220606e-14, 8.01668031e-13, 2.21323187e-15,\n",
                            "        1.90751108e-17, 1.07443792e-13, 8.90615775e-05, 6.18205078e-08,\n",
                            "        5.59677413e-13, 4.27481964e-16, 1.09538978e-09, 3.91359166e-18,\n",
                            "        3.77007292e-18, 8.41812445e-17, 3.08526779e-07, 1.78598422e-14,\n",
                            "        1.61451394e-10, 3.01052461e-19, 2.48584226e-12, 4.12366452e-12,\n",
                            "        5.07998862e-13, 6.22131173e-15, 4.77483431e-09, 1.07974367e-08,\n",
                            "        1.34447062e-15, 4.43921755e-13, 2.48949273e-05, 6.20164026e-24,\n",
                            "        6.95634640e-07, 7.12056977e-15, 3.93917722e-20, 3.98408765e-15,\n",
                            "        2.08868795e-12, 2.76661572e-22, 7.31313551e-11, 4.06714662e-07,\n",
                            "        2.66794948e-14, 2.31850603e-17, 2.10814589e-18, 5.57623325e-09,\n",
                            "        2.52223327e-08, 2.46338667e-18, 1.30926018e-19, 8.50554804e-16,\n",
                            "        4.79420013e-16, 3.21454615e-16, 2.24709432e-10, 1.60106720e-11,\n",
                            "        5.21373049e-12, 3.98600655e-16, 1.16454207e-11, 1.14349359e-06,\n",
                            "        4.48156239e-15, 1.13463672e-18, 3.00853700e-12, 5.44436837e-19,\n",
                            "        1.90992178e-09, 3.26595126e-16, 5.62852057e-11, 1.81521465e-11,\n",
                            "        1.45546408e-10, 1.25851252e-19, 1.48988188e-09, 2.38726923e-08,\n",
                            "        2.92048693e-13, 1.24675836e-18, 1.61417266e-13, 1.12595243e-15,\n",
                            "        3.17331166e-12, 1.85345961e-10, 6.68754963e-09, 2.19617213e-10,\n",
                            "        3.11704963e-27, 2.52491418e-06, 4.76342316e-12, 8.04939893e-10,\n",
                            "        2.25496253e-20, 2.95583293e-18, 7.11131520e-07, 2.41382191e-13,\n",
                            "        3.61201818e-13, 1.83794071e-14, 4.84310266e-11, 7.19233353e-11,\n",
                            "        1.37078965e-18, 4.05528766e-09, 1.98745460e-15, 7.69779706e-19,\n",
                            "        8.60476707e-12, 1.98989838e-10, 6.94466411e-19, 4.61140978e-12,\n",
                            "        1.50934087e-09, 3.95012078e-18, 1.40075850e-11, 3.05326337e-12,\n",
                            "        5.13225042e-13, 5.57959859e-17, 2.52927057e-18, 3.09051673e-10,\n",
                            "        4.20496521e-20, 8.43492671e-06, 1.18215889e-16, 1.17362908e-17,\n",
                            "        9.61536251e-18, 1.67669088e-14, 6.31466390e-09, 1.46251041e-17,\n",
                            "        7.42055462e-12, 1.04979359e-09, 1.66170359e-11, 2.59828381e-09,\n",
                            "        2.10525930e-09, 7.11325470e-07, 2.26833523e-20, 7.18233598e-11,\n",
                            "        2.06325702e-19, 1.07209545e-11, 1.51600204e-07, 4.92324877e-16,\n",
                            "        4.73380536e-11, 4.28579381e-17, 1.45344569e-14, 1.45806780e-15,\n",
                            "        6.55265718e-13, 1.26958491e-12, 7.98012495e-01, 5.18198982e-12,\n",
                            "        6.75609361e-17, 1.06606359e-08, 9.53154569e-12, 1.58447015e-16,\n",
                            "        2.78461525e-11, 3.64411680e-13, 3.24994302e-11, 4.35373986e-14,\n",
                            "        2.35513811e-13, 1.20966547e-07, 1.81298164e-16, 2.05672163e-13,\n",
                            "        1.75983548e-08, 6.64450645e-13, 7.12594920e-06, 7.23825557e-12,\n",
                            "        3.95283329e-12, 2.47605918e-08, 4.87711871e-09, 3.81845998e-21,\n",
                            "        2.76468555e-18, 7.87123498e-17, 4.46600835e-17, 2.51979410e-24,\n",
                            "        5.17719783e-19, 7.38214760e-14, 3.91372579e-16, 6.88650748e-10,\n",
                            "        2.13889887e-12, 1.82395027e-07, 9.88864710e-17, 2.97680141e-14]],\n",
                            "      dtype=float32)"
                        ]
                    },
                    "execution_count": 57,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "softmax(logits)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "top_character_probs: list[list[float]] = softmax_ordered[:, :, 1].tolist()\n",
                "\n",
                "top_characters: list[list[str]] = [\n",
                "    [\n",
                "        chr(int(softmax_ordered[batch_i, i, 2])) \n",
                "        for i in range(softmax_ordered.shape[1])\n",
                "    ] for batch_i in \n",
                "    range(softmax_ordered.shape[0])\n",
                "]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hello World"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 132,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TextReShitter(nn.Module):\n",
                "    \n",
                "    def __init__(self, alphabet: list[str], text: str):\n",
                "        \n",
                "        super(TextReShitter, self).__init__()\n",
                "        \n",
                "        self.alphabet: list[str] = alphabet\n",
                "        self.text: str = text\n",
                "        \n",
                "        self.logits: list[torch.Tensor] = []\n",
                "        \n",
                "        for c in self.text:\n",
                "            c_index: int = self.alphabet.index(c)\n",
                "            \n",
                "            char_logits: torch.Tensor = torch.rand((len(alphabet),))\n",
                "            char_logits[c_index] += 2\n",
                "            char_logits *= (torch.rand(1)+0.1)\n",
                "\n",
                "            self.logits.append(char_logits)\n",
                "\n",
                "        self.logits_tensor: torch.Tensor = torch.stack(self.logits, dim=0)\n",
                "        \n",
                "        self.logits_tensor = self.logits_tensor.unsqueeze(0) # batch, chars, logit\n",
                "        \n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        \n",
                "        self.logits_tensor = self.logits_tensor + x.sum() * 0.0  \n",
                "\n",
                "        softmax = torch.softmax(self.logits_tensor, dim=-1)\n",
                "        \n",
                "        # Create indices for the first dimension (char_prob_i)\n",
                "        char_prob_indices = torch.arange(softmax.size(-1), device=softmax.device).reshape(1, 1, -1, 1)\n",
                "        \n",
                "        # Create indices for the third dimension (ord(self.alphabet[char_prob_i]))\n",
                "        alphabet_indices = torch.tensor([ord(c) for c in self.alphabet], device=softmax.device).reshape(1, 1, -1, 1)\n",
                "        \n",
                "        # Expand dimensions to match softmax shape\n",
                "        char_prob_indices = char_prob_indices.expand(*softmax.shape, 1)\n",
                "        alphabet_indices = alphabet_indices.expand(*softmax.shape, 1)\n",
                "        \n",
                "        # Concatenate along the last dimension\n",
                "        softmax_ordered = torch.cat([char_prob_indices, softmax.unsqueeze(-1), alphabet_indices], dim=-1)\n",
                "        \n",
                "        # Sort along the probability dimension (dim=-2)\n",
                "        sorting_indices = softmax_ordered[..., 1].argsort(dim=-1, descending=True)\n",
                "        sorted_tensor = torch.gather(softmax_ordered, -2, sorting_indices.unsqueeze(-1).expand(-1, -1, -1, 3))\n",
                "        \n",
                "        x = x * 0.5\n",
                "        \n",
                "        unicodes: torch.Tensor = sorted_tensor[0, :, :, 2]\n",
                "        probs: torch.Tensor = sorted_tensor[0, :, :, 1]\n",
                "        \n",
                "        unicodes = unicodes.to(dtype=torch.int)\n",
                "        \n",
                "        return unicodes, probs \n",
                "        \n",
                "        \n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 133,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(tensor([[104,  54,  57,  98, 121, 113, 111, 105,  50, 118,  55, 119,  51,  43,\n",
                            "          116,  40, 108, 117, 247,  97, 215, 115, 122,  99,  52,  45, 110,  53,\n",
                            "           41, 112,  48,  46, 103, 100,  49, 109,  56, 120, 955, 106, 114, 107,\n",
                            "          101, 102],\n",
                            "         [101, 103,  57, 955,  53,  97, 100, 215,  51, 114, 119,  40, 109,  48,\n",
                            "          108,  54,  46,  50, 102, 121, 247, 120, 116, 115, 122,  99,  55, 104,\n",
                            "           98,  41, 107, 110, 106, 113, 118, 105,  43, 117,  45, 111,  52, 112,\n",
                            "           56,  49],\n",
                            "         [108,  51,  50, 103, 105, 100, 113, 116, 247, 109, 119,  99,  45, 104,\n",
                            "          121, 118,  46,  43,  98,  55, 120,  52, 955,  54,  41,  49,  57, 115,\n",
                            "          102,  48,  53, 112, 101,  40, 114, 111, 215, 122,  56, 106,  97, 117,\n",
                            "          107, 110],\n",
                            "         [108,  45, 116,  99,  54,  48, 102, 121, 106,  51,  98,  56,  46, 215,\n",
                            "          115, 247, 101,  40,  52,  49,  57, 104, 111, 120, 955,  55, 110, 122,\n",
                            "          119, 113, 100,  41, 109,  50,  97, 117,  43, 118, 103, 114, 107, 105,\n",
                            "           53, 112],\n",
                            "         [111, 101,  57,  48,  99, 118, 112, 215,  49, 104, 114, 122, 105,  98,\n",
                            "           46, 103, 110, 120, 115,  97,  54,  45,  53,  51, 116,  40,  50, 108,\n",
                            "           56, 117, 113, 109, 119,  43, 121, 107, 100,  41,  52,  55, 955, 102,\n",
                            "          247, 106],\n",
                            "         [ 46, 112, 117, 106, 111, 115, 247, 119,  54, 103, 109, 113, 107, 101,\n",
                            "           97, 122, 110, 121, 114,  43,  40, 116, 118, 105,  49, 215, 100,  57,\n",
                            "           48,  51,  52,  56,  55,  41, 104, 955,  53,  98, 108,  99,  45, 120,\n",
                            "          102,  50],\n",
                            "         [119, 112,  55,  45,  51, 111,  54,  98, 102,  52, 247,  57, 955,  40,\n",
                            "          118, 115, 100,  97, 103, 101, 110, 107, 117, 106, 121, 109,  41,  53,\n",
                            "          120, 105,  49,  46,  56, 114, 104,  48, 108,  43, 215, 122, 116,  99,\n",
                            "          113,  50],\n",
                            "         [111,  55, 107, 120, 100,  98,  57,  41, 113,  51,  99, 103,  50, 108,\n",
                            "          105, 116,  48, 215, 112, 106,  43,  56, 122,  46,  52, 119,  40, 109,\n",
                            "           45, 102,  97, 104, 101, 118,  49, 110, 114,  53, 247, 121,  54, 115,\n",
                            "          955, 117],\n",
                            "         [114,  56, 104,  97, 103,  55, 116,  41, 105, 215,  49,  48, 101, 118,\n",
                            "           57, 107, 119, 109, 247, 955,  40, 111,  52,  98, 108,  51,  54, 120,\n",
                            "          112, 115,  53,  45, 117, 121, 100,  46, 102,  99,  43,  50, 106, 110,\n",
                            "          122, 113],\n",
                            "         [108,  54,  43, 118, 115,  51, 102,  41,  55, 117,  98, 101, 122, 215,\n",
                            "          119, 100,  56, 116, 107,  99,  48, 109,  49, 106,  45, 121,  46, 105,\n",
                            "           53,  52,  97, 112, 955, 104, 113, 111, 114,  50, 247,  40, 103, 120,\n",
                            "           57, 110],\n",
                            "         [100,  46, 103, 105, 215, 117, 110, 104, 113, 119, 118, 247,  54,  48,\n",
                            "          121, 112, 122, 114,  49, 106,  57,  56, 120,  98, 102, 955,  52, 101,\n",
                            "          108, 107,  40, 115, 109,  43,  51,  99,  50, 111,  55,  97, 116,  45,\n",
                            "           53,  41]], dtype=torch.int32),\n",
                            " tensor([[0.1105, 0.0316, 0.0312, 0.0310, 0.0306, 0.0294, 0.0279, 0.0268, 0.0261,\n",
                            "          0.0260, 0.0260, 0.0257, 0.0255, 0.0242, 0.0237, 0.0235, 0.0226, 0.0226,\n",
                            "          0.0222, 0.0219, 0.0219, 0.0214, 0.0208, 0.0202, 0.0198, 0.0196, 0.0191,\n",
                            "          0.0187, 0.0187, 0.0170, 0.0165, 0.0162, 0.0154, 0.0151, 0.0150, 0.0145,\n",
                            "          0.0142, 0.0142, 0.0136, 0.0125, 0.0122, 0.0114, 0.0114, 0.0113],\n",
                            "         [0.0369, 0.0249, 0.0248, 0.0248, 0.0248, 0.0248, 0.0246, 0.0245, 0.0243,\n",
                            "          0.0243, 0.0241, 0.0240, 0.0239, 0.0239, 0.0238, 0.0238, 0.0236, 0.0233,\n",
                            "          0.0231, 0.0231, 0.0229, 0.0229, 0.0227, 0.0226, 0.0224, 0.0224, 0.0223,\n",
                            "          0.0219, 0.0219, 0.0217, 0.0216, 0.0212, 0.0212, 0.0210, 0.0208, 0.0201,\n",
                            "          0.0201, 0.0199, 0.0196, 0.0193, 0.0193, 0.0192, 0.0190, 0.0190],\n",
                            "         [0.0446, 0.0253, 0.0252, 0.0250, 0.0250, 0.0248, 0.0247, 0.0247, 0.0240,\n",
                            "          0.0240, 0.0240, 0.0239, 0.0237, 0.0235, 0.0235, 0.0234, 0.0232, 0.0229,\n",
                            "          0.0227, 0.0227, 0.0223, 0.0221, 0.0219, 0.0219, 0.0216, 0.0215, 0.0214,\n",
                            "          0.0211, 0.0210, 0.0210, 0.0208, 0.0206, 0.0206, 0.0205, 0.0205, 0.0205,\n",
                            "          0.0203, 0.0203, 0.0202, 0.0202, 0.0201, 0.0199, 0.0196, 0.0194],\n",
                            "         [0.0365, 0.0246, 0.0246, 0.0244, 0.0243, 0.0242, 0.0241, 0.0241, 0.0240,\n",
                            "          0.0239, 0.0239, 0.0237, 0.0237, 0.0234, 0.0234, 0.0234, 0.0230, 0.0228,\n",
                            "          0.0227, 0.0226, 0.0225, 0.0225, 0.0225, 0.0222, 0.0221, 0.0220, 0.0220,\n",
                            "          0.0220, 0.0219, 0.0218, 0.0217, 0.0215, 0.0213, 0.0212, 0.0210, 0.0208,\n",
                            "          0.0208, 0.0208, 0.0206, 0.0205, 0.0204, 0.0203, 0.0203, 0.0202],\n",
                            "         [0.1248, 0.0297, 0.0292, 0.0291, 0.0290, 0.0290, 0.0286, 0.0275, 0.0272,\n",
                            "          0.0262, 0.0250, 0.0244, 0.0243, 0.0241, 0.0234, 0.0230, 0.0226, 0.0218,\n",
                            "          0.0217, 0.0214, 0.0207, 0.0202, 0.0202, 0.0192, 0.0190, 0.0188, 0.0184,\n",
                            "          0.0184, 0.0182, 0.0176, 0.0174, 0.0168, 0.0154, 0.0148, 0.0144, 0.0142,\n",
                            "          0.0135, 0.0133, 0.0133, 0.0132, 0.0132, 0.0130, 0.0129, 0.0121],\n",
                            "         [0.0831, 0.0307, 0.0302, 0.0302, 0.0297, 0.0293, 0.0292, 0.0292, 0.0285,\n",
                            "          0.0281, 0.0271, 0.0266, 0.0250, 0.0245, 0.0234, 0.0233, 0.0230, 0.0228,\n",
                            "          0.0226, 0.0214, 0.0211, 0.0208, 0.0207, 0.0204, 0.0200, 0.0194, 0.0189,\n",
                            "          0.0182, 0.0177, 0.0177, 0.0177, 0.0168, 0.0166, 0.0164, 0.0163, 0.0160,\n",
                            "          0.0156, 0.0155, 0.0150, 0.0147, 0.0142, 0.0141, 0.0141, 0.0140],\n",
                            "         [0.0618, 0.0272, 0.0269, 0.0265, 0.0264, 0.0263, 0.0259, 0.0255, 0.0254,\n",
                            "          0.0251, 0.0251, 0.0249, 0.0246, 0.0242, 0.0237, 0.0234, 0.0233, 0.0232,\n",
                            "          0.0227, 0.0227, 0.0224, 0.0223, 0.0221, 0.0203, 0.0202, 0.0200, 0.0199,\n",
                            "          0.0199, 0.0199, 0.0196, 0.0194, 0.0193, 0.0193, 0.0191, 0.0190, 0.0189,\n",
                            "          0.0183, 0.0181, 0.0181, 0.0180, 0.0178, 0.0178, 0.0178, 0.0178],\n",
                            "         [0.0979, 0.0313, 0.0303, 0.0293, 0.0291, 0.0289, 0.0271, 0.0265, 0.0259,\n",
                            "          0.0257, 0.0252, 0.0244, 0.0241, 0.0236, 0.0231, 0.0230, 0.0216, 0.0215,\n",
                            "          0.0213, 0.0207, 0.0207, 0.0205, 0.0204, 0.0203, 0.0198, 0.0195, 0.0189,\n",
                            "          0.0188, 0.0184, 0.0183, 0.0180, 0.0180, 0.0169, 0.0168, 0.0164, 0.0163,\n",
                            "          0.0161, 0.0157, 0.0156, 0.0156, 0.0151, 0.0147, 0.0143, 0.0142],\n",
                            "         [0.0317, 0.0248, 0.0247, 0.0247, 0.0246, 0.0245, 0.0241, 0.0241, 0.0239,\n",
                            "          0.0238, 0.0236, 0.0236, 0.0233, 0.0233, 0.0233, 0.0232, 0.0232, 0.0228,\n",
                            "          0.0227, 0.0226, 0.0225, 0.0225, 0.0224, 0.0224, 0.0224, 0.0220, 0.0219,\n",
                            "          0.0219, 0.0218, 0.0218, 0.0218, 0.0216, 0.0215, 0.0214, 0.0212, 0.0212,\n",
                            "          0.0212, 0.0212, 0.0211, 0.0210, 0.0209, 0.0207, 0.0206, 0.0205],\n",
                            "         [0.0449, 0.0259, 0.0256, 0.0250, 0.0250, 0.0250, 0.0250, 0.0248, 0.0246,\n",
                            "          0.0245, 0.0243, 0.0238, 0.0237, 0.0236, 0.0233, 0.0233, 0.0232, 0.0231,\n",
                            "          0.0230, 0.0230, 0.0230, 0.0226, 0.0220, 0.0220, 0.0218, 0.0218, 0.0217,\n",
                            "          0.0213, 0.0212, 0.0209, 0.0207, 0.0207, 0.0203, 0.0202, 0.0201, 0.0200,\n",
                            "          0.0200, 0.0197, 0.0195, 0.0193, 0.0193, 0.0192, 0.0191, 0.0190],\n",
                            "         [0.0325, 0.0244, 0.0240, 0.0239, 0.0239, 0.0237, 0.0236, 0.0236, 0.0236,\n",
                            "          0.0236, 0.0233, 0.0233, 0.0230, 0.0229, 0.0229, 0.0228, 0.0228, 0.0228,\n",
                            "          0.0228, 0.0228, 0.0228, 0.0227, 0.0227, 0.0227, 0.0226, 0.0226, 0.0226,\n",
                            "          0.0225, 0.0223, 0.0223, 0.0223, 0.0222, 0.0221, 0.0215, 0.0214, 0.0214,\n",
                            "          0.0212, 0.0211, 0.0211, 0.0209, 0.0208, 0.0207, 0.0206, 0.0204]]))"
                        ]
                    },
                    "execution_count": 133,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "hello_world_model = TextReShitter(alphabet, \"hello.world\")\n",
                "\n",
                "hello_world_model.forward(torch.zeros(1, 1, 1, 1))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ONNX: Save Hello World"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 134,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved to hello_world.onnx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\Leon\\AppData\\Local\\Temp\\ipykernel_1824\\427549207.py:35: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
                        "  alphabet_indices = torch.tensor([ord(c) for c in self.alphabet], device=softmax.device).reshape(1, 1, -1, 1)\n"
                    ]
                }
            ],
            "source": [
                "# Create a dummy input tensor\n",
                "dummy_input = torch.randn(1, 1, 100, 100)  # Example input\n",
                "\n",
                "# Define the ONNX file path\n",
                "onnx_file_path = \"hello_world.onnx\"\n",
                "\n",
                "# Export the model\n",
                "torch.onnx.export(\n",
                "    hello_world_model,\n",
                "    dummy_input,\n",
                "    onnx_file_path,\n",
                "    input_names=[\"input\"],  # Name of the input layer\n",
                "    output_names=[\"unicode\", \"probability\"],  # Names of the output layers\n",
                "    dynamic_axes={\"input\": {2: \"height\", 3: \"width\"}},\n",
                "    opset_version=11  # Specify the ONNX opset version\n",
                ")\n",
                "\n",
                "print(f\"Model saved to {onnx_file_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Load Hello World Onnx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 135,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['h', 'e', 'l', 'l', 'o', '.', 'w', 'o', 'r', 'l', 'd']"
                        ]
                    },
                    "execution_count": 135,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "# Load the ONNX model\n",
                "model_path = \"hello_world.onnx\"\n",
                "session = onnxruntime.InferenceSession(model_path)\n",
                "\n",
                "input_image = np.random.random(\n",
                "    (\n",
                "        1,  # batch: stack as many images as you like here\n",
                "        1,  # channels: needs to be 1 (grayscale), pixels are 1.0 or 0.0\n",
                "        2,  # height: fixed to 1 for now\n",
                "        1   # width: fixed to 1 for now\n",
                "    )\n",
                ").astype(np.float32)\n",
                "\n",
                "# Run inference\n",
                "inputs: list[onnxruntime.NodeArg] = session.get_inputs()\n",
                "outputs: list[onnxruntime.NodeArg] = session.get_outputs()\n",
                "\n",
                "input_name: str = inputs[0].name\n",
                "output_names: list[str] = [out.name for out in outputs]\n",
                "softmax: np.ndarray\n",
                "softmax_ordered: np.ndarray\n",
                "logits: np.ndarray\n",
                "\n",
                "unicodes, probs = session.run(\n",
                "    output_names, \n",
                "    {input_name: input_image}\n",
                ")\n",
                "\n",
                "list(map(chr, unicodes[:, 0].tolist()))\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Create CNN Production"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded: encoder_conv_blocks.0.0.weight\n",
                        "Loaded: encoder_conv_blocks.0.0.bias\n",
                        "Loaded: encoder_conv_blocks.0.2.weight\n",
                        "Loaded: encoder_conv_blocks.0.2.bias\n",
                        "Loaded: encoder_conv_blocks.0.2.running_mean\n",
                        "Loaded: encoder_conv_blocks.0.2.running_var\n",
                        "Loaded: encoder_conv_blocks.0.2.num_batches_tracked\n",
                        "Loaded: encoder_conv_blocks.0.4.weight\n",
                        "Loaded: encoder_conv_blocks.0.4.bias\n",
                        "Loaded: encoder_conv_blocks.0.6.weight\n",
                        "Loaded: encoder_conv_blocks.0.6.bias\n",
                        "Loaded: encoder_conv_blocks.0.6.running_mean\n",
                        "Loaded: encoder_conv_blocks.0.6.running_var\n",
                        "Loaded: encoder_conv_blocks.0.6.num_batches_tracked\n",
                        "Loaded: encoder_conv_blocks.1.0.weight\n",
                        "Loaded: encoder_conv_blocks.1.0.bias\n",
                        "Loaded: encoder_conv_blocks.1.2.weight\n",
                        "Loaded: encoder_conv_blocks.1.2.bias\n",
                        "Loaded: encoder_conv_blocks.1.2.running_mean\n",
                        "Loaded: encoder_conv_blocks.1.2.running_var\n",
                        "Loaded: encoder_conv_blocks.1.2.num_batches_tracked\n",
                        "Loaded: encoder_conv_blocks.1.4.weight\n",
                        "Loaded: encoder_conv_blocks.1.4.bias\n",
                        "Loaded: encoder_conv_blocks.1.6.weight\n",
                        "Loaded: encoder_conv_blocks.1.6.bias\n",
                        "Loaded: encoder_conv_blocks.1.6.running_mean\n",
                        "Loaded: encoder_conv_blocks.1.6.running_var\n",
                        "Loaded: encoder_conv_blocks.1.6.num_batches_tracked\n",
                        "Loaded: encoder_conv_blocks.2.0.weight\n",
                        "Loaded: encoder_conv_blocks.2.0.bias\n",
                        "Loaded: encoder_conv_blocks.2.2.weight\n",
                        "Loaded: encoder_conv_blocks.2.2.bias\n",
                        "Loaded: encoder_conv_blocks.2.2.running_mean\n",
                        "Loaded: encoder_conv_blocks.2.2.running_var\n",
                        "Loaded: encoder_conv_blocks.2.2.num_batches_tracked\n",
                        "Loaded: encoder_conv_blocks.2.4.weight\n",
                        "Loaded: encoder_conv_blocks.2.4.bias\n",
                        "Loaded: encoder_conv_blocks.2.6.weight\n",
                        "Loaded: encoder_conv_blocks.2.6.bias\n",
                        "Loaded: encoder_conv_blocks.2.6.running_mean\n",
                        "Loaded: encoder_conv_blocks.2.6.running_var\n",
                        "Loaded: encoder_conv_blocks.2.6.num_batches_tracked\n",
                        "Loaded: encoder_conv_blocks.3.0.weight\n",
                        "Loaded: encoder_conv_blocks.3.0.bias\n",
                        "Loaded: encoder_conv_blocks.3.2.weight\n",
                        "Loaded: encoder_conv_blocks.3.2.bias\n",
                        "Loaded: encoder_conv_blocks.3.2.running_mean\n",
                        "Loaded: encoder_conv_blocks.3.2.running_var\n",
                        "Loaded: encoder_conv_blocks.3.2.num_batches_tracked\n",
                        "Loaded: encoder_conv_blocks.3.4.weight\n",
                        "Loaded: encoder_conv_blocks.3.4.bias\n",
                        "Loaded: encoder_conv_blocks.3.6.weight\n",
                        "Loaded: encoder_conv_blocks.3.6.bias\n",
                        "Loaded: encoder_conv_blocks.3.6.running_mean\n",
                        "Loaded: encoder_conv_blocks.3.6.running_var\n",
                        "Loaded: encoder_conv_blocks.3.6.num_batches_tracked\n",
                        "Loaded: encoder_conv_blocks.4.0.weight\n",
                        "Loaded: encoder_conv_blocks.4.0.bias\n",
                        "Loaded: encoder_conv_blocks.4.2.weight\n",
                        "Loaded: encoder_conv_blocks.4.2.bias\n",
                        "Loaded: encoder_conv_blocks.4.2.running_mean\n",
                        "Loaded: encoder_conv_blocks.4.2.running_var\n",
                        "Loaded: encoder_conv_blocks.4.2.num_batches_tracked\n",
                        "Loaded: encoder_conv_blocks.4.4.weight\n",
                        "Loaded: encoder_conv_blocks.4.4.bias\n",
                        "Loaded: encoder_conv_blocks.4.6.weight\n",
                        "Loaded: encoder_conv_blocks.4.6.bias\n",
                        "Loaded: encoder_conv_blocks.4.6.running_mean\n",
                        "Loaded: encoder_conv_blocks.4.6.running_var\n",
                        "Loaded: encoder_conv_blocks.4.6.num_batches_tracked\n",
                        "Loaded: fully_connected_blocks.0.0.weight\n",
                        "Loaded: fully_connected_blocks.0.0.bias\n",
                        "Loaded: fully_connected_blocks.1.0.weight\n",
                        "Loaded: fully_connected_blocks.1.0.bias\n",
                        "==========================================================================================\n",
                        "Layer (type:depth-idx)                   Output Shape              Param #\n",
                        "==========================================================================================\n",
                        "AllCNN2D                                 [1, 44]                   --\n",
                        "â”œâ”€ModuleList: 1-1                        --                        --\n",
                        "â”‚    â””â”€Sequential: 2-1                   [1, 16, 32, 32]           --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-2               [1, 16, 64, 64]           --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-3             [1, 16, 64, 64]           32\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-4               [1, 16, 64, 64]           --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-5                  [1, 16, 32, 32]           2,320\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-6               [1, 16, 32, 32]           --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-8               [1, 16, 32, 32]           --\n",
                        "â”‚    â””â”€Sequential: 2-2                   [1, 32, 16, 16]           --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-9                  [1, 32, 32, 32]           4,640\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-10              [1, 32, 32, 32]           --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-11            [1, 32, 32, 32]           64\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-12              [1, 32, 32, 32]           --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-13                 [1, 32, 16, 16]           9,248\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-14              [1, 32, 16, 16]           --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-15            [1, 32, 16, 16]           64\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-16              [1, 32, 16, 16]           --\n",
                        "â”‚    â””â”€Sequential: 2-3                   [1, 32, 8, 8]             --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-17                 [1, 32, 16, 16]           9,248\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-18              [1, 32, 16, 16]           --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-20              [1, 32, 16, 16]           --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-21                 [1, 32, 8, 8]             9,248\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-22              [1, 32, 8, 8]             --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-23            [1, 32, 8, 8]             64\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-24              [1, 32, 8, 8]             --\n",
                        "â”‚    â””â”€Sequential: 2-4                   [1, 32, 4, 4]             --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-25                 [1, 32, 8, 8]             9,248\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-26              [1, 32, 8, 8]             --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-27            [1, 32, 8, 8]             64\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-28              [1, 32, 8, 8]             --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-29                 [1, 32, 4, 4]             9,248\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-30              [1, 32, 4, 4]             --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-31            [1, 32, 4, 4]             64\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-32              [1, 32, 4, 4]             --\n",
                        "â”‚    â””â”€Sequential: 2-5                   [1, 32, 2, 2]             --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-33                 [1, 32, 4, 4]             9,248\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-34              [1, 32, 4, 4]             --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-35            [1, 32, 4, 4]             64\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-36              [1, 32, 4, 4]             --\n",
                        "â”‚    â”‚    â””â”€Conv2d: 3-37                 [1, 32, 2, 2]             9,248\n",
                        "â”‚    â”‚    â””â”€Dropout2d: 3-38              [1, 32, 2, 2]             --\n",
                        "â”‚    â”‚    â””â”€BatchNorm2d: 3-39            [1, 32, 2, 2]             64\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-40              [1, 32, 2, 2]             --\n",
                        "â”œâ”€Sequential: 1-2                        [1, 128]                  --\n",
                        "â”‚    â””â”€Flatten: 2-6                      [1, 128]                  --\n",
                        "â”œâ”€ModuleList: 1-3                        --                        --\n",
                        "â”‚    â””â”€Sequential: 2-7                   [1, 64]                   --\n",
                        "â”‚    â”‚    â””â”€Linear: 3-41                 [1, 64]                   8,256\n",
                        "â”‚    â”‚    â””â”€Dropout: 3-42                [1, 64]                   --\n",
                        "â”‚    â”‚    â””â”€LeakyReLU: 3-43              [1, 64]                   --\n",
                        "â”‚    â””â”€Sequential: 2-8                   [1, 44]                   --\n",
                        "â”‚    â”‚    â””â”€Linear: 3-44                 [1, 44]                   2,860\n",
                        "==========================================================================================\n",
                        "Total params: 83,548\n",
                        "Trainable params: 83,548\n",
                        "Non-trainable params: 0\n",
                        "Total mult-adds (Units.MEGABYTES): 14.05\n",
                        "==========================================================================================\n",
                        "Input size (MB): 0.02\n",
                        "Forward/backward pass size (MB): 2.18\n",
                        "Params size (MB): 0.33\n",
                        "Estimated Total Size (MB): 2.53\n",
                        "==========================================================================================\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\Leon\\AppData\\Local\\Temp\\ipykernel_1824\\2691209791.py:52: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
                        "  torch.tensor([0, 0, 0, 0], device=im.device)  # Default value if no foreground\n",
                        "C:\\Users\\Leon\\AppData\\Local\\Temp\\ipykernel_1824\\2691209791.py:57: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
                        "  torch.tensor([0, 0, im.size(2) - 1, im.size(3) - 1], device=im.device)  # Default value if no foreground\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved to char_model_lamda_calculus.onnx\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "\n",
                "class KrudModel(nn.Module):\n",
                "    \n",
                "    def __init__(\n",
                "        self, \n",
                "        alphabet: list[str], \n",
                "        target_width: int = 64, \n",
                "        target_height: int = 64, \n",
                "        padding: int = 1,\n",
                "        model: torch.nn.Module = None\n",
                "    ):\n",
                "        \n",
                "        super(KrudModel, self).__init__()\n",
                "        \n",
                "        self.alphabet: list[str] = alphabet\n",
                "        self.alphabet_float: torch.Tensor = torch.tensor([ord(a) for a in self.alphabet], dtype=torch.float32) \n",
                "        self.target_width: int = target_width\n",
                "        self.target_height: int = target_height\n",
                "        self.padding: int = padding\n",
                "        self._unpadded_dims: tuple[int] = (\n",
                "            self.target_height-self.padding*2,\n",
                "            self.target_width-self.padding*2\n",
                "        )\n",
                "        self.model: torch.nn.Module = model.eval()\n",
                "    \n",
                "        \n",
                "    def preprocess_image(\n",
                "        self, \n",
                "        im: torch.Tensor\n",
                "    ) -> torch.Tensor:\n",
                "        \"\"\"\n",
                "        Preprocesses the input image by cropping, resizing, binarizing, and padding it.\n",
                "\n",
                "        Args:\n",
                "            im (torch.Tensor): Input image tensor of shape (C, H, W) or (B, C, H, W).\n",
                "\n",
                "        Returns:\n",
                "            torch.Tensor: Preprocessed image tensor.\n",
                "        \"\"\"\n",
                "        # Step 1: Binarize the image (foreground = 0, background = 1)\n",
                "        mask = im > 0.5\n",
                "\n",
                "        # Step 2: Find bounding box coordinates of the foreground\n",
                "        coords = torch.nonzero(mask)  # Get coordinates of non-zero (foreground) pixels\n",
                "\n",
                "        # Step 3: Check if there are any foreground pixels (traceable)\n",
                "        has_foreground = torch.any(mask)\n",
                "\n",
                "        # Step 4: Compute min and max coordinates for cropping (if foreground exists)\n",
                "        min_coords = torch.where(\n",
                "            has_foreground,\n",
                "            coords.min(dim=0)[0],\n",
                "            torch.tensor([0, 0, 0, 0], device=im.device)  # Default value if no foreground\n",
                "        )\n",
                "        max_coords = torch.where(\n",
                "            has_foreground,\n",
                "            coords.max(dim=0)[0],\n",
                "            torch.tensor([0, 0, im.size(2) - 1, im.size(3) - 1], device=im.device)  # Default value if no foreground\n",
                "        )\n",
                "\n",
                "        # Step 5: Extract min and max coordinates for height and width (assuming input is 4D: B, C, H, W)\n",
                "        min_x, min_y = min_coords[2], min_coords[3]\n",
                "        max_x, max_y = max_coords[2], max_coords[3]\n",
                "\n",
                "        # Step 6: Crop the image (use slicing, which is traceable)\n",
                "        im = im[:, :, min_x:max_x + 1, min_y:max_y + 1]\n",
                "\n",
                "        # Step 7: Resize the image to the desired dimensions\n",
                "        im = torch_func.interpolate(\n",
                "            im, \n",
                "            size=self._unpadded_dims, \n",
                "            mode=\"bilinear\", \n",
                "            align_corners=False\n",
                "        )\n",
                "\n",
                "        # Step 8: Binarize the image again (optional, depending on your use case)\n",
                "        im = (im > 0.5).type(torch.uint8).type(torch.float32)\n",
                "\n",
                "        # Step 9: Pad the image\n",
                "        im = torch_func.pad(\n",
                "            im,\n",
                "            (self.padding, self.padding, self.padding, self.padding),\n",
                "            mode='constant',\n",
                "            value=0.0\n",
                "        )\n",
                "\n",
                "        return im\n",
                "    \n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        x = self.preprocess_image(x)\n",
                "        \n",
                "        #plt.imshow(x.squeeze(), cmap=\"gray\")\n",
                "        #plt.show()\n",
                "        \n",
                "        y_hat: torch.Tensor = self.model(x)\n",
                "        y_hat = y_hat.squeeze().squeeze()\n",
                "        \n",
                "        softmax = torch.softmax(y_hat, dim=-1)\n",
                "        \n",
                "        stacked = torch.stack([self.alphabet_float, softmax], dim=1)\n",
                "        sorted_indices = torch.argsort(stacked[:, 1], descending=True)\n",
                "        sorted_tensor = stacked[sorted_indices]\n",
                "\n",
                "        unicodes: torch.Tensor = sorted_tensor[:, 0]\n",
                "        probabilities: torch.Tensor = sorted_tensor[:, 1]\n",
                "\n",
                "        unicodes = unicodes.to(dtype=torch.int)\n",
                "        probabilities = probabilities.detach()\n",
                "\n",
                "        return unicodes.unsqueeze(0), probabilities.unsqueeze(0)\n",
                "        \n",
                "        \n",
                "       \n",
                "\n",
                "label_map: list[str] = ['(', ')', '+', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'Î»', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ã—', 'Ã·']\n",
                "\n",
                "checkpoint_path: str = r\"C:\\Users\\Leon\\visual-studio\\repos\\Le-o-n\\ocr-model-training\\src\\cnn_rnn\\20250423_115805__APL_RNN_FINAL_BEST_V1__Epoch86_tLoss0.03538_tAcc0.53847_vLoss0.04994_vAcc0.53487.pt\"\n",
                "\n",
                "cnn_model: nn.Module = AllCNN2D(\n",
                "    **{\n",
                "        \"conv_features\": (1, 16, 32, 32, 32),\n",
                "        \"fully_connected_features\": (256, 256),\n",
                "        \"expected_input_size\": (64, 64),\n",
                "        \"device\": \"cuda\",\n",
                "        \"conv_dropout\": 0.00,\n",
                "        \"verbose\": True,\n",
                "        \"name_prefix\": \"apl_cnn\",\n",
                "        \"checkpoint_path\": checkpoint_path,\n",
                "        \"frozen_layer_prefixes\": [],\n",
                "        \n",
                "    }\n",
                ")\n",
                "\n",
                "\n",
                "cnn_rnn_model: nn.Module = CNNRNNModel(\n",
                "    cnn_model,\n",
                "    rnn_type=\"rnn\",\n",
                "    rnn_num_layers = 4,\n",
                "    num_classes=len(alphabet)\n",
                ")\n",
                "\n",
                "krud_model: KrudModel = KrudModel(\n",
                "    label_map,\n",
                "    model=model\n",
                ")\n",
                "\n",
                "dummy_input = torch.randn(1, 1, 100, 100)  # Example input\n",
                "\n",
                "# Define the ONNX file path\n",
                "onnx_file_path = \"char_model_lamda_calculus.onnx\"\n",
                "\n",
                "# Export the model\n",
                "torch.onnx.export(\n",
                "    krud_model,\n",
                "    dummy_input,\n",
                "    onnx_file_path,\n",
                "    input_names=[\"input\"],  # Name of the input layer\n",
                "    output_names=[\"unicode\", \"probability\"],  # Names of the output layers\n",
                "    dynamic_axes={\"input\": {2: \"height\", 3: \"width\"}},\n",
                "    opset_version=11  # Specify the ONNX opset version\n",
                ")\n",
                "\n",
                "print(f\"Model saved to {onnx_file_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 139,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(tensor([[ 43, 215, 247,  55, 120, 955, 102, 121, 104, 107,  52, 116, 100,  49,\n",
                            "          122, 109, 113,  57, 114, 118,  53,  56,  97, 119,  45, 110,  51, 112,\n",
                            "          105, 103,  50,  98, 117, 115,  54,  41, 101, 108,  40, 106,  99,  48,\n",
                            "          111,  46]], dtype=torch.int32),\n",
                            " tensor([[9.3858e-01, 5.7565e-02, 1.5453e-03, 1.4862e-03, 5.4839e-04, 1.8937e-04,\n",
                            "          4.8974e-05, 2.8834e-05, 1.5799e-06, 8.6764e-07, 6.3947e-07, 1.6689e-07,\n",
                            "          1.0515e-07, 9.0722e-08, 6.1379e-08, 4.4690e-08, 3.3480e-08, 1.2193e-08,\n",
                            "          3.4486e-09, 9.5328e-10, 3.0586e-10, 1.8158e-10, 1.6832e-10, 7.8394e-11,\n",
                            "          4.7620e-11, 3.2993e-11, 1.9548e-11, 5.6589e-12, 2.6825e-12, 2.6386e-12,\n",
                            "          5.4703e-13, 4.1399e-13, 3.9216e-13, 1.3443e-13, 1.4182e-14, 8.0470e-15,\n",
                            "          4.4367e-15, 6.8224e-16, 3.5865e-16, 1.7180e-17, 1.5004e-17, 1.1964e-17,\n",
                            "          6.5156e-19, 2.4627e-22]]))"
                        ]
                    },
                    "execution_count": 139,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\"\".join(sorted(label_map)), \"\".join(label_map)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_dirpath: str = r\"C:\\Users\\LeonBass\\Documents\\visual_studio_code\\ocr-model-training\\data\\lambda_calc\"\n",
                "for im_filename in os.listdir(dataset_dirpath):\n",
                "    fullpath: str = os.path.join(dataset_dirpath, im_filename)\n",
                "\n",
                "    im = np.asarray(Image.open(fullpath))\n",
                "    \n",
                "    im = (im[:, :, 3] > 0.5).astype(np.uint8).astype(np.float32)\n",
                "    \n",
                "    im_tensor = torch.tensor(im, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
                "\n",
                "    print(chr(int(krud_model.forward(im_tensor)[0, 0].item())))\n",
                "    \n",
                "    plt.imshow(im)\n",
                "    plt.show()\n",
                "\n",
                "    \n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test Krud ONNX"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "metadata": {},
            "outputs": [],
            "source": [
                "from PIL import Image\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt \n",
                "import onnxruntime"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "input_image = Image.open(\"test_im.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 142,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "test_image = np.asarray(input_image)\n",
                "test_image = ((1.0-test_image[:, :, 0]/255) > 0.5).astype(np.uint8)*1.0\n",
                "\n",
                "plt.imshow(test_image, cmap=\"gray\")\n",
                "plt.show()\n",
                "\n",
                "test_image = np.expand_dims(np.expand_dims(test_image, 0), 0)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 143,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(1, 1, 143, 154)"
                        ]
                    },
                    "execution_count": 143,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_image.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
                            "         [0., 0., 0., ..., 0., 0., 0.],\n",
                            "         [0., 0., 0., ..., 0., 0., 0.],\n",
                            "         ...,\n",
                            "         [0., 0., 0., ..., 0., 0., 0.],\n",
                            "         [0., 0., 0., ..., 0., 0., 0.],\n",
                            "         [0., 0., 0., ..., 0., 0., 0.]]]])"
                        ]
                    },
                    "execution_count": 144,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Load the ONNX model\n",
                "model_path = \"char_model_lamda_calculus.onnx\"\n",
                "session = onnxruntime.InferenceSession(model_path)\n",
                "\n",
                "# Run inference\n",
                "inputs: list[onnxruntime.NodeArg] = session.get_inputs()\n",
                "outputs: list[onnxruntime.NodeArg] = session.get_outputs()\n",
                "\n",
                "input_name: str = inputs[0].name            # Only one input \n",
                "output_names: list[str] = [output.name for output in outputs]    # Only one output [unicode, prob] pairs for a single character\n",
                "\n",
                "unicodes: torch.Tensor\n",
                "probabilities: torch.Tensor\n",
                "unicodes, probabilities = session.run(\n",
                "    output_names, \n",
                "    {input_name: test_image.astype(np.float32)} # Must be float32 image of shape (batch, channels, height, width) -> (1, 1, Any, Any)\n",
                ")\n",
                "\n",
                "\n",
                "for char, prob in zip(unicodes[0], probabilities[0]):\n",
                "    print(chr(int(char)), prob)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[array([ 48, 112, 100,  54, 116,  56,  53, 111, 113, 102,  98,  40, 119,\n",
                            "        109, 107, 106, 104, 110,  50,  99, 120, 114, 215,  51,  45,  49,\n",
                            "        118,  57, 103, 122, 105, 101,  41, 115, 117, 121,  55,  97,  46,\n",
                            "         52, 108, 247, 955,  43], dtype=int32),\n",
                            " array([6.8143886e-01, 3.1727558e-01, 9.8913838e-04, 1.6000890e-04,\n",
                            "        5.1013758e-05, 2.8218346e-05, 2.4816827e-05, 8.7805711e-06,\n",
                            "        5.5376886e-06, 3.6561419e-06, 3.0133053e-06, 2.6766511e-06,\n",
                            "        2.4739402e-06, 1.5798223e-06, 1.5708143e-06, 8.6630882e-07,\n",
                            "        6.8614111e-07, 5.5757562e-07, 4.7443012e-07, 3.3036901e-07,\n",
                            "        6.3471326e-08, 2.9459986e-08, 2.2759442e-08, 1.8600712e-08,\n",
                            "        1.8000391e-08, 1.2019766e-08, 3.3489278e-09, 3.0067731e-09,\n",
                            "        2.6663645e-09, 2.0556845e-09, 1.1345208e-09, 3.8724163e-10,\n",
                            "        2.8197075e-10, 1.6642417e-10, 3.9026893e-11, 1.4455865e-11,\n",
                            "        1.0275350e-11, 8.5388979e-12, 2.8815811e-13, 2.1714051e-13,\n",
                            "        4.0094240e-14, 2.7764098e-14, 2.0496294e-15, 9.2305130e-16],\n",
                            "       dtype=float32)]"
                        ]
                    },
                    "execution_count": 68,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model_outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "tuple indices must be integers or slices, not tuple",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mkrud_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      3\u001b[0m [\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;28mint\u001b[39m(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m preds]\n",
                        "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
                    ]
                }
            ],
            "source": [
                "preds = krud_model.eval().forward(torch.tensor(test_image.astype(np.float32)))[:, 0].tolist()\n",
                "\n",
                "[chr(int(x)) for x in preds]"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
